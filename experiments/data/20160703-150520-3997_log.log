I0703 15:05:22.500262 14543 caffe.cpp:192] Using GPUs 0
I0703 15:05:22.833235 14543 solver.cpp:54] Initializing solver from parameters:
test_iter: 130
test_interval: 441
base_lr: 0.01
display: 55
max_iter: 44100
lr_policy: "exp"
gamma: 0.99985969
momentum: 0.9
weight_decay: 0.0001
snapshot: 4410
snapshot_prefix: "snapshot"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
solver_type: SGD
iter_size: 1
I0703 15:05:22.833703 14543 solver.cpp:97] Creating training net from net file: train_val.prototxt
I0703 15:05:22.834286 14543 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0703 15:05:22.834295 14543 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer label
I0703 15:05:22.834303 14543 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0703 15:05:22.834408 14543 net.cpp:52] Initializing net from parameters:
state {
phase: TRAIN
}
layer {
name: "data"
type: "Data"
top: "data"
include {
phase: TRAIN
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/train/a1_m0_s1_f2/lmdb_data"
batch_size: 64
backend: LMDB
}
}
layer {
name: "label"
type: "Data"
top: "label"
include {
phase: TRAIN
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/train/a1_m0_s1_f2/lmdb_labels"
batch_size: 64
backend: LMDB
}
}
layer {
name: "conv1"
type: "Convolution"
bottom: "data"
top: "conv1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 11
stride: 4
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu1"
type: "ReLU"
bottom: "conv1"
top: "conv1"
}
layer {
name: "norm1"
type: "LRN"
bottom: "conv1"
top: "norm1"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool1"
type: "Pooling"
bottom: "norm1"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv2"
type: "Convolution"
bottom: "pool1"
top: "conv2"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 2
kernel_size: 5
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu2"
type: "ReLU"
bottom: "conv2"
top: "conv2"
}
layer {
name: "norm2"
type: "LRN"
bottom: "conv2"
top: "norm2"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool2"
type: "Pooling"
bottom: "norm2"
top: "pool2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool2"
top: "conv3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "conv4"
type: "Convolution"
bottom: "conv3"
top: "conv4"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu4"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "conv5"
type: "Convolution"
bottom: "conv4"
top: "conv5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
group: 1
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "conv5"
top: "conv5"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "conv5"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fc6"
type: "InnerProduct"
bottom: "pool5"
top: "fc6"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "fc6"
top: "fc6"
}
layer {
name: "drop6"
type: "Dropout"
bottom: "fc6"
top: "fc6"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc7"
type: "InnerProduct"
bottom: "fc6"
top: "fc7"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "fc7"
top: "fc7"
}
layer {
name: "drop7"
type: "Dropout"
bottom: "fc7"
top: "fc7"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc8_species"
type: "InnerProduct"
bottom: "fc7"
top: "fc8_species"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 967
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "fc8_species"
bottom: "label"
top: "loss"
}
I0703 15:05:22.834470 14543 layer_factory.hpp:76] Creating layer data
I0703 15:05:22.837265 14543 net.cpp:109] Creating Layer data
I0703 15:05:22.837273 14543 net.cpp:414] data -> data
I0703 15:05:22.838609 14555 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/train/a1_m0_s1_f2/lmdb_data
I0703 15:05:22.839079 14543 data_layer.cpp:45] output data size: 64,3,224,224
I0703 15:05:22.893026 14543 net.cpp:153] Setting up data
I0703 15:05:22.893054 14543 net.cpp:160] Top shape: 64 3 224 224 (9633792)
I0703 15:05:22.893056 14543 net.cpp:168] Memory required for data: 38535168
I0703 15:05:22.893064 14543 layer_factory.hpp:76] Creating layer label
I0703 15:05:22.893133 14543 net.cpp:109] Creating Layer label
I0703 15:05:22.893148 14543 net.cpp:414] label -> label
I0703 15:05:22.897804 14557 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/train/a1_m0_s1_f2/lmdb_labels
I0703 15:05:22.897899 14543 data_layer.cpp:45] output data size: 64,1,1,1
I0703 15:05:22.897999 14543 net.cpp:153] Setting up label
I0703 15:05:22.898005 14543 net.cpp:160] Top shape: 64 1 1 1 (64)
I0703 15:05:22.898007 14543 net.cpp:168] Memory required for data: 38535424
I0703 15:05:22.898010 14543 layer_factory.hpp:76] Creating layer conv1
I0703 15:05:22.898018 14543 net.cpp:109] Creating Layer conv1
I0703 15:05:22.898031 14543 net.cpp:457] conv1 <- data
I0703 15:05:22.898039 14543 net.cpp:414] conv1 -> conv1
I0703 15:05:22.900179 14543 net.cpp:153] Setting up conv1
I0703 15:05:22.900192 14543 net.cpp:160] Top shape: 64 96 54 54 (17915904)
I0703 15:05:22.900194 14543 net.cpp:168] Memory required for data: 110199040
I0703 15:05:22.900203 14543 layer_factory.hpp:76] Creating layer relu1
I0703 15:05:22.900209 14543 net.cpp:109] Creating Layer relu1
I0703 15:05:22.900213 14543 net.cpp:457] relu1 <- conv1
I0703 15:05:22.900215 14543 net.cpp:400] relu1 -> conv1 (in-place)
I0703 15:05:22.900226 14543 net.cpp:153] Setting up relu1
I0703 15:05:22.900229 14543 net.cpp:160] Top shape: 64 96 54 54 (17915904)
I0703 15:05:22.900231 14543 net.cpp:168] Memory required for data: 181862656
I0703 15:05:22.900233 14543 layer_factory.hpp:76] Creating layer norm1
I0703 15:05:22.900398 14543 net.cpp:109] Creating Layer norm1
I0703 15:05:22.900415 14543 net.cpp:457] norm1 <- conv1
I0703 15:05:22.900418 14543 net.cpp:414] norm1 -> norm1
I0703 15:05:22.900454 14543 net.cpp:153] Setting up norm1
I0703 15:05:22.900457 14543 net.cpp:160] Top shape: 64 96 54 54 (17915904)
I0703 15:05:22.900459 14543 net.cpp:168] Memory required for data: 253526272
I0703 15:05:22.900460 14543 layer_factory.hpp:76] Creating layer pool1
I0703 15:05:22.900465 14543 net.cpp:109] Creating Layer pool1
I0703 15:05:22.900467 14543 net.cpp:457] pool1 <- norm1
I0703 15:05:22.900470 14543 net.cpp:414] pool1 -> pool1
I0703 15:05:22.900490 14543 net.cpp:153] Setting up pool1
I0703 15:05:22.900493 14543 net.cpp:160] Top shape: 64 96 27 27 (4478976)
I0703 15:05:22.900496 14543 net.cpp:168] Memory required for data: 271442176
I0703 15:05:22.900497 14543 layer_factory.hpp:76] Creating layer conv2
I0703 15:05:22.900501 14543 net.cpp:109] Creating Layer conv2
I0703 15:05:22.900503 14543 net.cpp:457] conv2 <- pool1
I0703 15:05:22.900506 14543 net.cpp:414] conv2 -> conv2
I0703 15:05:22.907487 14543 net.cpp:153] Setting up conv2
I0703 15:05:22.907505 14543 net.cpp:160] Top shape: 64 256 27 27 (11943936)
I0703 15:05:22.907507 14543 net.cpp:168] Memory required for data: 319217920
I0703 15:05:22.907516 14543 layer_factory.hpp:76] Creating layer relu2
I0703 15:05:22.907524 14543 net.cpp:109] Creating Layer relu2
I0703 15:05:22.907527 14543 net.cpp:457] relu2 <- conv2
I0703 15:05:22.907531 14543 net.cpp:400] relu2 -> conv2 (in-place)
I0703 15:05:22.907538 14543 net.cpp:153] Setting up relu2
I0703 15:05:22.907541 14543 net.cpp:160] Top shape: 64 256 27 27 (11943936)
I0703 15:05:22.907543 14543 net.cpp:168] Memory required for data: 366993664
I0703 15:05:22.907546 14543 layer_factory.hpp:76] Creating layer norm2
I0703 15:05:22.907552 14543 net.cpp:109] Creating Layer norm2
I0703 15:05:22.907553 14543 net.cpp:457] norm2 <- conv2
I0703 15:05:22.907557 14543 net.cpp:414] norm2 -> norm2
I0703 15:05:22.907585 14543 net.cpp:153] Setting up norm2
I0703 15:05:22.907589 14543 net.cpp:160] Top shape: 64 256 27 27 (11943936)
I0703 15:05:22.907591 14543 net.cpp:168] Memory required for data: 414769408
I0703 15:05:22.907593 14543 layer_factory.hpp:76] Creating layer pool2
I0703 15:05:22.907598 14543 net.cpp:109] Creating Layer pool2
I0703 15:05:22.907599 14543 net.cpp:457] pool2 <- norm2
I0703 15:05:22.907603 14543 net.cpp:414] pool2 -> pool2
I0703 15:05:22.907624 14543 net.cpp:153] Setting up pool2
I0703 15:05:22.907626 14543 net.cpp:160] Top shape: 64 256 13 13 (2768896)
I0703 15:05:22.907629 14543 net.cpp:168] Memory required for data: 425844992
I0703 15:05:22.907630 14543 layer_factory.hpp:76] Creating layer conv3
I0703 15:05:22.907635 14543 net.cpp:109] Creating Layer conv3
I0703 15:05:22.907637 14543 net.cpp:457] conv3 <- pool2
I0703 15:05:22.907640 14543 net.cpp:414] conv3 -> conv3
I0703 15:05:22.925300 14543 net.cpp:153] Setting up conv3
I0703 15:05:22.925319 14543 net.cpp:160] Top shape: 64 384 13 13 (4153344)
I0703 15:05:22.925323 14543 net.cpp:168] Memory required for data: 442458368
I0703 15:05:22.925330 14543 layer_factory.hpp:76] Creating layer relu3
I0703 15:05:22.925338 14543 net.cpp:109] Creating Layer relu3
I0703 15:05:22.925341 14543 net.cpp:457] relu3 <- conv3
I0703 15:05:22.925345 14543 net.cpp:400] relu3 -> conv3 (in-place)
I0703 15:05:22.925353 14543 net.cpp:153] Setting up relu3
I0703 15:05:22.925354 14543 net.cpp:160] Top shape: 64 384 13 13 (4153344)
I0703 15:05:22.925356 14543 net.cpp:168] Memory required for data: 459071744
I0703 15:05:22.925359 14543 layer_factory.hpp:76] Creating layer conv4
I0703 15:05:22.925364 14543 net.cpp:109] Creating Layer conv4
I0703 15:05:22.925366 14543 net.cpp:457] conv4 <- conv3
I0703 15:05:22.925370 14543 net.cpp:414] conv4 -> conv4
I0703 15:05:22.938622 14543 net.cpp:153] Setting up conv4
I0703 15:05:22.938642 14543 net.cpp:160] Top shape: 64 384 13 13 (4153344)
I0703 15:05:22.938644 14543 net.cpp:168] Memory required for data: 475685120
I0703 15:05:22.938649 14543 layer_factory.hpp:76] Creating layer relu4
I0703 15:05:22.938657 14543 net.cpp:109] Creating Layer relu4
I0703 15:05:22.938679 14543 net.cpp:457] relu4 <- conv4
I0703 15:05:22.938684 14543 net.cpp:400] relu4 -> conv4 (in-place)
I0703 15:05:22.938690 14543 net.cpp:153] Setting up relu4
I0703 15:05:22.938694 14543 net.cpp:160] Top shape: 64 384 13 13 (4153344)
I0703 15:05:22.938695 14543 net.cpp:168] Memory required for data: 492298496
I0703 15:05:22.938697 14543 layer_factory.hpp:76] Creating layer conv5
I0703 15:05:22.938704 14543 net.cpp:109] Creating Layer conv5
I0703 15:05:22.938705 14543 net.cpp:457] conv5 <- conv4
I0703 15:05:22.938709 14543 net.cpp:414] conv5 -> conv5
I0703 15:05:22.956274 14543 net.cpp:153] Setting up conv5
I0703 15:05:22.956291 14543 net.cpp:160] Top shape: 64 256 13 13 (2768896)
I0703 15:05:22.956293 14543 net.cpp:168] Memory required for data: 503374080
I0703 15:05:22.956301 14543 layer_factory.hpp:76] Creating layer relu5
I0703 15:05:22.956307 14543 net.cpp:109] Creating Layer relu5
I0703 15:05:22.956310 14543 net.cpp:457] relu5 <- conv5
I0703 15:05:22.956313 14543 net.cpp:400] relu5 -> conv5 (in-place)
I0703 15:05:22.956320 14543 net.cpp:153] Setting up relu5
I0703 15:05:22.956321 14543 net.cpp:160] Top shape: 64 256 13 13 (2768896)
I0703 15:05:22.956323 14543 net.cpp:168] Memory required for data: 514449664
I0703 15:05:22.956326 14543 layer_factory.hpp:76] Creating layer pool5
I0703 15:05:22.956331 14543 net.cpp:109] Creating Layer pool5
I0703 15:05:22.956332 14543 net.cpp:457] pool5 <- conv5
I0703 15:05:22.956334 14543 net.cpp:414] pool5 -> pool5
I0703 15:05:22.956357 14543 net.cpp:153] Setting up pool5
I0703 15:05:22.956359 14543 net.cpp:160] Top shape: 64 256 6 6 (589824)
I0703 15:05:22.956362 14543 net.cpp:168] Memory required for data: 516808960
I0703 15:05:22.956363 14543 layer_factory.hpp:76] Creating layer fc6
I0703 15:05:22.956368 14543 net.cpp:109] Creating Layer fc6
I0703 15:05:22.956370 14543 net.cpp:457] fc6 <- pool5
I0703 15:05:22.956372 14543 net.cpp:414] fc6 -> fc6
I0703 15:05:23.645107 14543 net.cpp:153] Setting up fc6
I0703 15:05:23.645126 14543 net.cpp:160] Top shape: 64 4096 (262144)
I0703 15:05:23.645129 14543 net.cpp:168] Memory required for data: 517857536
I0703 15:05:23.645135 14543 layer_factory.hpp:76] Creating layer relu6
I0703 15:05:23.645143 14543 net.cpp:109] Creating Layer relu6
I0703 15:05:23.645145 14543 net.cpp:457] relu6 <- fc6
I0703 15:05:23.645149 14543 net.cpp:400] relu6 -> fc6 (in-place)
I0703 15:05:23.645156 14543 net.cpp:153] Setting up relu6
I0703 15:05:23.645159 14543 net.cpp:160] Top shape: 64 4096 (262144)
I0703 15:05:23.645160 14543 net.cpp:168] Memory required for data: 518906112
I0703 15:05:23.645162 14543 layer_factory.hpp:76] Creating layer drop6
I0703 15:05:23.646968 14543 net.cpp:109] Creating Layer drop6
I0703 15:05:23.646975 14543 net.cpp:457] drop6 <- fc6
I0703 15:05:23.646977 14543 net.cpp:400] drop6 -> fc6 (in-place)
I0703 15:05:23.647002 14543 net.cpp:153] Setting up drop6
I0703 15:05:23.647006 14543 net.cpp:160] Top shape: 64 4096 (262144)
I0703 15:05:23.647007 14543 net.cpp:168] Memory required for data: 519954688
I0703 15:05:23.647011 14543 layer_factory.hpp:76] Creating layer fc7
I0703 15:05:23.647014 14543 net.cpp:109] Creating Layer fc7
I0703 15:05:23.647017 14543 net.cpp:457] fc7 <- fc6
I0703 15:05:23.647019 14543 net.cpp:414] fc7 -> fc7
I0703 15:05:23.985397 14543 net.cpp:153] Setting up fc7
I0703 15:05:23.985415 14543 net.cpp:160] Top shape: 64 4096 (262144)
I0703 15:05:23.985419 14543 net.cpp:168] Memory required for data: 521003264
I0703 15:05:23.985424 14543 layer_factory.hpp:76] Creating layer relu7
I0703 15:05:23.985430 14543 net.cpp:109] Creating Layer relu7
I0703 15:05:23.985435 14543 net.cpp:457] relu7 <- fc7
I0703 15:05:23.985438 14543 net.cpp:400] relu7 -> fc7 (in-place)
I0703 15:05:23.985445 14543 net.cpp:153] Setting up relu7
I0703 15:05:23.985447 14543 net.cpp:160] Top shape: 64 4096 (262144)
I0703 15:05:23.985450 14543 net.cpp:168] Memory required for data: 522051840
I0703 15:05:23.985451 14543 layer_factory.hpp:76] Creating layer drop7
I0703 15:05:23.985455 14543 net.cpp:109] Creating Layer drop7
I0703 15:05:23.985476 14543 net.cpp:457] drop7 <- fc7
I0703 15:05:23.985479 14543 net.cpp:400] drop7 -> fc7 (in-place)
I0703 15:05:23.985497 14543 net.cpp:153] Setting up drop7
I0703 15:05:23.985501 14543 net.cpp:160] Top shape: 64 4096 (262144)
I0703 15:05:23.985502 14543 net.cpp:168] Memory required for data: 523100416
I0703 15:05:23.985504 14543 layer_factory.hpp:76] Creating layer fc8_species
I0703 15:05:23.985508 14543 net.cpp:109] Creating Layer fc8_species
I0703 15:05:23.985510 14543 net.cpp:457] fc8_species <- fc7
I0703 15:05:23.985513 14543 net.cpp:414] fc8_species -> fc8_species
I0703 15:05:24.070500 14543 net.cpp:153] Setting up fc8_species
I0703 15:05:24.070518 14543 net.cpp:160] Top shape: 64 967 (61888)
I0703 15:05:24.070521 14543 net.cpp:168] Memory required for data: 523347968
I0703 15:05:24.070528 14543 layer_factory.hpp:76] Creating layer loss
I0703 15:05:24.072232 14543 net.cpp:109] Creating Layer loss
I0703 15:05:24.072238 14543 net.cpp:457] loss <- fc8_species
I0703 15:05:24.072242 14543 net.cpp:457] loss <- label
I0703 15:05:24.072245 14543 net.cpp:414] loss -> loss
I0703 15:05:24.072252 14543 layer_factory.hpp:76] Creating layer loss
I0703 15:05:24.072366 14543 net.cpp:153] Setting up loss
I0703 15:05:24.072371 14543 net.cpp:160] Top shape: (1)
I0703 15:05:24.072373 14543 net.cpp:163]     with loss weight 1
I0703 15:05:24.072388 14543 net.cpp:168] Memory required for data: 523347972
I0703 15:05:24.072391 14543 net.cpp:229] loss needs backward computation.
I0703 15:05:24.072392 14543 net.cpp:229] fc8_species needs backward computation.
I0703 15:05:24.072394 14543 net.cpp:229] drop7 needs backward computation.
I0703 15:05:24.072397 14543 net.cpp:229] relu7 needs backward computation.
I0703 15:05:24.072399 14543 net.cpp:229] fc7 needs backward computation.
I0703 15:05:24.072402 14543 net.cpp:229] drop6 needs backward computation.
I0703 15:05:24.072403 14543 net.cpp:229] relu6 needs backward computation.
I0703 15:05:24.072405 14543 net.cpp:229] fc6 needs backward computation.
I0703 15:05:24.072407 14543 net.cpp:229] pool5 needs backward computation.
I0703 15:05:24.072409 14543 net.cpp:229] relu5 needs backward computation.
I0703 15:05:24.072412 14543 net.cpp:229] conv5 needs backward computation.
I0703 15:05:24.072413 14543 net.cpp:229] relu4 needs backward computation.
I0703 15:05:24.072415 14543 net.cpp:229] conv4 needs backward computation.
I0703 15:05:24.072417 14543 net.cpp:229] relu3 needs backward computation.
I0703 15:05:24.072419 14543 net.cpp:229] conv3 needs backward computation.
I0703 15:05:24.072422 14543 net.cpp:229] pool2 needs backward computation.
I0703 15:05:24.072424 14543 net.cpp:229] norm2 needs backward computation.
I0703 15:05:24.072427 14543 net.cpp:229] relu2 needs backward computation.
I0703 15:05:24.072428 14543 net.cpp:229] conv2 needs backward computation.
I0703 15:05:24.072430 14543 net.cpp:229] pool1 needs backward computation.
I0703 15:05:24.072432 14543 net.cpp:229] norm1 needs backward computation.
I0703 15:05:24.072434 14543 net.cpp:229] relu1 needs backward computation.
I0703 15:05:24.072437 14543 net.cpp:229] conv1 needs backward computation.
I0703 15:05:24.072438 14543 net.cpp:231] label does not need backward computation.
I0703 15:05:24.072440 14543 net.cpp:231] data does not need backward computation.
I0703 15:05:24.072443 14543 net.cpp:273] This network produces output loss
I0703 15:05:24.072451 14543 net.cpp:286] Network initialization done.
I0703 15:05:24.073246 14543 solver.cpp:187] Creating test net (#0) specified by net file: train_val.prototxt
I0703 15:05:24.073288 14543 net.cpp:325] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0703 15:05:24.073292 14543 net.cpp:325] The NetState phase (1) differed from the phase (0) specified by a rule in layer label
I0703 15:05:24.073402 14543 net.cpp:52] Initializing net from parameters:
state {
phase: TEST
}
layer {
name: "data"
type: "Data"
top: "data"
include {
phase: TEST
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/test/a1_m0_s1_f2/lmdb_data"
batch_size: 64
backend: LMDB
}
}
layer {
name: "label"
type: "Data"
top: "label"
include {
phase: TEST
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/test/a1_m0_s1_f2/lmdb_labels"
batch_size: 64
backend: LMDB
}
}
layer {
name: "conv1"
type: "Convolution"
bottom: "data"
top: "conv1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 11
stride: 4
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu1"
type: "ReLU"
bottom: "conv1"
top: "conv1"
}
layer {
name: "norm1"
type: "LRN"
bottom: "conv1"
top: "norm1"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool1"
type: "Pooling"
bottom: "norm1"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv2"
type: "Convolution"
bottom: "pool1"
top: "conv2"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 2
kernel_size: 5
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu2"
type: "ReLU"
bottom: "conv2"
top: "conv2"
}
layer {
name: "norm2"
type: "LRN"
bottom: "conv2"
top: "norm2"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool2"
type: "Pooling"
bottom: "norm2"
top: "pool2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool2"
top: "conv3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "conv4"
type: "Convolution"
bottom: "conv3"
top: "conv4"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu4"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "conv5"
type: "Convolution"
bottom: "conv4"
top: "conv5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
group: 1
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "conv5"
top: "conv5"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "conv5"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fc6"
type: "InnerProduct"
bottom: "pool5"
top: "fc6"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "fc6"
top: "fc6"
}
layer {
name: "drop6"
type: "Dropout"
bottom: "fc6"
top: "fc6"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc7"
type: "InnerProduct"
bottom: "fc6"
top: "fc7"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "fc7"
top: "fc7"
}
layer {
name: "drop7"
type: "Dropout"
bottom: "fc7"
top: "fc7"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc8_species"
type: "InnerProduct"
bottom: "fc7"
top: "fc8_species"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 967
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "fc8_species"
bottom: "label"
top: "loss"
}
layer {
name: "accuracy"
type: "Accuracy"
bottom: "fc8_species"
bottom: "label"
top: "accuracy"
include {
phase: TEST
}
}
I0703 15:05:24.073484 14543 layer_factory.hpp:76] Creating layer data
I0703 15:05:24.073549 14543 net.cpp:109] Creating Layer data
I0703 15:05:24.073554 14543 net.cpp:414] data -> data
I0703 15:05:24.074383 14561 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/test/a1_m0_s1_f2/lmdb_data
I0703 15:05:24.074573 14543 data_layer.cpp:45] output data size: 64,3,224,224
I0703 15:05:24.132454 14543 net.cpp:153] Setting up data
I0703 15:05:24.132475 14543 net.cpp:160] Top shape: 64 3 224 224 (9633792)
I0703 15:05:24.132478 14543 net.cpp:168] Memory required for data: 38535168
I0703 15:05:24.132483 14543 layer_factory.hpp:76] Creating layer label
I0703 15:05:24.132545 14543 net.cpp:109] Creating Layer label
I0703 15:05:24.132561 14543 net.cpp:414] label -> label
I0703 15:05:24.134037 14563 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/test/a1_m0_s1_f2/lmdb_labels
I0703 15:05:24.137029 14543 data_layer.cpp:45] output data size: 64,1,1,1
I0703 15:05:24.137939 14543 net.cpp:153] Setting up label
I0703 15:05:24.137948 14543 net.cpp:160] Top shape: 64 1 1 1 (64)
I0703 15:05:24.137950 14543 net.cpp:168] Memory required for data: 38535424
I0703 15:05:24.137953 14543 layer_factory.hpp:76] Creating layer label_label_0_split
I0703 15:05:24.137969 14543 net.cpp:109] Creating Layer label_label_0_split
I0703 15:05:24.137970 14543 net.cpp:457] label_label_0_split <- label
I0703 15:05:24.137974 14543 net.cpp:414] label_label_0_split -> label_label_0_split_0
I0703 15:05:24.137979 14543 net.cpp:414] label_label_0_split -> label_label_0_split_1
I0703 15:05:24.138043 14543 net.cpp:153] Setting up label_label_0_split
I0703 15:05:24.138049 14543 net.cpp:160] Top shape: 64 1 1 1 (64)
I0703 15:05:24.138051 14543 net.cpp:160] Top shape: 64 1 1 1 (64)
I0703 15:05:24.138053 14543 net.cpp:168] Memory required for data: 38535936
I0703 15:05:24.138056 14543 layer_factory.hpp:76] Creating layer conv1
I0703 15:05:24.138062 14543 net.cpp:109] Creating Layer conv1
I0703 15:05:24.138063 14543 net.cpp:457] conv1 <- data
I0703 15:05:24.138067 14543 net.cpp:414] conv1 -> conv1
I0703 15:05:24.138926 14543 net.cpp:153] Setting up conv1
I0703 15:05:24.138931 14543 net.cpp:160] Top shape: 64 96 54 54 (17915904)
I0703 15:05:24.138933 14543 net.cpp:168] Memory required for data: 110199552
I0703 15:05:24.138941 14543 layer_factory.hpp:76] Creating layer relu1
I0703 15:05:24.138945 14543 net.cpp:109] Creating Layer relu1
I0703 15:05:24.138948 14543 net.cpp:457] relu1 <- conv1
I0703 15:05:24.138952 14543 net.cpp:400] relu1 -> conv1 (in-place)
I0703 15:05:24.138957 14543 net.cpp:153] Setting up relu1
I0703 15:05:24.138959 14543 net.cpp:160] Top shape: 64 96 54 54 (17915904)
I0703 15:05:24.138962 14543 net.cpp:168] Memory required for data: 181863168
I0703 15:05:24.138963 14543 layer_factory.hpp:76] Creating layer norm1
I0703 15:05:24.138968 14543 net.cpp:109] Creating Layer norm1
I0703 15:05:24.138970 14543 net.cpp:457] norm1 <- conv1
I0703 15:05:24.138972 14543 net.cpp:414] norm1 -> norm1
I0703 15:05:24.138995 14543 net.cpp:153] Setting up norm1
I0703 15:05:24.138998 14543 net.cpp:160] Top shape: 64 96 54 54 (17915904)
I0703 15:05:24.139015 14543 net.cpp:168] Memory required for data: 253526784
I0703 15:05:24.139017 14543 layer_factory.hpp:76] Creating layer pool1
I0703 15:05:24.139022 14543 net.cpp:109] Creating Layer pool1
I0703 15:05:24.139024 14543 net.cpp:457] pool1 <- norm1
I0703 15:05:24.139026 14543 net.cpp:414] pool1 -> pool1
I0703 15:05:24.139048 14543 net.cpp:153] Setting up pool1
I0703 15:05:24.139052 14543 net.cpp:160] Top shape: 64 96 27 27 (4478976)
I0703 15:05:24.139053 14543 net.cpp:168] Memory required for data: 271442688
I0703 15:05:24.139055 14543 layer_factory.hpp:76] Creating layer conv2
I0703 15:05:24.139060 14543 net.cpp:109] Creating Layer conv2
I0703 15:05:24.139062 14543 net.cpp:457] conv2 <- pool1
I0703 15:05:24.139065 14543 net.cpp:414] conv2 -> conv2
I0703 15:05:24.145289 14543 net.cpp:153] Setting up conv2
I0703 15:05:24.145306 14543 net.cpp:160] Top shape: 64 256 27 27 (11943936)
I0703 15:05:24.145310 14543 net.cpp:168] Memory required for data: 319218432
I0703 15:05:24.145318 14543 layer_factory.hpp:76] Creating layer relu2
I0703 15:05:24.145326 14543 net.cpp:109] Creating Layer relu2
I0703 15:05:24.145330 14543 net.cpp:457] relu2 <- conv2
I0703 15:05:24.145334 14543 net.cpp:400] relu2 -> conv2 (in-place)
I0703 15:05:24.145339 14543 net.cpp:153] Setting up relu2
I0703 15:05:24.145344 14543 net.cpp:160] Top shape: 64 256 27 27 (11943936)
I0703 15:05:24.145345 14543 net.cpp:168] Memory required for data: 366994176
I0703 15:05:24.145347 14543 layer_factory.hpp:76] Creating layer norm2
I0703 15:05:24.145352 14543 net.cpp:109] Creating Layer norm2
I0703 15:05:24.145355 14543 net.cpp:457] norm2 <- conv2
I0703 15:05:24.145359 14543 net.cpp:414] norm2 -> norm2
I0703 15:05:24.145386 14543 net.cpp:153] Setting up norm2
I0703 15:05:24.145391 14543 net.cpp:160] Top shape: 64 256 27 27 (11943936)
I0703 15:05:24.145393 14543 net.cpp:168] Memory required for data: 414769920
I0703 15:05:24.145395 14543 layer_factory.hpp:76] Creating layer pool2
I0703 15:05:24.145400 14543 net.cpp:109] Creating Layer pool2
I0703 15:05:24.145402 14543 net.cpp:457] pool2 <- norm2
I0703 15:05:24.145404 14543 net.cpp:414] pool2 -> pool2
I0703 15:05:24.145423 14543 net.cpp:153] Setting up pool2
I0703 15:05:24.145426 14543 net.cpp:160] Top shape: 64 256 13 13 (2768896)
I0703 15:05:24.145428 14543 net.cpp:168] Memory required for data: 425845504
I0703 15:05:24.145429 14543 layer_factory.hpp:76] Creating layer conv3
I0703 15:05:24.145434 14543 net.cpp:109] Creating Layer conv3
I0703 15:05:24.145437 14543 net.cpp:457] conv3 <- pool2
I0703 15:05:24.145440 14543 net.cpp:414] conv3 -> conv3
I0703 15:05:24.162498 14543 net.cpp:153] Setting up conv3
I0703 15:05:24.162515 14543 net.cpp:160] Top shape: 64 384 13 13 (4153344)
I0703 15:05:24.162518 14543 net.cpp:168] Memory required for data: 442458880
I0703 15:05:24.162528 14543 layer_factory.hpp:76] Creating layer relu3
I0703 15:05:24.162536 14543 net.cpp:109] Creating Layer relu3
I0703 15:05:24.162539 14543 net.cpp:457] relu3 <- conv3
I0703 15:05:24.162544 14543 net.cpp:400] relu3 -> conv3 (in-place)
I0703 15:05:24.162550 14543 net.cpp:153] Setting up relu3
I0703 15:05:24.162554 14543 net.cpp:160] Top shape: 64 384 13 13 (4153344)
I0703 15:05:24.162556 14543 net.cpp:168] Memory required for data: 459072256
I0703 15:05:24.162559 14543 layer_factory.hpp:76] Creating layer conv4
I0703 15:05:24.162564 14543 net.cpp:109] Creating Layer conv4
I0703 15:05:24.162566 14543 net.cpp:457] conv4 <- conv3
I0703 15:05:24.162569 14543 net.cpp:414] conv4 -> conv4
I0703 15:05:24.175406 14543 net.cpp:153] Setting up conv4
I0703 15:05:24.175425 14543 net.cpp:160] Top shape: 64 384 13 13 (4153344)
I0703 15:05:24.175427 14543 net.cpp:168] Memory required for data: 475685632
I0703 15:05:24.175432 14543 layer_factory.hpp:76] Creating layer relu4
I0703 15:05:24.175438 14543 net.cpp:109] Creating Layer relu4
I0703 15:05:24.175441 14543 net.cpp:457] relu4 <- conv4
I0703 15:05:24.175444 14543 net.cpp:400] relu4 -> conv4 (in-place)
I0703 15:05:24.175451 14543 net.cpp:153] Setting up relu4
I0703 15:05:24.175453 14543 net.cpp:160] Top shape: 64 384 13 13 (4153344)
I0703 15:05:24.175472 14543 net.cpp:168] Memory required for data: 492299008
I0703 15:05:24.175474 14543 layer_factory.hpp:76] Creating layer conv5
I0703 15:05:24.175480 14543 net.cpp:109] Creating Layer conv5
I0703 15:05:24.175482 14543 net.cpp:457] conv5 <- conv4
I0703 15:05:24.175485 14543 net.cpp:414] conv5 -> conv5
I0703 15:05:24.192776 14543 net.cpp:153] Setting up conv5
I0703 15:05:24.192803 14543 net.cpp:160] Top shape: 64 256 13 13 (2768896)
I0703 15:05:24.192806 14543 net.cpp:168] Memory required for data: 503374592
I0703 15:05:24.192813 14543 layer_factory.hpp:76] Creating layer relu5
I0703 15:05:24.192821 14543 net.cpp:109] Creating Layer relu5
I0703 15:05:24.192824 14543 net.cpp:457] relu5 <- conv5
I0703 15:05:24.192837 14543 net.cpp:400] relu5 -> conv5 (in-place)
I0703 15:05:24.192843 14543 net.cpp:153] Setting up relu5
I0703 15:05:24.192847 14543 net.cpp:160] Top shape: 64 256 13 13 (2768896)
I0703 15:05:24.192847 14543 net.cpp:168] Memory required for data: 514450176
I0703 15:05:24.192849 14543 layer_factory.hpp:76] Creating layer pool5
I0703 15:05:24.192853 14543 net.cpp:109] Creating Layer pool5
I0703 15:05:24.192855 14543 net.cpp:457] pool5 <- conv5
I0703 15:05:24.192858 14543 net.cpp:414] pool5 -> pool5
I0703 15:05:24.192883 14543 net.cpp:153] Setting up pool5
I0703 15:05:24.192885 14543 net.cpp:160] Top shape: 64 256 6 6 (589824)
I0703 15:05:24.192886 14543 net.cpp:168] Memory required for data: 516809472
I0703 15:05:24.192888 14543 layer_factory.hpp:76] Creating layer fc6
I0703 15:05:24.192893 14543 net.cpp:109] Creating Layer fc6
I0703 15:05:24.192894 14543 net.cpp:457] fc6 <- pool5
I0703 15:05:24.192898 14543 net.cpp:414] fc6 -> fc6
I0703 15:05:24.885078 14543 net.cpp:153] Setting up fc6
I0703 15:05:24.885098 14543 net.cpp:160] Top shape: 64 4096 (262144)
I0703 15:05:24.885102 14543 net.cpp:168] Memory required for data: 517858048
I0703 15:05:24.885107 14543 layer_factory.hpp:76] Creating layer relu6
I0703 15:05:24.885113 14543 net.cpp:109] Creating Layer relu6
I0703 15:05:24.885116 14543 net.cpp:457] relu6 <- fc6
I0703 15:05:24.885119 14543 net.cpp:400] relu6 -> fc6 (in-place)
I0703 15:05:24.885126 14543 net.cpp:153] Setting up relu6
I0703 15:05:24.885128 14543 net.cpp:160] Top shape: 64 4096 (262144)
I0703 15:05:24.885129 14543 net.cpp:168] Memory required for data: 518906624
I0703 15:05:24.885131 14543 layer_factory.hpp:76] Creating layer drop6
I0703 15:05:24.885135 14543 net.cpp:109] Creating Layer drop6
I0703 15:05:24.885138 14543 net.cpp:457] drop6 <- fc6
I0703 15:05:24.885140 14543 net.cpp:400] drop6 -> fc6 (in-place)
I0703 15:05:24.885152 14543 net.cpp:153] Setting up drop6
I0703 15:05:24.885155 14543 net.cpp:160] Top shape: 64 4096 (262144)
I0703 15:05:24.885156 14543 net.cpp:168] Memory required for data: 519955200
I0703 15:05:24.885159 14543 layer_factory.hpp:76] Creating layer fc7
I0703 15:05:24.885162 14543 net.cpp:109] Creating Layer fc7
I0703 15:05:24.885164 14543 net.cpp:457] fc7 <- fc6
I0703 15:05:24.885167 14543 net.cpp:414] fc7 -> fc7
I0703 15:05:25.190172 14543 net.cpp:153] Setting up fc7
I0703 15:05:25.190191 14543 net.cpp:160] Top shape: 64 4096 (262144)
I0703 15:05:25.190192 14543 net.cpp:168] Memory required for data: 521003776
I0703 15:05:25.190198 14543 layer_factory.hpp:76] Creating layer relu7
I0703 15:05:25.190204 14543 net.cpp:109] Creating Layer relu7
I0703 15:05:25.190207 14543 net.cpp:457] relu7 <- fc7
I0703 15:05:25.190210 14543 net.cpp:400] relu7 -> fc7 (in-place)
I0703 15:05:25.190217 14543 net.cpp:153] Setting up relu7
I0703 15:05:25.190219 14543 net.cpp:160] Top shape: 64 4096 (262144)
I0703 15:05:25.190222 14543 net.cpp:168] Memory required for data: 522052352
I0703 15:05:25.190222 14543 layer_factory.hpp:76] Creating layer drop7
I0703 15:05:25.190227 14543 net.cpp:109] Creating Layer drop7
I0703 15:05:25.190228 14543 net.cpp:457] drop7 <- fc7
I0703 15:05:25.190232 14543 net.cpp:400] drop7 -> fc7 (in-place)
I0703 15:05:25.190243 14543 net.cpp:153] Setting up drop7
I0703 15:05:25.190246 14543 net.cpp:160] Top shape: 64 4096 (262144)
I0703 15:05:25.190264 14543 net.cpp:168] Memory required for data: 523100928
I0703 15:05:25.190266 14543 layer_factory.hpp:76] Creating layer fc8_species
I0703 15:05:25.190270 14543 net.cpp:109] Creating Layer fc8_species
I0703 15:05:25.190273 14543 net.cpp:457] fc8_species <- fc7
I0703 15:05:25.190274 14543 net.cpp:414] fc8_species -> fc8_species
I0703 15:05:25.285195 14543 net.cpp:153] Setting up fc8_species
I0703 15:05:25.285214 14543 net.cpp:160] Top shape: 64 967 (61888)
I0703 15:05:25.285218 14543 net.cpp:168] Memory required for data: 523348480
I0703 15:05:25.285223 14543 layer_factory.hpp:76] Creating layer fc8_species_fc8_species_0_split
I0703 15:05:25.285229 14543 net.cpp:109] Creating Layer fc8_species_fc8_species_0_split
I0703 15:05:25.285233 14543 net.cpp:457] fc8_species_fc8_species_0_split <- fc8_species
I0703 15:05:25.285238 14543 net.cpp:414] fc8_species_fc8_species_0_split -> fc8_species_fc8_species_0_split_0
I0703 15:05:25.285243 14543 net.cpp:414] fc8_species_fc8_species_0_split -> fc8_species_fc8_species_0_split_1
I0703 15:05:25.285269 14543 net.cpp:153] Setting up fc8_species_fc8_species_0_split
I0703 15:05:25.285271 14543 net.cpp:160] Top shape: 64 967 (61888)
I0703 15:05:25.285274 14543 net.cpp:160] Top shape: 64 967 (61888)
I0703 15:05:25.285275 14543 net.cpp:168] Memory required for data: 523843584
I0703 15:05:25.285277 14543 layer_factory.hpp:76] Creating layer loss
I0703 15:05:25.285280 14543 net.cpp:109] Creating Layer loss
I0703 15:05:25.285282 14543 net.cpp:457] loss <- fc8_species_fc8_species_0_split_0
I0703 15:05:25.285285 14543 net.cpp:457] loss <- label_label_0_split_0
I0703 15:05:25.285287 14543 net.cpp:414] loss -> loss
I0703 15:05:25.285292 14543 layer_factory.hpp:76] Creating layer loss
I0703 15:05:25.285392 14543 net.cpp:153] Setting up loss
I0703 15:05:25.285397 14543 net.cpp:160] Top shape: (1)
I0703 15:05:25.285398 14543 net.cpp:163]     with loss weight 1
I0703 15:05:25.285405 14543 net.cpp:168] Memory required for data: 523843588
I0703 15:05:25.285406 14543 layer_factory.hpp:76] Creating layer accuracy
I0703 15:05:25.285419 14543 net.cpp:109] Creating Layer accuracy
I0703 15:05:25.285421 14543 net.cpp:457] accuracy <- fc8_species_fc8_species_0_split_1
I0703 15:05:25.285423 14543 net.cpp:457] accuracy <- label_label_0_split_1
I0703 15:05:25.285426 14543 net.cpp:414] accuracy -> accuracy
I0703 15:05:25.285430 14543 net.cpp:153] Setting up accuracy
I0703 15:05:25.285434 14543 net.cpp:160] Top shape: (1)
I0703 15:05:25.285434 14543 net.cpp:168] Memory required for data: 523843592
I0703 15:05:25.285436 14543 net.cpp:231] accuracy does not need backward computation.
I0703 15:05:25.285439 14543 net.cpp:229] loss needs backward computation.
I0703 15:05:25.285440 14543 net.cpp:229] fc8_species_fc8_species_0_split needs backward computation.
I0703 15:05:25.285442 14543 net.cpp:229] fc8_species needs backward computation.
I0703 15:05:25.285444 14543 net.cpp:229] drop7 needs backward computation.
I0703 15:05:25.285445 14543 net.cpp:229] relu7 needs backward computation.
I0703 15:05:25.285447 14543 net.cpp:229] fc7 needs backward computation.
I0703 15:05:25.285449 14543 net.cpp:229] drop6 needs backward computation.
I0703 15:05:25.285451 14543 net.cpp:229] relu6 needs backward computation.
I0703 15:05:25.285454 14543 net.cpp:229] fc6 needs backward computation.
I0703 15:05:25.285455 14543 net.cpp:229] pool5 needs backward computation.
I0703 15:05:25.285457 14543 net.cpp:229] relu5 needs backward computation.
I0703 15:05:25.285459 14543 net.cpp:229] conv5 needs backward computation.
I0703 15:05:25.285460 14543 net.cpp:229] relu4 needs backward computation.
I0703 15:05:25.285462 14543 net.cpp:229] conv4 needs backward computation.
I0703 15:05:25.285465 14543 net.cpp:229] relu3 needs backward computation.
I0703 15:05:25.285466 14543 net.cpp:229] conv3 needs backward computation.
I0703 15:05:25.285468 14543 net.cpp:229] pool2 needs backward computation.
I0703 15:05:25.285470 14543 net.cpp:229] norm2 needs backward computation.
I0703 15:05:25.285472 14543 net.cpp:229] relu2 needs backward computation.
I0703 15:05:25.285490 14543 net.cpp:229] conv2 needs backward computation.
I0703 15:05:25.285492 14543 net.cpp:229] pool1 needs backward computation.
I0703 15:05:25.285495 14543 net.cpp:229] norm1 needs backward computation.
I0703 15:05:25.285496 14543 net.cpp:229] relu1 needs backward computation.
I0703 15:05:25.285498 14543 net.cpp:229] conv1 needs backward computation.
I0703 15:05:25.285501 14543 net.cpp:231] label_label_0_split does not need backward computation.
I0703 15:05:25.285503 14543 net.cpp:231] label does not need backward computation.
I0703 15:05:25.285506 14543 net.cpp:231] data does not need backward computation.
I0703 15:05:25.285506 14543 net.cpp:273] This network produces output accuracy
I0703 15:05:25.285508 14543 net.cpp:273] This network produces output loss
I0703 15:05:25.285518 14543 net.cpp:286] Network initialization done.
I0703 15:05:25.285579 14543 solver.cpp:66] Solver scaffolding done.
I0703 15:05:25.285888 14543 caffe.cpp:220] Starting Optimization
I0703 15:05:25.285893 14543 solver.cpp:294] Solving
I0703 15:05:25.285894 14543 solver.cpp:295] Learning Rate Policy: exp
I0703 15:05:25.287000 14543 solver.cpp:347] Iteration 0, Testing net (#0)
I0703 15:05:33.925354 14543 solver.cpp:415]     Test net output #0: accuracy = 0.000480769
I0703 15:05:33.925377 14543 solver.cpp:415]     Test net output #1: loss = 6.87491 (* 1 = 6.87491 loss)
I0703 15:05:34.133676 14543 solver.cpp:243] Iteration 0, loss = 6.86222
I0703 15:05:34.133694 14543 solver.cpp:259]     Train net output #0: loss = 6.86222 (* 1 = 6.86222 loss)
I0703 15:05:34.133704 14543 solver.cpp:590] Iteration 0, lr = 0.01
I0703 15:05:40.910707 14543 solver.cpp:243] Iteration 55, loss = 6.70072
I0703 15:05:40.910728 14543 solver.cpp:259]     Train net output #0: loss = 6.70072 (* 1 = 6.70072 loss)
I0703 15:05:40.910734 14543 solver.cpp:590] Iteration 55, lr = 0.00992312
I0703 15:05:47.695302 14543 solver.cpp:243] Iteration 110, loss = 6.6729
I0703 15:05:47.695323 14543 solver.cpp:259]     Train net output #0: loss = 6.6729 (* 1 = 6.6729 loss)
I0703 15:05:47.695329 14543 solver.cpp:590] Iteration 110, lr = 0.00984683
I0703 15:05:54.481884 14543 solver.cpp:243] Iteration 165, loss = 6.81002
I0703 15:05:54.481930 14543 solver.cpp:259]     Train net output #0: loss = 6.81002 (* 1 = 6.81002 loss)
I0703 15:05:54.481935 14543 solver.cpp:590] Iteration 165, lr = 0.00977113
I0703 15:06:01.266171 14543 solver.cpp:243] Iteration 220, loss = 6.59699
I0703 15:06:01.266192 14543 solver.cpp:259]     Train net output #0: loss = 6.59699 (* 1 = 6.59699 loss)
I0703 15:06:01.266197 14543 solver.cpp:590] Iteration 220, lr = 0.00969601
I0703 15:06:08.045213 14543 solver.cpp:243] Iteration 275, loss = 6.60213
I0703 15:06:08.045235 14543 solver.cpp:259]     Train net output #0: loss = 6.60213 (* 1 = 6.60213 loss)
I0703 15:06:08.045240 14543 solver.cpp:590] Iteration 275, lr = 0.00962147
I0703 15:06:14.826263 14543 solver.cpp:243] Iteration 330, loss = 6.64128
I0703 15:06:14.826284 14543 solver.cpp:259]     Train net output #0: loss = 6.64128 (* 1 = 6.64128 loss)
I0703 15:06:14.826289 14543 solver.cpp:590] Iteration 330, lr = 0.0095475
I0703 15:06:21.610246 14543 solver.cpp:243] Iteration 385, loss = 6.64605
I0703 15:06:21.610267 14543 solver.cpp:259]     Train net output #0: loss = 6.64605 (* 1 = 6.64605 loss)
I0703 15:06:21.610273 14543 solver.cpp:590] Iteration 385, lr = 0.0094741
I0703 15:06:28.403549 14543 solver.cpp:243] Iteration 440, loss = 6.61053
I0703 15:06:28.403664 14543 solver.cpp:259]     Train net output #0: loss = 6.61053 (* 1 = 6.61053 loss)
I0703 15:06:28.403671 14543 solver.cpp:590] Iteration 440, lr = 0.00940127
I0703 15:06:28.403961 14543 solver.cpp:347] Iteration 441, Testing net (#0)
I0703 15:06:37.066994 14543 solver.cpp:415]     Test net output #0: accuracy = 0.00324519
I0703 15:06:37.067015 14543 solver.cpp:415]     Test net output #1: loss = 6.61755 (* 1 = 6.61755 loss)
I0703 15:06:43.836679 14543 solver.cpp:243] Iteration 495, loss = 6.68707
I0703 15:06:43.836701 14543 solver.cpp:259]     Train net output #0: loss = 6.68707 (* 1 = 6.68707 loss)
I0703 15:06:43.836706 14543 solver.cpp:590] Iteration 495, lr = 0.00932899
I0703 15:06:50.626981 14543 solver.cpp:243] Iteration 550, loss = 6.6743
I0703 15:06:50.627002 14543 solver.cpp:259]     Train net output #0: loss = 6.6743 (* 1 = 6.6743 loss)
I0703 15:06:50.627005 14543 solver.cpp:590] Iteration 550, lr = 0.00925727
I0703 15:06:57.412569 14543 solver.cpp:243] Iteration 605, loss = 6.48659
I0703 15:06:57.412591 14543 solver.cpp:259]     Train net output #0: loss = 6.48659 (* 1 = 6.48659 loss)
I0703 15:06:57.412595 14543 solver.cpp:590] Iteration 605, lr = 0.0091861
I0703 15:07:04.197118 14543 solver.cpp:243] Iteration 660, loss = 6.26208
I0703 15:07:04.197199 14543 solver.cpp:259]     Train net output #0: loss = 6.26208 (* 1 = 6.26208 loss)
I0703 15:07:04.197206 14543 solver.cpp:590] Iteration 660, lr = 0.00911548
I0703 15:07:10.983464 14543 solver.cpp:243] Iteration 715, loss = 6.34523
I0703 15:07:10.983486 14543 solver.cpp:259]     Train net output #0: loss = 6.34523 (* 1 = 6.34523 loss)
I0703 15:07:10.983492 14543 solver.cpp:590] Iteration 715, lr = 0.0090454
I0703 15:07:17.772125 14543 solver.cpp:243] Iteration 770, loss = 6.31207
I0703 15:07:17.772145 14543 solver.cpp:259]     Train net output #0: loss = 6.31207 (* 1 = 6.31207 loss)
I0703 15:07:17.772150 14543 solver.cpp:590] Iteration 770, lr = 0.00897587
I0703 15:07:24.560750 14543 solver.cpp:243] Iteration 825, loss = 6.24974
I0703 15:07:24.560770 14543 solver.cpp:259]     Train net output #0: loss = 6.24974 (* 1 = 6.24974 loss)
I0703 15:07:24.560775 14543 solver.cpp:590] Iteration 825, lr = 0.00890686
I0703 15:07:31.347571 14543 solver.cpp:243] Iteration 880, loss = 6.52356
I0703 15:07:31.347592 14543 solver.cpp:259]     Train net output #0: loss = 6.52356 (* 1 = 6.52356 loss)
I0703 15:07:31.347597 14543 solver.cpp:590] Iteration 880, lr = 0.00883839
I0703 15:07:31.471801 14543 solver.cpp:347] Iteration 882, Testing net (#0)
I0703 15:07:40.130722 14543 solver.cpp:415]     Test net output #0: accuracy = 0.0120192
I0703 15:07:40.130825 14543 solver.cpp:415]     Test net output #1: loss = 6.18215 (* 1 = 6.18215 loss)
I0703 15:07:46.777343 14543 solver.cpp:243] Iteration 935, loss = 6.28535
I0703 15:07:46.777364 14543 solver.cpp:259]     Train net output #0: loss = 6.28535 (* 1 = 6.28535 loss)
I0703 15:07:46.777369 14543 solver.cpp:590] Iteration 935, lr = 0.00877044
I0703 15:07:53.564924 14543 solver.cpp:243] Iteration 990, loss = 6.17865
I0703 15:07:53.564944 14543 solver.cpp:259]     Train net output #0: loss = 6.17865 (* 1 = 6.17865 loss)
I0703 15:07:53.564949 14543 solver.cpp:590] Iteration 990, lr = 0.00870301
I0703 15:08:00.354943 14543 solver.cpp:243] Iteration 1045, loss = 6.12705
I0703 15:08:00.354964 14543 solver.cpp:259]     Train net output #0: loss = 6.12705 (* 1 = 6.12705 loss)
I0703 15:08:00.354969 14543 solver.cpp:590] Iteration 1045, lr = 0.0086361
I0703 15:08:07.143578 14543 solver.cpp:243] Iteration 1100, loss = 6.16516
I0703 15:08:07.143599 14543 solver.cpp:259]     Train net output #0: loss = 6.16516 (* 1 = 6.16516 loss)
I0703 15:08:07.143604 14543 solver.cpp:590] Iteration 1100, lr = 0.00856971
I0703 15:08:13.924793 14543 solver.cpp:243] Iteration 1155, loss = 6.06833
I0703 15:08:13.924849 14543 solver.cpp:259]     Train net output #0: loss = 6.06833 (* 1 = 6.06833 loss)
I0703 15:08:13.924855 14543 solver.cpp:590] Iteration 1155, lr = 0.00850383
I0703 15:08:20.708225 14543 solver.cpp:243] Iteration 1210, loss = 5.95271
I0703 15:08:20.708245 14543 solver.cpp:259]     Train net output #0: loss = 5.95271 (* 1 = 5.95271 loss)
I0703 15:08:20.708250 14543 solver.cpp:590] Iteration 1210, lr = 0.00843845
I0703 15:08:27.500130 14543 solver.cpp:243] Iteration 1265, loss = 5.71383
I0703 15:08:27.500150 14543 solver.cpp:259]     Train net output #0: loss = 5.71383 (* 1 = 5.71383 loss)
I0703 15:08:27.500155 14543 solver.cpp:590] Iteration 1265, lr = 0.00837358
I0703 15:08:34.290093 14543 solver.cpp:243] Iteration 1320, loss = 6.07591
I0703 15:08:34.290114 14543 solver.cpp:259]     Train net output #0: loss = 6.07591 (* 1 = 6.07591 loss)
I0703 15:08:34.290119 14543 solver.cpp:590] Iteration 1320, lr = 0.0083092
I0703 15:08:34.537300 14543 solver.cpp:347] Iteration 1323, Testing net (#0)
I0703 15:08:43.199964 14543 solver.cpp:415]     Test net output #0: accuracy = 0.0185096
I0703 15:08:43.199985 14543 solver.cpp:415]     Test net output #1: loss = 5.86788 (* 1 = 5.86788 loss)
I0703 15:08:49.718263 14543 solver.cpp:243] Iteration 1375, loss = 6.01281
I0703 15:08:49.718346 14543 solver.cpp:259]     Train net output #0: loss = 6.01281 (* 1 = 6.01281 loss)
I0703 15:08:49.718351 14543 solver.cpp:590] Iteration 1375, lr = 0.00824532
I0703 15:08:56.505772 14543 solver.cpp:243] Iteration 1430, loss = 5.88414
I0703 15:08:56.505794 14543 solver.cpp:259]     Train net output #0: loss = 5.88414 (* 1 = 5.88414 loss)
I0703 15:08:56.505798 14543 solver.cpp:590] Iteration 1430, lr = 0.00818194
I0703 15:09:03.296211 14543 solver.cpp:243] Iteration 1485, loss = 5.93134
I0703 15:09:03.296231 14543 solver.cpp:259]     Train net output #0: loss = 5.93134 (* 1 = 5.93134 loss)
I0703 15:09:03.296236 14543 solver.cpp:590] Iteration 1485, lr = 0.00811903
I0703 15:09:10.088419 14543 solver.cpp:243] Iteration 1540, loss = 6.02608
I0703 15:09:10.088441 14543 solver.cpp:259]     Train net output #0: loss = 6.02608 (* 1 = 6.02608 loss)
I0703 15:09:10.088446 14543 solver.cpp:590] Iteration 1540, lr = 0.00805662
I0703 15:09:16.874970 14543 solver.cpp:243] Iteration 1595, loss = 5.87677
I0703 15:09:16.874990 14543 solver.cpp:259]     Train net output #0: loss = 5.87677 (* 1 = 5.87677 loss)
I0703 15:09:16.874994 14543 solver.cpp:590] Iteration 1595, lr = 0.00799468
I0703 15:09:23.662492 14543 solver.cpp:243] Iteration 1650, loss = 5.76416
I0703 15:09:23.662529 14543 solver.cpp:259]     Train net output #0: loss = 5.76416 (* 1 = 5.76416 loss)
I0703 15:09:23.662534 14543 solver.cpp:590] Iteration 1650, lr = 0.00793322
I0703 15:09:30.445838 14543 solver.cpp:243] Iteration 1705, loss = 5.53776
I0703 15:09:30.445861 14543 solver.cpp:259]     Train net output #0: loss = 5.53776 (* 1 = 5.53776 loss)
I0703 15:09:30.445868 14543 solver.cpp:590] Iteration 1705, lr = 0.00787223
I0703 15:09:37.233299 14543 solver.cpp:243] Iteration 1760, loss = 5.65969
I0703 15:09:37.233320 14543 solver.cpp:259]     Train net output #0: loss = 5.65969 (* 1 = 5.65969 loss)
I0703 15:09:37.233326 14543 solver.cpp:590] Iteration 1760, lr = 0.00781171
I0703 15:09:37.603868 14543 solver.cpp:347] Iteration 1764, Testing net (#0)
I0703 15:09:46.278862 14543 solver.cpp:415]     Test net output #0: accuracy = 0.0286058
I0703 15:09:46.278883 14543 solver.cpp:415]     Test net output #1: loss = 5.71872 (* 1 = 5.71872 loss)
I0703 15:09:52.677315 14543 solver.cpp:243] Iteration 1815, loss = 5.58066
I0703 15:09:52.677336 14543 solver.cpp:259]     Train net output #0: loss = 5.58066 (* 1 = 5.58066 loss)
I0703 15:09:52.677341 14543 solver.cpp:590] Iteration 1815, lr = 0.00775165
I0703 15:09:59.468282 14543 solver.cpp:243] Iteration 1870, loss = 5.6871
I0703 15:09:59.468371 14543 solver.cpp:259]     Train net output #0: loss = 5.6871 (* 1 = 5.6871 loss)
I0703 15:09:59.468379 14543 solver.cpp:590] Iteration 1870, lr = 0.00769206
I0703 15:10:06.259323 14543 solver.cpp:243] Iteration 1925, loss = 5.80462
I0703 15:10:06.259346 14543 solver.cpp:259]     Train net output #0: loss = 5.80462 (* 1 = 5.80462 loss)
I0703 15:10:06.259351 14543 solver.cpp:590] Iteration 1925, lr = 0.00763292
I0703 15:10:13.049502 14543 solver.cpp:243] Iteration 1980, loss = 5.91275
I0703 15:10:13.049523 14543 solver.cpp:259]     Train net output #0: loss = 5.91275 (* 1 = 5.91275 loss)
I0703 15:10:13.049528 14543 solver.cpp:590] Iteration 1980, lr = 0.00757424
I0703 15:10:19.835532 14543 solver.cpp:243] Iteration 2035, loss = 5.55614
I0703 15:10:19.835556 14543 solver.cpp:259]     Train net output #0: loss = 5.55614 (* 1 = 5.55614 loss)
I0703 15:10:19.835561 14543 solver.cpp:590] Iteration 2035, lr = 0.00751601
I0703 15:10:26.622467 14543 solver.cpp:243] Iteration 2090, loss = 5.8624
I0703 15:10:26.622486 14543 solver.cpp:259]     Train net output #0: loss = 5.8624 (* 1 = 5.8624 loss)
I0703 15:10:26.622491 14543 solver.cpp:590] Iteration 2090, lr = 0.00745823
I0703 15:10:33.415383 14543 solver.cpp:243] Iteration 2145, loss = 5.5488
I0703 15:10:33.415462 14543 solver.cpp:259]     Train net output #0: loss = 5.5488 (* 1 = 5.5488 loss)
I0703 15:10:33.415468 14543 solver.cpp:590] Iteration 2145, lr = 0.00740089
I0703 15:10:40.205088 14543 solver.cpp:243] Iteration 2200, loss = 5.51444
I0703 15:10:40.205111 14543 solver.cpp:259]     Train net output #0: loss = 5.51444 (* 1 = 5.51444 loss)
I0703 15:10:40.205116 14543 solver.cpp:590] Iteration 2200, lr = 0.00734399
I0703 15:10:40.699491 14543 solver.cpp:347] Iteration 2205, Testing net (#0)
I0703 15:10:49.388713 14543 solver.cpp:415]     Test net output #0: accuracy = 0.0401442
I0703 15:10:49.388734 14543 solver.cpp:415]     Test net output #1: loss = 5.54494 (* 1 = 5.54494 loss)
I0703 15:10:55.660593 14543 solver.cpp:243] Iteration 2255, loss = 5.40789
I0703 15:10:55.660614 14543 solver.cpp:259]     Train net output #0: loss = 5.40789 (* 1 = 5.40789 loss)
I0703 15:10:55.660619 14543 solver.cpp:590] Iteration 2255, lr = 0.00728753
I0703 15:11:02.447494 14543 solver.cpp:243] Iteration 2310, loss = 5.4806
I0703 15:11:02.447513 14543 solver.cpp:259]     Train net output #0: loss = 5.4806 (* 1 = 5.4806 loss)
I0703 15:11:02.447518 14543 solver.cpp:590] Iteration 2310, lr = 0.00723151
I0703 15:11:09.240854 14543 solver.cpp:243] Iteration 2365, loss = 5.81264
I0703 15:11:09.240918 14543 solver.cpp:259]     Train net output #0: loss = 5.81264 (* 1 = 5.81264 loss)
I0703 15:11:09.240924 14543 solver.cpp:590] Iteration 2365, lr = 0.00717591
I0703 15:11:16.029655 14543 solver.cpp:243] Iteration 2420, loss = 5.60882
I0703 15:11:16.029676 14543 solver.cpp:259]     Train net output #0: loss = 5.60882 (* 1 = 5.60882 loss)
I0703 15:11:16.029681 14543 solver.cpp:590] Iteration 2420, lr = 0.00712075
I0703 15:11:22.817342 14543 solver.cpp:243] Iteration 2475, loss = 5.41212
I0703 15:11:22.817361 14543 solver.cpp:259]     Train net output #0: loss = 5.41212 (* 1 = 5.41212 loss)
I0703 15:11:22.817368 14543 solver.cpp:590] Iteration 2475, lr = 0.007066
I0703 15:11:29.605262 14543 solver.cpp:243] Iteration 2530, loss = 5.30645
I0703 15:11:29.605283 14543 solver.cpp:259]     Train net output #0: loss = 5.30645 (* 1 = 5.30645 loss)
I0703 15:11:29.605288 14543 solver.cpp:590] Iteration 2530, lr = 0.00701168
I0703 15:11:36.394294 14543 solver.cpp:243] Iteration 2585, loss = 5.15476
I0703 15:11:36.394316 14543 solver.cpp:259]     Train net output #0: loss = 5.15476 (* 1 = 5.15476 loss)
I0703 15:11:36.394321 14543 solver.cpp:590] Iteration 2585, lr = 0.00695778
I0703 15:11:43.186177 14543 solver.cpp:243] Iteration 2640, loss = 5.6094
I0703 15:11:43.186269 14543 solver.cpp:259]     Train net output #0: loss = 5.6094 (* 1 = 5.6094 loss)
I0703 15:11:43.186285 14543 solver.cpp:590] Iteration 2640, lr = 0.00690429
I0703 15:11:43.804862 14543 solver.cpp:347] Iteration 2646, Testing net (#0)
I0703 15:11:52.481725 14543 solver.cpp:415]     Test net output #0: accuracy = 0.052524
I0703 15:11:52.481747 14543 solver.cpp:415]     Test net output #1: loss = 5.28992 (* 1 = 5.28992 loss)
I0703 15:11:58.636816 14543 solver.cpp:243] Iteration 2695, loss = 5.36192
I0703 15:11:58.636838 14543 solver.cpp:259]     Train net output #0: loss = 5.36192 (* 1 = 5.36192 loss)
I0703 15:11:58.636844 14543 solver.cpp:590] Iteration 2695, lr = 0.00685121
I0703 15:12:05.430069 14543 solver.cpp:243] Iteration 2750, loss = 5.1228
I0703 15:12:05.430091 14543 solver.cpp:259]     Train net output #0: loss = 5.1228 (* 1 = 5.1228 loss)
I0703 15:12:05.430097 14543 solver.cpp:590] Iteration 2750, lr = 0.00679854
I0703 15:12:12.215873 14543 solver.cpp:243] Iteration 2805, loss = 5.32736
I0703 15:12:12.215895 14543 solver.cpp:259]     Train net output #0: loss = 5.32736 (* 1 = 5.32736 loss)
I0703 15:12:12.215901 14543 solver.cpp:590] Iteration 2805, lr = 0.00674627
I0703 15:12:19.001289 14543 solver.cpp:243] Iteration 2860, loss = 5.4004
I0703 15:12:19.001348 14543 solver.cpp:259]     Train net output #0: loss = 5.4004 (* 1 = 5.4004 loss)
I0703 15:12:19.001353 14543 solver.cpp:590] Iteration 2860, lr = 0.00669441
I0703 15:12:25.789487 14543 solver.cpp:243] Iteration 2915, loss = 5.08304
I0703 15:12:25.789508 14543 solver.cpp:259]     Train net output #0: loss = 5.08304 (* 1 = 5.08304 loss)
I0703 15:12:25.789513 14543 solver.cpp:590] Iteration 2915, lr = 0.00664294
I0703 15:12:32.581966 14543 solver.cpp:243] Iteration 2970, loss = 5.18694
I0703 15:12:32.581989 14543 solver.cpp:259]     Train net output #0: loss = 5.18694 (* 1 = 5.18694 loss)
I0703 15:12:32.581995 14543 solver.cpp:590] Iteration 2970, lr = 0.00659187
I0703 15:12:39.377022 14543 solver.cpp:243] Iteration 3025, loss = 5.26339
I0703 15:12:39.377043 14543 solver.cpp:259]     Train net output #0: loss = 5.26339 (* 1 = 5.26339 loss)
I0703 15:12:39.377048 14543 solver.cpp:590] Iteration 3025, lr = 0.00654119
I0703 15:12:46.173481 14543 solver.cpp:243] Iteration 3080, loss = 5.35108
I0703 15:12:46.173501 14543 solver.cpp:259]     Train net output #0: loss = 5.35108 (* 1 = 5.35108 loss)
I0703 15:12:46.173506 14543 solver.cpp:590] Iteration 3080, lr = 0.00649091
I0703 15:12:46.914330 14543 solver.cpp:347] Iteration 3087, Testing net (#0)
I0703 15:12:55.560469 14543 solver.cpp:415]     Test net output #0: accuracy = 0.0591346
I0703 15:12:55.560531 14543 solver.cpp:415]     Test net output #1: loss = 5.1691 (* 1 = 5.1691 loss)
I0703 15:13:01.583668 14543 solver.cpp:243] Iteration 3135, loss = 5.03506
I0703 15:13:01.583689 14543 solver.cpp:259]     Train net output #0: loss = 5.03506 (* 1 = 5.03506 loss)
I0703 15:13:01.583695 14543 solver.cpp:590] Iteration 3135, lr = 0.006441
I0703 15:13:08.373710 14543 solver.cpp:243] Iteration 3190, loss = 5.22928
I0703 15:13:08.373731 14543 solver.cpp:259]     Train net output #0: loss = 5.22928 (* 1 = 5.22928 loss)
I0703 15:13:08.373736 14543 solver.cpp:590] Iteration 3190, lr = 0.00639149
I0703 15:13:15.166575 14543 solver.cpp:243] Iteration 3245, loss = 4.60131
I0703 15:13:15.166595 14543 solver.cpp:259]     Train net output #0: loss = 4.60131 (* 1 = 4.60131 loss)
I0703 15:13:15.166600 14543 solver.cpp:590] Iteration 3245, lr = 0.00634235
I0703 15:13:21.958766 14543 solver.cpp:243] Iteration 3300, loss = 4.82891
I0703 15:13:21.958787 14543 solver.cpp:259]     Train net output #0: loss = 4.82891 (* 1 = 4.82891 loss)
I0703 15:13:21.958792 14543 solver.cpp:590] Iteration 3300, lr = 0.00629359
I0703 15:13:28.747488 14543 solver.cpp:243] Iteration 3355, loss = 4.88616
I0703 15:13:28.747578 14543 solver.cpp:259]     Train net output #0: loss = 4.88616 (* 1 = 4.88616 loss)
I0703 15:13:28.747584 14543 solver.cpp:590] Iteration 3355, lr = 0.00624521
