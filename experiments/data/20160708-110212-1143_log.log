I0708 11:02:14.166347 31135 caffe.cpp:192] Using GPUs 0
I0708 11:02:14.345316 31135 solver.cpp:54] Initializing solver from parameters:
test_iter: 260
test_interval: 882
base_lr: 0.01
display: 110
max_iter: 70560
lr_policy: "exp"
gamma: 0.99991232
momentum: 0.9
weight_decay: 0.0001
snapshot: 8820
snapshot_prefix: "snapshot"
solver_mode: GPU
device_id: 0
random_seed: 0
net: "train_val.prototxt"
solver_type: SGD
iter_size: 1
I0708 11:02:14.345757 31135 solver.cpp:97] Creating training net from net file: train_val.prototxt
I0708 11:02:14.346246 31135 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0708 11:02:14.346253 31135 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer label
I0708 11:02:14.346261 31135 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0708 11:02:14.346336 31135 net.cpp:52] Initializing net from parameters:
state {
phase: TRAIN
}
layer {
name: "data"
type: "Data"
top: "data"
include {
phase: TRAIN
}
transform_param {
mean_file: "/home/ffw/scratch/plantClef/scatnet_output/train/a4_m2_s1s2_f2/lmdb_mean_coeff.binaryproto"
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/train/a4_m2_s1s2_f2/lmdb_data"
batch_size: 32
backend: LMDB
}
}
layer {
name: "label"
type: "Data"
top: "label"
include {
phase: TRAIN
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/train/a4_m2_s1s2_f2/lmdb_labels"
batch_size: 32
backend: LMDB
}
}
layer {
name: "pool1"
type: "Pooling"
bottom: "data"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 6
stride: 5
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool1"
top: "conv3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "conv4"
type: "Convolution"
bottom: "conv3"
top: "conv4"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu4"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "conv5"
type: "Convolution"
bottom: "conv4"
top: "conv5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
group: 1
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "conv5"
top: "conv5"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "conv5"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fc6"
type: "InnerProduct"
bottom: "pool5"
top: "fc6"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "fc6"
top: "fc6"
}
layer {
name: "drop6"
type: "Dropout"
bottom: "fc6"
top: "fc6"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc7"
type: "InnerProduct"
bottom: "fc6"
top: "fc7"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "fc7"
top: "fc7"
}
layer {
name: "drop7"
type: "Dropout"
bottom: "fc7"
top: "fc7"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc8_species"
type: "InnerProduct"
bottom: "fc7"
top: "fc8_species"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 967
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "fc8_species"
bottom: "label"
top: "loss"
}
I0708 11:02:14.346391 31135 layer_factory.hpp:76] Creating layer data
I0708 11:02:14.346451 31135 net.cpp:109] Creating Layer data
I0708 11:02:14.346457 31135 net.cpp:414] data -> data
I0708 11:02:14.346472 31135 data_transformer.cpp:25] Loading mean file from: /home/ffw/scratch/plantClef/scatnet_output/train/a4_m2_s1s2_f2/lmdb_mean_coeff.binaryproto
I0708 11:02:14.350734 31147 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/train/a4_m2_s1s2_f2/lmdb_data
I0708 11:02:14.362999 31135 data_layer.cpp:45] output data size: 32,75,105,105
I0708 11:02:14.473084 31135 net.cpp:153] Setting up data
I0708 11:02:14.473130 31135 net.cpp:160] Top shape: 32 75 105 105 (26460000)
I0708 11:02:14.473134 31135 net.cpp:168] Memory required for data: 105840000
I0708 11:02:14.473140 31135 layer_factory.hpp:76] Creating layer label
I0708 11:02:14.473186 31135 net.cpp:109] Creating Layer label
I0708 11:02:14.473189 31135 net.cpp:414] label -> label
I0708 11:02:14.475852 31149 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/train/a4_m2_s1s2_f2/lmdb_labels
I0708 11:02:14.483526 31135 data_layer.cpp:45] output data size: 32,1,1,1
I0708 11:02:14.483738 31135 net.cpp:153] Setting up label
I0708 11:02:14.483747 31135 net.cpp:160] Top shape: 32 1 1 1 (32)
I0708 11:02:14.483749 31135 net.cpp:168] Memory required for data: 105840128
I0708 11:02:14.483753 31135 layer_factory.hpp:76] Creating layer pool1
I0708 11:02:14.483762 31135 net.cpp:109] Creating Layer pool1
I0708 11:02:14.483765 31135 net.cpp:457] pool1 <- data
I0708 11:02:14.483773 31135 net.cpp:414] pool1 -> pool1
I0708 11:02:14.483814 31135 net.cpp:153] Setting up pool1
I0708 11:02:14.483819 31135 net.cpp:160] Top shape: 32 75 21 21 (1058400)
I0708 11:02:14.483820 31135 net.cpp:168] Memory required for data: 110073728
I0708 11:02:14.483822 31135 layer_factory.hpp:76] Creating layer conv3
I0708 11:02:14.483830 31135 net.cpp:109] Creating Layer conv3
I0708 11:02:14.483831 31135 net.cpp:457] conv3 <- pool1
I0708 11:02:14.483835 31135 net.cpp:414] conv3 -> conv3
I0708 11:02:14.489436 31135 net.cpp:153] Setting up conv3
I0708 11:02:14.489454 31135 net.cpp:160] Top shape: 32 384 21 21 (5419008)
I0708 11:02:14.489456 31135 net.cpp:168] Memory required for data: 131749760
I0708 11:02:14.489466 31135 layer_factory.hpp:76] Creating layer relu3
I0708 11:02:14.489475 31135 net.cpp:109] Creating Layer relu3
I0708 11:02:14.489477 31135 net.cpp:457] relu3 <- conv3
I0708 11:02:14.489480 31135 net.cpp:400] relu3 -> conv3 (in-place)
I0708 11:02:14.489490 31135 net.cpp:153] Setting up relu3
I0708 11:02:14.489491 31135 net.cpp:160] Top shape: 32 384 21 21 (5419008)
I0708 11:02:14.489493 31135 net.cpp:168] Memory required for data: 153425792
I0708 11:02:14.489495 31135 layer_factory.hpp:76] Creating layer conv4
I0708 11:02:14.489501 31135 net.cpp:109] Creating Layer conv4
I0708 11:02:14.489502 31135 net.cpp:457] conv4 <- conv3
I0708 11:02:14.489506 31135 net.cpp:414] conv4 -> conv4
I0708 11:02:14.502279 31135 net.cpp:153] Setting up conv4
I0708 11:02:14.502295 31135 net.cpp:160] Top shape: 32 384 21 21 (5419008)
I0708 11:02:14.502297 31135 net.cpp:168] Memory required for data: 175101824
I0708 11:02:14.502305 31135 layer_factory.hpp:76] Creating layer relu4
I0708 11:02:14.502311 31135 net.cpp:109] Creating Layer relu4
I0708 11:02:14.502315 31135 net.cpp:457] relu4 <- conv4
I0708 11:02:14.502317 31135 net.cpp:400] relu4 -> conv4 (in-place)
I0708 11:02:14.502341 31135 net.cpp:153] Setting up relu4
I0708 11:02:14.502343 31135 net.cpp:160] Top shape: 32 384 21 21 (5419008)
I0708 11:02:14.502346 31135 net.cpp:168] Memory required for data: 196777856
I0708 11:02:14.502347 31135 layer_factory.hpp:76] Creating layer conv5
I0708 11:02:14.502353 31135 net.cpp:109] Creating Layer conv5
I0708 11:02:14.502356 31135 net.cpp:457] conv5 <- conv4
I0708 11:02:14.502358 31135 net.cpp:414] conv5 -> conv5
I0708 11:02:14.520292 31135 net.cpp:153] Setting up conv5
I0708 11:02:14.520308 31135 net.cpp:160] Top shape: 32 256 21 21 (3612672)
I0708 11:02:14.520310 31135 net.cpp:168] Memory required for data: 211228544
I0708 11:02:14.520318 31135 layer_factory.hpp:76] Creating layer relu5
I0708 11:02:14.520325 31135 net.cpp:109] Creating Layer relu5
I0708 11:02:14.520328 31135 net.cpp:457] relu5 <- conv5
I0708 11:02:14.520333 31135 net.cpp:400] relu5 -> conv5 (in-place)
I0708 11:02:14.520339 31135 net.cpp:153] Setting up relu5
I0708 11:02:14.520341 31135 net.cpp:160] Top shape: 32 256 21 21 (3612672)
I0708 11:02:14.520342 31135 net.cpp:168] Memory required for data: 225679232
I0708 11:02:14.520344 31135 layer_factory.hpp:76] Creating layer pool5
I0708 11:02:14.520349 31135 net.cpp:109] Creating Layer pool5
I0708 11:02:14.520350 31135 net.cpp:457] pool5 <- conv5
I0708 11:02:14.520354 31135 net.cpp:414] pool5 -> pool5
I0708 11:02:14.520372 31135 net.cpp:153] Setting up pool5
I0708 11:02:14.520375 31135 net.cpp:160] Top shape: 32 256 10 10 (819200)
I0708 11:02:14.520376 31135 net.cpp:168] Memory required for data: 228956032
I0708 11:02:14.520378 31135 layer_factory.hpp:76] Creating layer fc6
I0708 11:02:14.520383 31135 net.cpp:109] Creating Layer fc6
I0708 11:02:14.520385 31135 net.cpp:457] fc6 <- pool5
I0708 11:02:14.520387 31135 net.cpp:414] fc6 -> fc6
I0708 11:02:16.478246 31135 net.cpp:153] Setting up fc6
I0708 11:02:16.478267 31135 net.cpp:160] Top shape: 32 4096 (131072)
I0708 11:02:16.478271 31135 net.cpp:168] Memory required for data: 229480320
I0708 11:02:16.478277 31135 layer_factory.hpp:76] Creating layer relu6
I0708 11:02:16.478286 31135 net.cpp:109] Creating Layer relu6
I0708 11:02:16.478288 31135 net.cpp:457] relu6 <- fc6
I0708 11:02:16.478292 31135 net.cpp:400] relu6 -> fc6 (in-place)
I0708 11:02:16.478299 31135 net.cpp:153] Setting up relu6
I0708 11:02:16.478302 31135 net.cpp:160] Top shape: 32 4096 (131072)
I0708 11:02:16.478303 31135 net.cpp:168] Memory required for data: 230004608
I0708 11:02:16.478305 31135 layer_factory.hpp:76] Creating layer drop6
I0708 11:02:16.478314 31135 net.cpp:109] Creating Layer drop6
I0708 11:02:16.478317 31135 net.cpp:457] drop6 <- fc6
I0708 11:02:16.478318 31135 net.cpp:400] drop6 -> fc6 (in-place)
I0708 11:02:16.478333 31135 net.cpp:153] Setting up drop6
I0708 11:02:16.478337 31135 net.cpp:160] Top shape: 32 4096 (131072)
I0708 11:02:16.478338 31135 net.cpp:168] Memory required for data: 230528896
I0708 11:02:16.478339 31135 layer_factory.hpp:76] Creating layer fc7
I0708 11:02:16.478344 31135 net.cpp:109] Creating Layer fc7
I0708 11:02:16.478346 31135 net.cpp:457] fc7 <- fc6
I0708 11:02:16.478349 31135 net.cpp:414] fc7 -> fc7
I0708 11:02:16.781517 31135 net.cpp:153] Setting up fc7
I0708 11:02:16.781538 31135 net.cpp:160] Top shape: 32 4096 (131072)
I0708 11:02:16.781539 31135 net.cpp:168] Memory required for data: 231053184
I0708 11:02:16.781548 31135 layer_factory.hpp:76] Creating layer relu7
I0708 11:02:16.781553 31135 net.cpp:109] Creating Layer relu7
I0708 11:02:16.781556 31135 net.cpp:457] relu7 <- fc7
I0708 11:02:16.781560 31135 net.cpp:400] relu7 -> fc7 (in-place)
I0708 11:02:16.781566 31135 net.cpp:153] Setting up relu7
I0708 11:02:16.781569 31135 net.cpp:160] Top shape: 32 4096 (131072)
I0708 11:02:16.781571 31135 net.cpp:168] Memory required for data: 231577472
I0708 11:02:16.781572 31135 layer_factory.hpp:76] Creating layer drop7
I0708 11:02:16.781576 31135 net.cpp:109] Creating Layer drop7
I0708 11:02:16.781579 31135 net.cpp:457] drop7 <- fc7
I0708 11:02:16.781580 31135 net.cpp:400] drop7 -> fc7 (in-place)
I0708 11:02:16.781615 31135 net.cpp:153] Setting up drop7
I0708 11:02:16.781618 31135 net.cpp:160] Top shape: 32 4096 (131072)
I0708 11:02:16.781620 31135 net.cpp:168] Memory required for data: 232101760
I0708 11:02:16.781622 31135 layer_factory.hpp:76] Creating layer fc8_species
I0708 11:02:16.781628 31135 net.cpp:109] Creating Layer fc8_species
I0708 11:02:16.781630 31135 net.cpp:457] fc8_species <- fc7
I0708 11:02:16.781632 31135 net.cpp:414] fc8_species -> fc8_species
I0708 11:02:16.853512 31135 net.cpp:153] Setting up fc8_species
I0708 11:02:16.853528 31135 net.cpp:160] Top shape: 32 967 (30944)
I0708 11:02:16.853531 31135 net.cpp:168] Memory required for data: 232225536
I0708 11:02:16.853538 31135 layer_factory.hpp:76] Creating layer loss
I0708 11:02:16.853543 31135 net.cpp:109] Creating Layer loss
I0708 11:02:16.853546 31135 net.cpp:457] loss <- fc8_species
I0708 11:02:16.853549 31135 net.cpp:457] loss <- label
I0708 11:02:16.853554 31135 net.cpp:414] loss -> loss
I0708 11:02:16.853567 31135 layer_factory.hpp:76] Creating layer loss
I0708 11:02:16.853984 31135 net.cpp:153] Setting up loss
I0708 11:02:16.853991 31135 net.cpp:160] Top shape: (1)
I0708 11:02:16.853993 31135 net.cpp:163]     with loss weight 1
I0708 11:02:16.854014 31135 net.cpp:168] Memory required for data: 232225540
I0708 11:02:16.854017 31135 net.cpp:229] loss needs backward computation.
I0708 11:02:16.854018 31135 net.cpp:229] fc8_species needs backward computation.
I0708 11:02:16.854020 31135 net.cpp:229] drop7 needs backward computation.
I0708 11:02:16.854022 31135 net.cpp:229] relu7 needs backward computation.
I0708 11:02:16.854024 31135 net.cpp:229] fc7 needs backward computation.
I0708 11:02:16.854027 31135 net.cpp:229] drop6 needs backward computation.
I0708 11:02:16.854028 31135 net.cpp:229] relu6 needs backward computation.
I0708 11:02:16.854029 31135 net.cpp:229] fc6 needs backward computation.
I0708 11:02:16.854032 31135 net.cpp:229] pool5 needs backward computation.
I0708 11:02:16.854033 31135 net.cpp:229] relu5 needs backward computation.
I0708 11:02:16.854035 31135 net.cpp:229] conv5 needs backward computation.
I0708 11:02:16.854038 31135 net.cpp:229] relu4 needs backward computation.
I0708 11:02:16.854039 31135 net.cpp:229] conv4 needs backward computation.
I0708 11:02:16.854041 31135 net.cpp:229] relu3 needs backward computation.
I0708 11:02:16.854043 31135 net.cpp:229] conv3 needs backward computation.
I0708 11:02:16.854045 31135 net.cpp:231] pool1 does not need backward computation.
I0708 11:02:16.854048 31135 net.cpp:231] label does not need backward computation.
I0708 11:02:16.854049 31135 net.cpp:231] data does not need backward computation.
I0708 11:02:16.854050 31135 net.cpp:273] This network produces output loss
I0708 11:02:16.854058 31135 net.cpp:286] Network initialization done.
I0708 11:02:16.854827 31135 solver.cpp:187] Creating test net (#0) specified by net file: train_val.prototxt
I0708 11:02:16.854873 31135 net.cpp:325] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0708 11:02:16.854888 31135 net.cpp:325] The NetState phase (1) differed from the phase (0) specified by a rule in layer label
I0708 11:02:16.854984 31135 net.cpp:52] Initializing net from parameters:
state {
phase: TEST
}
layer {
name: "data"
type: "Data"
top: "data"
include {
phase: TEST
}
transform_param {
mean_file: "/home/ffw/scratch/plantClef/scatnet_output/train/a4_m2_s1s2_f2/lmdb_mean_coeff.binaryproto"
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/test/a4_m2_s1s2_f2/lmdb_data"
batch_size: 32
backend: LMDB
}
}
layer {
name: "label"
type: "Data"
top: "label"
include {
phase: TEST
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/test/a4_m2_s1s2_f2/lmdb_labels"
batch_size: 32
backend: LMDB
}
}
layer {
name: "pool1"
type: "Pooling"
bottom: "data"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 6
stride: 5
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool1"
top: "conv3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "conv4"
type: "Convolution"
bottom: "conv3"
top: "conv4"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu4"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "conv5"
type: "Convolution"
bottom: "conv4"
top: "conv5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
group: 1
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "conv5"
top: "conv5"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "conv5"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fc6"
type: "InnerProduct"
bottom: "pool5"
top: "fc6"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "fc6"
top: "fc6"
}
layer {
name: "drop6"
type: "Dropout"
bottom: "fc6"
top: "fc6"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc7"
type: "InnerProduct"
bottom: "fc6"
top: "fc7"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "fc7"
top: "fc7"
}
layer {
name: "drop7"
type: "Dropout"
bottom: "fc7"
top: "fc7"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc8_species"
type: "InnerProduct"
bottom: "fc7"
top: "fc8_species"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 967
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "fc8_species"
bottom: "label"
top: "loss"
}
layer {
name: "accuracy"
type: "Accuracy"
bottom: "fc8_species"
bottom: "label"
top: "accuracy"
include {
phase: TEST
}
}
I0708 11:02:16.855046 31135 layer_factory.hpp:76] Creating layer data
I0708 11:02:16.855098 31135 net.cpp:109] Creating Layer data
I0708 11:02:16.855111 31135 net.cpp:414] data -> data
I0708 11:02:16.855116 31135 data_transformer.cpp:25] Loading mean file from: /home/ffw/scratch/plantClef/scatnet_output/train/a4_m2_s1s2_f2/lmdb_mean_coeff.binaryproto
I0708 11:02:16.856495 31151 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/test/a4_m2_s1s2_f2/lmdb_data
I0708 11:02:16.864384 31135 data_layer.cpp:45] output data size: 32,75,105,105
I0708 11:02:16.975829 31135 net.cpp:153] Setting up data
I0708 11:02:16.975849 31135 net.cpp:160] Top shape: 32 75 105 105 (26460000)
I0708 11:02:16.975852 31135 net.cpp:168] Memory required for data: 105840000
I0708 11:02:16.975857 31135 layer_factory.hpp:76] Creating layer label
I0708 11:02:16.975900 31135 net.cpp:109] Creating Layer label
I0708 11:02:16.975915 31135 net.cpp:414] label -> label
I0708 11:02:16.979583 31153 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/test/a4_m2_s1s2_f2/lmdb_labels
I0708 11:02:16.986261 31135 data_layer.cpp:45] output data size: 32,1,1,1
I0708 11:02:16.986433 31135 net.cpp:153] Setting up label
I0708 11:02:16.986443 31135 net.cpp:160] Top shape: 32 1 1 1 (32)
I0708 11:02:16.986445 31135 net.cpp:168] Memory required for data: 105840128
I0708 11:02:16.986449 31135 layer_factory.hpp:76] Creating layer label_label_0_split
I0708 11:02:16.986460 31135 net.cpp:109] Creating Layer label_label_0_split
I0708 11:02:16.986464 31135 net.cpp:457] label_label_0_split <- label
I0708 11:02:16.986467 31135 net.cpp:414] label_label_0_split -> label_label_0_split_0
I0708 11:02:16.986474 31135 net.cpp:414] label_label_0_split -> label_label_0_split_1
I0708 11:02:16.986570 31135 net.cpp:153] Setting up label_label_0_split
I0708 11:02:16.986579 31135 net.cpp:160] Top shape: 32 1 1 1 (32)
I0708 11:02:16.986582 31135 net.cpp:160] Top shape: 32 1 1 1 (32)
I0708 11:02:16.986584 31135 net.cpp:168] Memory required for data: 105840384
I0708 11:02:16.986587 31135 layer_factory.hpp:76] Creating layer pool1
I0708 11:02:16.986593 31135 net.cpp:109] Creating Layer pool1
I0708 11:02:16.986595 31135 net.cpp:457] pool1 <- data
I0708 11:02:16.986598 31135 net.cpp:414] pool1 -> pool1
I0708 11:02:16.986624 31135 net.cpp:153] Setting up pool1
I0708 11:02:16.986627 31135 net.cpp:160] Top shape: 32 75 21 21 (1058400)
I0708 11:02:16.986629 31135 net.cpp:168] Memory required for data: 110073984
I0708 11:02:16.986631 31135 layer_factory.hpp:76] Creating layer conv3
I0708 11:02:16.986637 31135 net.cpp:109] Creating Layer conv3
I0708 11:02:16.986640 31135 net.cpp:457] conv3 <- pool1
I0708 11:02:16.986644 31135 net.cpp:414] conv3 -> conv3
I0708 11:02:16.992331 31135 net.cpp:153] Setting up conv3
I0708 11:02:16.992349 31135 net.cpp:160] Top shape: 32 384 21 21 (5419008)
I0708 11:02:16.992352 31135 net.cpp:168] Memory required for data: 131750016
I0708 11:02:16.992359 31135 layer_factory.hpp:76] Creating layer relu3
I0708 11:02:16.992367 31135 net.cpp:109] Creating Layer relu3
I0708 11:02:16.992368 31135 net.cpp:457] relu3 <- conv3
I0708 11:02:16.992372 31135 net.cpp:400] relu3 -> conv3 (in-place)
I0708 11:02:16.992378 31135 net.cpp:153] Setting up relu3
I0708 11:02:16.992380 31135 net.cpp:160] Top shape: 32 384 21 21 (5419008)
I0708 11:02:16.992383 31135 net.cpp:168] Memory required for data: 153426048
I0708 11:02:16.992384 31135 layer_factory.hpp:76] Creating layer conv4
I0708 11:02:16.992389 31135 net.cpp:109] Creating Layer conv4
I0708 11:02:16.992391 31135 net.cpp:457] conv4 <- conv3
I0708 11:02:16.992393 31135 net.cpp:414] conv4 -> conv4
I0708 11:02:17.006024 31135 net.cpp:153] Setting up conv4
I0708 11:02:17.006042 31135 net.cpp:160] Top shape: 32 384 21 21 (5419008)
I0708 11:02:17.006044 31135 net.cpp:168] Memory required for data: 175102080
I0708 11:02:17.006052 31135 layer_factory.hpp:76] Creating layer relu4
I0708 11:02:17.006058 31135 net.cpp:109] Creating Layer relu4
I0708 11:02:17.006062 31135 net.cpp:457] relu4 <- conv4
I0708 11:02:17.006065 31135 net.cpp:400] relu4 -> conv4 (in-place)
I0708 11:02:17.006070 31135 net.cpp:153] Setting up relu4
I0708 11:02:17.006073 31135 net.cpp:160] Top shape: 32 384 21 21 (5419008)
I0708 11:02:17.006074 31135 net.cpp:168] Memory required for data: 196778112
I0708 11:02:17.006077 31135 layer_factory.hpp:76] Creating layer conv5
I0708 11:02:17.006083 31135 net.cpp:109] Creating Layer conv5
I0708 11:02:17.006084 31135 net.cpp:457] conv5 <- conv4
I0708 11:02:17.006088 31135 net.cpp:414] conv5 -> conv5
I0708 11:02:17.024103 31135 net.cpp:153] Setting up conv5
I0708 11:02:17.024119 31135 net.cpp:160] Top shape: 32 256 21 21 (3612672)
I0708 11:02:17.024121 31135 net.cpp:168] Memory required for data: 211228800
I0708 11:02:17.024128 31135 layer_factory.hpp:76] Creating layer relu5
I0708 11:02:17.024134 31135 net.cpp:109] Creating Layer relu5
I0708 11:02:17.024137 31135 net.cpp:457] relu5 <- conv5
I0708 11:02:17.024142 31135 net.cpp:400] relu5 -> conv5 (in-place)
I0708 11:02:17.024163 31135 net.cpp:153] Setting up relu5
I0708 11:02:17.024165 31135 net.cpp:160] Top shape: 32 256 21 21 (3612672)
I0708 11:02:17.024166 31135 net.cpp:168] Memory required for data: 225679488
I0708 11:02:17.024168 31135 layer_factory.hpp:76] Creating layer pool5
I0708 11:02:17.024173 31135 net.cpp:109] Creating Layer pool5
I0708 11:02:17.024174 31135 net.cpp:457] pool5 <- conv5
I0708 11:02:17.024176 31135 net.cpp:414] pool5 -> pool5
I0708 11:02:17.024199 31135 net.cpp:153] Setting up pool5
I0708 11:02:17.024202 31135 net.cpp:160] Top shape: 32 256 10 10 (819200)
I0708 11:02:17.024204 31135 net.cpp:168] Memory required for data: 228956288
I0708 11:02:17.024205 31135 layer_factory.hpp:76] Creating layer fc6
I0708 11:02:17.024209 31135 net.cpp:109] Creating Layer fc6
I0708 11:02:17.024211 31135 net.cpp:457] fc6 <- pool5
I0708 11:02:17.024214 31135 net.cpp:414] fc6 -> fc6
I0708 11:02:17.173118 31152 blocking_queue.cpp:50] Waiting for data
I0708 11:02:18.991767 31135 net.cpp:153] Setting up fc6
I0708 11:02:18.991786 31135 net.cpp:160] Top shape: 32 4096 (131072)
I0708 11:02:18.991789 31135 net.cpp:168] Memory required for data: 229480576
I0708 11:02:18.991796 31135 layer_factory.hpp:76] Creating layer relu6
I0708 11:02:18.991803 31135 net.cpp:109] Creating Layer relu6
I0708 11:02:18.991806 31135 net.cpp:457] relu6 <- fc6
I0708 11:02:18.991809 31135 net.cpp:400] relu6 -> fc6 (in-place)
I0708 11:02:18.991816 31135 net.cpp:153] Setting up relu6
I0708 11:02:18.991818 31135 net.cpp:160] Top shape: 32 4096 (131072)
I0708 11:02:18.991821 31135 net.cpp:168] Memory required for data: 230004864
I0708 11:02:18.991822 31135 layer_factory.hpp:76] Creating layer drop6
I0708 11:02:18.991827 31135 net.cpp:109] Creating Layer drop6
I0708 11:02:18.991828 31135 net.cpp:457] drop6 <- fc6
I0708 11:02:18.991830 31135 net.cpp:400] drop6 -> fc6 (in-place)
I0708 11:02:18.991849 31135 net.cpp:153] Setting up drop6
I0708 11:02:18.991852 31135 net.cpp:160] Top shape: 32 4096 (131072)
I0708 11:02:18.991854 31135 net.cpp:168] Memory required for data: 230529152
I0708 11:02:18.991857 31135 layer_factory.hpp:76] Creating layer fc7
I0708 11:02:18.991860 31135 net.cpp:109] Creating Layer fc7
I0708 11:02:18.991863 31135 net.cpp:457] fc7 <- fc6
I0708 11:02:18.991865 31135 net.cpp:414] fc7 -> fc7
I0708 11:02:19.300149 31135 net.cpp:153] Setting up fc7
I0708 11:02:19.300168 31135 net.cpp:160] Top shape: 32 4096 (131072)
I0708 11:02:19.300171 31135 net.cpp:168] Memory required for data: 231053440
I0708 11:02:19.300180 31135 layer_factory.hpp:76] Creating layer relu7
I0708 11:02:19.300187 31135 net.cpp:109] Creating Layer relu7
I0708 11:02:19.300190 31135 net.cpp:457] relu7 <- fc7
I0708 11:02:19.300194 31135 net.cpp:400] relu7 -> fc7 (in-place)
I0708 11:02:19.300200 31135 net.cpp:153] Setting up relu7
I0708 11:02:19.300204 31135 net.cpp:160] Top shape: 32 4096 (131072)
I0708 11:02:19.300205 31135 net.cpp:168] Memory required for data: 231577728
I0708 11:02:19.300206 31135 layer_factory.hpp:76] Creating layer drop7
I0708 11:02:19.300212 31135 net.cpp:109] Creating Layer drop7
I0708 11:02:19.300215 31135 net.cpp:457] drop7 <- fc7
I0708 11:02:19.300217 31135 net.cpp:400] drop7 -> fc7 (in-place)
I0708 11:02:19.300236 31135 net.cpp:153] Setting up drop7
I0708 11:02:19.300240 31135 net.cpp:160] Top shape: 32 4096 (131072)
I0708 11:02:19.300241 31135 net.cpp:168] Memory required for data: 232102016
I0708 11:02:19.300242 31135 layer_factory.hpp:76] Creating layer fc8_species
I0708 11:02:19.300247 31135 net.cpp:109] Creating Layer fc8_species
I0708 11:02:19.300249 31135 net.cpp:457] fc8_species <- fc7
I0708 11:02:19.300252 31135 net.cpp:414] fc8_species -> fc8_species
I0708 11:02:19.373409 31135 net.cpp:153] Setting up fc8_species
I0708 11:02:19.373427 31135 net.cpp:160] Top shape: 32 967 (30944)
I0708 11:02:19.373430 31135 net.cpp:168] Memory required for data: 232225792
I0708 11:02:19.373435 31135 layer_factory.hpp:76] Creating layer fc8_species_fc8_species_0_split
I0708 11:02:19.373441 31135 net.cpp:109] Creating Layer fc8_species_fc8_species_0_split
I0708 11:02:19.373461 31135 net.cpp:457] fc8_species_fc8_species_0_split <- fc8_species
I0708 11:02:19.373466 31135 net.cpp:414] fc8_species_fc8_species_0_split -> fc8_species_fc8_species_0_split_0
I0708 11:02:19.373471 31135 net.cpp:414] fc8_species_fc8_species_0_split -> fc8_species_fc8_species_0_split_1
I0708 11:02:19.373500 31135 net.cpp:153] Setting up fc8_species_fc8_species_0_split
I0708 11:02:19.373503 31135 net.cpp:160] Top shape: 32 967 (30944)
I0708 11:02:19.373505 31135 net.cpp:160] Top shape: 32 967 (30944)
I0708 11:02:19.373507 31135 net.cpp:168] Memory required for data: 232473344
I0708 11:02:19.373509 31135 layer_factory.hpp:76] Creating layer loss
I0708 11:02:19.373512 31135 net.cpp:109] Creating Layer loss
I0708 11:02:19.373514 31135 net.cpp:457] loss <- fc8_species_fc8_species_0_split_0
I0708 11:02:19.373517 31135 net.cpp:457] loss <- label_label_0_split_0
I0708 11:02:19.373519 31135 net.cpp:414] loss -> loss
I0708 11:02:19.373523 31135 layer_factory.hpp:76] Creating layer loss
I0708 11:02:19.373610 31135 net.cpp:153] Setting up loss
I0708 11:02:19.373615 31135 net.cpp:160] Top shape: (1)
I0708 11:02:19.373615 31135 net.cpp:163]     with loss weight 1
I0708 11:02:19.373622 31135 net.cpp:168] Memory required for data: 232473348
I0708 11:02:19.373625 31135 layer_factory.hpp:76] Creating layer accuracy
I0708 11:02:19.373628 31135 net.cpp:109] Creating Layer accuracy
I0708 11:02:19.373631 31135 net.cpp:457] accuracy <- fc8_species_fc8_species_0_split_1
I0708 11:02:19.373632 31135 net.cpp:457] accuracy <- label_label_0_split_1
I0708 11:02:19.373636 31135 net.cpp:414] accuracy -> accuracy
I0708 11:02:19.373639 31135 net.cpp:153] Setting up accuracy
I0708 11:02:19.373641 31135 net.cpp:160] Top shape: (1)
I0708 11:02:19.373643 31135 net.cpp:168] Memory required for data: 232473352
I0708 11:02:19.373644 31135 net.cpp:231] accuracy does not need backward computation.
I0708 11:02:19.373646 31135 net.cpp:229] loss needs backward computation.
I0708 11:02:19.373649 31135 net.cpp:229] fc8_species_fc8_species_0_split needs backward computation.
I0708 11:02:19.373651 31135 net.cpp:229] fc8_species needs backward computation.
I0708 11:02:19.373652 31135 net.cpp:229] drop7 needs backward computation.
I0708 11:02:19.373654 31135 net.cpp:229] relu7 needs backward computation.
I0708 11:02:19.373656 31135 net.cpp:229] fc7 needs backward computation.
I0708 11:02:19.373658 31135 net.cpp:229] drop6 needs backward computation.
I0708 11:02:19.373659 31135 net.cpp:229] relu6 needs backward computation.
I0708 11:02:19.373661 31135 net.cpp:229] fc6 needs backward computation.
I0708 11:02:19.373663 31135 net.cpp:229] pool5 needs backward computation.
I0708 11:02:19.373666 31135 net.cpp:229] relu5 needs backward computation.
I0708 11:02:19.373667 31135 net.cpp:229] conv5 needs backward computation.
I0708 11:02:19.373669 31135 net.cpp:229] relu4 needs backward computation.
I0708 11:02:19.373672 31135 net.cpp:229] conv4 needs backward computation.
I0708 11:02:19.373672 31135 net.cpp:229] relu3 needs backward computation.
I0708 11:02:19.373674 31135 net.cpp:229] conv3 needs backward computation.
I0708 11:02:19.373677 31135 net.cpp:231] pool1 does not need backward computation.
I0708 11:02:19.373678 31135 net.cpp:231] label_label_0_split does not need backward computation.
I0708 11:02:19.373682 31135 net.cpp:231] label does not need backward computation.
I0708 11:02:19.373682 31135 net.cpp:231] data does not need backward computation.
I0708 11:02:19.373684 31135 net.cpp:273] This network produces output accuracy
I0708 11:02:19.373685 31135 net.cpp:273] This network produces output loss
I0708 11:02:19.373693 31135 net.cpp:286] Network initialization done.
I0708 11:02:19.373740 31135 solver.cpp:66] Solver scaffolding done.
I0708 11:02:19.373986 31135 caffe.cpp:220] Starting Optimization
I0708 11:02:19.373991 31135 solver.cpp:294] Solving
I0708 11:02:19.373992 31135 solver.cpp:295] Learning Rate Policy: exp
I0708 11:02:19.374976 31135 solver.cpp:347] Iteration 0, Testing net (#0)
I0708 11:02:19.721787 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 11:02:41.801995 31135 solver.cpp:415]     Test net output #0: accuracy = 0.000120192
I0708 11:02:41.802026 31135 solver.cpp:415]     Test net output #1: loss = 6.87511 (* 1 = 6.87511 loss)
I0708 11:02:41.910207 31135 solver.cpp:243] Iteration 0, loss = 6.88175
I0708 11:02:41.910269 31135 solver.cpp:259]     Train net output #0: loss = 6.88175 (* 1 = 6.88175 loss)
I0708 11:02:41.910310 31135 solver.cpp:590] Iteration 0, lr = 0.01
I0708 11:03:04.571660 31135 solver.cpp:243] Iteration 110, loss = 6.62686
I0708 11:03:04.571888 31135 solver.cpp:259]     Train net output #0: loss = 6.62686 (* 1 = 6.62686 loss)
I0708 11:03:04.571895 31135 solver.cpp:590] Iteration 110, lr = 0.00990401
I0708 11:03:27.215538 31135 solver.cpp:243] Iteration 220, loss = 6.6511
I0708 11:03:27.215560 31135 solver.cpp:259]     Train net output #0: loss = 6.6511 (* 1 = 6.6511 loss)
I0708 11:03:27.215565 31135 solver.cpp:590] Iteration 220, lr = 0.00980895
I0708 11:03:49.839555 31135 solver.cpp:243] Iteration 330, loss = 6.72103
I0708 11:03:49.839645 31135 solver.cpp:259]     Train net output #0: loss = 6.72103 (* 1 = 6.72103 loss)
I0708 11:03:49.839661 31135 solver.cpp:590] Iteration 330, lr = 0.00971479
I0708 11:04:12.498790 31135 solver.cpp:243] Iteration 440, loss = 6.26062
I0708 11:04:12.498813 31135 solver.cpp:259]     Train net output #0: loss = 6.26062 (* 1 = 6.26062 loss)
I0708 11:04:12.498818 31135 solver.cpp:590] Iteration 440, lr = 0.00962154
I0708 11:04:35.139403 31135 solver.cpp:243] Iteration 550, loss = 6.25948
I0708 11:04:35.139489 31135 solver.cpp:259]     Train net output #0: loss = 6.25948 (* 1 = 6.25948 loss)
I0708 11:04:35.139495 31135 solver.cpp:590] Iteration 550, lr = 0.00952919
I0708 11:04:57.780273 31135 solver.cpp:243] Iteration 660, loss = 6.59959
I0708 11:04:57.780297 31135 solver.cpp:259]     Train net output #0: loss = 6.59959 (* 1 = 6.59959 loss)
I0708 11:04:57.780303 31135 solver.cpp:590] Iteration 660, lr = 0.00943772
I0708 11:05:20.410869 31135 solver.cpp:243] Iteration 770, loss = 6.41187
I0708 11:05:20.410964 31135 solver.cpp:259]     Train net output #0: loss = 6.41187 (* 1 = 6.41187 loss)
I0708 11:05:20.410970 31135 solver.cpp:590] Iteration 770, lr = 0.00934713
I0708 11:05:43.043308 31135 solver.cpp:243] Iteration 880, loss = 6.35424
I0708 11:05:43.043329 31135 solver.cpp:259]     Train net output #0: loss = 6.35424 (* 1 = 6.35424 loss)
I0708 11:05:43.043334 31135 solver.cpp:590] Iteration 880, lr = 0.00925741
I0708 11:05:43.248414 31135 solver.cpp:347] Iteration 882, Testing net (#0)
I0708 11:06:06.318819 31135 solver.cpp:415]     Test net output #0: accuracy = 0.015024
I0708 11:06:06.318897 31135 solver.cpp:415]     Test net output #1: loss = 6.22257 (* 1 = 6.22257 loss)
I0708 11:06:28.710124 31135 solver.cpp:243] Iteration 990, loss = 6.43498
I0708 11:06:28.710149 31135 solver.cpp:259]     Train net output #0: loss = 6.43498 (* 1 = 6.43498 loss)
I0708 11:06:28.710155 31135 solver.cpp:590] Iteration 990, lr = 0.00916855
I0708 11:06:51.379631 31135 solver.cpp:243] Iteration 1100, loss = 6.5181
I0708 11:06:51.379714 31135 solver.cpp:259]     Train net output #0: loss = 6.5181 (* 1 = 6.5181 loss)
I0708 11:06:51.379731 31135 solver.cpp:590] Iteration 1100, lr = 0.00908055
I0708 11:07:14.021469 31135 solver.cpp:243] Iteration 1210, loss = 6.09256
I0708 11:07:14.021494 31135 solver.cpp:259]     Train net output #0: loss = 6.09256 (* 1 = 6.09256 loss)
I0708 11:07:14.021502 31135 solver.cpp:590] Iteration 1210, lr = 0.00899339
I0708 11:07:36.633400 31135 solver.cpp:243] Iteration 1320, loss = 6.10041
I0708 11:07:36.633481 31135 solver.cpp:259]     Train net output #0: loss = 6.10041 (* 1 = 6.10041 loss)
I0708 11:07:36.633496 31135 solver.cpp:590] Iteration 1320, lr = 0.00890706
I0708 11:07:59.252892 31135 solver.cpp:243] Iteration 1430, loss = 5.76638
I0708 11:07:59.252915 31135 solver.cpp:259]     Train net output #0: loss = 5.76638 (* 1 = 5.76638 loss)
I0708 11:07:59.252920 31135 solver.cpp:590] Iteration 1430, lr = 0.00882157
I0708 11:08:21.898109 31135 solver.cpp:243] Iteration 1540, loss = 5.82551
I0708 11:08:21.898214 31135 solver.cpp:259]     Train net output #0: loss = 5.82551 (* 1 = 5.82551 loss)
I0708 11:08:21.898221 31135 solver.cpp:590] Iteration 1540, lr = 0.00873689
I0708 11:08:44.529232 31135 solver.cpp:243] Iteration 1650, loss = 5.77762
I0708 11:08:44.529254 31135 solver.cpp:259]     Train net output #0: loss = 5.77762 (* 1 = 5.77762 loss)
I0708 11:08:44.529260 31135 solver.cpp:590] Iteration 1650, lr = 0.00865303
I0708 11:09:07.151311 31135 solver.cpp:243] Iteration 1760, loss = 6.11701
I0708 11:09:07.151618 31135 solver.cpp:259]     Train net output #0: loss = 6.11701 (* 1 = 6.11701 loss)
I0708 11:09:07.151625 31135 solver.cpp:590] Iteration 1760, lr = 0.00856997
I0708 11:09:07.771200 31135 solver.cpp:347] Iteration 1764, Testing net (#0)
I0708 11:09:31.132393 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0313702
I0708 11:09:31.132419 31135 solver.cpp:415]     Test net output #1: loss = 5.87114 (* 1 = 5.87114 loss)
I0708 11:09:53.089473 31135 solver.cpp:243] Iteration 1870, loss = 5.81918
I0708 11:09:53.089562 31135 solver.cpp:259]     Train net output #0: loss = 5.81918 (* 1 = 5.81918 loss)
I0708 11:09:53.089579 31135 solver.cpp:590] Iteration 1870, lr = 0.00848771
I0708 11:10:15.722030 31135 solver.cpp:243] Iteration 1980, loss = 5.82712
I0708 11:10:15.722053 31135 solver.cpp:259]     Train net output #0: loss = 5.82712 (* 1 = 5.82712 loss)
I0708 11:10:15.722059 31135 solver.cpp:590] Iteration 1980, lr = 0.00840624
I0708 11:10:38.345628 31135 solver.cpp:243] Iteration 2090, loss = 6.12111
I0708 11:10:38.346011 31135 solver.cpp:259]     Train net output #0: loss = 6.12111 (* 1 = 6.12111 loss)
I0708 11:10:38.346019 31135 solver.cpp:590] Iteration 2090, lr = 0.00832555
I0708 11:11:01.011142 31135 solver.cpp:243] Iteration 2200, loss = 6.13751
I0708 11:11:01.011165 31135 solver.cpp:259]     Train net output #0: loss = 6.13751 (* 1 = 6.13751 loss)
I0708 11:11:01.011171 31135 solver.cpp:590] Iteration 2200, lr = 0.00824564
I0708 11:11:23.643128 31135 solver.cpp:243] Iteration 2310, loss = 5.64218
I0708 11:11:23.643333 31135 solver.cpp:259]     Train net output #0: loss = 5.64218 (* 1 = 5.64218 loss)
I0708 11:11:23.643352 31135 solver.cpp:590] Iteration 2310, lr = 0.00816649
I0708 11:11:46.265302 31135 solver.cpp:243] Iteration 2420, loss = 5.59243
I0708 11:11:46.265327 31135 solver.cpp:259]     Train net output #0: loss = 5.59243 (* 1 = 5.59243 loss)
I0708 11:11:46.265333 31135 solver.cpp:590] Iteration 2420, lr = 0.0080881
I0708 11:12:08.877291 31135 solver.cpp:243] Iteration 2530, loss = 5.28613
I0708 11:12:08.877673 31135 solver.cpp:259]     Train net output #0: loss = 5.28613 (* 1 = 5.28613 loss)
I0708 11:12:08.877681 31135 solver.cpp:590] Iteration 2530, lr = 0.00801047
I0708 11:12:31.516805 31135 solver.cpp:243] Iteration 2640, loss = 5.50653
I0708 11:12:31.516829 31135 solver.cpp:259]     Train net output #0: loss = 5.50653 (* 1 = 5.50653 loss)
I0708 11:12:31.516835 31135 solver.cpp:590] Iteration 2640, lr = 0.00793358
I0708 11:12:32.545372 31135 solver.cpp:347] Iteration 2646, Testing net (#0)
I0708 11:12:52.945932 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 11:12:54.670538 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0382212
I0708 11:12:54.670564 31135 solver.cpp:415]     Test net output #1: loss = 5.7017 (* 1 = 5.7017 loss)
I0708 11:13:16.224663 31135 solver.cpp:243] Iteration 2750, loss = 5.35555
I0708 11:13:16.224687 31135 solver.cpp:259]     Train net output #0: loss = 5.35555 (* 1 = 5.35555 loss)
I0708 11:13:16.224694 31135 solver.cpp:590] Iteration 2750, lr = 0.00785742
I0708 11:13:38.861379 31135 solver.cpp:243] Iteration 2860, loss = 5.33141
I0708 11:13:38.861469 31135 solver.cpp:259]     Train net output #0: loss = 5.33141 (* 1 = 5.33141 loss)
I0708 11:13:38.861485 31135 solver.cpp:590] Iteration 2860, lr = 0.007782
I0708 11:14:01.460300 31135 solver.cpp:243] Iteration 2970, loss = 5.65968
I0708 11:14:01.460328 31135 solver.cpp:259]     Train net output #0: loss = 5.65968 (* 1 = 5.65968 loss)
I0708 11:14:01.460335 31135 solver.cpp:590] Iteration 2970, lr = 0.00770731
I0708 11:14:24.054779 31135 solver.cpp:243] Iteration 3080, loss = 5.37764
I0708 11:14:24.054879 31135 solver.cpp:259]     Train net output #0: loss = 5.37764 (* 1 = 5.37764 loss)
I0708 11:14:24.054885 31135 solver.cpp:590] Iteration 3080, lr = 0.00763333
I0708 11:14:46.692085 31135 solver.cpp:243] Iteration 3190, loss = 5.49171
I0708 11:14:46.692107 31135 solver.cpp:259]     Train net output #0: loss = 5.49171 (* 1 = 5.49171 loss)
I0708 11:14:46.692113 31135 solver.cpp:590] Iteration 3190, lr = 0.00756006
I0708 11:15:09.337620 31135 solver.cpp:243] Iteration 3300, loss = 5.49649
I0708 11:15:09.337895 31135 solver.cpp:259]     Train net output #0: loss = 5.49649 (* 1 = 5.49649 loss)
I0708 11:15:09.337904 31135 solver.cpp:590] Iteration 3300, lr = 0.00748749
I0708 11:15:31.914916 31135 solver.cpp:243] Iteration 3410, loss = 4.92887
I0708 11:15:31.914937 31135 solver.cpp:259]     Train net output #0: loss = 4.92887 (* 1 = 4.92887 loss)
I0708 11:15:31.914942 31135 solver.cpp:590] Iteration 3410, lr = 0.00741562
I0708 11:15:54.512907 31135 solver.cpp:243] Iteration 3520, loss = 4.86892
I0708 11:15:54.512990 31135 solver.cpp:259]     Train net output #0: loss = 4.86892 (* 1 = 4.86892 loss)
I0708 11:15:54.512997 31135 solver.cpp:590] Iteration 3520, lr = 0.00734444
I0708 11:15:55.953176 31135 solver.cpp:347] Iteration 3528, Testing net (#0)
I0708 11:16:20.579571 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0555288
I0708 11:16:20.579597 31135 solver.cpp:415]     Test net output #1: loss = 5.36832 (* 1 = 5.36832 loss)
I0708 11:16:41.699535 31135 solver.cpp:243] Iteration 3630, loss = 5.19961
I0708 11:16:41.699651 31135 solver.cpp:259]     Train net output #0: loss = 5.19961 (* 1 = 5.19961 loss)
I0708 11:16:41.699657 31135 solver.cpp:590] Iteration 3630, lr = 0.00727394
I0708 11:17:04.329692 31135 solver.cpp:243] Iteration 3740, loss = 5.18043
I0708 11:17:04.329715 31135 solver.cpp:259]     Train net output #0: loss = 5.18043 (* 1 = 5.18043 loss)
I0708 11:17:04.329721 31135 solver.cpp:590] Iteration 3740, lr = 0.00720412
I0708 11:17:26.973790 31135 solver.cpp:243] Iteration 3850, loss = 4.66713
I0708 11:17:26.973883 31135 solver.cpp:259]     Train net output #0: loss = 4.66713 (* 1 = 4.66713 loss)
I0708 11:17:26.973899 31135 solver.cpp:590] Iteration 3850, lr = 0.00713497
I0708 11:17:49.582418 31135 solver.cpp:243] Iteration 3960, loss = 4.87564
I0708 11:17:49.582442 31135 solver.cpp:259]     Train net output #0: loss = 4.87564 (* 1 = 4.87564 loss)
I0708 11:17:49.582448 31135 solver.cpp:590] Iteration 3960, lr = 0.00706649
I0708 11:18:12.190601 31135 solver.cpp:243] Iteration 4070, loss = 5.21003
I0708 11:18:12.190687 31135 solver.cpp:259]     Train net output #0: loss = 5.21003 (* 1 = 5.21003 loss)
I0708 11:18:12.190693 31135 solver.cpp:590] Iteration 4070, lr = 0.00699866
I0708 11:18:34.803237 31135 solver.cpp:243] Iteration 4180, loss = 5.03899
I0708 11:18:34.803262 31135 solver.cpp:259]     Train net output #0: loss = 5.03899 (* 1 = 5.03899 loss)
I0708 11:18:34.803268 31135 solver.cpp:590] Iteration 4180, lr = 0.00693148
I0708 11:18:57.450610 31135 solver.cpp:243] Iteration 4290, loss = 4.9489
I0708 11:18:57.450701 31135 solver.cpp:259]     Train net output #0: loss = 4.9489 (* 1 = 4.9489 loss)
I0708 11:18:57.450707 31135 solver.cpp:590] Iteration 4290, lr = 0.00686495
I0708 11:19:20.084197 31135 solver.cpp:243] Iteration 4400, loss = 4.03498
I0708 11:19:20.084221 31135 solver.cpp:259]     Train net output #0: loss = 4.03498 (* 1 = 4.03498 loss)
I0708 11:19:20.084229 31135 solver.cpp:590] Iteration 4400, lr = 0.00679905
I0708 11:19:21.938190 31135 solver.cpp:347] Iteration 4410, Testing net (#0)
I0708 11:19:46.365361 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0591346
I0708 11:19:46.365452 31135 solver.cpp:415]     Test net output #1: loss = 5.36935 (* 1 = 5.36935 loss)
I0708 11:20:07.094276 31135 solver.cpp:243] Iteration 4510, loss = 4.35892
I0708 11:20:07.094298 31135 solver.cpp:259]     Train net output #0: loss = 4.35892 (* 1 = 4.35892 loss)
I0708 11:20:07.094303 31135 solver.cpp:590] Iteration 4510, lr = 0.00673379
I0708 11:20:29.701947 31135 solver.cpp:243] Iteration 4620, loss = 5.15561
I0708 11:20:29.702055 31135 solver.cpp:259]     Train net output #0: loss = 5.15561 (* 1 = 5.15561 loss)
I0708 11:20:29.702074 31135 solver.cpp:590] Iteration 4620, lr = 0.00666915
I0708 11:20:52.332782 31135 solver.cpp:243] Iteration 4730, loss = 5.11979
I0708 11:20:52.332803 31135 solver.cpp:259]     Train net output #0: loss = 5.11979 (* 1 = 5.11979 loss)
I0708 11:20:52.332808 31135 solver.cpp:590] Iteration 4730, lr = 0.00660514
I0708 11:21:14.983109 31135 solver.cpp:243] Iteration 4840, loss = 4.75312
I0708 11:21:14.983361 31135 solver.cpp:259]     Train net output #0: loss = 4.75312 (* 1 = 4.75312 loss)
I0708 11:21:14.983371 31135 solver.cpp:590] Iteration 4840, lr = 0.00654174
I0708 11:21:37.607692 31135 solver.cpp:243] Iteration 4950, loss = 5.0324
I0708 11:21:37.607714 31135 solver.cpp:259]     Train net output #0: loss = 5.0324 (* 1 = 5.0324 loss)
I0708 11:21:37.607720 31135 solver.cpp:590] Iteration 4950, lr = 0.00647895
I0708 11:22:00.241420 31135 solver.cpp:243] Iteration 5060, loss = 4.44571
I0708 11:22:00.241752 31135 solver.cpp:259]     Train net output #0: loss = 4.44571 (* 1 = 4.44571 loss)
I0708 11:22:00.241760 31135 solver.cpp:590] Iteration 5060, lr = 0.00641676
I0708 11:22:22.858769 31135 solver.cpp:243] Iteration 5170, loss = 4.11541
I0708 11:22:22.858793 31135 solver.cpp:259]     Train net output #0: loss = 4.11541 (* 1 = 4.11541 loss)
I0708 11:22:22.858798 31135 solver.cpp:590] Iteration 5170, lr = 0.00635516
I0708 11:22:45.490396 31135 solver.cpp:243] Iteration 5280, loss = 5.28582
I0708 11:22:45.490737 31135 solver.cpp:259]     Train net output #0: loss = 5.28582 (* 1 = 5.28582 loss)
I0708 11:22:45.490747 31135 solver.cpp:590] Iteration 5280, lr = 0.00629416
I0708 11:22:47.758584 31135 solver.cpp:347] Iteration 5292, Testing net (#0)
I0708 11:23:12.164193 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0664663
I0708 11:23:12.164219 31135 solver.cpp:415]     Test net output #1: loss = 5.29855 (* 1 = 5.29855 loss)
I0708 11:23:32.488927 31135 solver.cpp:243] Iteration 5390, loss = 4.14186
I0708 11:23:32.489194 31135 solver.cpp:259]     Train net output #0: loss = 4.14186 (* 1 = 4.14186 loss)
I0708 11:23:32.489203 31135 solver.cpp:590] Iteration 5390, lr = 0.00623375
I0708 11:23:55.110644 31135 solver.cpp:243] Iteration 5500, loss = 4.82155
I0708 11:23:55.110668 31135 solver.cpp:259]     Train net output #0: loss = 4.82155 (* 1 = 4.82155 loss)
I0708 11:23:55.110674 31135 solver.cpp:590] Iteration 5500, lr = 0.00617391
I0708 11:24:17.734776 31135 solver.cpp:243] Iteration 5610, loss = 4.18761
I0708 11:24:17.735157 31135 solver.cpp:259]     Train net output #0: loss = 4.18761 (* 1 = 4.18761 loss)
I0708 11:24:17.735164 31135 solver.cpp:590] Iteration 5610, lr = 0.00611465
I0708 11:24:40.347059 31135 solver.cpp:243] Iteration 5720, loss = 4.64625
I0708 11:24:40.347084 31135 solver.cpp:259]     Train net output #0: loss = 4.64625 (* 1 = 4.64625 loss)
I0708 11:24:40.347090 31135 solver.cpp:590] Iteration 5720, lr = 0.00605596
I0708 11:25:02.974334 31135 solver.cpp:243] Iteration 5830, loss = 4.48348
I0708 11:25:02.974709 31135 solver.cpp:259]     Train net output #0: loss = 4.48348 (* 1 = 4.48348 loss)
I0708 11:25:02.974717 31135 solver.cpp:590] Iteration 5830, lr = 0.00599783
I0708 11:25:25.587661 31135 solver.cpp:243] Iteration 5940, loss = 3.87091
I0708 11:25:25.587682 31135 solver.cpp:259]     Train net output #0: loss = 3.87091 (* 1 = 3.87091 loss)
I0708 11:25:25.587687 31135 solver.cpp:590] Iteration 5940, lr = 0.00594026
I0708 11:25:48.226398 31135 solver.cpp:243] Iteration 6050, loss = 3.90396
I0708 11:25:48.235683 31135 solver.cpp:259]     Train net output #0: loss = 3.90396 (* 1 = 3.90396 loss)
I0708 11:25:48.235692 31135 solver.cpp:590] Iteration 6050, lr = 0.00588324
I0708 11:26:10.851366 31135 solver.cpp:243] Iteration 6160, loss = 4.28722
I0708 11:26:10.851390 31135 solver.cpp:259]     Train net output #0: loss = 4.28722 (* 1 = 4.28722 loss)
I0708 11:26:10.851397 31135 solver.cpp:590] Iteration 6160, lr = 0.00582677
I0708 11:26:13.527307 31135 solver.cpp:347] Iteration 6174, Testing net (#0)
I0708 11:26:29.562587 31152 blocking_queue.cpp:50] Waiting for data
I0708 11:26:32.121876 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 11:26:35.840410 31135 solver.cpp:415]     Test net output #0: accuracy = 0.072476
I0708 11:26:35.840435 31135 solver.cpp:415]     Test net output #1: loss = 5.3579 (* 1 = 5.3579 loss)
I0708 11:26:55.725756 31135 solver.cpp:243] Iteration 6270, loss = 4.12836
I0708 11:26:55.725785 31135 solver.cpp:259]     Train net output #0: loss = 4.12836 (* 1 = 4.12836 loss)
I0708 11:26:55.725792 31135 solver.cpp:590] Iteration 6270, lr = 0.00577084
I0708 11:27:18.343847 31135 solver.cpp:243] Iteration 6380, loss = 4.47165
I0708 11:27:18.344332 31135 solver.cpp:259]     Train net output #0: loss = 4.47165 (* 1 = 4.47165 loss)
I0708 11:27:18.344341 31135 solver.cpp:590] Iteration 6380, lr = 0.00571545
I0708 11:27:40.971622 31135 solver.cpp:243] Iteration 6490, loss = 2.91683
I0708 11:27:40.971647 31135 solver.cpp:259]     Train net output #0: loss = 2.91683 (* 1 = 2.91683 loss)
I0708 11:27:40.971652 31135 solver.cpp:590] Iteration 6490, lr = 0.00566058
I0708 11:28:03.591867 31135 solver.cpp:243] Iteration 6600, loss = 3.37744
I0708 11:28:03.592362 31135 solver.cpp:259]     Train net output #0: loss = 3.37744 (* 1 = 3.37744 loss)
I0708 11:28:03.592380 31135 solver.cpp:590] Iteration 6600, lr = 0.00560625
I0708 11:28:26.247098 31135 solver.cpp:243] Iteration 6710, loss = 4.2493
I0708 11:28:26.247123 31135 solver.cpp:259]     Train net output #0: loss = 4.2493 (* 1 = 4.2493 loss)
I0708 11:28:26.247128 31135 solver.cpp:590] Iteration 6710, lr = 0.00555244
I0708 11:28:48.873486 31135 solver.cpp:243] Iteration 6820, loss = 3.61592
I0708 11:28:48.873944 31135 solver.cpp:259]     Train net output #0: loss = 3.61592 (* 1 = 3.61592 loss)
I0708 11:28:48.873950 31135 solver.cpp:590] Iteration 6820, lr = 0.00549914
I0708 11:29:11.488009 31135 solver.cpp:243] Iteration 6930, loss = 3.05389
I0708 11:29:11.488037 31135 solver.cpp:259]     Train net output #0: loss = 3.05389 (* 1 = 3.05389 loss)
I0708 11:29:11.488045 31135 solver.cpp:590] Iteration 6930, lr = 0.00544636
I0708 11:29:34.109668 31135 solver.cpp:243] Iteration 7040, loss = 3.18516
I0708 11:29:34.110035 31135 solver.cpp:259]     Train net output #0: loss = 3.18516 (* 1 = 3.18516 loss)
I0708 11:29:34.110044 31135 solver.cpp:590] Iteration 7040, lr = 0.00539408
I0708 11:29:37.190889 31135 solver.cpp:347] Iteration 7056, Testing net (#0)
I0708 11:29:59.451717 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0740385
I0708 11:29:59.451745 31135 solver.cpp:415]     Test net output #1: loss = 5.40385 (* 1 = 5.40385 loss)
I0708 11:30:18.934314 31135 solver.cpp:243] Iteration 7150, loss = 3.61643
I0708 11:30:18.934599 31135 solver.cpp:259]     Train net output #0: loss = 3.61643 (* 1 = 3.61643 loss)
I0708 11:30:18.934607 31135 solver.cpp:590] Iteration 7150, lr = 0.0053423
I0708 11:30:41.574990 31135 solver.cpp:243] Iteration 7260, loss = 4.1014
I0708 11:30:41.575014 31135 solver.cpp:259]     Train net output #0: loss = 4.1014 (* 1 = 4.1014 loss)
I0708 11:30:41.575021 31135 solver.cpp:590] Iteration 7260, lr = 0.00529102
I0708 11:31:04.208905 31135 solver.cpp:243] Iteration 7370, loss = 3.02793
I0708 11:31:04.209275 31135 solver.cpp:259]     Train net output #0: loss = 3.02793 (* 1 = 3.02793 loss)
I0708 11:31:04.209283 31135 solver.cpp:590] Iteration 7370, lr = 0.00524024
I0708 11:31:26.849474 31135 solver.cpp:243] Iteration 7480, loss = 3.85388
I0708 11:31:26.849498 31135 solver.cpp:259]     Train net output #0: loss = 3.85388 (* 1 = 3.85388 loss)
I0708 11:31:26.849503 31135 solver.cpp:590] Iteration 7480, lr = 0.00518994
I0708 11:31:49.451406 31135 solver.cpp:243] Iteration 7590, loss = 3.42498
I0708 11:31:49.451891 31135 solver.cpp:259]     Train net output #0: loss = 3.42498 (* 1 = 3.42498 loss)
I0708 11:31:49.451900 31135 solver.cpp:590] Iteration 7590, lr = 0.00514012
I0708 11:32:12.068151 31135 solver.cpp:243] Iteration 7700, loss = 3.28447
I0708 11:32:12.068172 31135 solver.cpp:259]     Train net output #0: loss = 3.28447 (* 1 = 3.28447 loss)
I0708 11:32:12.068178 31135 solver.cpp:590] Iteration 7700, lr = 0.00509078
I0708 11:32:34.701547 31135 solver.cpp:243] Iteration 7810, loss = 3.13171
I0708 11:32:34.701910 31135 solver.cpp:259]     Train net output #0: loss = 3.13171 (* 1 = 3.13171 loss)
I0708 11:32:34.701918 31135 solver.cpp:590] Iteration 7810, lr = 0.00504192
I0708 11:32:57.318205 31135 solver.cpp:243] Iteration 7920, loss = 3.2993
I0708 11:32:57.318230 31135 solver.cpp:259]     Train net output #0: loss = 3.2993 (* 1 = 3.2993 loss)
I0708 11:32:57.318236 31135 solver.cpp:590] Iteration 7920, lr = 0.00499352
I0708 11:33:00.808724 31135 solver.cpp:347] Iteration 7938, Testing net (#0)
I0708 11:33:24.337895 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0746394
I0708 11:33:24.338265 31135 solver.cpp:415]     Test net output #1: loss = 5.50334 (* 1 = 5.50334 loss)
I0708 11:33:43.426059 31135 solver.cpp:243] Iteration 8030, loss = 3.75434
I0708 11:33:43.426087 31135 solver.cpp:259]     Train net output #0: loss = 3.75434 (* 1 = 3.75434 loss)
I0708 11:33:43.426095 31135 solver.cpp:590] Iteration 8030, lr = 0.00494559
I0708 11:34:06.051193 31135 solver.cpp:243] Iteration 8140, loss = 2.99233
I0708 11:34:06.051862 31135 solver.cpp:259]     Train net output #0: loss = 2.99233 (* 1 = 2.99233 loss)
I0708 11:34:06.051869 31135 solver.cpp:590] Iteration 8140, lr = 0.00489812
I0708 11:34:28.665266 31135 solver.cpp:243] Iteration 8250, loss = 3.27095
I0708 11:34:28.665287 31135 solver.cpp:259]     Train net output #0: loss = 3.27095 (* 1 = 3.27095 loss)
I0708 11:34:28.665292 31135 solver.cpp:590] Iteration 8250, lr = 0.0048511
I0708 11:34:51.293756 31135 solver.cpp:243] Iteration 8360, loss = 3.78249
I0708 11:34:51.293891 31135 solver.cpp:259]     Train net output #0: loss = 3.78249 (* 1 = 3.78249 loss)
I0708 11:34:51.293900 31135 solver.cpp:590] Iteration 8360, lr = 0.00480454
I0708 11:35:13.948185 31135 solver.cpp:243] Iteration 8470, loss = 3.46193
I0708 11:35:13.948210 31135 solver.cpp:259]     Train net output #0: loss = 3.46193 (* 1 = 3.46193 loss)
I0708 11:35:13.948215 31135 solver.cpp:590] Iteration 8470, lr = 0.00475842
I0708 11:35:36.573617 31135 solver.cpp:243] Iteration 8580, loss = 3.67354
I0708 11:35:36.573699 31135 solver.cpp:259]     Train net output #0: loss = 3.67354 (* 1 = 3.67354 loss)
I0708 11:35:36.573707 31135 solver.cpp:590] Iteration 8580, lr = 0.00471275
I0708 11:35:59.165220 31135 solver.cpp:243] Iteration 8690, loss = 3.37362
I0708 11:35:59.165242 31135 solver.cpp:259]     Train net output #0: loss = 3.37362 (* 1 = 3.37362 loss)
I0708 11:35:59.165248 31135 solver.cpp:590] Iteration 8690, lr = 0.00466751
I0708 11:36:21.755468 31135 solver.cpp:243] Iteration 8800, loss = 2.80945
I0708 11:36:21.755573 31135 solver.cpp:259]     Train net output #0: loss = 2.80945 (* 1 = 2.80945 loss)
I0708 11:36:21.755589 31135 solver.cpp:590] Iteration 8800, lr = 0.00462271
I0708 11:36:25.663015 31135 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_8820.caffemodel
I0708 11:36:40.159915 31135 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_8820.solverstate
I0708 11:36:42.398919 31135 solver.cpp:347] Iteration 8820, Testing net (#0)
I0708 11:37:05.120787 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0674279
I0708 11:37:05.120923 31135 solver.cpp:415]     Test net output #1: loss = 5.71841 (* 1 = 5.71841 loss)
I0708 11:37:23.802599 31135 solver.cpp:243] Iteration 8910, loss = 2.78097
I0708 11:37:23.802623 31135 solver.cpp:259]     Train net output #0: loss = 2.78097 (* 1 = 2.78097 loss)
I0708 11:37:23.802629 31135 solver.cpp:590] Iteration 8910, lr = 0.00457834
I0708 11:37:46.427284 31135 solver.cpp:243] Iteration 9020, loss = 2.66282
I0708 11:37:46.427386 31135 solver.cpp:259]     Train net output #0: loss = 2.66282 (* 1 = 2.66282 loss)
I0708 11:37:46.427393 31135 solver.cpp:590] Iteration 9020, lr = 0.00453439
I0708 11:38:09.086992 31135 solver.cpp:243] Iteration 9130, loss = 2.57149
I0708 11:38:09.087013 31135 solver.cpp:259]     Train net output #0: loss = 2.57149 (* 1 = 2.57149 loss)
I0708 11:38:09.087019 31135 solver.cpp:590] Iteration 9130, lr = 0.00449087
I0708 11:38:31.726457 31135 solver.cpp:243] Iteration 9240, loss = 2.04682
I0708 11:38:31.726982 31135 solver.cpp:259]     Train net output #0: loss = 2.04682 (* 1 = 2.04682 loss)
I0708 11:38:31.726992 31135 solver.cpp:590] Iteration 9240, lr = 0.00444776
I0708 11:38:54.367851 31135 solver.cpp:243] Iteration 9350, loss = 2.28572
I0708 11:38:54.367873 31135 solver.cpp:259]     Train net output #0: loss = 2.28572 (* 1 = 2.28572 loss)
I0708 11:38:54.367879 31135 solver.cpp:590] Iteration 9350, lr = 0.00440507
I0708 11:39:17.012362 31135 solver.cpp:243] Iteration 9460, loss = 2.80993
I0708 11:39:17.012574 31135 solver.cpp:259]     Train net output #0: loss = 2.80993 (* 1 = 2.80993 loss)
I0708 11:39:17.012583 31135 solver.cpp:590] Iteration 9460, lr = 0.00436279
I0708 11:39:39.650557 31135 solver.cpp:243] Iteration 9570, loss = 2.61431
I0708 11:39:39.650580 31135 solver.cpp:259]     Train net output #0: loss = 2.61431 (* 1 = 2.61431 loss)
I0708 11:39:39.650586 31135 solver.cpp:590] Iteration 9570, lr = 0.00432091
I0708 11:40:02.303354 31135 solver.cpp:243] Iteration 9680, loss = 3.00843
I0708 11:40:02.303674 31135 solver.cpp:259]     Train net output #0: loss = 3.00843 (* 1 = 3.00843 loss)
I0708 11:40:02.303683 31135 solver.cpp:590] Iteration 9680, lr = 0.00427943
I0708 11:40:06.635586 31135 solver.cpp:347] Iteration 9702, Testing net (#0)
I0708 11:40:25.112450 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 11:40:31.132777 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0704327
I0708 11:40:31.132802 31135 solver.cpp:415]     Test net output #1: loss = 5.73743 (* 1 = 5.73743 loss)
I0708 11:40:49.411795 31135 solver.cpp:243] Iteration 9790, loss = 2.37325
I0708 11:40:49.412279 31135 solver.cpp:259]     Train net output #0: loss = 2.37325 (* 1 = 2.37325 loss)
I0708 11:40:49.412287 31135 solver.cpp:590] Iteration 9790, lr = 0.00423836
I0708 11:41:12.053087 31135 solver.cpp:243] Iteration 9900, loss = 2.95387
I0708 11:41:12.053112 31135 solver.cpp:259]     Train net output #0: loss = 2.95387 (* 1 = 2.95387 loss)
I0708 11:41:12.053118 31135 solver.cpp:590] Iteration 9900, lr = 0.00419767
I0708 11:41:34.678177 31135 solver.cpp:243] Iteration 10010, loss = 2.75112
I0708 11:41:34.678272 31135 solver.cpp:259]     Train net output #0: loss = 2.75112 (* 1 = 2.75112 loss)
I0708 11:41:34.678287 31135 solver.cpp:590] Iteration 10010, lr = 0.00415738
I0708 11:41:57.306779 31135 solver.cpp:243] Iteration 10120, loss = 3.48094
I0708 11:41:57.306802 31135 solver.cpp:259]     Train net output #0: loss = 3.48094 (* 1 = 3.48094 loss)
I0708 11:41:57.306808 31135 solver.cpp:590] Iteration 10120, lr = 0.00411748
I0708 11:42:19.979367 31135 solver.cpp:243] Iteration 10230, loss = 2.70034
I0708 11:42:19.979457 31135 solver.cpp:259]     Train net output #0: loss = 2.70034 (* 1 = 2.70034 loss)
I0708 11:42:19.979473 31135 solver.cpp:590] Iteration 10230, lr = 0.00407795
I0708 11:42:42.611227 31135 solver.cpp:243] Iteration 10340, loss = 2.51418
I0708 11:42:42.611251 31135 solver.cpp:259]     Train net output #0: loss = 2.51418 (* 1 = 2.51418 loss)
I0708 11:42:42.611258 31135 solver.cpp:590] Iteration 10340, lr = 0.00403881
I0708 11:43:05.231154 31135 solver.cpp:243] Iteration 10450, loss = 2.25839
I0708 11:43:05.231245 31135 solver.cpp:259]     Train net output #0: loss = 2.25839 (* 1 = 2.25839 loss)
I0708 11:43:05.231251 31135 solver.cpp:590] Iteration 10450, lr = 0.00400004
I0708 11:43:27.846782 31135 solver.cpp:243] Iteration 10560, loss = 1.73771
I0708 11:43:27.846804 31135 solver.cpp:259]     Train net output #0: loss = 1.73771 (* 1 = 1.73771 loss)
I0708 11:43:27.846810 31135 solver.cpp:590] Iteration 10560, lr = 0.00396165
I0708 11:43:32.585494 31135 solver.cpp:347] Iteration 10584, Testing net (#0)
I0708 11:43:56.566382 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0676683
I0708 11:43:56.566541 31135 solver.cpp:415]     Test net output #1: loss = 5.77315 (* 1 = 5.77315 loss)
I0708 11:44:14.447203 31135 solver.cpp:243] Iteration 10670, loss = 2.58112
I0708 11:44:14.447227 31135 solver.cpp:259]     Train net output #0: loss = 2.58112 (* 1 = 2.58112 loss)
I0708 11:44:14.447232 31135 solver.cpp:590] Iteration 10670, lr = 0.00392362
I0708 11:44:37.114516 31135 solver.cpp:243] Iteration 10780, loss = 2.89098
I0708 11:44:37.114956 31135 solver.cpp:259]     Train net output #0: loss = 2.89098 (* 1 = 2.89098 loss)
I0708 11:44:37.114964 31135 solver.cpp:590] Iteration 10780, lr = 0.00388596
I0708 11:44:59.782212 31135 solver.cpp:243] Iteration 10890, loss = 1.90319
I0708 11:44:59.782233 31135 solver.cpp:259]     Train net output #0: loss = 1.90319 (* 1 = 1.90319 loss)
I0708 11:44:59.782239 31135 solver.cpp:590] Iteration 10890, lr = 0.00384866
I0708 11:45:22.427815 31135 solver.cpp:243] Iteration 11000, loss = 1.39967
I0708 11:45:22.427911 31135 solver.cpp:259]     Train net output #0: loss = 1.39967 (* 1 = 1.39967 loss)
I0708 11:45:22.427927 31135 solver.cpp:590] Iteration 11000, lr = 0.00381172
I0708 11:45:45.062086 31135 solver.cpp:243] Iteration 11110, loss = 1.97021
I0708 11:45:45.062110 31135 solver.cpp:259]     Train net output #0: loss = 1.97021 (* 1 = 1.97021 loss)
I0708 11:45:45.062116 31135 solver.cpp:590] Iteration 11110, lr = 0.00377513
I0708 11:46:07.733130 31135 solver.cpp:243] Iteration 11220, loss = 2.45438
I0708 11:46:07.733261 31135 solver.cpp:259]     Train net output #0: loss = 2.45438 (* 1 = 2.45438 loss)
I0708 11:46:07.733268 31135 solver.cpp:590] Iteration 11220, lr = 0.00373889
I0708 11:46:30.409821 31135 solver.cpp:243] Iteration 11330, loss = 2.47586
I0708 11:46:30.409842 31135 solver.cpp:259]     Train net output #0: loss = 2.47586 (* 1 = 2.47586 loss)
I0708 11:46:30.409847 31135 solver.cpp:590] Iteration 11330, lr = 0.00370301
I0708 11:46:53.068819 31135 solver.cpp:243] Iteration 11440, loss = 2.39039
I0708 11:46:53.068913 31135 solver.cpp:259]     Train net output #0: loss = 2.39039 (* 1 = 2.39039 loss)
I0708 11:46:53.068929 31135 solver.cpp:590] Iteration 11440, lr = 0.00366746
I0708 11:46:58.211486 31135 solver.cpp:347] Iteration 11466, Testing net (#0)
I0708 11:47:22.343886 31135 solver.cpp:415]     Test net output #0: accuracy = 0.069351
I0708 11:47:22.343916 31135 solver.cpp:415]     Test net output #1: loss = 5.93115 (* 1 = 5.93115 loss)
I0708 11:47:39.804051 31135 solver.cpp:243] Iteration 11550, loss = 1.50916
I0708 11:47:39.804142 31135 solver.cpp:259]     Train net output #0: loss = 1.50916 (* 1 = 1.50916 loss)
I0708 11:47:39.804150 31135 solver.cpp:590] Iteration 11550, lr = 0.00363226
I0708 11:48:02.429639 31135 solver.cpp:243] Iteration 11660, loss = 1.89968
I0708 11:48:02.429672 31135 solver.cpp:259]     Train net output #0: loss = 1.89968 (* 1 = 1.89968 loss)
I0708 11:48:02.429678 31135 solver.cpp:590] Iteration 11660, lr = 0.00359739
I0708 11:48:25.077730 31135 solver.cpp:243] Iteration 11770, loss = 1.58612
I0708 11:48:25.077811 31135 solver.cpp:259]     Train net output #0: loss = 1.58612 (* 1 = 1.58612 loss)
I0708 11:48:25.077818 31135 solver.cpp:590] Iteration 11770, lr = 0.00356286
I0708 11:48:47.748935 31135 solver.cpp:243] Iteration 11880, loss = 2.42998
I0708 11:48:47.748961 31135 solver.cpp:259]     Train net output #0: loss = 2.42998 (* 1 = 2.42998 loss)
I0708 11:48:47.748968 31135 solver.cpp:590] Iteration 11880, lr = 0.00352867
I0708 11:49:10.410023 31135 solver.cpp:243] Iteration 11990, loss = 1.71053
I0708 11:49:10.410112 31135 solver.cpp:259]     Train net output #0: loss = 1.71053 (* 1 = 1.71053 loss)
I0708 11:49:10.410120 31135 solver.cpp:590] Iteration 11990, lr = 0.00349479
I0708 11:49:33.071599 31135 solver.cpp:243] Iteration 12100, loss = 1.47973
I0708 11:49:33.071622 31135 solver.cpp:259]     Train net output #0: loss = 1.47973 (* 1 = 1.47973 loss)
I0708 11:49:33.071629 31135 solver.cpp:590] Iteration 12100, lr = 0.00346125
I0708 11:49:55.722671 31135 solver.cpp:243] Iteration 12210, loss = 1.77201
I0708 11:49:55.722774 31135 solver.cpp:259]     Train net output #0: loss = 1.77201 (* 1 = 1.77201 loss)
I0708 11:49:55.722781 31135 solver.cpp:590] Iteration 12210, lr = 0.00342803
I0708 11:50:18.379456 31135 solver.cpp:243] Iteration 12320, loss = 1.90939
I0708 11:50:18.379480 31135 solver.cpp:259]     Train net output #0: loss = 1.90939 (* 1 = 1.90939 loss)
I0708 11:50:18.379485 31135 solver.cpp:590] Iteration 12320, lr = 0.00339512
I0708 11:50:23.947443 31135 solver.cpp:347] Iteration 12348, Testing net (#0)
I0708 11:50:46.801796 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0670673
I0708 11:50:46.802834 31135 solver.cpp:415]     Test net output #1: loss = 5.89465 (* 1 = 5.89465 loss)
I0708 11:51:03.863749 31135 solver.cpp:243] Iteration 12430, loss = 1.79596
I0708 11:51:03.863785 31135 solver.cpp:259]     Train net output #0: loss = 1.79596 (* 1 = 1.79596 loss)
I0708 11:51:03.863795 31135 solver.cpp:590] Iteration 12430, lr = 0.00336253
I0708 11:51:26.537335 31135 solver.cpp:243] Iteration 12540, loss = 2.09118
I0708 11:51:26.537714 31135 solver.cpp:259]     Train net output #0: loss = 2.09118 (* 1 = 2.09118 loss)
I0708 11:51:26.537732 31135 solver.cpp:590] Iteration 12540, lr = 0.00333026
I0708 11:51:49.208969 31135 solver.cpp:243] Iteration 12650, loss = 1.27375
I0708 11:51:49.208992 31135 solver.cpp:259]     Train net output #0: loss = 1.27375 (* 1 = 1.27375 loss)
I0708 11:51:49.208998 31135 solver.cpp:590] Iteration 12650, lr = 0.00329829
I0708 11:52:11.859313 31135 solver.cpp:243] Iteration 12760, loss = 1.57096
I0708 11:52:11.859403 31135 solver.cpp:259]     Train net output #0: loss = 1.57096 (* 1 = 1.57096 loss)
I0708 11:52:11.859419 31135 solver.cpp:590] Iteration 12760, lr = 0.00326663
I0708 11:52:34.490768 31135 solver.cpp:243] Iteration 12870, loss = 1.46895
I0708 11:52:34.490792 31135 solver.cpp:259]     Train net output #0: loss = 1.46895 (* 1 = 1.46895 loss)
I0708 11:52:34.490798 31135 solver.cpp:590] Iteration 12870, lr = 0.00323528
I0708 11:52:57.155266 31135 solver.cpp:243] Iteration 12980, loss = 1.4384
I0708 11:52:57.155328 31135 solver.cpp:259]     Train net output #0: loss = 1.4384 (* 1 = 1.4384 loss)
I0708 11:52:57.155345 31135 solver.cpp:590] Iteration 12980, lr = 0.00320422
I0708 11:53:19.823303 31135 solver.cpp:243] Iteration 13090, loss = 2.22928
I0708 11:53:19.823326 31135 solver.cpp:259]     Train net output #0: loss = 2.22928 (* 1 = 2.22928 loss)
I0708 11:53:19.823333 31135 solver.cpp:590] Iteration 13090, lr = 0.00317347
I0708 11:53:42.481747 31135 solver.cpp:243] Iteration 13200, loss = 1.03514
I0708 11:53:42.481832 31135 solver.cpp:259]     Train net output #0: loss = 1.03514 (* 1 = 1.03514 loss)
I0708 11:53:42.481839 31135 solver.cpp:590] Iteration 13200, lr = 0.003143
I0708 11:53:48.457437 31135 solver.cpp:347] Iteration 13230, Testing net (#0)
I0708 11:54:01.664296 31152 blocking_queue.cpp:50] Waiting for data
I0708 11:54:04.589516 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 11:54:12.413105 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0658654
I0708 11:54:12.413131 31135 solver.cpp:415]     Test net output #1: loss = 6.00888 (* 1 = 6.00888 loss)
I0708 11:54:29.046159 31135 solver.cpp:243] Iteration 13310, loss = 1.25509
I0708 11:54:29.046259 31135 solver.cpp:259]     Train net output #0: loss = 1.25509 (* 1 = 1.25509 loss)
I0708 11:54:29.046265 31135 solver.cpp:590] Iteration 13310, lr = 0.00311284
I0708 11:54:51.707180 31135 solver.cpp:243] Iteration 13420, loss = 1.84784
I0708 11:54:51.707204 31135 solver.cpp:259]     Train net output #0: loss = 1.84784 (* 1 = 1.84784 loss)
I0708 11:54:51.707211 31135 solver.cpp:590] Iteration 13420, lr = 0.00308296
I0708 11:55:14.352226 31135 solver.cpp:243] Iteration 13530, loss = 1.02448
I0708 11:55:14.352325 31135 solver.cpp:259]     Train net output #0: loss = 1.02448 (* 1 = 1.02448 loss)
I0708 11:55:14.352334 31135 solver.cpp:590] Iteration 13530, lr = 0.00305336
I0708 11:55:37.001292 31135 solver.cpp:243] Iteration 13640, loss = 1.15665
I0708 11:55:37.001315 31135 solver.cpp:259]     Train net output #0: loss = 1.15665 (* 1 = 1.15665 loss)
I0708 11:55:37.001322 31135 solver.cpp:590] Iteration 13640, lr = 0.00302406
I0708 11:55:59.657882 31135 solver.cpp:243] Iteration 13750, loss = 1.78813
I0708 11:55:59.657977 31135 solver.cpp:259]     Train net output #0: loss = 1.78813 (* 1 = 1.78813 loss)
I0708 11:55:59.657994 31135 solver.cpp:590] Iteration 13750, lr = 0.00299503
I0708 11:56:22.295073 31135 solver.cpp:243] Iteration 13860, loss = 1.24957
I0708 11:56:22.295095 31135 solver.cpp:259]     Train net output #0: loss = 1.24957 (* 1 = 1.24957 loss)
I0708 11:56:22.295101 31135 solver.cpp:590] Iteration 13860, lr = 0.00296628
I0708 11:56:44.931007 31135 solver.cpp:243] Iteration 13970, loss = 0.923105
I0708 11:56:44.931241 31135 solver.cpp:259]     Train net output #0: loss = 0.923105 (* 1 = 0.923105 loss)
I0708 11:56:44.931249 31135 solver.cpp:590] Iteration 13970, lr = 0.00293781
I0708 11:57:07.594369 31135 solver.cpp:243] Iteration 14080, loss = 0.951117
I0708 11:57:07.594393 31135 solver.cpp:259]     Train net output #0: loss = 0.951117 (* 1 = 0.951117 loss)
I0708 11:57:07.594399 31135 solver.cpp:590] Iteration 14080, lr = 0.00290961
I0708 11:57:13.975440 31135 solver.cpp:347] Iteration 14112, Testing net (#0)
I0708 11:57:35.139241 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0663462
I0708 11:57:35.139417 31135 solver.cpp:415]     Test net output #1: loss = 6.16629 (* 1 = 6.16629 loss)
I0708 11:57:51.352294 31135 solver.cpp:243] Iteration 14190, loss = 0.865279
I0708 11:57:51.352316 31135 solver.cpp:259]     Train net output #0: loss = 0.865279 (* 1 = 0.865279 loss)
I0708 11:57:51.352322 31135 solver.cpp:590] Iteration 14190, lr = 0.00288168
I0708 11:58:14.023138 31135 solver.cpp:243] Iteration 14300, loss = 1.37273
I0708 11:58:14.023375 31135 solver.cpp:259]     Train net output #0: loss = 1.37273 (* 1 = 1.37273 loss)
I0708 11:58:14.023383 31135 solver.cpp:590] Iteration 14300, lr = 0.00285402
I0708 11:58:36.665917 31135 solver.cpp:243] Iteration 14410, loss = 1.3316
I0708 11:58:36.665940 31135 solver.cpp:259]     Train net output #0: loss = 1.3316 (* 1 = 1.3316 loss)
I0708 11:58:36.665946 31135 solver.cpp:590] Iteration 14410, lr = 0.00282663
I0708 11:58:59.312034 31135 solver.cpp:243] Iteration 14520, loss = 1.82488
I0708 11:58:59.312122 31135 solver.cpp:259]     Train net output #0: loss = 1.82488 (* 1 = 1.82488 loss)
I0708 11:58:59.312130 31135 solver.cpp:590] Iteration 14520, lr = 0.00279949
I0708 11:59:21.956676 31135 solver.cpp:243] Iteration 14630, loss = 1.86559
I0708 11:59:21.956696 31135 solver.cpp:259]     Train net output #0: loss = 1.86559 (* 1 = 1.86559 loss)
I0708 11:59:21.956702 31135 solver.cpp:590] Iteration 14630, lr = 0.00277262
I0708 11:59:44.603070 31135 solver.cpp:243] Iteration 14740, loss = 0.817796
I0708 11:59:44.603152 31135 solver.cpp:259]     Train net output #0: loss = 0.817796 (* 1 = 0.817796 loss)
I0708 11:59:44.603168 31135 solver.cpp:590] Iteration 14740, lr = 0.00274601
I0708 12:00:07.273690 31135 solver.cpp:243] Iteration 14850, loss = 0.741322
I0708 12:00:07.273718 31135 solver.cpp:259]     Train net output #0: loss = 0.741322 (* 1 = 0.741322 loss)
I0708 12:00:07.273725 31135 solver.cpp:590] Iteration 14850, lr = 0.00271965
I0708 12:00:29.911047 31135 solver.cpp:243] Iteration 14960, loss = 1.0219
I0708 12:00:29.911136 31135 solver.cpp:259]     Train net output #0: loss = 1.0219 (* 1 = 1.0219 loss)
I0708 12:00:29.911152 31135 solver.cpp:590] Iteration 14960, lr = 0.00269355
I0708 12:00:36.700718 31135 solver.cpp:347] Iteration 14994, Testing net (#0)
I0708 12:00:59.624711 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0674279
I0708 12:00:59.624747 31135 solver.cpp:415]     Test net output #1: loss = 6.12528 (* 1 = 6.12528 loss)
I0708 12:01:15.421583 31135 solver.cpp:243] Iteration 15070, loss = 1.84814
I0708 12:01:15.421674 31135 solver.cpp:259]     Train net output #0: loss = 1.84814 (* 1 = 1.84814 loss)
I0708 12:01:15.421690 31135 solver.cpp:590] Iteration 15070, lr = 0.00266769
I0708 12:01:38.068024 31135 solver.cpp:243] Iteration 15180, loss = 0.946114
I0708 12:01:38.068045 31135 solver.cpp:259]     Train net output #0: loss = 0.946115 (* 1 = 0.946115 loss)
I0708 12:01:38.068051 31135 solver.cpp:590] Iteration 15180, lr = 0.00264208
I0708 12:02:00.711513 31135 solver.cpp:243] Iteration 15290, loss = 0.673591
I0708 12:02:00.711622 31135 solver.cpp:259]     Train net output #0: loss = 0.673591 (* 1 = 0.673591 loss)
I0708 12:02:00.711640 31135 solver.cpp:590] Iteration 15290, lr = 0.00261672
I0708 12:02:23.348179 31135 solver.cpp:243] Iteration 15400, loss = 1.06633
I0708 12:02:23.348204 31135 solver.cpp:259]     Train net output #0: loss = 1.06633 (* 1 = 1.06633 loss)
I0708 12:02:23.348211 31135 solver.cpp:590] Iteration 15400, lr = 0.00259161
I0708 12:02:45.982730 31135 solver.cpp:243] Iteration 15510, loss = 1.14679
I0708 12:02:45.983062 31135 solver.cpp:259]     Train net output #0: loss = 1.14679 (* 1 = 1.14679 loss)
I0708 12:02:45.983070 31135 solver.cpp:590] Iteration 15510, lr = 0.00256673
I0708 12:03:08.626932 31135 solver.cpp:243] Iteration 15620, loss = 1.88086
I0708 12:03:08.626955 31135 solver.cpp:259]     Train net output #0: loss = 1.88086 (* 1 = 1.88086 loss)
I0708 12:03:08.626960 31135 solver.cpp:590] Iteration 15620, lr = 0.00254209
I0708 12:03:31.253393 31135 solver.cpp:243] Iteration 15730, loss = 0.427359
I0708 12:03:31.253667 31135 solver.cpp:259]     Train net output #0: loss = 0.42736 (* 1 = 0.42736 loss)
I0708 12:03:31.253676 31135 solver.cpp:590] Iteration 15730, lr = 0.00251769
I0708 12:03:53.903635 31135 solver.cpp:243] Iteration 15840, loss = 0.958291
I0708 12:03:53.903658 31135 solver.cpp:259]     Train net output #0: loss = 0.958291 (* 1 = 0.958291 loss)
I0708 12:03:53.903664 31135 solver.cpp:590] Iteration 15840, lr = 0.00249353
I0708 12:04:01.110474 31135 solver.cpp:347] Iteration 15876, Testing net (#0)
I0708 12:04:27.339781 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0682692
I0708 12:04:27.340087 31135 solver.cpp:415]     Test net output #1: loss = 6.08272 (* 1 = 6.08272 loss)
I0708 12:04:42.732028 31135 solver.cpp:243] Iteration 15950, loss = 0.664703
I0708 12:04:42.732053 31135 solver.cpp:259]     Train net output #0: loss = 0.664703 (* 1 = 0.664703 loss)
I0708 12:04:42.732059 31135 solver.cpp:590] Iteration 15950, lr = 0.00246959
I0708 12:05:05.389855 31135 solver.cpp:243] Iteration 16060, loss = 1.25447
I0708 12:05:05.390319 31135 solver.cpp:259]     Train net output #0: loss = 1.25447 (* 1 = 1.25447 loss)
I0708 12:05:05.390328 31135 solver.cpp:590] Iteration 16060, lr = 0.00244589
I0708 12:05:28.059288 31135 solver.cpp:243] Iteration 16170, loss = 0.418815
I0708 12:05:28.059310 31135 solver.cpp:259]     Train net output #0: loss = 0.418815 (* 1 = 0.418815 loss)
I0708 12:05:28.059316 31135 solver.cpp:590] Iteration 16170, lr = 0.00242241
I0708 12:05:50.697034 31135 solver.cpp:243] Iteration 16280, loss = 0.685057
I0708 12:05:50.697139 31135 solver.cpp:259]     Train net output #0: loss = 0.685058 (* 1 = 0.685058 loss)
I0708 12:05:50.697146 31135 solver.cpp:590] Iteration 16280, lr = 0.00239916
I0708 12:06:13.336776 31135 solver.cpp:243] Iteration 16390, loss = 2.49529
I0708 12:06:13.336801 31135 solver.cpp:259]     Train net output #0: loss = 2.49529 (* 1 = 2.49529 loss)
I0708 12:06:13.336807 31135 solver.cpp:590] Iteration 16390, lr = 0.00237613
I0708 12:06:35.989863 31135 solver.cpp:243] Iteration 16500, loss = 1.15456
I0708 12:06:35.989974 31135 solver.cpp:259]     Train net output #0: loss = 1.15456 (* 1 = 1.15456 loss)
I0708 12:06:35.989984 31135 solver.cpp:590] Iteration 16500, lr = 0.00235332
I0708 12:06:58.650606 31135 solver.cpp:243] Iteration 16610, loss = 0.997293
I0708 12:06:58.650627 31135 solver.cpp:259]     Train net output #0: loss = 0.997293 (* 1 = 0.997293 loss)
I0708 12:06:58.650634 31135 solver.cpp:590] Iteration 16610, lr = 0.00233073
I0708 12:07:21.305323 31135 solver.cpp:243] Iteration 16720, loss = 0.90102
I0708 12:07:21.305424 31135 solver.cpp:259]     Train net output #0: loss = 0.90102 (* 1 = 0.90102 loss)
I0708 12:07:21.305433 31135 solver.cpp:590] Iteration 16720, lr = 0.00230836
I0708 12:07:28.934423 31135 solver.cpp:347] Iteration 16758, Testing net (#0)
I0708 12:07:41.245265 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 12:07:53.992558 31135 solver.cpp:415]     Test net output #0: accuracy = 0.071274
I0708 12:07:53.992764 31135 solver.cpp:415]     Test net output #1: loss = 6.19356 (* 1 = 6.19356 loss)
I0708 12:08:08.970738 31135 solver.cpp:243] Iteration 16830, loss = 0.278499
I0708 12:08:08.970760 31135 solver.cpp:259]     Train net output #0: loss = 0.278499 (* 1 = 0.278499 loss)
I0708 12:08:08.970767 31135 solver.cpp:590] Iteration 16830, lr = 0.0022862
I0708 12:08:31.613214 31135 solver.cpp:243] Iteration 16940, loss = 0.686987
I0708 12:08:31.613308 31135 solver.cpp:259]     Train net output #0: loss = 0.686987 (* 1 = 0.686987 loss)
I0708 12:08:31.613324 31135 solver.cpp:590] Iteration 16940, lr = 0.00226426
I0708 12:08:54.274281 31135 solver.cpp:243] Iteration 17050, loss = 0.525235
I0708 12:08:54.274304 31135 solver.cpp:259]     Train net output #0: loss = 0.525235 (* 1 = 0.525235 loss)
I0708 12:08:54.274309 31135 solver.cpp:590] Iteration 17050, lr = 0.00224252
I0708 12:09:16.914532 31135 solver.cpp:243] Iteration 17160, loss = 0.722568
I0708 12:09:16.914649 31135 solver.cpp:259]     Train net output #0: loss = 0.722568 (* 1 = 0.722568 loss)
I0708 12:09:16.914674 31135 solver.cpp:590] Iteration 17160, lr = 0.002221
I0708 12:09:39.545895 31135 solver.cpp:243] Iteration 17270, loss = 0.601265
I0708 12:09:39.545918 31135 solver.cpp:259]     Train net output #0: loss = 0.601265 (* 1 = 0.601265 loss)
I0708 12:09:39.545924 31135 solver.cpp:590] Iteration 17270, lr = 0.00219968
I0708 12:10:02.172655 31135 solver.cpp:243] Iteration 17380, loss = 0.402429
I0708 12:10:02.172732 31135 solver.cpp:259]     Train net output #0: loss = 0.402429 (* 1 = 0.402429 loss)
I0708 12:10:02.172749 31135 solver.cpp:590] Iteration 17380, lr = 0.00217857
I0708 12:10:24.828502 31135 solver.cpp:243] Iteration 17490, loss = 0.982646
I0708 12:10:24.828526 31135 solver.cpp:259]     Train net output #0: loss = 0.982646 (* 1 = 0.982646 loss)
I0708 12:10:24.828532 31135 solver.cpp:590] Iteration 17490, lr = 0.00215766
I0708 12:10:47.483070 31135 solver.cpp:243] Iteration 17600, loss = 0.0981487
I0708 12:10:47.483155 31135 solver.cpp:259]     Train net output #0: loss = 0.0981487 (* 1 = 0.0981487 loss)
I0708 12:10:47.483161 31135 solver.cpp:590] Iteration 17600, lr = 0.00213694
I0708 12:10:55.499282 31135 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_17640.caffemodel
I0708 12:11:14.950649 31135 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_17640.solverstate
I0708 12:11:17.234871 31135 solver.cpp:347] Iteration 17640, Testing net (#0)
I0708 12:11:41.914854 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0725962
I0708 12:11:41.914944 31135 solver.cpp:415]     Test net output #1: loss = 6.12053 (* 1 = 6.12053 loss)
I0708 12:11:56.462168 31135 solver.cpp:243] Iteration 17710, loss = 0.163063
I0708 12:11:56.462189 31135 solver.cpp:259]     Train net output #0: loss = 0.163063 (* 1 = 0.163063 loss)
I0708 12:11:56.462194 31135 solver.cpp:590] Iteration 17710, lr = 0.00211643
I0708 12:12:19.047291 31135 solver.cpp:243] Iteration 17820, loss = 0.198387
I0708 12:12:19.047379 31135 solver.cpp:259]     Train net output #0: loss = 0.198387 (* 1 = 0.198387 loss)
I0708 12:12:19.047395 31135 solver.cpp:590] Iteration 17820, lr = 0.00209612
I0708 12:12:41.653594 31135 solver.cpp:243] Iteration 17930, loss = 0.412072
I0708 12:12:41.653619 31135 solver.cpp:259]     Train net output #0: loss = 0.412072 (* 1 = 0.412072 loss)
I0708 12:12:41.653625 31135 solver.cpp:590] Iteration 17930, lr = 0.002076
I0708 12:13:04.272819 31135 solver.cpp:243] Iteration 18040, loss = 0.452923
I0708 12:13:04.272902 31135 solver.cpp:259]     Train net output #0: loss = 0.452923 (* 1 = 0.452923 loss)
I0708 12:13:04.272908 31135 solver.cpp:590] Iteration 18040, lr = 0.00205607
I0708 12:13:26.907793 31135 solver.cpp:243] Iteration 18150, loss = 0.558169
I0708 12:13:26.907815 31135 solver.cpp:259]     Train net output #0: loss = 0.558169 (* 1 = 0.558169 loss)
I0708 12:13:26.907821 31135 solver.cpp:590] Iteration 18150, lr = 0.00203634
I0708 12:13:49.508543 31135 solver.cpp:243] Iteration 18260, loss = 0.364496
I0708 12:13:49.508652 31135 solver.cpp:259]     Train net output #0: loss = 0.364496 (* 1 = 0.364496 loss)
I0708 12:13:49.508668 31135 solver.cpp:590] Iteration 18260, lr = 0.00201679
I0708 12:14:12.113112 31135 solver.cpp:243] Iteration 18370, loss = 0.77639
I0708 12:14:12.113135 31135 solver.cpp:259]     Train net output #0: loss = 0.77639 (* 1 = 0.77639 loss)
I0708 12:14:12.113142 31135 solver.cpp:590] Iteration 18370, lr = 0.00199743
I0708 12:14:34.744107 31135 solver.cpp:243] Iteration 18480, loss = 0.544186
I0708 12:14:34.744299 31135 solver.cpp:259]     Train net output #0: loss = 0.544186 (* 1 = 0.544186 loss)
I0708 12:14:34.744308 31135 solver.cpp:590] Iteration 18480, lr = 0.00197826
I0708 12:14:43.194792 31135 solver.cpp:347] Iteration 18522, Testing net (#0)
I0708 12:15:08.602632 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0770433
I0708 12:15:08.602758 31135 solver.cpp:415]     Test net output #1: loss = 6.1235 (* 1 = 6.1235 loss)
I0708 12:15:22.767104 31135 solver.cpp:243] Iteration 18590, loss = 0.617636
I0708 12:15:22.767130 31135 solver.cpp:259]     Train net output #0: loss = 0.617636 (* 1 = 0.617636 loss)
I0708 12:15:22.767138 31135 solver.cpp:590] Iteration 18590, lr = 0.00195927
I0708 12:15:45.423063 31135 solver.cpp:243] Iteration 18700, loss = 0.588525
I0708 12:15:45.423161 31135 solver.cpp:259]     Train net output #0: loss = 0.588525 (* 1 = 0.588525 loss)
I0708 12:15:45.423167 31135 solver.cpp:590] Iteration 18700, lr = 0.00194046
I0708 12:16:08.034518 31135 solver.cpp:243] Iteration 18810, loss = 0.337005
I0708 12:16:08.034541 31135 solver.cpp:259]     Train net output #0: loss = 0.337005 (* 1 = 0.337005 loss)
I0708 12:16:08.034548 31135 solver.cpp:590] Iteration 18810, lr = 0.00192184
I0708 12:16:30.660259 31135 solver.cpp:243] Iteration 18920, loss = 0.283247
I0708 12:16:30.660348 31135 solver.cpp:259]     Train net output #0: loss = 0.283247 (* 1 = 0.283247 loss)
I0708 12:16:30.660364 31135 solver.cpp:590] Iteration 18920, lr = 0.00190339
I0708 12:16:53.294910 31135 solver.cpp:243] Iteration 19030, loss = 0.643925
I0708 12:16:53.294934 31135 solver.cpp:259]     Train net output #0: loss = 0.643925 (* 1 = 0.643925 loss)
I0708 12:16:53.294940 31135 solver.cpp:590] Iteration 19030, lr = 0.00188512
I0708 12:17:15.939741 31135 solver.cpp:243] Iteration 19140, loss = 1.26037
I0708 12:17:15.939836 31135 solver.cpp:259]     Train net output #0: loss = 1.26037 (* 1 = 1.26037 loss)
I0708 12:17:15.939842 31135 solver.cpp:590] Iteration 19140, lr = 0.00186703
I0708 12:17:38.573688 31135 solver.cpp:243] Iteration 19250, loss = 0.301743
I0708 12:17:38.573707 31135 solver.cpp:259]     Train net output #0: loss = 0.301743 (* 1 = 0.301743 loss)
I0708 12:17:38.573714 31135 solver.cpp:590] Iteration 19250, lr = 0.0018491
I0708 12:18:01.173581 31135 solver.cpp:243] Iteration 19360, loss = 0.202082
I0708 12:18:01.173677 31135 solver.cpp:259]     Train net output #0: loss = 0.202082 (* 1 = 0.202082 loss)
I0708 12:18:01.173696 31135 solver.cpp:590] Iteration 19360, lr = 0.00183136
I0708 12:18:10.011533 31135 solver.cpp:347] Iteration 19404, Testing net (#0)
I0708 12:18:15.691781 31152 blocking_queue.cpp:50] Waiting for data
I0708 12:18:34.421874 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0753606
I0708 12:18:34.421955 31135 solver.cpp:415]     Test net output #1: loss = 6.31561 (* 1 = 6.31561 loss)
I0708 12:18:48.148947 31135 solver.cpp:243] Iteration 19470, loss = 0.334515
I0708 12:18:48.148972 31135 solver.cpp:259]     Train net output #0: loss = 0.334515 (* 1 = 0.334515 loss)
I0708 12:18:48.148977 31135 solver.cpp:590] Iteration 19470, lr = 0.00181378
I0708 12:19:10.753113 31135 solver.cpp:243] Iteration 19580, loss = 0.242151
I0708 12:19:10.753188 31135 solver.cpp:259]     Train net output #0: loss = 0.242151 (* 1 = 0.242151 loss)
I0708 12:19:10.753196 31135 solver.cpp:590] Iteration 19580, lr = 0.00179637
I0708 12:19:33.370012 31135 solver.cpp:243] Iteration 19690, loss = 0.187754
I0708 12:19:33.370034 31135 solver.cpp:259]     Train net output #0: loss = 0.187754 (* 1 = 0.187754 loss)
I0708 12:19:33.370039 31135 solver.cpp:590] Iteration 19690, lr = 0.00177912
I0708 12:19:56.008085 31135 solver.cpp:243] Iteration 19800, loss = 0.811991
I0708 12:19:56.008471 31135 solver.cpp:259]     Train net output #0: loss = 0.811991 (* 1 = 0.811991 loss)
I0708 12:19:56.008478 31135 solver.cpp:590] Iteration 19800, lr = 0.00176205
I0708 12:20:18.620992 31135 solver.cpp:243] Iteration 19910, loss = 0.208727
I0708 12:20:18.621013 31135 solver.cpp:259]     Train net output #0: loss = 0.208727 (* 1 = 0.208727 loss)
I0708 12:20:18.621018 31135 solver.cpp:590] Iteration 19910, lr = 0.00174513
I0708 12:20:41.223727 31135 solver.cpp:243] Iteration 20020, loss = 0.640627
I0708 12:20:41.224194 31135 solver.cpp:259]     Train net output #0: loss = 0.640628 (* 1 = 0.640628 loss)
I0708 12:20:41.224201 31135 solver.cpp:590] Iteration 20020, lr = 0.00172838
I0708 12:21:03.842022 31135 solver.cpp:243] Iteration 20130, loss = 0.610722
I0708 12:21:03.842044 31135 solver.cpp:259]     Train net output #0: loss = 0.610723 (* 1 = 0.610723 loss)
I0708 12:21:03.842051 31135 solver.cpp:590] Iteration 20130, lr = 0.00171179
I0708 12:21:26.484947 31135 solver.cpp:243] Iteration 20240, loss = 0.432668
I0708 12:21:26.485409 31135 solver.cpp:259]     Train net output #0: loss = 0.432669 (* 1 = 0.432669 loss)
I0708 12:21:26.485419 31135 solver.cpp:590] Iteration 20240, lr = 0.00169536
I0708 12:21:35.744638 31135 solver.cpp:347] Iteration 20286, Testing net (#0)
I0708 12:21:45.819751 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 12:21:59.297597 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0795673
I0708 12:21:59.297718 31135 solver.cpp:415]     Test net output #1: loss = 6.28694 (* 1 = 6.28694 loss)
I0708 12:22:12.639734 31135 solver.cpp:243] Iteration 20350, loss = 0.473122
I0708 12:22:12.639755 31135 solver.cpp:259]     Train net output #0: loss = 0.473122 (* 1 = 0.473122 loss)
I0708 12:22:12.639760 31135 solver.cpp:590] Iteration 20350, lr = 0.00167909
I0708 12:22:35.250907 31135 solver.cpp:243] Iteration 20460, loss = 0.248987
I0708 12:22:35.251188 31135 solver.cpp:259]     Train net output #0: loss = 0.248988 (* 1 = 0.248988 loss)
I0708 12:22:35.251196 31135 solver.cpp:590] Iteration 20460, lr = 0.00166297
I0708 12:22:57.844696 31135 solver.cpp:243] Iteration 20570, loss = 0.0633087
I0708 12:22:57.844719 31135 solver.cpp:259]     Train net output #0: loss = 0.0633094 (* 1 = 0.0633094 loss)
I0708 12:22:57.844724 31135 solver.cpp:590] Iteration 20570, lr = 0.00164701
I0708 12:23:20.463728 31135 solver.cpp:243] Iteration 20680, loss = 0.428735
I0708 12:23:20.464205 31135 solver.cpp:259]     Train net output #0: loss = 0.428736 (* 1 = 0.428736 loss)
I0708 12:23:20.464215 31135 solver.cpp:590] Iteration 20680, lr = 0.0016312
I0708 12:23:43.104410 31135 solver.cpp:243] Iteration 20790, loss = 0.782723
I0708 12:23:43.104434 31135 solver.cpp:259]     Train net output #0: loss = 0.782724 (* 1 = 0.782724 loss)
I0708 12:23:43.104440 31135 solver.cpp:590] Iteration 20790, lr = 0.00161554
I0708 12:24:05.721216 31135 solver.cpp:243] Iteration 20900, loss = 0.129849
I0708 12:24:05.721479 31135 solver.cpp:259]     Train net output #0: loss = 0.129849 (* 1 = 0.129849 loss)
I0708 12:24:05.721488 31135 solver.cpp:590] Iteration 20900, lr = 0.00160004
I0708 12:24:28.321841 31135 solver.cpp:243] Iteration 21010, loss = 0.23969
I0708 12:24:28.321877 31135 solver.cpp:259]     Train net output #0: loss = 0.239691 (* 1 = 0.239691 loss)
I0708 12:24:28.321883 31135 solver.cpp:590] Iteration 21010, lr = 0.00158468
I0708 12:24:50.925583 31135 solver.cpp:243] Iteration 21120, loss = 0.475826
I0708 12:24:50.926035 31135 solver.cpp:259]     Train net output #0: loss = 0.475827 (* 1 = 0.475827 loss)
I0708 12:24:50.926043 31135 solver.cpp:590] Iteration 21120, lr = 0.00156947
I0708 12:25:00.591433 31135 solver.cpp:347] Iteration 21168, Testing net (#0)
I0708 12:25:24.531636 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0829327
I0708 12:25:24.531791 31135 solver.cpp:415]     Test net output #1: loss = 6.29138 (* 1 = 6.29138 loss)
I0708 12:25:37.427539 31135 solver.cpp:243] Iteration 21230, loss = 0.504408
I0708 12:25:37.427563 31135 solver.cpp:259]     Train net output #0: loss = 0.504409 (* 1 = 0.504409 loss)
I0708 12:25:37.427569 31135 solver.cpp:590] Iteration 21230, lr = 0.0015544
I0708 12:26:00.026952 31135 solver.cpp:243] Iteration 21340, loss = 0.151669
I0708 12:26:00.027367 31135 solver.cpp:259]     Train net output #0: loss = 0.151669 (* 1 = 0.151669 loss)
I0708 12:26:00.027375 31135 solver.cpp:590] Iteration 21340, lr = 0.00153948
I0708 12:26:22.660159 31135 solver.cpp:243] Iteration 21450, loss = 0.0954984
I0708 12:26:22.660182 31135 solver.cpp:259]     Train net output #0: loss = 0.0954992 (* 1 = 0.0954992 loss)
I0708 12:26:22.660188 31135 solver.cpp:590] Iteration 21450, lr = 0.0015247
I0708 12:26:45.281698 31135 solver.cpp:243] Iteration 21560, loss = 0.627905
I0708 12:26:45.281785 31135 solver.cpp:259]     Train net output #0: loss = 0.627906 (* 1 = 0.627906 loss)
I0708 12:26:45.281790 31135 solver.cpp:590] Iteration 21560, lr = 0.00151007
I0708 12:27:07.893723 31135 solver.cpp:243] Iteration 21670, loss = 0.169105
I0708 12:27:07.893745 31135 solver.cpp:259]     Train net output #0: loss = 0.169106 (* 1 = 0.169106 loss)
I0708 12:27:07.893751 31135 solver.cpp:590] Iteration 21670, lr = 0.00149557
I0708 12:27:30.476178 31135 solver.cpp:243] Iteration 21780, loss = 0.20522
I0708 12:27:30.476275 31135 solver.cpp:259]     Train net output #0: loss = 0.205221 (* 1 = 0.205221 loss)
I0708 12:27:30.476282 31135 solver.cpp:590] Iteration 21780, lr = 0.00148122
I0708 12:27:53.099584 31135 solver.cpp:243] Iteration 21890, loss = 0.2474
I0708 12:27:53.099609 31135 solver.cpp:259]     Train net output #0: loss = 0.247401 (* 1 = 0.247401 loss)
I0708 12:27:53.099616 31135 solver.cpp:590] Iteration 21890, lr = 0.001467
I0708 12:28:15.705309 31135 solver.cpp:243] Iteration 22000, loss = 0.136815
I0708 12:28:15.705405 31135 solver.cpp:259]     Train net output #0: loss = 0.136816 (* 1 = 0.136816 loss)
I0708 12:28:15.705422 31135 solver.cpp:590] Iteration 22000, lr = 0.00145292
I0708 12:28:25.781846 31135 solver.cpp:347] Iteration 22050, Testing net (#0)
I0708 12:28:49.889885 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0813702
I0708 12:28:49.890007 31135 solver.cpp:415]     Test net output #1: loss = 6.219 (* 1 = 6.219 loss)
I0708 12:29:02.395584 31135 solver.cpp:243] Iteration 22110, loss = 0.189159
I0708 12:29:02.395606 31135 solver.cpp:259]     Train net output #0: loss = 0.18916 (* 1 = 0.18916 loss)
I0708 12:29:02.395612 31135 solver.cpp:590] Iteration 22110, lr = 0.00143897
I0708 12:29:25.009765 31135 solver.cpp:243] Iteration 22220, loss = 0.272398
I0708 12:29:25.009855 31135 solver.cpp:259]     Train net output #0: loss = 0.2724 (* 1 = 0.2724 loss)
I0708 12:29:25.009862 31135 solver.cpp:590] Iteration 22220, lr = 0.00142516
I0708 12:29:47.605628 31135 solver.cpp:243] Iteration 22330, loss = 0.126284
I0708 12:29:47.605649 31135 solver.cpp:259]     Train net output #0: loss = 0.126285 (* 1 = 0.126285 loss)
I0708 12:29:47.605655 31135 solver.cpp:590] Iteration 22330, lr = 0.00141148
I0708 12:30:10.211382 31135 solver.cpp:243] Iteration 22440, loss = 0.0470811
I0708 12:30:10.211452 31135 solver.cpp:259]     Train net output #0: loss = 0.047082 (* 1 = 0.047082 loss)
I0708 12:30:10.211470 31135 solver.cpp:590] Iteration 22440, lr = 0.00139793
I0708 12:30:32.826911 31135 solver.cpp:243] Iteration 22550, loss = 0.546887
I0708 12:30:32.826933 31135 solver.cpp:259]     Train net output #0: loss = 0.546888 (* 1 = 0.546888 loss)
I0708 12:30:32.826939 31135 solver.cpp:590] Iteration 22550, lr = 0.00138451
I0708 12:30:55.448120 31135 solver.cpp:243] Iteration 22660, loss = 0.0198471
I0708 12:30:55.448230 31135 solver.cpp:259]     Train net output #0: loss = 0.019848 (* 1 = 0.019848 loss)
I0708 12:30:55.448247 31135 solver.cpp:590] Iteration 22660, lr = 0.00137123
I0708 12:31:18.062340 31135 solver.cpp:243] Iteration 22770, loss = 0.0168478
I0708 12:31:18.062363 31135 solver.cpp:259]     Train net output #0: loss = 0.0168486 (* 1 = 0.0168486 loss)
I0708 12:31:18.062369 31135 solver.cpp:590] Iteration 22770, lr = 0.00135806
I0708 12:31:40.667091 31135 solver.cpp:243] Iteration 22880, loss = 0.255695
I0708 12:31:40.667601 31135 solver.cpp:259]     Train net output #0: loss = 0.255695 (* 1 = 0.255695 loss)
I0708 12:31:40.667609 31135 solver.cpp:590] Iteration 22880, lr = 0.00134503
I0708 12:31:51.154690 31135 solver.cpp:347] Iteration 22932, Testing net (#0)
I0708 12:32:13.184128 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0841346
I0708 12:32:13.184232 31135 solver.cpp:415]     Test net output #1: loss = 6.26589 (* 1 = 6.26589 loss)
I0708 12:32:25.273645 31135 solver.cpp:243] Iteration 22990, loss = 0.0491604
I0708 12:32:25.273669 31135 solver.cpp:259]     Train net output #0: loss = 0.0491611 (* 1 = 0.0491611 loss)
I0708 12:32:25.273675 31135 solver.cpp:590] Iteration 22990, lr = 0.00133212
I0708 12:32:47.907912 31135 solver.cpp:243] Iteration 23100, loss = 0.0706329
I0708 12:32:47.908001 31135 solver.cpp:259]     Train net output #0: loss = 0.0706336 (* 1 = 0.0706336 loss)
I0708 12:32:47.908007 31135 solver.cpp:590] Iteration 23100, lr = 0.00131933
I0708 12:33:10.555078 31135 solver.cpp:243] Iteration 23210, loss = 0.0567324
I0708 12:33:10.555102 31135 solver.cpp:259]     Train net output #0: loss = 0.0567331 (* 1 = 0.0567331 loss)
I0708 12:33:10.555109 31135 solver.cpp:590] Iteration 23210, lr = 0.00130667
I0708 12:33:33.177247 31135 solver.cpp:243] Iteration 23320, loss = 0.0308234
I0708 12:33:33.177340 31135 solver.cpp:259]     Train net output #0: loss = 0.030824 (* 1 = 0.030824 loss)
I0708 12:33:33.177346 31135 solver.cpp:590] Iteration 23320, lr = 0.00129412
I0708 12:33:55.791412 31135 solver.cpp:243] Iteration 23430, loss = 0.0488439
I0708 12:33:55.791437 31135 solver.cpp:259]     Train net output #0: loss = 0.0488445 (* 1 = 0.0488445 loss)
I0708 12:33:55.791443 31135 solver.cpp:590] Iteration 23430, lr = 0.0012817
I0708 12:34:18.415227 31135 solver.cpp:243] Iteration 23540, loss = 0.181525
I0708 12:34:18.415316 31135 solver.cpp:259]     Train net output #0: loss = 0.181526 (* 1 = 0.181526 loss)
I0708 12:34:18.415323 31135 solver.cpp:590] Iteration 23540, lr = 0.0012694
I0708 12:34:41.048241 31135 solver.cpp:243] Iteration 23650, loss = 0.175975
I0708 12:34:41.048265 31135 solver.cpp:259]     Train net output #0: loss = 0.175976 (* 1 = 0.175976 loss)
I0708 12:34:41.048271 31135 solver.cpp:590] Iteration 23650, lr = 0.00125722
I0708 12:35:03.672003 31135 solver.cpp:243] Iteration 23760, loss = 0.119519
I0708 12:35:03.672096 31135 solver.cpp:259]     Train net output #0: loss = 0.11952 (* 1 = 0.11952 loss)
I0708 12:35:03.672113 31135 solver.cpp:590] Iteration 23760, lr = 0.00124515
I0708 12:35:14.573693 31135 solver.cpp:347] Iteration 23814, Testing net (#0)
I0708 12:35:23.928616 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 12:35:40.367795 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0832933
I0708 12:35:40.367897 31135 solver.cpp:415]     Test net output #1: loss = 6.29412 (* 1 = 6.29412 loss)
I0708 12:35:52.039095 31135 solver.cpp:243] Iteration 23870, loss = 0.57297
I0708 12:35:52.039119 31135 solver.cpp:259]     Train net output #0: loss = 0.572971 (* 1 = 0.572971 loss)
I0708 12:35:52.039125 31135 solver.cpp:590] Iteration 23870, lr = 0.0012332
I0708 12:36:14.642882 31135 solver.cpp:243] Iteration 23980, loss = 0.817186
I0708 12:36:14.642938 31135 solver.cpp:259]     Train net output #0: loss = 0.817187 (* 1 = 0.817187 loss)
I0708 12:36:14.642945 31135 solver.cpp:590] Iteration 23980, lr = 0.00122136
I0708 12:36:37.257392 31135 solver.cpp:243] Iteration 24090, loss = 0.00450902
I0708 12:36:37.257414 31135 solver.cpp:259]     Train net output #0: loss = 0.00451012 (* 1 = 0.00451012 loss)
I0708 12:36:37.257421 31135 solver.cpp:590] Iteration 24090, lr = 0.00120964
I0708 12:36:59.881124 31135 solver.cpp:243] Iteration 24200, loss = 0.220366
I0708 12:36:59.881227 31135 solver.cpp:259]     Train net output #0: loss = 0.220367 (* 1 = 0.220367 loss)
I0708 12:36:59.881243 31135 solver.cpp:590] Iteration 24200, lr = 0.00119802
I0708 12:37:22.504729 31135 solver.cpp:243] Iteration 24310, loss = 0.00954841
I0708 12:37:22.504753 31135 solver.cpp:259]     Train net output #0: loss = 0.00954961 (* 1 = 0.00954961 loss)
I0708 12:37:22.504758 31135 solver.cpp:590] Iteration 24310, lr = 0.00118653
I0708 12:37:45.117820 31135 solver.cpp:243] Iteration 24420, loss = 0.590107
I0708 12:37:45.119372 31135 solver.cpp:259]     Train net output #0: loss = 0.590108 (* 1 = 0.590108 loss)
I0708 12:37:45.119384 31135 solver.cpp:590] Iteration 24420, lr = 0.00117514
I0708 12:38:07.725790 31135 solver.cpp:243] Iteration 24530, loss = 0.132455
I0708 12:38:07.725817 31135 solver.cpp:259]     Train net output #0: loss = 0.132456 (* 1 = 0.132456 loss)
I0708 12:38:07.725823 31135 solver.cpp:590] Iteration 24530, lr = 0.00116386
I0708 12:38:30.348803 31135 solver.cpp:243] Iteration 24640, loss = 0.154483
I0708 12:38:30.349062 31135 solver.cpp:259]     Train net output #0: loss = 0.154485 (* 1 = 0.154485 loss)
I0708 12:38:30.349071 31135 solver.cpp:590] Iteration 24640, lr = 0.00115268
I0708 12:38:41.669960 31135 solver.cpp:347] Iteration 24696, Testing net (#0)
I0708 12:38:45.518479 31152 blocking_queue.cpp:50] Waiting for data
I0708 12:39:07.130462 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0856971
I0708 12:39:07.130770 31135 solver.cpp:415]     Test net output #1: loss = 6.37384 (* 1 = 6.37384 loss)
I0708 12:39:18.394213 31135 solver.cpp:243] Iteration 24750, loss = 0.00178679
I0708 12:39:18.394237 31135 solver.cpp:259]     Train net output #0: loss = 0.001788 (* 1 = 0.001788 loss)
I0708 12:39:18.394243 31135 solver.cpp:590] Iteration 24750, lr = 0.00114162
I0708 12:39:41.030233 31135 solver.cpp:243] Iteration 24860, loss = 0.0834797
I0708 12:39:41.030336 31135 solver.cpp:259]     Train net output #0: loss = 0.0834808 (* 1 = 0.0834808 loss)
I0708 12:39:41.030344 31135 solver.cpp:590] Iteration 24860, lr = 0.00113066
I0708 12:40:03.660907 31135 solver.cpp:243] Iteration 24970, loss = 0.334404
I0708 12:40:03.660933 31135 solver.cpp:259]     Train net output #0: loss = 0.334405 (* 1 = 0.334405 loss)
I0708 12:40:03.660938 31135 solver.cpp:590] Iteration 24970, lr = 0.00111981
I0708 12:40:26.256769 31135 solver.cpp:243] Iteration 25080, loss = 0.176801
I0708 12:40:26.256856 31135 solver.cpp:259]     Train net output #0: loss = 0.176802 (* 1 = 0.176802 loss)
I0708 12:40:26.256872 31135 solver.cpp:590] Iteration 25080, lr = 0.00110906
I0708 12:40:48.857882 31135 solver.cpp:243] Iteration 25190, loss = 0.0309863
I0708 12:40:48.857904 31135 solver.cpp:259]     Train net output #0: loss = 0.0309875 (* 1 = 0.0309875 loss)
I0708 12:40:48.857910 31135 solver.cpp:590] Iteration 25190, lr = 0.00109842
I0708 12:41:11.485766 31135 solver.cpp:243] Iteration 25300, loss = 0.00509173
I0708 12:41:11.485857 31135 solver.cpp:259]     Train net output #0: loss = 0.00509292 (* 1 = 0.00509292 loss)
I0708 12:41:11.485867 31135 solver.cpp:590] Iteration 25300, lr = 0.00108787
I0708 12:41:34.109189 31135 solver.cpp:243] Iteration 25410, loss = 0.0749012
I0708 12:41:34.109210 31135 solver.cpp:259]     Train net output #0: loss = 0.0749025 (* 1 = 0.0749025 loss)
I0708 12:41:34.109215 31135 solver.cpp:590] Iteration 25410, lr = 0.00107743
I0708 12:41:56.692530 31135 solver.cpp:243] Iteration 25520, loss = 0.14695
I0708 12:41:56.692611 31135 solver.cpp:259]     Train net output #0: loss = 0.146951 (* 1 = 0.146951 loss)
I0708 12:41:56.692617 31135 solver.cpp:590] Iteration 25520, lr = 0.00106709
I0708 12:42:08.402124 31135 solver.cpp:347] Iteration 25578, Testing net (#0)
I0708 12:42:32.915860 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0873798
I0708 12:42:32.916013 31135 solver.cpp:415]     Test net output #1: loss = 6.36236 (* 1 = 6.36236 loss)
I0708 12:42:43.761919 31135 solver.cpp:243] Iteration 25630, loss = 0.0696646
I0708 12:42:43.761945 31135 solver.cpp:259]     Train net output #0: loss = 0.069666 (* 1 = 0.069666 loss)
I0708 12:42:43.761950 31135 solver.cpp:590] Iteration 25630, lr = 0.00105685
I0708 12:43:06.379391 31135 solver.cpp:243] Iteration 25740, loss = 0.05019
I0708 12:43:06.380066 31135 solver.cpp:259]     Train net output #0: loss = 0.0501913 (* 1 = 0.0501913 loss)
I0708 12:43:06.380077 31135 solver.cpp:590] Iteration 25740, lr = 0.0010467
I0708 12:43:28.986635 31135 solver.cpp:243] Iteration 25850, loss = 0.107349
I0708 12:43:28.986681 31135 solver.cpp:259]     Train net output #0: loss = 0.107351 (* 1 = 0.107351 loss)
I0708 12:43:28.986696 31135 solver.cpp:590] Iteration 25850, lr = 0.00103665
I0708 12:43:51.612334 31135 solver.cpp:243] Iteration 25960, loss = 0.361367
I0708 12:43:51.612421 31135 solver.cpp:259]     Train net output #0: loss = 0.361368 (* 1 = 0.361368 loss)
I0708 12:43:51.612428 31135 solver.cpp:590] Iteration 25960, lr = 0.0010267
I0708 12:44:14.231052 31135 solver.cpp:243] Iteration 26070, loss = 0.118667
I0708 12:44:14.231076 31135 solver.cpp:259]     Train net output #0: loss = 0.118669 (* 1 = 0.118669 loss)
I0708 12:44:14.231082 31135 solver.cpp:590] Iteration 26070, lr = 0.00101685
I0708 12:44:36.836896 31135 solver.cpp:243] Iteration 26180, loss = 0.0277319
I0708 12:44:36.836977 31135 solver.cpp:259]     Train net output #0: loss = 0.0277332 (* 1 = 0.0277332 loss)
I0708 12:44:36.836984 31135 solver.cpp:590] Iteration 26180, lr = 0.00100709
I0708 12:44:59.436769 31135 solver.cpp:243] Iteration 26290, loss = 0.12867
I0708 12:44:59.436794 31135 solver.cpp:259]     Train net output #0: loss = 0.128671 (* 1 = 0.128671 loss)
I0708 12:44:59.436799 31135 solver.cpp:590] Iteration 26290, lr = 0.000997421
I0708 12:45:22.098327 31135 solver.cpp:243] Iteration 26400, loss = 0.0471023
I0708 12:45:22.098418 31135 solver.cpp:259]     Train net output #0: loss = 0.0471036 (* 1 = 0.0471036 loss)
I0708 12:45:22.098434 31135 solver.cpp:590] Iteration 26400, lr = 0.000987847
I0708 12:45:34.226802 31135 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_26460.caffemodel
I0708 12:45:41.330382 31135 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_26460.solverstate
I0708 12:45:43.530975 31135 solver.cpp:347] Iteration 26460, Testing net (#0)
I0708 12:46:10.689754 31135 solver.cpp:415]     Test net output #0: accuracy = 0.091226
I0708 12:46:10.689864 31135 solver.cpp:415]     Test net output #1: loss = 6.36111 (* 1 = 6.36111 loss)
I0708 12:46:21.130143 31135 solver.cpp:243] Iteration 26510, loss = 0.421082
I0708 12:46:21.130169 31135 solver.cpp:259]     Train net output #0: loss = 0.421084 (* 1 = 0.421084 loss)
I0708 12:46:21.130175 31135 solver.cpp:590] Iteration 26510, lr = 0.000978365
I0708 12:46:43.755116 31135 solver.cpp:243] Iteration 26620, loss = 0.0615818
I0708 12:46:43.755208 31135 solver.cpp:259]     Train net output #0: loss = 0.0615831 (* 1 = 0.0615831 loss)
I0708 12:46:43.755223 31135 solver.cpp:590] Iteration 26620, lr = 0.000968974
I0708 12:47:06.403246 31135 solver.cpp:243] Iteration 26730, loss = 0.277527
I0708 12:47:06.403272 31135 solver.cpp:259]     Train net output #0: loss = 0.277528 (* 1 = 0.277528 loss)
I0708 12:47:06.403277 31135 solver.cpp:590] Iteration 26730, lr = 0.000959673
I0708 12:47:29.004894 31135 solver.cpp:243] Iteration 26840, loss = 0.605537
I0708 12:47:29.004998 31135 solver.cpp:259]     Train net output #0: loss = 0.605539 (* 1 = 0.605539 loss)
I0708 12:47:29.005017 31135 solver.cpp:590] Iteration 26840, lr = 0.000950462
I0708 12:47:51.608891 31135 solver.cpp:243] Iteration 26950, loss = 0.0627299
I0708 12:47:51.608913 31135 solver.cpp:259]     Train net output #0: loss = 0.0627311 (* 1 = 0.0627311 loss)
I0708 12:47:51.608919 31135 solver.cpp:590] Iteration 26950, lr = 0.000941339
I0708 12:48:14.239837 31135 solver.cpp:243] Iteration 27060, loss = 0.239912
I0708 12:48:14.239958 31135 solver.cpp:259]     Train net output #0: loss = 0.239913 (* 1 = 0.239913 loss)
I0708 12:48:14.239974 31135 solver.cpp:590] Iteration 27060, lr = 0.000932303
I0708 12:48:36.888345 31135 solver.cpp:243] Iteration 27170, loss = 0.0232292
I0708 12:48:36.888368 31135 solver.cpp:259]     Train net output #0: loss = 0.0232304 (* 1 = 0.0232304 loss)
I0708 12:48:36.888373 31135 solver.cpp:590] Iteration 27170, lr = 0.000923354
I0708 12:48:59.505969 31135 solver.cpp:243] Iteration 27280, loss = 0.0117409
I0708 12:48:59.506647 31135 solver.cpp:259]     Train net output #0: loss = 0.0117421 (* 1 = 0.0117421 loss)
I0708 12:48:59.506669 31135 solver.cpp:590] Iteration 27280, lr = 0.000914491
I0708 12:49:12.050760 31135 solver.cpp:347] Iteration 27342, Testing net (#0)
I0708 12:49:19.158772 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 12:49:36.390554 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0893029
I0708 12:49:36.390650 31135 solver.cpp:415]     Test net output #1: loss = 6.30614 (* 1 = 6.30614 loss)
I0708 12:49:46.409678 31135 solver.cpp:243] Iteration 27390, loss = 0.00222459
I0708 12:49:46.409703 31135 solver.cpp:259]     Train net output #0: loss = 0.00222579 (* 1 = 0.00222579 loss)
I0708 12:49:46.409708 31135 solver.cpp:590] Iteration 27390, lr = 0.000905713
I0708 12:50:09.026639 31135 solver.cpp:243] Iteration 27500, loss = 0.420572
I0708 12:50:09.026772 31135 solver.cpp:259]     Train net output #0: loss = 0.420573 (* 1 = 0.420573 loss)
I0708 12:50:09.026780 31135 solver.cpp:590] Iteration 27500, lr = 0.00089702
I0708 12:50:31.654356 31135 solver.cpp:243] Iteration 27610, loss = 0.0996829
I0708 12:50:31.654381 31135 solver.cpp:259]     Train net output #0: loss = 0.0996842 (* 1 = 0.0996842 loss)
I0708 12:50:31.654386 31135 solver.cpp:590] Iteration 27610, lr = 0.000888409
I0708 12:50:54.300156 31135 solver.cpp:243] Iteration 27720, loss = 0.213402
I0708 12:50:54.301607 31135 solver.cpp:259]     Train net output #0: loss = 0.213403 (* 1 = 0.213403 loss)
I0708 12:50:54.301614 31135 solver.cpp:590] Iteration 27720, lr = 0.000879882
I0708 12:51:16.953239 31135 solver.cpp:243] Iteration 27830, loss = 0.177577
I0708 12:51:16.953263 31135 solver.cpp:259]     Train net output #0: loss = 0.177578 (* 1 = 0.177578 loss)
I0708 12:51:16.953269 31135 solver.cpp:590] Iteration 27830, lr = 0.000871436
I0708 12:51:39.582967 31135 solver.cpp:243] Iteration 27940, loss = 0.160648
I0708 12:51:39.583062 31135 solver.cpp:259]     Train net output #0: loss = 0.160649 (* 1 = 0.160649 loss)
I0708 12:51:39.583078 31135 solver.cpp:590] Iteration 27940, lr = 0.000863072
I0708 12:52:02.194206 31135 solver.cpp:243] Iteration 28050, loss = 0.393002
I0708 12:52:02.194227 31135 solver.cpp:259]     Train net output #0: loss = 0.393003 (* 1 = 0.393003 loss)
I0708 12:52:02.194234 31135 solver.cpp:590] Iteration 28050, lr = 0.000854787
I0708 12:52:24.830878 31135 solver.cpp:243] Iteration 28160, loss = 0.0428713
I0708 12:52:24.830968 31135 solver.cpp:259]     Train net output #0: loss = 0.0428723 (* 1 = 0.0428723 loss)
I0708 12:52:24.830974 31135 solver.cpp:590] Iteration 28160, lr = 0.000846582
I0708 12:52:37.793690 31135 solver.cpp:347] Iteration 28224, Testing net (#0)
I0708 12:52:44.899677 31152 blocking_queue.cpp:50] Waiting for data
I0708 12:53:04.380305 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0908654
I0708 12:53:04.380378 31135 solver.cpp:415]     Test net output #1: loss = 6.45468 (* 1 = 6.45468 loss)
I0708 12:53:14.017088 31135 solver.cpp:243] Iteration 28270, loss = 0.012038
I0708 12:53:14.017113 31135 solver.cpp:259]     Train net output #0: loss = 0.0120392 (* 1 = 0.0120392 loss)
I0708 12:53:14.017119 31135 solver.cpp:590] Iteration 28270, lr = 0.000838456
I0708 12:53:36.650547 31135 solver.cpp:243] Iteration 28380, loss = 0.0658918
I0708 12:53:36.650638 31135 solver.cpp:259]     Train net output #0: loss = 0.0658929 (* 1 = 0.0658929 loss)
I0708 12:53:36.650655 31135 solver.cpp:590] Iteration 28380, lr = 0.000830408
I0708 12:53:59.265864 31135 solver.cpp:243] Iteration 28490, loss = 0.0127612
I0708 12:53:59.265889 31135 solver.cpp:259]     Train net output #0: loss = 0.0127623 (* 1 = 0.0127623 loss)
I0708 12:53:59.265895 31135 solver.cpp:590] Iteration 28490, lr = 0.000822437
I0708 12:54:21.914682 31135 solver.cpp:243] Iteration 28600, loss = 0.0258118
I0708 12:54:21.914788 31135 solver.cpp:259]     Train net output #0: loss = 0.0258128 (* 1 = 0.0258128 loss)
I0708 12:54:21.914805 31135 solver.cpp:590] Iteration 28600, lr = 0.000814543
I0708 12:54:44.577285 31135 solver.cpp:243] Iteration 28710, loss = 0.0369486
I0708 12:54:44.577306 31135 solver.cpp:259]     Train net output #0: loss = 0.0369496 (* 1 = 0.0369496 loss)
I0708 12:54:44.577311 31135 solver.cpp:590] Iteration 28710, lr = 0.000806724
I0708 12:55:07.229385 31135 solver.cpp:243] Iteration 28820, loss = 0.351387
I0708 12:55:07.229723 31135 solver.cpp:259]     Train net output #0: loss = 0.351388 (* 1 = 0.351388 loss)
I0708 12:55:07.229732 31135 solver.cpp:590] Iteration 28820, lr = 0.000798981
I0708 12:55:29.853981 31135 solver.cpp:243] Iteration 28930, loss = 0.240933
I0708 12:55:29.854006 31135 solver.cpp:259]     Train net output #0: loss = 0.240933 (* 1 = 0.240933 loss)
I0708 12:55:29.854012 31135 solver.cpp:590] Iteration 28930, lr = 0.000791312
I0708 12:55:52.475479 31135 solver.cpp:243] Iteration 29040, loss = 0.142914
I0708 12:55:52.475819 31135 solver.cpp:259]     Train net output #0: loss = 0.142915 (* 1 = 0.142915 loss)
I0708 12:55:52.475828 31135 solver.cpp:590] Iteration 29040, lr = 0.000783716
I0708 12:56:05.850692 31135 solver.cpp:347] Iteration 29106, Testing net (#0)
I0708 12:56:28.943033 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0893029
I0708 12:56:28.943130 31135 solver.cpp:415]     Test net output #1: loss = 6.33086 (* 1 = 6.33086 loss)
I0708 12:56:38.150923 31135 solver.cpp:243] Iteration 29150, loss = 0.0816473
I0708 12:56:38.150949 31135 solver.cpp:259]     Train net output #0: loss = 0.0816482 (* 1 = 0.0816482 loss)
I0708 12:56:38.150954 31135 solver.cpp:590] Iteration 29150, lr = 0.000776194
I0708 12:57:00.819947 31135 solver.cpp:243] Iteration 29260, loss = 0.126925
I0708 12:57:00.820032 31135 solver.cpp:259]     Train net output #0: loss = 0.126926 (* 1 = 0.126926 loss)
I0708 12:57:00.820039 31135 solver.cpp:590] Iteration 29260, lr = 0.000768743
I0708 12:57:23.469513 31135 solver.cpp:243] Iteration 29370, loss = 0.232682
I0708 12:57:23.469537 31135 solver.cpp:259]     Train net output #0: loss = 0.232683 (* 1 = 0.232683 loss)
I0708 12:57:23.469542 31135 solver.cpp:590] Iteration 29370, lr = 0.000761364
I0708 12:57:46.099032 31135 solver.cpp:243] Iteration 29480, loss = 0.000137258
I0708 12:57:46.099119 31135 solver.cpp:259]     Train net output #0: loss = 0.000138206 (* 1 = 0.000138206 loss)
I0708 12:57:46.099135 31135 solver.cpp:590] Iteration 29480, lr = 0.000754056
I0708 12:58:08.741457 31135 solver.cpp:243] Iteration 29590, loss = 0.0318592
I0708 12:58:08.741478 31135 solver.cpp:259]     Train net output #0: loss = 0.0318601 (* 1 = 0.0318601 loss)
I0708 12:58:08.741484 31135 solver.cpp:590] Iteration 29590, lr = 0.000746818
I0708 12:58:31.370744 31135 solver.cpp:243] Iteration 29700, loss = 0.0349949
I0708 12:58:31.370836 31135 solver.cpp:259]     Train net output #0: loss = 0.0349958 (* 1 = 0.0349958 loss)
I0708 12:58:31.370851 31135 solver.cpp:590] Iteration 29700, lr = 0.00073965
I0708 12:58:54.001482 31135 solver.cpp:243] Iteration 29810, loss = 0.237341
I0708 12:58:54.001505 31135 solver.cpp:259]     Train net output #0: loss = 0.237342 (* 1 = 0.237342 loss)
I0708 12:58:54.001510 31135 solver.cpp:590] Iteration 29810, lr = 0.00073255
I0708 12:59:16.671255 31135 solver.cpp:243] Iteration 29920, loss = 0.0568222
I0708 12:59:16.671352 31135 solver.cpp:259]     Train net output #0: loss = 0.056823 (* 1 = 0.056823 loss)
I0708 12:59:16.671367 31135 solver.cpp:590] Iteration 29920, lr = 0.000725519
I0708 12:59:30.454939 31135 solver.cpp:347] Iteration 29988, Testing net (#0)
I0708 12:59:55.201406 31135 solver.cpp:415]     Test net output #0: accuracy = 0.097476
I0708 12:59:55.201530 31135 solver.cpp:415]     Test net output #1: loss = 6.43557 (* 1 = 6.43557 loss)
I0708 13:00:04.002506 31135 solver.cpp:243] Iteration 30030, loss = 0.133769
I0708 13:00:04.002529 31135 solver.cpp:259]     Train net output #0: loss = 0.13377 (* 1 = 0.13377 loss)
I0708 13:00:04.002535 31135 solver.cpp:590] Iteration 30030, lr = 0.000718555
I0708 13:00:26.663355 31135 solver.cpp:243] Iteration 30140, loss = 0.0212111
I0708 13:00:26.663517 31135 solver.cpp:259]     Train net output #0: loss = 0.021212 (* 1 = 0.021212 loss)
I0708 13:00:26.663525 31135 solver.cpp:590] Iteration 30140, lr = 0.000711657
I0708 13:00:49.301192 31135 solver.cpp:243] Iteration 30250, loss = 0.0567791
I0708 13:00:49.301216 31135 solver.cpp:259]     Train net output #0: loss = 0.05678 (* 1 = 0.05678 loss)
I0708 13:00:49.301223 31135 solver.cpp:590] Iteration 30250, lr = 0.000704826
I0708 13:01:11.933902 31135 solver.cpp:243] Iteration 30360, loss = 0.0372395
I0708 13:01:11.934351 31135 solver.cpp:259]     Train net output #0: loss = 0.0372404 (* 1 = 0.0372404 loss)
I0708 13:01:11.934370 31135 solver.cpp:590] Iteration 30360, lr = 0.000698061
I0708 13:01:34.596863 31135 solver.cpp:243] Iteration 30470, loss = 0.217503
I0708 13:01:34.596889 31135 solver.cpp:259]     Train net output #0: loss = 0.217504 (* 1 = 0.217504 loss)
I0708 13:01:34.596897 31135 solver.cpp:590] Iteration 30470, lr = 0.000691361
I0708 13:01:57.269713 31135 solver.cpp:243] Iteration 30580, loss = 0.025287
I0708 13:01:57.273757 31135 solver.cpp:259]     Train net output #0: loss = 0.0252879 (* 1 = 0.0252879 loss)
I0708 13:01:57.273766 31135 solver.cpp:590] Iteration 30580, lr = 0.000684724
I0708 13:02:19.929996 31135 solver.cpp:243] Iteration 30690, loss = 0.111095
I0708 13:02:19.930019 31135 solver.cpp:259]     Train net output #0: loss = 0.111096 (* 1 = 0.111096 loss)
I0708 13:02:19.930025 31135 solver.cpp:590] Iteration 30690, lr = 0.000678152
I0708 13:02:42.567972 31135 solver.cpp:243] Iteration 30800, loss = 0.0288664
I0708 13:02:42.569300 31135 solver.cpp:259]     Train net output #0: loss = 0.0288673 (* 1 = 0.0288673 loss)
I0708 13:02:42.569309 31135 solver.cpp:590] Iteration 30800, lr = 0.000671643
I0708 13:02:56.759280 31135 solver.cpp:347] Iteration 30870, Testing net (#0)
I0708 13:03:00.915236 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 13:03:21.387238 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0941106
I0708 13:03:21.387362 31135 solver.cpp:415]     Test net output #1: loss = 6.39345 (* 1 = 6.39345 loss)
I0708 13:03:29.780946 31135 solver.cpp:243] Iteration 30910, loss = 0.12801
I0708 13:03:29.780971 31135 solver.cpp:259]     Train net output #0: loss = 0.128011 (* 1 = 0.128011 loss)
I0708 13:03:29.780977 31135 solver.cpp:590] Iteration 30910, lr = 0.000665196
I0708 13:03:52.444839 31135 solver.cpp:243] Iteration 31020, loss = 0.0263764
I0708 13:03:52.445015 31135 solver.cpp:259]     Train net output #0: loss = 0.0263772 (* 1 = 0.0263772 loss)
I0708 13:03:52.445024 31135 solver.cpp:590] Iteration 31020, lr = 0.000658811
I0708 13:04:15.090816 31135 solver.cpp:243] Iteration 31130, loss = 0.0123931
I0708 13:04:15.090838 31135 solver.cpp:259]     Train net output #0: loss = 0.012394 (* 1 = 0.012394 loss)
I0708 13:04:15.090844 31135 solver.cpp:590] Iteration 31130, lr = 0.000652487
I0708 13:04:37.739742 31135 solver.cpp:243] Iteration 31240, loss = 0.0328775
I0708 13:04:37.740360 31135 solver.cpp:259]     Train net output #0: loss = 0.0328785 (* 1 = 0.0328785 loss)
I0708 13:04:37.740370 31135 solver.cpp:590] Iteration 31240, lr = 0.000646224
I0708 13:05:00.375681 31135 solver.cpp:243] Iteration 31350, loss = 0.0354665
I0708 13:05:00.375702 31135 solver.cpp:259]     Train net output #0: loss = 0.0354675 (* 1 = 0.0354675 loss)
I0708 13:05:00.375708 31135 solver.cpp:590] Iteration 31350, lr = 0.000640021
I0708 13:05:23.010071 31135 solver.cpp:243] Iteration 31460, loss = 0.0322887
I0708 13:05:23.010349 31135 solver.cpp:259]     Train net output #0: loss = 0.0322896 (* 1 = 0.0322896 loss)
I0708 13:05:23.010357 31135 solver.cpp:590] Iteration 31460, lr = 0.000633878
I0708 13:05:45.677829 31135 solver.cpp:243] Iteration 31570, loss = 0.0756113
I0708 13:05:45.677855 31135 solver.cpp:259]     Train net output #0: loss = 0.0756122 (* 1 = 0.0756122 loss)
I0708 13:05:45.677861 31135 solver.cpp:590] Iteration 31570, lr = 0.000627793
I0708 13:06:08.325523 31135 solver.cpp:243] Iteration 31680, loss = 0.00727433
I0708 13:06:08.325899 31135 solver.cpp:259]     Train net output #0: loss = 0.00727526 (* 1 = 0.00727526 loss)
I0708 13:06:08.325907 31135 solver.cpp:590] Iteration 31680, lr = 0.000621767
I0708 13:06:22.931605 31135 solver.cpp:347] Iteration 31752, Testing net (#0)
I0708 13:06:46.861682 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0919471
I0708 13:06:46.861945 31135 solver.cpp:415]     Test net output #1: loss = 6.40771 (* 1 = 6.40771 loss)
I0708 13:06:54.839462 31135 solver.cpp:243] Iteration 31790, loss = 0.408277
I0708 13:06:54.839485 31135 solver.cpp:259]     Train net output #0: loss = 0.408278 (* 1 = 0.408278 loss)
I0708 13:06:54.839491 31135 solver.cpp:590] Iteration 31790, lr = 0.000615799
I0708 13:07:17.461767 31135 solver.cpp:243] Iteration 31900, loss = 0.00907488
I0708 13:07:17.461863 31135 solver.cpp:259]     Train net output #0: loss = 0.00907574 (* 1 = 0.00907574 loss)
I0708 13:07:17.461870 31135 solver.cpp:590] Iteration 31900, lr = 0.000609888
I0708 13:07:40.104450 31135 solver.cpp:243] Iteration 32010, loss = 0.0132667
I0708 13:07:40.104475 31135 solver.cpp:259]     Train net output #0: loss = 0.0132675 (* 1 = 0.0132675 loss)
I0708 13:07:40.104480 31135 solver.cpp:590] Iteration 32010, lr = 0.000604034
I0708 13:08:02.767225 31135 solver.cpp:243] Iteration 32120, loss = 0.0997045
I0708 13:08:02.767313 31135 solver.cpp:259]     Train net output #0: loss = 0.0997054 (* 1 = 0.0997054 loss)
I0708 13:08:02.767320 31135 solver.cpp:590] Iteration 32120, lr = 0.000598236
I0708 13:08:25.435358 31135 solver.cpp:243] Iteration 32230, loss = 0.00529658
I0708 13:08:25.435381 31135 solver.cpp:259]     Train net output #0: loss = 0.0052975 (* 1 = 0.0052975 loss)
I0708 13:08:25.435387 31135 solver.cpp:590] Iteration 32230, lr = 0.000592494
I0708 13:08:48.068639 31135 solver.cpp:243] Iteration 32340, loss = 0.326977
I0708 13:08:48.068724 31135 solver.cpp:259]     Train net output #0: loss = 0.326978 (* 1 = 0.326978 loss)
I0708 13:08:48.068730 31135 solver.cpp:590] Iteration 32340, lr = 0.000586807
I0708 13:09:10.690673 31135 solver.cpp:243] Iteration 32450, loss = 0.0113255
I0708 13:09:10.690696 31135 solver.cpp:259]     Train net output #0: loss = 0.0113266 (* 1 = 0.0113266 loss)
I0708 13:09:10.690702 31135 solver.cpp:590] Iteration 32450, lr = 0.000581174
I0708 13:09:33.353848 31135 solver.cpp:243] Iteration 32560, loss = 0.130061
I0708 13:09:33.353937 31135 solver.cpp:259]     Train net output #0: loss = 0.130062 (* 1 = 0.130062 loss)
I0708 13:09:33.353943 31135 solver.cpp:590] Iteration 32560, lr = 0.000575596
I0708 13:09:48.408540 31135 solver.cpp:347] Iteration 32634, Testing net (#0)
I0708 13:10:10.311189 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0960337
I0708 13:10:10.311321 31135 solver.cpp:415]     Test net output #1: loss = 6.41142 (* 1 = 6.41142 loss)
I0708 13:10:17.887603 31135 solver.cpp:243] Iteration 32670, loss = 0.216082
I0708 13:10:17.887625 31135 solver.cpp:259]     Train net output #0: loss = 0.216083 (* 1 = 0.216083 loss)
I0708 13:10:17.887631 31135 solver.cpp:590] Iteration 32670, lr = 0.000570071
I0708 13:10:40.581753 31135 solver.cpp:243] Iteration 32780, loss = 0.0251269
I0708 13:10:40.581881 31135 solver.cpp:259]     Train net output #0: loss = 0.0251279 (* 1 = 0.0251279 loss)
I0708 13:10:40.581888 31135 solver.cpp:590] Iteration 32780, lr = 0.000564599
I0708 13:11:03.232066 31135 solver.cpp:243] Iteration 32890, loss = 0.253998
I0708 13:11:03.232100 31135 solver.cpp:259]     Train net output #0: loss = 0.253999 (* 1 = 0.253999 loss)
I0708 13:11:03.232107 31135 solver.cpp:590] Iteration 32890, lr = 0.000559179
I0708 13:11:25.868752 31135 solver.cpp:243] Iteration 33000, loss = 0.00427031
I0708 13:11:25.868892 31135 solver.cpp:259]     Train net output #0: loss = 0.00427138 (* 1 = 0.00427138 loss)
I0708 13:11:25.868901 31135 solver.cpp:590] Iteration 33000, lr = 0.000553812
I0708 13:11:48.514219 31135 solver.cpp:243] Iteration 33110, loss = 0.0328989
I0708 13:11:48.514243 31135 solver.cpp:259]     Train net output #0: loss = 0.0329 (* 1 = 0.0329 loss)
I0708 13:11:48.514250 31135 solver.cpp:590] Iteration 33110, lr = 0.000548496
I0708 13:12:11.181604 31135 solver.cpp:243] Iteration 33220, loss = 0.0367129
I0708 13:12:11.183377 31135 solver.cpp:259]     Train net output #0: loss = 0.0367141 (* 1 = 0.0367141 loss)
I0708 13:12:11.183387 31135 solver.cpp:590] Iteration 33220, lr = 0.000543231
I0708 13:12:33.848163 31135 solver.cpp:243] Iteration 33330, loss = 0.0451082
I0708 13:12:33.848194 31135 solver.cpp:259]     Train net output #0: loss = 0.0451093 (* 1 = 0.0451093 loss)
I0708 13:12:33.848202 31135 solver.cpp:590] Iteration 33330, lr = 0.000538017
I0708 13:12:56.474731 31135 solver.cpp:243] Iteration 33440, loss = 0.00379655
I0708 13:12:56.475172 31135 solver.cpp:259]     Train net output #0: loss = 0.00379769 (* 1 = 0.00379769 loss)
I0708 13:12:56.475180 31135 solver.cpp:590] Iteration 33440, lr = 0.000532853
I0708 13:13:11.893693 31135 solver.cpp:347] Iteration 33516, Testing net (#0)
I0708 13:13:21.556445 31152 blocking_queue.cpp:50] Waiting for data
I0708 13:13:35.853103 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0954327
I0708 13:13:35.853562 31135 solver.cpp:415]     Test net output #1: loss = 6.4401 (* 1 = 6.4401 loss)
I0708 13:13:43.000699 31135 solver.cpp:243] Iteration 33550, loss = 0.034594
I0708 13:13:43.000725 31135 solver.cpp:259]     Train net output #0: loss = 0.0345953 (* 1 = 0.0345953 loss)
I0708 13:13:43.000730 31135 solver.cpp:590] Iteration 33550, lr = 0.000527738
I0708 13:14:05.625779 31135 solver.cpp:243] Iteration 33660, loss = 0.0199713
I0708 13:14:05.625799 31135 solver.cpp:259]     Train net output #0: loss = 0.0199725 (* 1 = 0.0199725 loss)
I0708 13:14:05.625805 31135 solver.cpp:590] Iteration 33660, lr = 0.000522672
I0708 13:14:28.280586 31135 solver.cpp:243] Iteration 33770, loss = 0.0243851
I0708 13:14:28.280946 31135 solver.cpp:259]     Train net output #0: loss = 0.0243862 (* 1 = 0.0243862 loss)
I0708 13:14:28.280953 31135 solver.cpp:590] Iteration 33770, lr = 0.000517655
I0708 13:14:50.952405 31135 solver.cpp:243] Iteration 33880, loss = 0.157576
I0708 13:14:50.952427 31135 solver.cpp:259]     Train net output #0: loss = 0.157577 (* 1 = 0.157577 loss)
I0708 13:14:50.952433 31135 solver.cpp:590] Iteration 33880, lr = 0.000512687
I0708 13:15:13.575712 31135 solver.cpp:243] Iteration 33990, loss = 0.0557219
I0708 13:15:13.576076 31135 solver.cpp:259]     Train net output #0: loss = 0.0557231 (* 1 = 0.0557231 loss)
I0708 13:15:13.576086 31135 solver.cpp:590] Iteration 33990, lr = 0.000507766
I0708 13:15:36.207834 31135 solver.cpp:243] Iteration 34100, loss = 0.00689881
I0708 13:15:36.207859 31135 solver.cpp:259]     Train net output #0: loss = 0.00689992 (* 1 = 0.00689992 loss)
I0708 13:15:36.207865 31135 solver.cpp:590] Iteration 34100, lr = 0.000502892
I0708 13:15:58.860967 31135 solver.cpp:243] Iteration 34210, loss = 0.00125374
I0708 13:15:58.861366 31135 solver.cpp:259]     Train net output #0: loss = 0.00125479 (* 1 = 0.00125479 loss)
I0708 13:15:58.861376 31135 solver.cpp:590] Iteration 34210, lr = 0.000498065
I0708 13:16:21.527734 31135 solver.cpp:243] Iteration 34320, loss = 0.0840307
I0708 13:16:21.527756 31135 solver.cpp:259]     Train net output #0: loss = 0.0840319 (* 1 = 0.0840319 loss)
I0708 13:16:21.527762 31135 solver.cpp:590] Iteration 34320, lr = 0.000493284
I0708 13:16:37.370810 31135 solver.cpp:347] Iteration 34398, Testing net (#0)
I0708 13:16:39.257293 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 13:17:00.622735 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0954327
I0708 13:17:00.622761 31135 solver.cpp:415]     Test net output #1: loss = 6.37568 (* 1 = 6.37568 loss)
I0708 13:17:07.368162 31135 solver.cpp:243] Iteration 34430, loss = 0.0298191
I0708 13:17:07.368185 31135 solver.cpp:259]     Train net output #0: loss = 0.0298202 (* 1 = 0.0298202 loss)
I0708 13:17:07.368191 31135 solver.cpp:590] Iteration 34430, lr = 0.000488549
I0708 13:17:30.000357 31135 solver.cpp:243] Iteration 34540, loss = 0.0106655
I0708 13:17:30.000466 31135 solver.cpp:259]     Train net output #0: loss = 0.0106666 (* 1 = 0.0106666 loss)
I0708 13:17:30.000483 31135 solver.cpp:590] Iteration 34540, lr = 0.000483859
I0708 13:17:52.620121 31135 solver.cpp:243] Iteration 34650, loss = 0.0166786
I0708 13:17:52.620143 31135 solver.cpp:259]     Train net output #0: loss = 0.0166798 (* 1 = 0.0166798 loss)
I0708 13:17:52.620149 31135 solver.cpp:590] Iteration 34650, lr = 0.000479215
I0708 13:18:15.256870 31135 solver.cpp:243] Iteration 34760, loss = 0.0236791
I0708 13:18:15.257505 31135 solver.cpp:259]     Train net output #0: loss = 0.0236803 (* 1 = 0.0236803 loss)
I0708 13:18:15.257515 31135 solver.cpp:590] Iteration 34760, lr = 0.000474615
I0708 13:18:37.921766 31135 solver.cpp:243] Iteration 34870, loss = 0.0895142
I0708 13:18:37.921792 31135 solver.cpp:259]     Train net output #0: loss = 0.0895153 (* 1 = 0.0895153 loss)
I0708 13:18:37.921797 31135 solver.cpp:590] Iteration 34870, lr = 0.00047006
I0708 13:19:00.556870 31135 solver.cpp:243] Iteration 34980, loss = 0.000419656
I0708 13:19:00.556957 31135 solver.cpp:259]     Train net output #0: loss = 0.000420693 (* 1 = 0.000420693 loss)
I0708 13:19:00.556964 31135 solver.cpp:590] Iteration 34980, lr = 0.000465548
I0708 13:19:23.155905 31135 solver.cpp:243] Iteration 35090, loss = 0.3369
I0708 13:19:23.155928 31135 solver.cpp:259]     Train net output #0: loss = 0.336901 (* 1 = 0.336901 loss)
I0708 13:19:23.155935 31135 solver.cpp:590] Iteration 35090, lr = 0.000461079
I0708 13:19:45.793277 31135 solver.cpp:243] Iteration 35200, loss = 0.00548348
I0708 13:19:45.793366 31135 solver.cpp:259]     Train net output #0: loss = 0.00548454 (* 1 = 0.00548454 loss)
I0708 13:19:45.793375 31135 solver.cpp:590] Iteration 35200, lr = 0.000456653
I0708 13:20:02.069385 31135 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_35280.caffemodel
I0708 13:20:06.845921 31135 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_35280.solverstate
I0708 13:20:09.064355 31135 solver.cpp:347] Iteration 35280, Testing net (#0)
I0708 13:20:36.410948 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0965144
I0708 13:20:36.411057 31135 solver.cpp:415]     Test net output #1: loss = 6.41431 (* 1 = 6.41431 loss)
I0708 13:20:42.750298 31135 solver.cpp:243] Iteration 35310, loss = 0.00384689
I0708 13:20:42.750320 31135 solver.cpp:259]     Train net output #0: loss = 0.0038479 (* 1 = 0.0038479 loss)
I0708 13:20:42.750326 31135 solver.cpp:590] Iteration 35310, lr = 0.00045227
I0708 13:21:05.395081 31135 solver.cpp:243] Iteration 35420, loss = 0.00604535
I0708 13:21:05.395105 31135 solver.cpp:259]     Train net output #0: loss = 0.00604635 (* 1 = 0.00604635 loss)
I0708 13:21:05.395112 31135 solver.cpp:590] Iteration 35420, lr = 0.000447929
I0708 13:21:28.042677 31135 solver.cpp:243] Iteration 35530, loss = 0.187864
I0708 13:21:28.042763 31135 solver.cpp:259]     Train net output #0: loss = 0.187865 (* 1 = 0.187865 loss)
I0708 13:21:28.042770 31135 solver.cpp:590] Iteration 35530, lr = 0.000443629
I0708 13:21:50.701860 31135 solver.cpp:243] Iteration 35640, loss = 0.114923
I0708 13:21:50.701884 31135 solver.cpp:259]     Train net output #0: loss = 0.114924 (* 1 = 0.114924 loss)
I0708 13:21:50.701889 31135 solver.cpp:590] Iteration 35640, lr = 0.000439371
I0708 13:22:13.366614 31135 solver.cpp:243] Iteration 35750, loss = 0.00138384
I0708 13:22:13.366749 31135 solver.cpp:259]     Train net output #0: loss = 0.00138492 (* 1 = 0.00138492 loss)
I0708 13:22:13.366756 31135 solver.cpp:590] Iteration 35750, lr = 0.000435154
I0708 13:22:36.003238 31135 solver.cpp:243] Iteration 35860, loss = 0.0336081
I0708 13:22:36.003262 31135 solver.cpp:259]     Train net output #0: loss = 0.0336092 (* 1 = 0.0336092 loss)
I0708 13:22:36.003268 31135 solver.cpp:590] Iteration 35860, lr = 0.000430977
I0708 13:22:58.647310 31135 solver.cpp:243] Iteration 35970, loss = 0.0285656
I0708 13:22:58.647413 31135 solver.cpp:259]     Train net output #0: loss = 0.0285666 (* 1 = 0.0285666 loss)
I0708 13:22:58.647429 31135 solver.cpp:590] Iteration 35970, lr = 0.00042684
I0708 13:23:21.303138 31135 solver.cpp:243] Iteration 36080, loss = 0.0102322
I0708 13:23:21.303159 31135 solver.cpp:259]     Train net output #0: loss = 0.0102332 (* 1 = 0.0102332 loss)
I0708 13:23:21.303164 31135 solver.cpp:590] Iteration 36080, lr = 0.000422743
I0708 13:23:37.985777 31135 solver.cpp:347] Iteration 36162, Testing net (#0)
I0708 13:24:03.722779 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0945913
I0708 13:24:03.722805 31135 solver.cpp:415]     Test net output #1: loss = 6.43248 (* 1 = 6.43248 loss)
I0708 13:24:09.650495 31135 solver.cpp:243] Iteration 36190, loss = 0.0450746
I0708 13:24:09.650637 31135 solver.cpp:259]     Train net output #0: loss = 0.0450756 (* 1 = 0.0450756 loss)
I0708 13:24:09.650645 31135 solver.cpp:590] Iteration 36190, lr = 0.000418685
I0708 13:24:32.311774 31135 solver.cpp:243] Iteration 36300, loss = 0.0740266
I0708 13:24:32.311799 31135 solver.cpp:259]     Train net output #0: loss = 0.0740277 (* 1 = 0.0740277 loss)
I0708 13:24:32.311805 31135 solver.cpp:590] Iteration 36300, lr = 0.000414666
I0708 13:24:54.958654 31135 solver.cpp:243] Iteration 36410, loss = 0.134608
I0708 13:24:54.958745 31135 solver.cpp:259]     Train net output #0: loss = 0.134609 (* 1 = 0.134609 loss)
I0708 13:24:54.958751 31135 solver.cpp:590] Iteration 36410, lr = 0.000410686
I0708 13:25:17.593920 31135 solver.cpp:243] Iteration 36520, loss = 0.0016193
I0708 13:25:17.593946 31135 solver.cpp:259]     Train net output #0: loss = 0.00162048 (* 1 = 0.00162048 loss)
I0708 13:25:17.593953 31135 solver.cpp:590] Iteration 36520, lr = 0.000406744
I0708 13:25:40.243377 31135 solver.cpp:243] Iteration 36630, loss = 0.00827235
I0708 13:25:40.243463 31135 solver.cpp:259]     Train net output #0: loss = 0.00827357 (* 1 = 0.00827357 loss)
I0708 13:25:40.243469 31135 solver.cpp:590] Iteration 36630, lr = 0.00040284
I0708 13:26:02.900831 31135 solver.cpp:243] Iteration 36740, loss = 0.202378
I0708 13:26:02.900856 31135 solver.cpp:259]     Train net output #0: loss = 0.202379 (* 1 = 0.202379 loss)
I0708 13:26:02.900861 31135 solver.cpp:590] Iteration 36740, lr = 0.000398973
I0708 13:26:25.547930 31135 solver.cpp:243] Iteration 36850, loss = 0.0101832
I0708 13:26:25.548018 31135 solver.cpp:259]     Train net output #0: loss = 0.0101844 (* 1 = 0.0101844 loss)
I0708 13:26:25.548025 31135 solver.cpp:590] Iteration 36850, lr = 0.000395143
I0708 13:26:48.173586 31135 solver.cpp:243] Iteration 36960, loss = 0.0525666
I0708 13:26:48.173610 31135 solver.cpp:259]     Train net output #0: loss = 0.0525678 (* 1 = 0.0525678 loss)
I0708 13:26:48.173617 31135 solver.cpp:590] Iteration 36960, lr = 0.00039135
I0708 13:27:05.264962 31135 solver.cpp:347] Iteration 37044, Testing net (#0)
I0708 13:27:27.807369 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 13:27:27.959405 31135 solver.cpp:415]     Test net output #0: accuracy = 0.096875
I0708 13:27:27.959441 31135 solver.cpp:415]     Test net output #1: loss = 6.38648 (* 1 = 6.38648 loss)
I0708 13:27:33.471740 31135 solver.cpp:243] Iteration 37070, loss = 0.00309705
I0708 13:27:33.471763 31135 solver.cpp:259]     Train net output #0: loss = 0.00309821 (* 1 = 0.00309821 loss)
I0708 13:27:33.471771 31135 solver.cpp:590] Iteration 37070, lr = 0.000387594
I0708 13:27:56.108561 31135 solver.cpp:243] Iteration 37180, loss = 0.00123689
I0708 13:27:56.108645 31135 solver.cpp:259]     Train net output #0: loss = 0.0012381 (* 1 = 0.0012381 loss)
I0708 13:27:56.108652 31135 solver.cpp:590] Iteration 37180, lr = 0.000383874
I0708 13:28:18.743041 31135 solver.cpp:243] Iteration 37290, loss = 0.311602
I0708 13:28:18.743065 31135 solver.cpp:259]     Train net output #0: loss = 0.311603 (* 1 = 0.311603 loss)
I0708 13:28:18.743070 31135 solver.cpp:590] Iteration 37290, lr = 0.000380189
I0708 13:28:41.401185 31135 solver.cpp:243] Iteration 37400, loss = 0.129079
I0708 13:28:41.401299 31135 solver.cpp:259]     Train net output #0: loss = 0.12908 (* 1 = 0.12908 loss)
I0708 13:28:41.401306 31135 solver.cpp:590] Iteration 37400, lr = 0.00037654
I0708 13:29:04.042490 31135 solver.cpp:243] Iteration 37510, loss = 0.0308521
I0708 13:29:04.042512 31135 solver.cpp:259]     Train net output #0: loss = 0.0308533 (* 1 = 0.0308533 loss)
I0708 13:29:04.042518 31135 solver.cpp:590] Iteration 37510, lr = 0.000372925
I0708 13:29:26.683965 31135 solver.cpp:243] Iteration 37620, loss = 0.00215293
I0708 13:29:26.684244 31135 solver.cpp:259]     Train net output #0: loss = 0.0021541 (* 1 = 0.0021541 loss)
I0708 13:29:26.684253 31135 solver.cpp:590] Iteration 37620, lr = 0.000369346
I0708 13:29:49.328281 31135 solver.cpp:243] Iteration 37730, loss = 0.00981747
I0708 13:29:49.328305 31135 solver.cpp:259]     Train net output #0: loss = 0.00981863 (* 1 = 0.00981863 loss)
I0708 13:29:49.328311 31135 solver.cpp:590] Iteration 37730, lr = 0.0003658
I0708 13:30:11.984890 31135 solver.cpp:243] Iteration 37840, loss = 0.113235
I0708 13:30:11.985146 31135 solver.cpp:259]     Train net output #0: loss = 0.113237 (* 1 = 0.113237 loss)
I0708 13:30:11.985154 31135 solver.cpp:590] Iteration 37840, lr = 0.000362289
I0708 13:30:29.489768 31135 solver.cpp:347] Iteration 37926, Testing net (#0)
I0708 13:30:52.977474 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0979567
I0708 13:30:52.977720 31135 solver.cpp:415]     Test net output #1: loss = 6.41847 (* 1 = 6.41847 loss)
I0708 13:30:58.076272 31135 solver.cpp:243] Iteration 37950, loss = 0.019439
I0708 13:30:58.076293 31135 solver.cpp:259]     Train net output #0: loss = 0.0194401 (* 1 = 0.0194401 loss)
I0708 13:30:58.076299 31135 solver.cpp:590] Iteration 37950, lr = 0.000358812
I0708 13:31:20.716190 31135 solver.cpp:243] Iteration 38060, loss = 0.193763
I0708 13:31:20.716214 31135 solver.cpp:259]     Train net output #0: loss = 0.193764 (* 1 = 0.193764 loss)
I0708 13:31:20.716223 31135 solver.cpp:590] Iteration 38060, lr = 0.000355368
I0708 13:31:43.370442 31135 solver.cpp:243] Iteration 38170, loss = 0.00434075
I0708 13:31:43.370522 31135 solver.cpp:259]     Train net output #0: loss = 0.00434201 (* 1 = 0.00434201 loss)
I0708 13:31:43.370528 31135 solver.cpp:590] Iteration 38170, lr = 0.000351957
I0708 13:32:06.020802 31135 solver.cpp:243] Iteration 38280, loss = 0.0616351
I0708 13:32:06.020823 31135 solver.cpp:259]     Train net output #0: loss = 0.0616363 (* 1 = 0.0616363 loss)
I0708 13:32:06.020829 31135 solver.cpp:590] Iteration 38280, lr = 0.000348578
I0708 13:32:28.661852 31135 solver.cpp:243] Iteration 38390, loss = 0.00274394
I0708 13:32:28.661942 31135 solver.cpp:259]     Train net output #0: loss = 0.00274523 (* 1 = 0.00274523 loss)
I0708 13:32:28.661949 31135 solver.cpp:590] Iteration 38390, lr = 0.000345232
I0708 13:32:51.326982 31135 solver.cpp:243] Iteration 38500, loss = 0.000515175
I0708 13:32:51.327005 31135 solver.cpp:259]     Train net output #0: loss = 0.000516489 (* 1 = 0.000516489 loss)
I0708 13:32:51.327011 31135 solver.cpp:590] Iteration 38500, lr = 0.000341919
I0708 13:33:13.962714 31135 solver.cpp:243] Iteration 38610, loss = 0.151371
I0708 13:33:13.962805 31135 solver.cpp:259]     Train net output #0: loss = 0.151372 (* 1 = 0.151372 loss)
I0708 13:33:13.962821 31135 solver.cpp:590] Iteration 38610, lr = 0.000338637
I0708 13:33:36.600534 31135 solver.cpp:243] Iteration 38720, loss = 0.0212467
I0708 13:33:36.600559 31135 solver.cpp:259]     Train net output #0: loss = 0.0212479 (* 1 = 0.0212479 loss)
I0708 13:33:36.600564 31135 solver.cpp:590] Iteration 38720, lr = 0.000335386
I0708 13:33:54.490753 31135 solver.cpp:347] Iteration 38808, Testing net (#0)
I0708 13:34:03.656137 31152 blocking_queue.cpp:50] Waiting for data
I0708 13:34:18.112869 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0954327
I0708 13:34:18.112895 31135 solver.cpp:415]     Test net output #1: loss = 6.43008 (* 1 = 6.43008 loss)
I0708 13:34:22.800817 31135 solver.cpp:243] Iteration 38830, loss = 0.0027395
I0708 13:34:22.800839 31135 solver.cpp:259]     Train net output #0: loss = 0.00274076 (* 1 = 0.00274076 loss)
I0708 13:34:22.800845 31135 solver.cpp:590] Iteration 38830, lr = 0.000332167
I0708 13:34:45.441707 31135 solver.cpp:243] Iteration 38940, loss = 0.0639724
I0708 13:34:45.441818 31135 solver.cpp:259]     Train net output #0: loss = 0.0639737 (* 1 = 0.0639737 loss)
I0708 13:34:45.441828 31135 solver.cpp:590] Iteration 38940, lr = 0.000328979
I0708 13:35:08.100980 31135 solver.cpp:243] Iteration 39050, loss = 0.00363581
I0708 13:35:08.101006 31135 solver.cpp:259]     Train net output #0: loss = 0.00363707 (* 1 = 0.00363707 loss)
I0708 13:35:08.101011 31135 solver.cpp:590] Iteration 39050, lr = 0.000325821
I0708 13:35:30.782933 31135 solver.cpp:243] Iteration 39160, loss = 0.054996
I0708 13:35:30.783409 31135 solver.cpp:259]     Train net output #0: loss = 0.0549973 (* 1 = 0.0549973 loss)
I0708 13:35:30.783418 31135 solver.cpp:590] Iteration 39160, lr = 0.000322693
I0708 13:35:53.437886 31135 solver.cpp:243] Iteration 39270, loss = 0.0220483
I0708 13:35:53.437909 31135 solver.cpp:259]     Train net output #0: loss = 0.0220495 (* 1 = 0.0220495 loss)
I0708 13:35:53.437916 31135 solver.cpp:590] Iteration 39270, lr = 0.000319596
I0708 13:36:16.086199 31135 solver.cpp:243] Iteration 39380, loss = 0.000340447
I0708 13:36:16.086294 31135 solver.cpp:259]     Train net output #0: loss = 0.000341773 (* 1 = 0.000341773 loss)
I0708 13:36:16.086302 31135 solver.cpp:590] Iteration 39380, lr = 0.000316528
I0708 13:36:38.729694 31135 solver.cpp:243] Iteration 39490, loss = 0.168503
I0708 13:36:38.729717 31135 solver.cpp:259]     Train net output #0: loss = 0.168505 (* 1 = 0.168505 loss)
I0708 13:36:38.729722 31135 solver.cpp:590] Iteration 39490, lr = 0.00031349
I0708 13:37:01.389376 31135 solver.cpp:243] Iteration 39600, loss = 0.23419
I0708 13:37:01.389464 31135 solver.cpp:259]     Train net output #0: loss = 0.234192 (* 1 = 0.234192 loss)
I0708 13:37:01.389472 31135 solver.cpp:590] Iteration 39600, lr = 0.000310481
I0708 13:37:19.716002 31135 solver.cpp:347] Iteration 39690, Testing net (#0)
I0708 13:37:43.693765 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0947115
I0708 13:37:43.693876 31135 solver.cpp:415]     Test net output #1: loss = 6.4281 (* 1 = 6.4281 loss)
I0708 13:37:47.980300 31135 solver.cpp:243] Iteration 39710, loss = 0.080956
I0708 13:37:47.980324 31135 solver.cpp:259]     Train net output #0: loss = 0.0809575 (* 1 = 0.0809575 loss)
I0708 13:37:47.980329 31135 solver.cpp:590] Iteration 39710, lr = 0.000307501
I0708 13:38:10.625509 31135 solver.cpp:243] Iteration 39820, loss = 0.0901941
I0708 13:38:10.625533 31135 solver.cpp:259]     Train net output #0: loss = 0.0901955 (* 1 = 0.0901955 loss)
I0708 13:38:10.625540 31135 solver.cpp:590] Iteration 39820, lr = 0.000304549
I0708 13:38:33.265364 31135 solver.cpp:243] Iteration 39930, loss = 0.0178465
I0708 13:38:33.265453 31135 solver.cpp:259]     Train net output #0: loss = 0.0178479 (* 1 = 0.0178479 loss)
I0708 13:38:33.265470 31135 solver.cpp:590] Iteration 39930, lr = 0.000301626
I0708 13:38:55.895524 31135 solver.cpp:243] Iteration 40040, loss = 0.0286051
I0708 13:38:55.895547 31135 solver.cpp:259]     Train net output #0: loss = 0.0286065 (* 1 = 0.0286065 loss)
I0708 13:38:55.895553 31135 solver.cpp:590] Iteration 40040, lr = 0.000298731
I0708 13:39:18.552268 31135 solver.cpp:243] Iteration 40150, loss = 0.0357156
I0708 13:39:18.552351 31135 solver.cpp:259]     Train net output #0: loss = 0.035717 (* 1 = 0.035717 loss)
I0708 13:39:18.552358 31135 solver.cpp:590] Iteration 40150, lr = 0.000295863
I0708 13:39:41.228997 31135 solver.cpp:243] Iteration 40260, loss = 0.388192
I0708 13:39:41.229022 31135 solver.cpp:259]     Train net output #0: loss = 0.388193 (* 1 = 0.388193 loss)
I0708 13:39:41.229027 31135 solver.cpp:590] Iteration 40260, lr = 0.000293023
I0708 13:40:03.875993 31135 solver.cpp:243] Iteration 40370, loss = 0.0309815
I0708 13:40:03.876083 31135 solver.cpp:259]     Train net output #0: loss = 0.030983 (* 1 = 0.030983 loss)
I0708 13:40:03.876101 31135 solver.cpp:590] Iteration 40370, lr = 0.000290211
I0708 13:40:26.509285 31135 solver.cpp:243] Iteration 40480, loss = 0.0129798
I0708 13:40:26.509308 31135 solver.cpp:259]     Train net output #0: loss = 0.0129812 (* 1 = 0.0129812 loss)
I0708 13:40:26.509315 31135 solver.cpp:590] Iteration 40480, lr = 0.000287425
I0708 13:40:45.244077 31135 solver.cpp:347] Iteration 40572, Testing net (#0)
I0708 13:41:08.811254 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 13:41:10.839099 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0939904
I0708 13:41:10.839128 31135 solver.cpp:415]     Test net output #1: loss = 6.46286 (* 1 = 6.46286 loss)
I0708 13:41:14.707399 31135 solver.cpp:243] Iteration 40590, loss = 0.014045
I0708 13:41:14.707423 31135 solver.cpp:259]     Train net output #0: loss = 0.0140464 (* 1 = 0.0140464 loss)
I0708 13:41:14.707429 31135 solver.cpp:590] Iteration 40590, lr = 0.000284666
I0708 13:41:37.380970 31135 solver.cpp:243] Iteration 40700, loss = 0.234802
I0708 13:41:37.381233 31135 solver.cpp:259]     Train net output #0: loss = 0.234804 (* 1 = 0.234804 loss)
I0708 13:41:37.381242 31135 solver.cpp:590] Iteration 40700, lr = 0.000281934
I0708 13:42:00.044728 31135 solver.cpp:243] Iteration 40810, loss = 0.0071317
I0708 13:42:00.044752 31135 solver.cpp:259]     Train net output #0: loss = 0.00713307 (* 1 = 0.00713307 loss)
I0708 13:42:00.044759 31135 solver.cpp:590] Iteration 40810, lr = 0.000279227
I0708 13:42:22.673962 31135 solver.cpp:243] Iteration 40920, loss = 0.00198577
I0708 13:42:22.674371 31135 solver.cpp:259]     Train net output #0: loss = 0.00198717 (* 1 = 0.00198717 loss)
I0708 13:42:22.674387 31135 solver.cpp:590] Iteration 40920, lr = 0.000276547
I0708 13:42:45.323393 31135 solver.cpp:243] Iteration 41030, loss = 0.0367857
I0708 13:42:45.323416 31135 solver.cpp:259]     Train net output #0: loss = 0.0367871 (* 1 = 0.0367871 loss)
I0708 13:42:45.323422 31135 solver.cpp:590] Iteration 41030, lr = 0.000273893
I0708 13:43:07.988245 31135 solver.cpp:243] Iteration 41140, loss = 0.00872933
I0708 13:43:07.988325 31135 solver.cpp:259]     Train net output #0: loss = 0.00873068 (* 1 = 0.00873068 loss)
I0708 13:43:07.988343 31135 solver.cpp:590] Iteration 41140, lr = 0.000271264
I0708 13:43:30.668831 31135 solver.cpp:243] Iteration 41250, loss = 0.0240905
I0708 13:43:30.668855 31135 solver.cpp:259]     Train net output #0: loss = 0.0240918 (* 1 = 0.0240918 loss)
I0708 13:43:30.668861 31135 solver.cpp:590] Iteration 41250, lr = 0.00026866
I0708 13:43:53.319027 31135 solver.cpp:243] Iteration 41360, loss = 0.0839363
I0708 13:43:53.319118 31135 solver.cpp:259]     Train net output #0: loss = 0.0839376 (* 1 = 0.0839376 loss)
I0708 13:43:53.319133 31135 solver.cpp:590] Iteration 41360, lr = 0.000266081
I0708 13:44:12.446851 31135 solver.cpp:347] Iteration 41454, Testing net (#0)
I0708 13:44:37.365792 31135 solver.cpp:415]     Test net output #0: accuracy = 0.096274
I0708 13:44:37.365898 31135 solver.cpp:415]     Test net output #1: loss = 6.42038 (* 1 = 6.42038 loss)
I0708 13:44:40.817317 31135 solver.cpp:243] Iteration 41470, loss = 0.288456
I0708 13:44:40.817340 31135 solver.cpp:259]     Train net output #0: loss = 0.288458 (* 1 = 0.288458 loss)
I0708 13:44:40.817347 31135 solver.cpp:590] Iteration 41470, lr = 0.000263527
I0708 13:45:03.437083 31135 solver.cpp:243] Iteration 41580, loss = 0.00115232
I0708 13:45:03.437109 31135 solver.cpp:259]     Train net output #0: loss = 0.00115359 (* 1 = 0.00115359 loss)
I0708 13:45:03.437114 31135 solver.cpp:590] Iteration 41580, lr = 0.000260998
I0708 13:45:26.080914 31135 solver.cpp:243] Iteration 41690, loss = 0.0330495
I0708 13:45:26.080997 31135 solver.cpp:259]     Train net output #0: loss = 0.0330508 (* 1 = 0.0330508 loss)
I0708 13:45:26.081004 31135 solver.cpp:590] Iteration 41690, lr = 0.000258492
I0708 13:45:48.749009 31135 solver.cpp:243] Iteration 41800, loss = 0.000288569
I0708 13:45:48.749034 31135 solver.cpp:259]     Train net output #0: loss = 0.000289914 (* 1 = 0.000289914 loss)
I0708 13:45:48.749040 31135 solver.cpp:590] Iteration 41800, lr = 0.000256011
I0708 13:46:11.398869 31135 solver.cpp:243] Iteration 41910, loss = 0.0355466
I0708 13:46:11.398970 31135 solver.cpp:259]     Train net output #0: loss = 0.0355479 (* 1 = 0.0355479 loss)
I0708 13:46:11.398988 31135 solver.cpp:590] Iteration 41910, lr = 0.000253554
I0708 13:46:34.031177 31135 solver.cpp:243] Iteration 42020, loss = 0.0112409
I0708 13:46:34.031200 31135 solver.cpp:259]     Train net output #0: loss = 0.0112422 (* 1 = 0.0112422 loss)
I0708 13:46:34.031206 31135 solver.cpp:590] Iteration 42020, lr = 0.00025112
I0708 13:46:56.671010 31135 solver.cpp:243] Iteration 42130, loss = 0.204222
I0708 13:46:56.679357 31135 solver.cpp:259]     Train net output #0: loss = 0.204223 (* 1 = 0.204223 loss)
I0708 13:46:56.679364 31135 solver.cpp:590] Iteration 42130, lr = 0.00024871
I0708 13:47:19.335242 31135 solver.cpp:243] Iteration 42240, loss = 0.0017145
I0708 13:47:19.335266 31135 solver.cpp:259]     Train net output #0: loss = 0.00171579 (* 1 = 0.00171579 loss)
I0708 13:47:19.335273 31135 solver.cpp:590] Iteration 42240, lr = 0.000246322
I0708 13:47:38.917224 31135 solver.cpp:347] Iteration 42336, Testing net (#0)
I0708 13:48:00.984576 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0959135
I0708 13:48:00.984603 31135 solver.cpp:415]     Test net output #1: loss = 6.44288 (* 1 = 6.44288 loss)
I0708 13:48:04.027344 31135 solver.cpp:243] Iteration 42350, loss = 0.0012056
I0708 13:48:04.027367 31135 solver.cpp:259]     Train net output #0: loss = 0.00120686 (* 1 = 0.00120686 loss)
I0708 13:48:04.027374 31135 solver.cpp:590] Iteration 42350, lr = 0.000243958
I0708 13:48:26.702651 31135 solver.cpp:243] Iteration 42460, loss = 0.159276
I0708 13:48:26.703440 31135 solver.cpp:259]     Train net output #0: loss = 0.159277 (* 1 = 0.159277 loss)
I0708 13:48:26.703460 31135 solver.cpp:590] Iteration 42460, lr = 0.000241616
I0708 13:48:49.341502 31135 solver.cpp:243] Iteration 42570, loss = 0.0429027
I0708 13:48:49.341526 31135 solver.cpp:259]     Train net output #0: loss = 0.042904 (* 1 = 0.042904 loss)
I0708 13:48:49.341531 31135 solver.cpp:590] Iteration 42570, lr = 0.000239297
I0708 13:49:11.967490 31135 solver.cpp:243] Iteration 42680, loss = 0.0130148
I0708 13:49:11.967876 31135 solver.cpp:259]     Train net output #0: loss = 0.0130162 (* 1 = 0.0130162 loss)
I0708 13:49:11.967898 31135 solver.cpp:590] Iteration 42680, lr = 0.000237
I0708 13:49:34.612372 31135 solver.cpp:243] Iteration 42790, loss = 0.000964567
I0708 13:49:34.612395 31135 solver.cpp:259]     Train net output #0: loss = 0.000965998 (* 1 = 0.000965998 loss)
I0708 13:49:34.612401 31135 solver.cpp:590] Iteration 42790, lr = 0.000234725
I0708 13:49:57.256546 31135 solver.cpp:243] Iteration 42900, loss = 0.00290015
I0708 13:49:57.256599 31135 solver.cpp:259]     Train net output #0: loss = 0.00290159 (* 1 = 0.00290159 loss)
I0708 13:49:57.256606 31135 solver.cpp:590] Iteration 42900, lr = 0.000232472
I0708 13:50:19.915376 31135 solver.cpp:243] Iteration 43010, loss = 0.00704978
I0708 13:50:19.915402 31135 solver.cpp:259]     Train net output #0: loss = 0.0070512 (* 1 = 0.0070512 loss)
I0708 13:50:19.915410 31135 solver.cpp:590] Iteration 43010, lr = 0.000230241
I0708 13:50:42.538717 31135 solver.cpp:243] Iteration 43120, loss = 0.0020654
I0708 13:50:42.538802 31135 solver.cpp:259]     Train net output #0: loss = 0.0020668 (* 1 = 0.0020668 loss)
I0708 13:50:42.538820 31135 solver.cpp:590] Iteration 43120, lr = 0.000228031
I0708 13:51:02.509245 31135 solver.cpp:347] Iteration 43218, Testing net (#0)
I0708 13:51:22.424455 31152 blocking_queue.cpp:50] Waiting for data
I0708 13:51:28.661593 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0953125
I0708 13:51:28.661619 31135 solver.cpp:415]     Test net output #1: loss = 6.43433 (* 1 = 6.43433 loss)
I0708 13:51:31.291497 31135 solver.cpp:243] Iteration 43230, loss = 0.00567897
I0708 13:51:31.291522 31135 solver.cpp:259]     Train net output #0: loss = 0.0056804 (* 1 = 0.0056804 loss)
I0708 13:51:31.291528 31135 solver.cpp:590] Iteration 43230, lr = 0.000225842
I0708 13:51:53.935312 31135 solver.cpp:243] Iteration 43340, loss = 0.0206274
I0708 13:51:53.935443 31135 solver.cpp:259]     Train net output #0: loss = 0.0206288 (* 1 = 0.0206288 loss)
I0708 13:51:53.935451 31135 solver.cpp:590] Iteration 43340, lr = 0.000223674
I0708 13:52:16.586343 31135 solver.cpp:243] Iteration 43450, loss = 0.165231
I0708 13:52:16.586364 31135 solver.cpp:259]     Train net output #0: loss = 0.165233 (* 1 = 0.165233 loss)
I0708 13:52:16.586369 31135 solver.cpp:590] Iteration 43450, lr = 0.000221527
I0708 13:52:39.230651 31135 solver.cpp:243] Iteration 43560, loss = 0.147327
I0708 13:52:39.231014 31135 solver.cpp:259]     Train net output #0: loss = 0.147328 (* 1 = 0.147328 loss)
I0708 13:52:39.231021 31135 solver.cpp:590] Iteration 43560, lr = 0.000219401
I0708 13:53:01.907764 31135 solver.cpp:243] Iteration 43670, loss = 0.369919
I0708 13:53:01.907789 31135 solver.cpp:259]     Train net output #0: loss = 0.36992 (* 1 = 0.36992 loss)
I0708 13:53:01.907795 31135 solver.cpp:590] Iteration 43670, lr = 0.000217295
I0708 13:53:24.586740 31135 solver.cpp:243] Iteration 43780, loss = 0.0273087
I0708 13:53:24.587141 31135 solver.cpp:259]     Train net output #0: loss = 0.0273103 (* 1 = 0.0273103 loss)
I0708 13:53:24.587162 31135 solver.cpp:590] Iteration 43780, lr = 0.000215209
I0708 13:53:47.226217 31135 solver.cpp:243] Iteration 43890, loss = 0.0364145
I0708 13:53:47.226241 31135 solver.cpp:259]     Train net output #0: loss = 0.0364161 (* 1 = 0.0364161 loss)
I0708 13:53:47.226248 31135 solver.cpp:590] Iteration 43890, lr = 0.000213143
I0708 13:54:09.879204 31135 solver.cpp:243] Iteration 44000, loss = 0.391568
I0708 13:54:09.892885 31135 solver.cpp:259]     Train net output #0: loss = 0.391569 (* 1 = 0.391569 loss)
I0708 13:54:09.892894 31135 solver.cpp:590] Iteration 44000, lr = 0.000211098
I0708 13:54:30.288646 31135 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_44100.caffemodel
I0708 13:54:52.324002 31135 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_44100.solverstate
I0708 13:54:54.651216 31135 solver.cpp:347] Iteration 44100, Testing net (#0)
I0708 13:55:14.747962 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 13:55:18.954808 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0941106
I0708 13:55:18.954849 31135 solver.cpp:415]     Test net output #1: loss = 6.45329 (* 1 = 6.45329 loss)
I0708 13:55:21.168926 31135 solver.cpp:243] Iteration 44110, loss = 0.00021082
I0708 13:55:21.168949 31135 solver.cpp:259]     Train net output #0: loss = 0.000212372 (* 1 = 0.000212372 loss)
I0708 13:55:21.168956 31135 solver.cpp:590] Iteration 44110, lr = 0.000209071
I0708 13:55:43.800897 31135 solver.cpp:243] Iteration 44220, loss = 0.00435299
I0708 13:55:43.800981 31135 solver.cpp:259]     Train net output #0: loss = 0.00435458 (* 1 = 0.00435458 loss)
I0708 13:55:43.800988 31135 solver.cpp:590] Iteration 44220, lr = 0.000207064
I0708 13:56:06.450990 31135 solver.cpp:243] Iteration 44330, loss = 0.0412359
I0708 13:56:06.451017 31135 solver.cpp:259]     Train net output #0: loss = 0.0412375 (* 1 = 0.0412375 loss)
I0708 13:56:06.451025 31135 solver.cpp:590] Iteration 44330, lr = 0.000205077
I0708 13:56:29.089758 31135 solver.cpp:243] Iteration 44440, loss = 0.003678
I0708 13:56:29.089848 31135 solver.cpp:259]     Train net output #0: loss = 0.00367961 (* 1 = 0.00367961 loss)
I0708 13:56:29.089854 31135 solver.cpp:590] Iteration 44440, lr = 0.000203108
I0708 13:56:51.756999 31135 solver.cpp:243] Iteration 44550, loss = 0.00119088
I0708 13:56:51.757025 31135 solver.cpp:259]     Train net output #0: loss = 0.0011925 (* 1 = 0.0011925 loss)
I0708 13:56:51.757030 31135 solver.cpp:590] Iteration 44550, lr = 0.000201159
I0708 13:57:14.397090 31135 solver.cpp:243] Iteration 44660, loss = 0.0676145
I0708 13:57:14.397182 31135 solver.cpp:259]     Train net output #0: loss = 0.0676162 (* 1 = 0.0676162 loss)
I0708 13:57:14.397198 31135 solver.cpp:590] Iteration 44660, lr = 0.000199228
I0708 13:57:37.031384 31135 solver.cpp:243] Iteration 44770, loss = 0.00120458
I0708 13:57:37.031407 31135 solver.cpp:259]     Train net output #0: loss = 0.00120624 (* 1 = 0.00120624 loss)
I0708 13:57:37.031414 31135 solver.cpp:590] Iteration 44770, lr = 0.000197316
I0708 13:57:59.694536 31135 solver.cpp:243] Iteration 44880, loss = 0.00204917
I0708 13:57:59.694658 31135 solver.cpp:259]     Train net output #0: loss = 0.00205086 (* 1 = 0.00205086 loss)
I0708 13:57:59.694665 31135 solver.cpp:590] Iteration 44880, lr = 0.000195422
I0708 13:58:20.528507 31135 solver.cpp:347] Iteration 44982, Testing net (#0)
I0708 13:58:43.226297 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0950721
I0708 13:58:43.226507 31135 solver.cpp:415]     Test net output #1: loss = 6.46285 (* 1 = 6.46285 loss)
I0708 13:58:45.036011 31135 solver.cpp:243] Iteration 44990, loss = 0.00737768
I0708 13:58:45.036051 31135 solver.cpp:259]     Train net output #0: loss = 0.0073794 (* 1 = 0.0073794 loss)
I0708 13:58:45.036064 31135 solver.cpp:590] Iteration 44990, lr = 0.000193546
I0708 13:59:07.710659 31135 solver.cpp:243] Iteration 45100, loss = 0.00764947
I0708 13:59:07.710683 31135 solver.cpp:259]     Train net output #0: loss = 0.00765122 (* 1 = 0.00765122 loss)
I0708 13:59:07.710690 31135 solver.cpp:590] Iteration 45100, lr = 0.000191688
I0708 13:59:30.368845 31135 solver.cpp:243] Iteration 45210, loss = 0.0725884
I0708 13:59:30.369139 31135 solver.cpp:259]     Train net output #0: loss = 0.0725901 (* 1 = 0.0725901 loss)
I0708 13:59:30.369160 31135 solver.cpp:590] Iteration 45210, lr = 0.000189848
I0708 13:59:53.021575 31135 solver.cpp:243] Iteration 45320, loss = 0.00056083
I0708 13:59:53.021600 31135 solver.cpp:259]     Train net output #0: loss = 0.000562536 (* 1 = 0.000562536 loss)
I0708 13:59:53.021605 31135 solver.cpp:590] Iteration 45320, lr = 0.000188026
I0708 14:00:15.684092 31135 solver.cpp:243] Iteration 45430, loss = 0.00839847
I0708 14:00:15.684332 31135 solver.cpp:259]     Train net output #0: loss = 0.00840017 (* 1 = 0.00840017 loss)
I0708 14:00:15.684350 31135 solver.cpp:590] Iteration 45430, lr = 0.000186221
I0708 14:00:38.334092 31135 solver.cpp:243] Iteration 45540, loss = 0.0443391
I0708 14:00:38.334117 31135 solver.cpp:259]     Train net output #0: loss = 0.0443407 (* 1 = 0.0443407 loss)
I0708 14:00:38.334123 31135 solver.cpp:590] Iteration 45540, lr = 0.000184434
I0708 14:01:01.015182 31135 solver.cpp:243] Iteration 45650, loss = 0.12226
I0708 14:01:01.015415 31135 solver.cpp:259]     Train net output #0: loss = 0.122262 (* 1 = 0.122262 loss)
I0708 14:01:01.015434 31135 solver.cpp:590] Iteration 45650, lr = 0.000182663
I0708 14:01:23.690309 31135 solver.cpp:243] Iteration 45760, loss = 0.051851
I0708 14:01:23.690332 31135 solver.cpp:259]     Train net output #0: loss = 0.0518527 (* 1 = 0.0518527 loss)
I0708 14:01:23.690338 31135 solver.cpp:590] Iteration 45760, lr = 0.00018091
I0708 14:01:44.897578 31135 solver.cpp:347] Iteration 45864, Testing net (#0)
I0708 14:02:07.678407 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0955529
I0708 14:02:07.678433 31135 solver.cpp:415]     Test net output #1: loss = 6.4693 (* 1 = 6.4693 loss)
I0708 14:02:09.073459 31135 solver.cpp:243] Iteration 45870, loss = 0.000859983
I0708 14:02:09.073482 31135 solver.cpp:259]     Train net output #0: loss = 0.000861594 (* 1 = 0.000861594 loss)
I0708 14:02:09.073488 31135 solver.cpp:590] Iteration 45870, lr = 0.000179173
I0708 14:02:31.737362 31135 solver.cpp:243] Iteration 45980, loss = 0.005577
I0708 14:02:31.737452 31135 solver.cpp:259]     Train net output #0: loss = 0.00557861 (* 1 = 0.00557861 loss)
I0708 14:02:31.737460 31135 solver.cpp:590] Iteration 45980, lr = 0.000177454
I0708 14:02:54.379514 31135 solver.cpp:243] Iteration 46090, loss = 0.0188146
I0708 14:02:54.379537 31135 solver.cpp:259]     Train net output #0: loss = 0.0188163 (* 1 = 0.0188163 loss)
I0708 14:02:54.379544 31135 solver.cpp:590] Iteration 46090, lr = 0.00017575
I0708 14:03:17.052796 31135 solver.cpp:243] Iteration 46200, loss = 0.000908179
I0708 14:03:17.052903 31135 solver.cpp:259]     Train net output #0: loss = 0.000909935 (* 1 = 0.000909935 loss)
I0708 14:03:17.052911 31135 solver.cpp:590] Iteration 46200, lr = 0.000174063
I0708 14:03:39.750759 31135 solver.cpp:243] Iteration 46310, loss = 0.184402
I0708 14:03:39.750782 31135 solver.cpp:259]     Train net output #0: loss = 0.184404 (* 1 = 0.184404 loss)
I0708 14:03:39.750788 31135 solver.cpp:590] Iteration 46310, lr = 0.000172393
I0708 14:04:02.423809 31135 solver.cpp:243] Iteration 46420, loss = 0.0135409
I0708 14:04:02.424098 31135 solver.cpp:259]     Train net output #0: loss = 0.0135427 (* 1 = 0.0135427 loss)
I0708 14:04:02.424106 31135 solver.cpp:590] Iteration 46420, lr = 0.000170738
I0708 14:04:25.075090 31135 solver.cpp:243] Iteration 46530, loss = 0.0120522
I0708 14:04:25.075129 31135 solver.cpp:259]     Train net output #0: loss = 0.012054 (* 1 = 0.012054 loss)
I0708 14:04:25.075144 31135 solver.cpp:590] Iteration 46530, lr = 0.000169099
I0708 14:04:47.740458 31135 solver.cpp:243] Iteration 46640, loss = 0.00426454
I0708 14:04:47.740734 31135 solver.cpp:259]     Train net output #0: loss = 0.00426641 (* 1 = 0.00426641 loss)
I0708 14:04:47.740744 31135 solver.cpp:590] Iteration 46640, lr = 0.000167476
I0708 14:05:09.402750 31135 solver.cpp:347] Iteration 46746, Testing net (#0)
I0708 14:05:31.899201 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0947115
I0708 14:05:31.899446 31135 solver.cpp:415]     Test net output #1: loss = 6.45221 (* 1 = 6.45221 loss)
I0708 14:05:32.885962 31135 solver.cpp:243] Iteration 46750, loss = 0.0261788
I0708 14:05:32.885985 31135 solver.cpp:259]     Train net output #0: loss = 0.0261806 (* 1 = 0.0261806 loss)
I0708 14:05:32.885992 31135 solver.cpp:590] Iteration 46750, lr = 0.000165868
I0708 14:05:55.568580 31135 solver.cpp:243] Iteration 46860, loss = 0.00606296
I0708 14:05:55.568599 31135 solver.cpp:259]     Train net output #0: loss = 0.00606484 (* 1 = 0.00606484 loss)
I0708 14:05:55.568605 31135 solver.cpp:590] Iteration 46860, lr = 0.000164276
I0708 14:06:18.230500 31135 solver.cpp:243] Iteration 46970, loss = 0.000914159
I0708 14:06:18.230945 31135 solver.cpp:259]     Train net output #0: loss = 0.000916057 (* 1 = 0.000916057 loss)
I0708 14:06:18.230953 31135 solver.cpp:590] Iteration 46970, lr = 0.000162699
I0708 14:06:40.880496 31135 solver.cpp:243] Iteration 47080, loss = 0.00511439
I0708 14:06:40.880519 31135 solver.cpp:259]     Train net output #0: loss = 0.00511635 (* 1 = 0.00511635 loss)
I0708 14:06:40.880525 31135 solver.cpp:590] Iteration 47080, lr = 0.000161138
I0708 14:07:03.521060 31135 solver.cpp:243] Iteration 47190, loss = 0.000429413
I0708 14:07:03.525481 31135 solver.cpp:259]     Train net output #0: loss = 0.000431335 (* 1 = 0.000431335 loss)
I0708 14:07:03.525490 31135 solver.cpp:590] Iteration 47190, lr = 0.000159591
I0708 14:07:26.232174 31135 solver.cpp:243] Iteration 47300, loss = 0.0214723
I0708 14:07:26.232197 31135 solver.cpp:259]     Train net output #0: loss = 0.0214743 (* 1 = 0.0214743 loss)
I0708 14:07:26.232203 31135 solver.cpp:590] Iteration 47300, lr = 0.000158059
I0708 14:07:48.916921 31135 solver.cpp:243] Iteration 47410, loss = 0.0252838
I0708 14:07:48.917229 31135 solver.cpp:259]     Train net output #0: loss = 0.0252858 (* 1 = 0.0252858 loss)
I0708 14:07:48.917237 31135 solver.cpp:590] Iteration 47410, lr = 0.000156542
I0708 14:08:11.571810 31135 solver.cpp:243] Iteration 47520, loss = 0.00166446
I0708 14:08:11.571836 31135 solver.cpp:259]     Train net output #0: loss = 0.00166641 (* 1 = 0.00166641 loss)
I0708 14:08:11.571843 31135 solver.cpp:590] Iteration 47520, lr = 0.000155039
I0708 14:08:33.610415 31135 solver.cpp:347] Iteration 47628, Testing net (#0)
I0708 14:08:50.799834 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 14:08:57.160787 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0947115
I0708 14:08:57.160812 31135 solver.cpp:415]     Test net output #1: loss = 6.47314 (* 1 = 6.47314 loss)
I0708 14:08:57.733053 31135 solver.cpp:243] Iteration 47630, loss = 0.00535253
I0708 14:08:57.733093 31135 solver.cpp:259]     Train net output #0: loss = 0.00535448 (* 1 = 0.00535448 loss)
I0708 14:08:57.733106 31135 solver.cpp:590] Iteration 47630, lr = 0.000153551
I0708 14:09:20.390336 31135 solver.cpp:243] Iteration 47740, loss = 0.0407975
I0708 14:09:20.390446 31135 solver.cpp:259]     Train net output #0: loss = 0.0407994 (* 1 = 0.0407994 loss)
I0708 14:09:20.390455 31135 solver.cpp:590] Iteration 47740, lr = 0.000152077
I0708 14:09:43.073235 31135 solver.cpp:243] Iteration 47850, loss = 0.0924637
I0708 14:09:43.073259 31135 solver.cpp:259]     Train net output #0: loss = 0.0924657 (* 1 = 0.0924657 loss)
I0708 14:09:43.073266 31135 solver.cpp:590] Iteration 47850, lr = 0.000150617
I0708 14:10:05.751250 31135 solver.cpp:243] Iteration 47960, loss = 0.132153
I0708 14:10:05.751814 31135 solver.cpp:259]     Train net output #0: loss = 0.132155 (* 1 = 0.132155 loss)
I0708 14:10:05.751826 31135 solver.cpp:590] Iteration 47960, lr = 0.000149172
I0708 14:10:28.407641 31135 solver.cpp:243] Iteration 48070, loss = 0.0358325
I0708 14:10:28.407665 31135 solver.cpp:259]     Train net output #0: loss = 0.0358345 (* 1 = 0.0358345 loss)
I0708 14:10:28.407670 31135 solver.cpp:590] Iteration 48070, lr = 0.00014774
I0708 14:10:51.072335 31135 solver.cpp:243] Iteration 48180, loss = 0.137103
I0708 14:10:51.072633 31135 solver.cpp:259]     Train net output #0: loss = 0.137105 (* 1 = 0.137105 loss)
I0708 14:10:51.072643 31135 solver.cpp:590] Iteration 48180, lr = 0.000146322
I0708 14:11:13.737120 31135 solver.cpp:243] Iteration 48290, loss = 0.00123195
I0708 14:11:13.737150 31135 solver.cpp:259]     Train net output #0: loss = 0.00123396 (* 1 = 0.00123396 loss)
I0708 14:11:13.737159 31135 solver.cpp:590] Iteration 48290, lr = 0.000144917
I0708 14:11:36.423440 31135 solver.cpp:243] Iteration 48400, loss = 0.00317631
I0708 14:11:36.423812 31135 solver.cpp:259]     Train net output #0: loss = 0.00317833 (* 1 = 0.00317833 loss)
I0708 14:11:36.423821 31135 solver.cpp:590] Iteration 48400, lr = 0.000143526
I0708 14:11:58.865290 31135 solver.cpp:347] Iteration 48510, Testing net (#0)
I0708 14:12:20.790673 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0949519
I0708 14:12:20.790745 31135 solver.cpp:415]     Test net output #1: loss = 6.47352 (* 1 = 6.47352 loss)
I0708 14:12:20.951401 31135 solver.cpp:243] Iteration 48510, loss = 0.018575
I0708 14:12:20.951431 31135 solver.cpp:259]     Train net output #0: loss = 0.018577 (* 1 = 0.018577 loss)
I0708 14:12:20.951437 31135 solver.cpp:590] Iteration 48510, lr = 0.000142149
I0708 14:12:43.598691 31135 solver.cpp:243] Iteration 48620, loss = 0.00206725
I0708 14:12:43.598716 31135 solver.cpp:259]     Train net output #0: loss = 0.00206934 (* 1 = 0.00206934 loss)
I0708 14:12:43.598721 31135 solver.cpp:590] Iteration 48620, lr = 0.000140784
I0708 14:13:06.257340 31135 solver.cpp:243] Iteration 48730, loss = 0.0802164
I0708 14:13:06.257431 31135 solver.cpp:259]     Train net output #0: loss = 0.0802184 (* 1 = 0.0802184 loss)
I0708 14:13:06.257438 31135 solver.cpp:590] Iteration 48730, lr = 0.000139433
I0708 14:13:28.896277 31135 solver.cpp:243] Iteration 48840, loss = 0.00894426
I0708 14:13:28.896299 31135 solver.cpp:259]     Train net output #0: loss = 0.00894632 (* 1 = 0.00894632 loss)
I0708 14:13:28.896306 31135 solver.cpp:590] Iteration 48840, lr = 0.000138094
I0708 14:13:51.552635 31135 solver.cpp:243] Iteration 48950, loss = 0.015147
I0708 14:13:51.552726 31135 solver.cpp:259]     Train net output #0: loss = 0.0151491 (* 1 = 0.0151491 loss)
I0708 14:13:51.552732 31135 solver.cpp:590] Iteration 48950, lr = 0.000136769
I0708 14:14:14.214536 31135 solver.cpp:243] Iteration 49060, loss = 0.0451859
I0708 14:14:14.214560 31135 solver.cpp:259]     Train net output #0: loss = 0.0451879 (* 1 = 0.0451879 loss)
I0708 14:14:14.214566 31135 solver.cpp:590] Iteration 49060, lr = 0.000135456
I0708 14:14:36.845302 31135 solver.cpp:243] Iteration 49170, loss = 0.0115788
I0708 14:14:36.845391 31135 solver.cpp:259]     Train net output #0: loss = 0.0115808 (* 1 = 0.0115808 loss)
I0708 14:14:36.845407 31135 solver.cpp:590] Iteration 49170, lr = 0.000134156
I0708 14:14:59.484439 31135 solver.cpp:243] Iteration 49280, loss = 0.0436575
I0708 14:14:59.484462 31135 solver.cpp:259]     Train net output #0: loss = 0.0436595 (* 1 = 0.0436595 loss)
I0708 14:14:59.484467 31135 solver.cpp:590] Iteration 49280, lr = 0.000132868
I0708 14:15:22.121420 31135 solver.cpp:243] Iteration 49390, loss = 0.000482246
I0708 14:15:22.121523 31135 solver.cpp:259]     Train net output #0: loss = 0.000484219 (* 1 = 0.000484219 loss)
I0708 14:15:22.121541 31135 solver.cpp:590] Iteration 49390, lr = 0.000131593
I0708 14:15:22.329205 31135 solver.cpp:347] Iteration 49392, Testing net (#0)
I0708 14:15:42.614904 31152 blocking_queue.cpp:50] Waiting for data
I0708 14:15:46.104919 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0941106
I0708 14:15:46.104944 31135 solver.cpp:415]     Test net output #1: loss = 6.48198 (* 1 = 6.48198 loss)
I0708 14:16:08.496158 31135 solver.cpp:243] Iteration 49500, loss = 0.0315797
I0708 14:16:08.496459 31135 solver.cpp:259]     Train net output #0: loss = 0.0315817 (* 1 = 0.0315817 loss)
I0708 14:16:08.496466 31135 solver.cpp:590] Iteration 49500, lr = 0.00013033
I0708 14:16:31.155707 31135 solver.cpp:243] Iteration 49610, loss = 0.000705715
I0708 14:16:31.155730 31135 solver.cpp:259]     Train net output #0: loss = 0.000707697 (* 1 = 0.000707697 loss)
I0708 14:16:31.155736 31135 solver.cpp:590] Iteration 49610, lr = 0.000129079
I0708 14:16:53.791601 31135 solver.cpp:243] Iteration 49720, loss = 0.0270415
I0708 14:16:53.791731 31135 solver.cpp:259]     Train net output #0: loss = 0.0270435 (* 1 = 0.0270435 loss)
I0708 14:16:53.791741 31135 solver.cpp:590] Iteration 49720, lr = 0.00012784
I0708 14:17:16.422848 31135 solver.cpp:243] Iteration 49830, loss = 0.0316615
I0708 14:17:16.422873 31135 solver.cpp:259]     Train net output #0: loss = 0.0316634 (* 1 = 0.0316634 loss)
I0708 14:17:16.422878 31135 solver.cpp:590] Iteration 49830, lr = 0.000126613
I0708 14:17:39.072002 31135 solver.cpp:243] Iteration 49940, loss = 0.00442837
I0708 14:17:39.072136 31135 solver.cpp:259]     Train net output #0: loss = 0.00443039 (* 1 = 0.00443039 loss)
I0708 14:17:39.072144 31135 solver.cpp:590] Iteration 49940, lr = 0.000125397
I0708 14:18:01.734908 31135 solver.cpp:243] Iteration 50050, loss = 0.144874
I0708 14:18:01.734932 31135 solver.cpp:259]     Train net output #0: loss = 0.144876 (* 1 = 0.144876 loss)
I0708 14:18:01.734937 31135 solver.cpp:590] Iteration 50050, lr = 0.000124194
I0708 14:18:24.382683 31135 solver.cpp:243] Iteration 50160, loss = 0.00594689
I0708 14:18:24.382772 31135 solver.cpp:259]     Train net output #0: loss = 0.00594894 (* 1 = 0.00594894 loss)
I0708 14:18:24.382778 31135 solver.cpp:590] Iteration 50160, lr = 0.000123002
I0708 14:18:47.034189 31135 solver.cpp:243] Iteration 50270, loss = 0.00585118
I0708 14:18:47.034221 31135 solver.cpp:259]     Train net output #0: loss = 0.00585324 (* 1 = 0.00585324 loss)
I0708 14:18:47.034229 31135 solver.cpp:590] Iteration 50270, lr = 0.000121821
I0708 14:18:47.650110 31135 solver.cpp:347] Iteration 50274, Testing net (#0)
I0708 14:19:11.078166 31135 solver.cpp:415]     Test net output #0: accuracy = 0.094351
I0708 14:19:11.078259 31135 solver.cpp:415]     Test net output #1: loss = 6.49772 (* 1 = 6.49772 loss)
I0708 14:19:33.052983 31135 solver.cpp:243] Iteration 50380, loss = 0.000383382
I0708 14:19:33.053006 31135 solver.cpp:259]     Train net output #0: loss = 0.000385453 (* 1 = 0.000385453 loss)
I0708 14:19:33.053012 31135 solver.cpp:590] Iteration 50380, lr = 0.000120652
I0708 14:19:55.696122 31135 solver.cpp:243] Iteration 50490, loss = 0.0277361
I0708 14:19:55.696239 31135 solver.cpp:259]     Train net output #0: loss = 0.0277382 (* 1 = 0.0277382 loss)
I0708 14:19:55.696247 31135 solver.cpp:590] Iteration 50490, lr = 0.000119494
I0708 14:20:18.341352 31135 solver.cpp:243] Iteration 50600, loss = 0.196396
I0708 14:20:18.341377 31135 solver.cpp:259]     Train net output #0: loss = 0.196398 (* 1 = 0.196398 loss)
I0708 14:20:18.341382 31135 solver.cpp:590] Iteration 50600, lr = 0.000118347
I0708 14:20:40.978669 31135 solver.cpp:243] Iteration 50710, loss = 0.0297821
I0708 14:20:40.978771 31135 solver.cpp:259]     Train net output #0: loss = 0.0297843 (* 1 = 0.0297843 loss)
I0708 14:20:40.978778 31135 solver.cpp:590] Iteration 50710, lr = 0.000117211
I0708 14:21:03.595315 31135 solver.cpp:243] Iteration 50820, loss = 0.00213883
I0708 14:21:03.595340 31135 solver.cpp:259]     Train net output #0: loss = 0.00214095 (* 1 = 0.00214095 loss)
I0708 14:21:03.595347 31135 solver.cpp:590] Iteration 50820, lr = 0.000116086
I0708 14:21:26.220446 31135 solver.cpp:243] Iteration 50930, loss = 0.0273434
I0708 14:21:26.220934 31135 solver.cpp:259]     Train net output #0: loss = 0.0273455 (* 1 = 0.0273455 loss)
I0708 14:21:26.220954 31135 solver.cpp:590] Iteration 50930, lr = 0.000114971
I0708 14:21:48.856439 31135 solver.cpp:243] Iteration 51040, loss = 0.0357698
I0708 14:21:48.856465 31135 solver.cpp:259]     Train net output #0: loss = 0.035772 (* 1 = 0.035772 loss)
I0708 14:21:48.856472 31135 solver.cpp:590] Iteration 51040, lr = 0.000113868
I0708 14:22:11.497913 31135 solver.cpp:243] Iteration 51150, loss = 0.0269174
I0708 14:22:11.498179 31135 solver.cpp:259]     Train net output #0: loss = 0.0269195 (* 1 = 0.0269195 loss)
I0708 14:22:11.498188 31135 solver.cpp:590] Iteration 51150, lr = 0.000112775
I0708 14:22:12.523731 31135 solver.cpp:347] Iteration 51156, Testing net (#0)
I0708 14:22:28.091295 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 14:22:38.331493 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0955529
I0708 14:22:38.331518 31135 solver.cpp:415]     Test net output #1: loss = 6.50332 (* 1 = 6.50332 loss)
I0708 14:22:59.883368 31135 solver.cpp:243] Iteration 51260, loss = 0.00647495
I0708 14:22:59.883462 31135 solver.cpp:259]     Train net output #0: loss = 0.00647702 (* 1 = 0.00647702 loss)
I0708 14:22:59.883469 31135 solver.cpp:590] Iteration 51260, lr = 0.000111692
I0708 14:23:22.528661 31135 solver.cpp:243] Iteration 51370, loss = 0.25129
I0708 14:23:22.528684 31135 solver.cpp:259]     Train net output #0: loss = 0.251292 (* 1 = 0.251292 loss)
I0708 14:23:22.528690 31135 solver.cpp:590] Iteration 51370, lr = 0.00011062
I0708 14:23:45.155676 31135 solver.cpp:243] Iteration 51480, loss = 0.00140866
I0708 14:23:45.155768 31135 solver.cpp:259]     Train net output #0: loss = 0.00141074 (* 1 = 0.00141074 loss)
I0708 14:23:45.155776 31135 solver.cpp:590] Iteration 51480, lr = 0.000109558
I0708 14:24:07.769340 31135 solver.cpp:243] Iteration 51590, loss = 0.0175747
I0708 14:24:07.769366 31135 solver.cpp:259]     Train net output #0: loss = 0.0175768 (* 1 = 0.0175768 loss)
I0708 14:24:07.769371 31135 solver.cpp:590] Iteration 51590, lr = 0.000108507
I0708 14:24:30.407207 31135 solver.cpp:243] Iteration 51700, loss = 0.226296
I0708 14:24:30.407299 31135 solver.cpp:259]     Train net output #0: loss = 0.226298 (* 1 = 0.226298 loss)
I0708 14:24:30.407305 31135 solver.cpp:590] Iteration 51700, lr = 0.000107465
I0708 14:24:53.047502 31135 solver.cpp:243] Iteration 51810, loss = 0.00601843
I0708 14:24:53.047526 31135 solver.cpp:259]     Train net output #0: loss = 0.00602053 (* 1 = 0.00602053 loss)
I0708 14:24:53.047533 31135 solver.cpp:590] Iteration 51810, lr = 0.000106434
I0708 14:25:15.661423 31135 solver.cpp:243] Iteration 51920, loss = 0.00333874
I0708 14:25:15.661583 31135 solver.cpp:259]     Train net output #0: loss = 0.00334084 (* 1 = 0.00334084 loss)
I0708 14:25:15.661602 31135 solver.cpp:590] Iteration 51920, lr = 0.000105412
I0708 14:25:38.299407 31135 solver.cpp:243] Iteration 52030, loss = 0.000135474
I0708 14:25:38.299430 31135 solver.cpp:259]     Train net output #0: loss = 0.000137574 (* 1 = 0.000137574 loss)
I0708 14:25:38.299437 31135 solver.cpp:590] Iteration 52030, lr = 0.0001044
I0708 14:25:39.742650 31135 solver.cpp:347] Iteration 52038, Testing net (#0)
I0708 14:26:02.722295 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0949519
I0708 14:26:02.722370 31135 solver.cpp:415]     Test net output #1: loss = 6.48685 (* 1 = 6.48685 loss)
I0708 14:26:23.834491 31135 solver.cpp:243] Iteration 52140, loss = 0.00630315
I0708 14:26:23.834514 31135 solver.cpp:259]     Train net output #0: loss = 0.00630521 (* 1 = 0.00630521 loss)
I0708 14:26:23.834520 31135 solver.cpp:590] Iteration 52140, lr = 0.000103398
I0708 14:26:46.481752 31135 solver.cpp:243] Iteration 52250, loss = 0.002997
I0708 14:26:46.481837 31135 solver.cpp:259]     Train net output #0: loss = 0.00299905 (* 1 = 0.00299905 loss)
I0708 14:26:46.481854 31135 solver.cpp:590] Iteration 52250, lr = 0.000102406
I0708 14:27:09.135570 31135 solver.cpp:243] Iteration 52360, loss = 0.00540426
I0708 14:27:09.135594 31135 solver.cpp:259]     Train net output #0: loss = 0.00540636 (* 1 = 0.00540636 loss)
I0708 14:27:09.135601 31135 solver.cpp:590] Iteration 52360, lr = 0.000101423
I0708 14:27:31.764287 31135 solver.cpp:243] Iteration 52470, loss = 0.00227195
I0708 14:27:31.764603 31135 solver.cpp:259]     Train net output #0: loss = 0.00227406 (* 1 = 0.00227406 loss)
I0708 14:27:31.764612 31135 solver.cpp:590] Iteration 52470, lr = 0.000100449
I0708 14:27:54.386381 31135 solver.cpp:243] Iteration 52580, loss = 0.000851927
I0708 14:27:54.386405 31135 solver.cpp:259]     Train net output #0: loss = 0.000853978 (* 1 = 0.000853978 loss)
I0708 14:27:54.386411 31135 solver.cpp:590] Iteration 52580, lr = 9.94849e-05
I0708 14:28:17.016628 31135 solver.cpp:243] Iteration 52690, loss = 0.0709173
I0708 14:28:17.016716 31135 solver.cpp:259]     Train net output #0: loss = 0.0709194 (* 1 = 0.0709194 loss)
I0708 14:28:17.016722 31135 solver.cpp:590] Iteration 52690, lr = 9.853e-05
I0708 14:28:39.679838 31135 solver.cpp:243] Iteration 52800, loss = 0.383759
I0708 14:28:39.679863 31135 solver.cpp:259]     Train net output #0: loss = 0.383762 (* 1 = 0.383762 loss)
I0708 14:28:39.679869 31135 solver.cpp:590] Iteration 52800, lr = 9.75843e-05
I0708 14:29:02.303648 31135 solver.cpp:243] Iteration 52910, loss = 0.00712411
I0708 14:29:02.303735 31135 solver.cpp:259]     Train net output #0: loss = 0.00712618 (* 1 = 0.00712618 loss)
I0708 14:29:02.303742 31135 solver.cpp:590] Iteration 52910, lr = 9.66476e-05
I0708 14:29:04.156646 31135 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_52920.caffemodel
I0708 14:29:28.101322 31135 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_52920.solverstate
I0708 14:29:30.352099 31135 solver.cpp:347] Iteration 52920, Testing net (#0)
I0708 14:29:54.177701 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0945913
I0708 14:29:54.177804 31135 solver.cpp:415]     Test net output #1: loss = 6.47719 (* 1 = 6.47719 loss)
I0708 14:30:14.903359 31135 solver.cpp:243] Iteration 53020, loss = 0.206439
I0708 14:30:14.903384 31135 solver.cpp:259]     Train net output #0: loss = 0.206441 (* 1 = 0.206441 loss)
I0708 14:30:14.903389 31135 solver.cpp:590] Iteration 53020, lr = 9.57199e-05
I0708 14:30:37.554898 31135 solver.cpp:243] Iteration 53130, loss = 0.00844957
I0708 14:30:37.554989 31135 solver.cpp:259]     Train net output #0: loss = 0.00845171 (* 1 = 0.00845171 loss)
I0708 14:30:37.555006 31135 solver.cpp:590] Iteration 53130, lr = 9.48011e-05
I0708 14:31:00.210078 31135 solver.cpp:243] Iteration 53240, loss = 0.000116691
I0708 14:31:00.210103 31135 solver.cpp:259]     Train net output #0: loss = 0.000118783 (* 1 = 0.000118783 loss)
I0708 14:31:00.210108 31135 solver.cpp:590] Iteration 53240, lr = 9.38911e-05
I0708 14:31:22.850656 31135 solver.cpp:243] Iteration 53350, loss = 0.00182488
I0708 14:31:22.850760 31135 solver.cpp:259]     Train net output #0: loss = 0.00182702 (* 1 = 0.00182702 loss)
I0708 14:31:22.850777 31135 solver.cpp:590] Iteration 53350, lr = 9.29899e-05
I0708 14:31:45.477926 31135 solver.cpp:243] Iteration 53460, loss = 0.000614325
I0708 14:31:45.477949 31135 solver.cpp:259]     Train net output #0: loss = 0.000616503 (* 1 = 0.000616503 loss)
I0708 14:31:45.477955 31135 solver.cpp:590] Iteration 53460, lr = 9.20973e-05
I0708 14:32:08.122148 31135 solver.cpp:243] Iteration 53570, loss = 0.000299162
I0708 14:32:08.122251 31135 solver.cpp:259]     Train net output #0: loss = 0.000301338 (* 1 = 0.000301338 loss)
I0708 14:32:08.122267 31135 solver.cpp:590] Iteration 53570, lr = 9.12133e-05
I0708 14:32:30.756992 31135 solver.cpp:243] Iteration 53680, loss = 0.015816
I0708 14:32:30.757016 31135 solver.cpp:259]     Train net output #0: loss = 0.0158182 (* 1 = 0.0158182 loss)
I0708 14:32:30.757021 31135 solver.cpp:590] Iteration 53680, lr = 9.03378e-05
I0708 14:32:53.409553 31135 solver.cpp:243] Iteration 53790, loss = 0.0756082
I0708 14:32:53.409823 31135 solver.cpp:259]     Train net output #0: loss = 0.0756104 (* 1 = 0.0756104 loss)
I0708 14:32:53.409832 31135 solver.cpp:590] Iteration 53790, lr = 8.94707e-05
I0708 14:32:55.670007 31135 solver.cpp:347] Iteration 53802, Testing net (#0)
I0708 14:33:19.171921 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0956731
I0708 14:33:19.171947 31135 solver.cpp:415]     Test net output #1: loss = 6.46181 (* 1 = 6.46181 loss)
I0708 14:33:39.512749 31135 solver.cpp:243] Iteration 53900, loss = 0.00223029
I0708 14:33:39.512837 31135 solver.cpp:259]     Train net output #0: loss = 0.00223244 (* 1 = 0.00223244 loss)
I0708 14:33:39.512845 31135 solver.cpp:590] Iteration 53900, lr = 8.86119e-05
I0708 14:34:02.147001 31135 solver.cpp:243] Iteration 54010, loss = 0.0201039
I0708 14:34:02.147025 31135 solver.cpp:259]     Train net output #0: loss = 0.0201061 (* 1 = 0.0201061 loss)
I0708 14:34:02.147032 31135 solver.cpp:590] Iteration 54010, lr = 8.77613e-05
I0708 14:34:24.788369 31135 solver.cpp:243] Iteration 54120, loss = 0.00038913
I0708 14:34:24.788452 31135 solver.cpp:259]     Train net output #0: loss = 0.00039126 (* 1 = 0.00039126 loss)
I0708 14:34:24.788460 31135 solver.cpp:590] Iteration 54120, lr = 8.69189e-05
I0708 14:34:47.433089 31135 solver.cpp:243] Iteration 54230, loss = 0.00208785
I0708 14:34:47.433114 31135 solver.cpp:259]     Train net output #0: loss = 0.00208997 (* 1 = 0.00208997 loss)
I0708 14:34:47.433120 31135 solver.cpp:590] Iteration 54230, lr = 8.60846e-05
I0708 14:35:10.120363 31135 solver.cpp:243] Iteration 54340, loss = 0.0100977
I0708 14:35:10.120457 31135 solver.cpp:259]     Train net output #0: loss = 0.0100998 (* 1 = 0.0100998 loss)
I0708 14:35:10.120474 31135 solver.cpp:590] Iteration 54340, lr = 8.52583e-05
I0708 14:35:32.775421 31135 solver.cpp:243] Iteration 54450, loss = 0.02112
I0708 14:35:32.775446 31135 solver.cpp:259]     Train net output #0: loss = 0.0211222 (* 1 = 0.0211222 loss)
I0708 14:35:32.775451 31135 solver.cpp:590] Iteration 54450, lr = 8.44399e-05
I0708 14:35:55.435557 31135 solver.cpp:243] Iteration 54560, loss = 0.00053509
I0708 14:35:55.435645 31135 solver.cpp:259]     Train net output #0: loss = 0.000537269 (* 1 = 0.000537269 loss)
I0708 14:35:55.435652 31135 solver.cpp:590] Iteration 54560, lr = 8.36294e-05
I0708 14:36:18.064820 31135 solver.cpp:243] Iteration 54670, loss = 0.00069386
I0708 14:36:18.064843 31135 solver.cpp:259]     Train net output #0: loss = 0.000695978 (* 1 = 0.000695978 loss)
I0708 14:36:18.064849 31135 solver.cpp:590] Iteration 54670, lr = 8.28267e-05
I0708 14:36:20.740075 31135 solver.cpp:347] Iteration 54684, Testing net (#0)
I0708 14:36:32.407210 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 14:36:43.165547 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0960337
I0708 14:36:43.165570 31135 solver.cpp:415]     Test net output #1: loss = 6.44521 (* 1 = 6.44521 loss)
I0708 14:37:03.070477 31135 solver.cpp:243] Iteration 54780, loss = 0.00593629
I0708 14:37:03.070564 31135 solver.cpp:259]     Train net output #0: loss = 0.00593839 (* 1 = 0.00593839 loss)
I0708 14:37:03.070580 31135 solver.cpp:590] Iteration 54780, lr = 8.20317e-05
I0708 14:37:25.696948 31135 solver.cpp:243] Iteration 54890, loss = 0.0110365
I0708 14:37:25.696971 31135 solver.cpp:259]     Train net output #0: loss = 0.0110385 (* 1 = 0.0110385 loss)
I0708 14:37:25.696977 31135 solver.cpp:590] Iteration 54890, lr = 8.12443e-05
I0708 14:37:48.361482 31135 solver.cpp:243] Iteration 55000, loss = 0.16847
I0708 14:37:48.361601 31135 solver.cpp:259]     Train net output #0: loss = 0.168472 (* 1 = 0.168472 loss)
I0708 14:37:48.361618 31135 solver.cpp:590] Iteration 55000, lr = 8.04644e-05
I0708 14:38:11.010341 31135 solver.cpp:243] Iteration 55110, loss = 0.140928
I0708 14:38:11.010365 31135 solver.cpp:259]     Train net output #0: loss = 0.14093 (* 1 = 0.14093 loss)
I0708 14:38:11.010370 31135 solver.cpp:590] Iteration 55110, lr = 7.96921e-05
I0708 14:38:33.628190 31135 solver.cpp:243] Iteration 55220, loss = 0.00192355
I0708 14:38:33.628486 31135 solver.cpp:259]     Train net output #0: loss = 0.00192559 (* 1 = 0.00192559 loss)
I0708 14:38:33.628494 31135 solver.cpp:590] Iteration 55220, lr = 7.89271e-05
I0708 14:38:56.249861 31135 solver.cpp:243] Iteration 55330, loss = 0.0124361
I0708 14:38:56.249886 31135 solver.cpp:259]     Train net output #0: loss = 0.0124381 (* 1 = 0.0124381 loss)
I0708 14:38:56.249892 31135 solver.cpp:590] Iteration 55330, lr = 7.81695e-05
I0708 14:39:18.911545 31135 solver.cpp:243] Iteration 55440, loss = 0.0421086
I0708 14:39:18.911900 31135 solver.cpp:259]     Train net output #0: loss = 0.0421107 (* 1 = 0.0421107 loss)
I0708 14:39:18.911907 31135 solver.cpp:590] Iteration 55440, lr = 7.74192e-05
I0708 14:39:41.551162 31135 solver.cpp:243] Iteration 55550, loss = 0.0752616
I0708 14:39:41.551187 31135 solver.cpp:259]     Train net output #0: loss = 0.0752636 (* 1 = 0.0752636 loss)
I0708 14:39:41.551193 31135 solver.cpp:590] Iteration 55550, lr = 7.66761e-05
I0708 14:39:44.636988 31135 solver.cpp:347] Iteration 55566, Testing net (#0)
I0708 14:40:07.222584 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0959135
I0708 14:40:07.223016 31135 solver.cpp:415]     Test net output #1: loss = 6.45278 (* 1 = 6.45278 loss)
I0708 14:40:26.719823 31135 solver.cpp:243] Iteration 55660, loss = 0.0145561
I0708 14:40:26.719846 31135 solver.cpp:259]     Train net output #0: loss = 0.0145581 (* 1 = 0.0145581 loss)
I0708 14:40:26.719851 31135 solver.cpp:590] Iteration 55660, lr = 7.59401e-05
I0708 14:40:49.345331 31135 solver.cpp:243] Iteration 55770, loss = 0.0126625
I0708 14:40:49.345631 31135 solver.cpp:259]     Train net output #0: loss = 0.0126645 (* 1 = 0.0126645 loss)
I0708 14:40:49.345644 31135 solver.cpp:590] Iteration 55770, lr = 7.52112e-05
I0708 14:41:11.973978 31135 solver.cpp:243] Iteration 55880, loss = 0.0644135
I0708 14:41:11.974004 31135 solver.cpp:259]     Train net output #0: loss = 0.0644156 (* 1 = 0.0644156 loss)
I0708 14:41:11.974010 31135 solver.cpp:590] Iteration 55880, lr = 7.44892e-05
I0708 14:41:34.625211 31135 solver.cpp:243] Iteration 55990, loss = 0.0139434
I0708 14:41:34.625854 31135 solver.cpp:259]     Train net output #0: loss = 0.0139455 (* 1 = 0.0139455 loss)
I0708 14:41:34.625862 31135 solver.cpp:590] Iteration 55990, lr = 7.37742e-05
I0708 14:41:57.293931 31135 solver.cpp:243] Iteration 56100, loss = 0.0111136
I0708 14:41:57.293953 31135 solver.cpp:259]     Train net output #0: loss = 0.0111157 (* 1 = 0.0111157 loss)
I0708 14:41:57.293959 31135 solver.cpp:590] Iteration 56100, lr = 7.30661e-05
I0708 14:42:19.906474 31135 solver.cpp:243] Iteration 56210, loss = 0.0159704
I0708 14:42:19.906962 31135 solver.cpp:259]     Train net output #0: loss = 0.0159725 (* 1 = 0.0159725 loss)
I0708 14:42:19.906980 31135 solver.cpp:590] Iteration 56210, lr = 7.23648e-05
I0708 14:42:42.533701 31135 solver.cpp:243] Iteration 56320, loss = 0.00012387
I0708 14:42:42.533725 31135 solver.cpp:259]     Train net output #0: loss = 0.000125932 (* 1 = 0.000125932 loss)
I0708 14:42:42.533731 31135 solver.cpp:590] Iteration 56320, lr = 7.16702e-05
I0708 14:43:05.205381 31135 solver.cpp:243] Iteration 56430, loss = 0.231521
I0708 14:43:05.205472 31135 solver.cpp:259]     Train net output #0: loss = 0.231523 (* 1 = 0.231523 loss)
I0708 14:43:05.205479 31135 solver.cpp:590] Iteration 56430, lr = 7.09822e-05
I0708 14:43:08.710396 31135 solver.cpp:347] Iteration 56448, Testing net (#0)
I0708 14:43:19.494658 31152 blocking_queue.cpp:50] Waiting for data
I0708 14:43:31.897265 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0960337
I0708 14:43:31.897291 31135 solver.cpp:415]     Test net output #1: loss = 6.45603 (* 1 = 6.45603 loss)
I0708 14:43:50.994267 31135 solver.cpp:243] Iteration 56540, loss = 0.0769615
I0708 14:43:50.994479 31135 solver.cpp:259]     Train net output #0: loss = 0.0769636 (* 1 = 0.0769636 loss)
I0708 14:43:50.994488 31135 solver.cpp:590] Iteration 56540, lr = 7.03009e-05
I0708 14:44:13.644387 31135 solver.cpp:243] Iteration 56650, loss = 5.73586e-05
I0708 14:44:13.644410 31135 solver.cpp:259]     Train net output #0: loss = 5.94658e-05 (* 1 = 5.94658e-05 loss)
I0708 14:44:13.644417 31135 solver.cpp:590] Iteration 56650, lr = 6.96261e-05
I0708 14:44:36.281095 31135 solver.cpp:243] Iteration 56760, loss = 0.0042465
I0708 14:44:36.281728 31135 solver.cpp:259]     Train net output #0: loss = 0.00424858 (* 1 = 0.00424858 loss)
I0708 14:44:36.281738 31135 solver.cpp:590] Iteration 56760, lr = 6.89578e-05
I0708 14:44:58.914230 31135 solver.cpp:243] Iteration 56870, loss = 0.0681433
I0708 14:44:58.914254 31135 solver.cpp:259]     Train net output #0: loss = 0.0681453 (* 1 = 0.0681453 loss)
I0708 14:44:58.914260 31135 solver.cpp:590] Iteration 56870, lr = 6.82959e-05
I0708 14:45:21.538990 31135 solver.cpp:243] Iteration 56980, loss = 0.0423555
I0708 14:45:21.539239 31135 solver.cpp:259]     Train net output #0: loss = 0.0423576 (* 1 = 0.0423576 loss)
I0708 14:45:21.539247 31135 solver.cpp:590] Iteration 56980, lr = 6.76403e-05
I0708 14:45:44.201786 31135 solver.cpp:243] Iteration 57090, loss = 0.0125181
I0708 14:45:44.201809 31135 solver.cpp:259]     Train net output #0: loss = 0.0125201 (* 1 = 0.0125201 loss)
I0708 14:45:44.201815 31135 solver.cpp:590] Iteration 57090, lr = 6.69911e-05
I0708 14:46:06.849100 31135 solver.cpp:243] Iteration 57200, loss = 0.00665221
I0708 14:46:06.849432 31135 solver.cpp:259]     Train net output #0: loss = 0.00665424 (* 1 = 0.00665424 loss)
I0708 14:46:06.849442 31135 solver.cpp:590] Iteration 57200, lr = 6.6348e-05
I0708 14:46:29.478828 31135 solver.cpp:243] Iteration 57310, loss = 0.000869147
I0708 14:46:29.478852 31135 solver.cpp:259]     Train net output #0: loss = 0.000871228 (* 1 = 0.000871228 loss)
I0708 14:46:29.478859 31135 solver.cpp:590] Iteration 57310, lr = 6.57112e-05
I0708 14:46:33.391012 31135 solver.cpp:347] Iteration 57330, Testing net (#0)
I0708 14:46:56.509969 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0971154
I0708 14:46:56.510090 31135 solver.cpp:415]     Test net output #1: loss = 6.46939 (* 1 = 6.46939 loss)
I0708 14:47:15.197059 31135 solver.cpp:243] Iteration 57420, loss = 0.0623441
I0708 14:47:15.197084 31135 solver.cpp:259]     Train net output #0: loss = 0.0623461 (* 1 = 0.0623461 loss)
I0708 14:47:15.197090 31135 solver.cpp:590] Iteration 57420, lr = 6.50804e-05
I0708 14:47:37.816890 31135 solver.cpp:243] Iteration 57530, loss = 0.00035102
I0708 14:47:37.816979 31135 solver.cpp:259]     Train net output #0: loss = 0.00035309 (* 1 = 0.00035309 loss)
I0708 14:47:37.816987 31135 solver.cpp:590] Iteration 57530, lr = 6.44558e-05
I0708 14:48:00.453042 31135 solver.cpp:243] Iteration 57640, loss = 0.0467238
I0708 14:48:00.453065 31135 solver.cpp:259]     Train net output #0: loss = 0.0467259 (* 1 = 0.0467259 loss)
I0708 14:48:00.453071 31135 solver.cpp:590] Iteration 57640, lr = 6.38371e-05
I0708 14:48:23.096580 31135 solver.cpp:243] Iteration 57750, loss = 2.25045e-05
I0708 14:48:23.096669 31135 solver.cpp:259]     Train net output #0: loss = 2.46287e-05 (* 1 = 2.46287e-05 loss)
I0708 14:48:23.096686 31135 solver.cpp:590] Iteration 57750, lr = 6.32243e-05
I0708 14:48:45.751935 31135 solver.cpp:243] Iteration 57860, loss = 0.111418
I0708 14:48:45.751960 31135 solver.cpp:259]     Train net output #0: loss = 0.11142 (* 1 = 0.11142 loss)
I0708 14:48:45.751965 31135 solver.cpp:590] Iteration 57860, lr = 6.26174e-05
I0708 14:49:08.382915 31135 solver.cpp:243] Iteration 57970, loss = 0.0238909
I0708 14:49:08.383007 31135 solver.cpp:259]     Train net output #0: loss = 0.0238929 (* 1 = 0.0238929 loss)
I0708 14:49:08.383023 31135 solver.cpp:590] Iteration 57970, lr = 6.20164e-05
I0708 14:49:31.022336 31135 solver.cpp:243] Iteration 58080, loss = 0.0293999
I0708 14:49:31.022357 31135 solver.cpp:259]     Train net output #0: loss = 0.0294019 (* 1 = 0.0294019 loss)
I0708 14:49:31.022363 31135 solver.cpp:590] Iteration 58080, lr = 6.14211e-05
I0708 14:49:53.654870 31135 solver.cpp:243] Iteration 58190, loss = 0.0966153
I0708 14:49:53.654971 31135 solver.cpp:259]     Train net output #0: loss = 0.0966173 (* 1 = 0.0966173 loss)
I0708 14:49:53.654978 31135 solver.cpp:590] Iteration 58190, lr = 6.08316e-05
I0708 14:49:57.978504 31135 solver.cpp:347] Iteration 58212, Testing net (#0)
I0708 14:50:07.969175 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 14:50:21.451423 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0961538
I0708 14:50:21.451449 31135 solver.cpp:415]     Test net output #1: loss = 6.46955 (* 1 = 6.46955 loss)
I0708 14:50:39.734338 31135 solver.cpp:243] Iteration 58300, loss = 0.194919
I0708 14:50:39.734632 31135 solver.cpp:259]     Train net output #0: loss = 0.194921 (* 1 = 0.194921 loss)
I0708 14:50:39.734642 31135 solver.cpp:590] Iteration 58300, lr = 6.02477e-05
I0708 14:51:02.396512 31135 solver.cpp:243] Iteration 58410, loss = 0.000782934
I0708 14:51:02.396535 31135 solver.cpp:259]     Train net output #0: loss = 0.000784964 (* 1 = 0.000784964 loss)
I0708 14:51:02.396541 31135 solver.cpp:590] Iteration 58410, lr = 5.96694e-05
I0708 14:51:25.037130 31135 solver.cpp:243] Iteration 58520, loss = 0.191576
I0708 14:51:25.037232 31135 solver.cpp:259]     Train net output #0: loss = 0.191578 (* 1 = 0.191578 loss)
I0708 14:51:25.037248 31135 solver.cpp:590] Iteration 58520, lr = 5.90966e-05
I0708 14:51:47.690800 31135 solver.cpp:243] Iteration 58630, loss = 0.00848764
I0708 14:51:47.690820 31135 solver.cpp:259]     Train net output #0: loss = 0.00848966 (* 1 = 0.00848966 loss)
I0708 14:51:47.690826 31135 solver.cpp:590] Iteration 58630, lr = 5.85294e-05
I0708 14:52:10.341209 31135 solver.cpp:243] Iteration 58740, loss = 0.000362189
I0708 14:52:10.341291 31135 solver.cpp:259]     Train net output #0: loss = 0.000364233 (* 1 = 0.000364233 loss)
I0708 14:52:10.341297 31135 solver.cpp:590] Iteration 58740, lr = 5.79676e-05
I0708 14:52:32.983784 31135 solver.cpp:243] Iteration 58850, loss = 0.139347
I0708 14:52:32.983811 31135 solver.cpp:259]     Train net output #0: loss = 0.139349 (* 1 = 0.139349 loss)
I0708 14:52:32.983819 31135 solver.cpp:590] Iteration 58850, lr = 5.74111e-05
I0708 14:52:55.622038 31135 solver.cpp:243] Iteration 58960, loss = 0.0191846
I0708 14:52:55.622133 31135 solver.cpp:259]     Train net output #0: loss = 0.0191866 (* 1 = 0.0191866 loss)
I0708 14:52:55.622140 31135 solver.cpp:590] Iteration 58960, lr = 5.68601e-05
I0708 14:53:18.286383 31135 solver.cpp:243] Iteration 59070, loss = 0.083168
I0708 14:53:18.286408 31135 solver.cpp:259]     Train net output #0: loss = 0.0831701 (* 1 = 0.0831701 loss)
I0708 14:53:18.286413 31135 solver.cpp:590] Iteration 59070, lr = 5.63143e-05
I0708 14:53:23.017452 31135 solver.cpp:347] Iteration 59094, Testing net (#0)
I0708 14:53:45.750278 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0949519
I0708 14:53:45.750382 31135 solver.cpp:415]     Test net output #1: loss = 6.4581 (* 1 = 6.4581 loss)
I0708 14:54:03.631827 31135 solver.cpp:243] Iteration 59180, loss = 0.00263134
I0708 14:54:03.631852 31135 solver.cpp:259]     Train net output #0: loss = 0.00263336 (* 1 = 0.00263336 loss)
I0708 14:54:03.631858 31135 solver.cpp:590] Iteration 59180, lr = 5.57737e-05
I0708 14:54:26.284138 31135 solver.cpp:243] Iteration 59290, loss = 0.00128036
I0708 14:54:26.284229 31135 solver.cpp:259]     Train net output #0: loss = 0.00128239 (* 1 = 0.00128239 loss)
I0708 14:54:26.284245 31135 solver.cpp:590] Iteration 59290, lr = 5.52384e-05
I0708 14:54:48.929738 31135 solver.cpp:243] Iteration 59400, loss = 0.0232069
I0708 14:54:48.929760 31135 solver.cpp:259]     Train net output #0: loss = 0.0232089 (* 1 = 0.0232089 loss)
I0708 14:54:48.929766 31135 solver.cpp:590] Iteration 59400, lr = 5.47082e-05
I0708 14:55:11.616868 31135 solver.cpp:243] Iteration 59510, loss = 0.0258218
I0708 14:55:11.616974 31135 solver.cpp:259]     Train net output #0: loss = 0.0258238 (* 1 = 0.0258238 loss)
I0708 14:55:11.616991 31135 solver.cpp:590] Iteration 59510, lr = 5.4183e-05
I0708 14:55:34.266003 31135 solver.cpp:243] Iteration 59620, loss = 0.00453306
I0708 14:55:34.266028 31135 solver.cpp:259]     Train net output #0: loss = 0.00453505 (* 1 = 0.00453505 loss)
I0708 14:55:34.266034 31135 solver.cpp:590] Iteration 59620, lr = 5.3663e-05
I0708 14:55:56.909728 31135 solver.cpp:243] Iteration 59730, loss = 0.138181
I0708 14:55:56.910140 31135 solver.cpp:259]     Train net output #0: loss = 0.138183 (* 1 = 0.138183 loss)
I0708 14:55:56.910151 31135 solver.cpp:590] Iteration 59730, lr = 5.31479e-05
I0708 14:56:19.528415 31135 solver.cpp:243] Iteration 59840, loss = 0.00476846
I0708 14:56:19.528440 31135 solver.cpp:259]     Train net output #0: loss = 0.00477036 (* 1 = 0.00477036 loss)
I0708 14:56:19.528446 31135 solver.cpp:590] Iteration 59840, lr = 5.26377e-05
I0708 14:56:42.190888 31135 solver.cpp:243] Iteration 59950, loss = 0.000310659
I0708 14:56:42.191282 31135 solver.cpp:259]     Train net output #0: loss = 0.00031259 (* 1 = 0.00031259 loss)
I0708 14:56:42.191296 31135 solver.cpp:590] Iteration 59950, lr = 5.21325e-05
I0708 14:56:47.341361 31135 solver.cpp:347] Iteration 59976, Testing net (#0)
I0708 14:57:11.205765 31135 solver.cpp:415]     Test net output #0: accuracy = 0.096274
I0708 14:57:11.205788 31135 solver.cpp:415]     Test net output #1: loss = 6.45773 (* 1 = 6.45773 loss)
I0708 14:57:28.685384 31135 solver.cpp:243] Iteration 60060, loss = 0.00927972
I0708 14:57:28.685473 31135 solver.cpp:259]     Train net output #0: loss = 0.00928154 (* 1 = 0.00928154 loss)
I0708 14:57:28.685480 31135 solver.cpp:590] Iteration 60060, lr = 5.16321e-05
I0708 14:57:51.335778 31135 solver.cpp:243] Iteration 60170, loss = 0.00486911
I0708 14:57:51.335800 31135 solver.cpp:259]     Train net output #0: loss = 0.00487093 (* 1 = 0.00487093 loss)
I0708 14:57:51.335806 31135 solver.cpp:590] Iteration 60170, lr = 5.11365e-05
I0708 14:58:13.985234 31135 solver.cpp:243] Iteration 60280, loss = 0.0171179
I0708 14:58:13.985326 31135 solver.cpp:259]     Train net output #0: loss = 0.0171197 (* 1 = 0.0171197 loss)
I0708 14:58:13.985333 31135 solver.cpp:590] Iteration 60280, lr = 5.06456e-05
I0708 14:58:36.639605 31135 solver.cpp:243] Iteration 60390, loss = 0.0703618
I0708 14:58:36.639628 31135 solver.cpp:259]     Train net output #0: loss = 0.0703637 (* 1 = 0.0703637 loss)
I0708 14:58:36.639636 31135 solver.cpp:590] Iteration 60390, lr = 5.01595e-05
I0708 14:58:59.288786 31135 solver.cpp:243] Iteration 60500, loss = 0.0126828
I0708 14:58:59.288877 31135 solver.cpp:259]     Train net output #0: loss = 0.0126848 (* 1 = 0.0126848 loss)
I0708 14:58:59.288884 31135 solver.cpp:590] Iteration 60500, lr = 4.9678e-05
I0708 14:59:21.949771 31135 solver.cpp:243] Iteration 60610, loss = 0.00148194
I0708 14:59:21.949795 31135 solver.cpp:259]     Train net output #0: loss = 0.0014839 (* 1 = 0.0014839 loss)
I0708 14:59:21.949801 31135 solver.cpp:590] Iteration 60610, lr = 4.92012e-05
I0708 14:59:44.613247 31135 solver.cpp:243] Iteration 60720, loss = 0.0054165
I0708 14:59:44.613338 31135 solver.cpp:259]     Train net output #0: loss = 0.00541846 (* 1 = 0.00541846 loss)
I0708 14:59:44.613355 31135 solver.cpp:590] Iteration 60720, lr = 4.87289e-05
I0708 15:00:07.268903 31135 solver.cpp:243] Iteration 60830, loss = 0.000879715
I0708 15:00:07.268952 31135 solver.cpp:259]     Train net output #0: loss = 0.000881727 (* 1 = 0.000881727 loss)
I0708 15:00:07.268960 31135 solver.cpp:590] Iteration 60830, lr = 4.82612e-05
I0708 15:00:12.828296 31135 solver.cpp:347] Iteration 60858, Testing net (#0)
I0708 15:00:37.681684 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0966346
I0708 15:00:37.681818 31135 solver.cpp:415]     Test net output #1: loss = 6.46175 (* 1 = 6.46175 loss)
I0708 15:00:54.728307 31135 solver.cpp:243] Iteration 60940, loss = 0.0278878
I0708 15:00:54.728370 31135 solver.cpp:259]     Train net output #0: loss = 0.0278898 (* 1 = 0.0278898 loss)
I0708 15:00:54.728384 31135 solver.cpp:590] Iteration 60940, lr = 4.77979e-05
I0708 15:01:17.366132 31135 solver.cpp:243] Iteration 61050, loss = 0.00422646
I0708 15:01:17.366250 31135 solver.cpp:259]     Train net output #0: loss = 0.00422843 (* 1 = 0.00422843 loss)
I0708 15:01:17.366267 31135 solver.cpp:590] Iteration 61050, lr = 4.73391e-05
I0708 15:01:40.047258 31135 solver.cpp:243] Iteration 61160, loss = 0.0982517
I0708 15:01:40.047283 31135 solver.cpp:259]     Train net output #0: loss = 0.0982537 (* 1 = 0.0982537 loss)
I0708 15:01:40.047291 31135 solver.cpp:590] Iteration 61160, lr = 4.68847e-05
I0708 15:02:02.717929 31135 solver.cpp:243] Iteration 61270, loss = 0.122256
I0708 15:02:02.718334 31135 solver.cpp:259]     Train net output #0: loss = 0.122258 (* 1 = 0.122258 loss)
I0708 15:02:02.718344 31135 solver.cpp:590] Iteration 61270, lr = 4.64347e-05
I0708 15:02:25.367492 31135 solver.cpp:243] Iteration 61380, loss = 0.00863072
I0708 15:02:25.367516 31135 solver.cpp:259]     Train net output #0: loss = 0.00863273 (* 1 = 0.00863273 loss)
I0708 15:02:25.367522 31135 solver.cpp:590] Iteration 61380, lr = 4.5989e-05
I0708 15:02:47.999734 31135 solver.cpp:243] Iteration 61490, loss = 0.182057
I0708 15:02:47.999825 31135 solver.cpp:259]     Train net output #0: loss = 0.18206 (* 1 = 0.18206 loss)
I0708 15:02:47.999832 31135 solver.cpp:590] Iteration 61490, lr = 4.55476e-05
I0708 15:03:10.665426 31135 solver.cpp:243] Iteration 61600, loss = 0.000839233
I0708 15:03:10.665448 31135 solver.cpp:259]     Train net output #0: loss = 0.00084123 (* 1 = 0.00084123 loss)
I0708 15:03:10.665455 31135 solver.cpp:590] Iteration 61600, lr = 4.51104e-05
I0708 15:03:33.323807 31135 solver.cpp:243] Iteration 61710, loss = 0.00347229
I0708 15:03:33.323899 31135 solver.cpp:259]     Train net output #0: loss = 0.00347428 (* 1 = 0.00347428 loss)
I0708 15:03:33.323916 31135 solver.cpp:590] Iteration 61710, lr = 4.46774e-05
I0708 15:03:39.299207 31135 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_61740.caffemodel
I0708 15:03:48.610419 31135 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_61740.solverstate
I0708 15:03:50.928913 31135 solver.cpp:347] Iteration 61740, Testing net (#0)
I0708 15:03:58.964582 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 15:04:05.937604 31152 blocking_queue.cpp:50] Waiting for data
I0708 15:04:15.726263 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0963942
I0708 15:04:15.726287 31135 solver.cpp:415]     Test net output #1: loss = 6.45979 (* 1 = 6.45979 loss)
I0708 15:04:32.352133 31135 solver.cpp:243] Iteration 61820, loss = 0.0180536
I0708 15:04:32.352157 31135 solver.cpp:259]     Train net output #0: loss = 0.0180556 (* 1 = 0.0180556 loss)
I0708 15:04:32.352162 31135 solver.cpp:590] Iteration 61820, lr = 4.42485e-05
I0708 15:04:55.004112 31135 solver.cpp:243] Iteration 61930, loss = 0.0240061
I0708 15:04:55.004200 31135 solver.cpp:259]     Train net output #0: loss = 0.0240081 (* 1 = 0.0240081 loss)
I0708 15:04:55.004206 31135 solver.cpp:590] Iteration 61930, lr = 4.38238e-05
I0708 15:05:17.637383 31135 solver.cpp:243] Iteration 62040, loss = 0.00836447
I0708 15:05:17.637404 31135 solver.cpp:259]     Train net output #0: loss = 0.00836642 (* 1 = 0.00836642 loss)
I0708 15:05:17.637410 31135 solver.cpp:590] Iteration 62040, lr = 4.34031e-05
I0708 15:05:40.249657 31135 solver.cpp:243] Iteration 62150, loss = 0.0902774
I0708 15:05:40.249745 31135 solver.cpp:259]     Train net output #0: loss = 0.0902794 (* 1 = 0.0902794 loss)
I0708 15:05:40.249761 31135 solver.cpp:590] Iteration 62150, lr = 4.29865e-05
I0708 15:06:02.877629 31135 solver.cpp:243] Iteration 62260, loss = 0.00134403
I0708 15:06:02.877658 31135 solver.cpp:259]     Train net output #0: loss = 0.00134599 (* 1 = 0.00134599 loss)
I0708 15:06:02.877666 31135 solver.cpp:590] Iteration 62260, lr = 4.25739e-05
I0708 15:06:25.535745 31135 solver.cpp:243] Iteration 62370, loss = 0.04311
I0708 15:06:25.535846 31135 solver.cpp:259]     Train net output #0: loss = 0.0431119 (* 1 = 0.0431119 loss)
I0708 15:06:25.535853 31135 solver.cpp:590] Iteration 62370, lr = 4.21653e-05
I0708 15:06:48.192327 31135 solver.cpp:243] Iteration 62480, loss = 0.0212022
I0708 15:06:48.192347 31135 solver.cpp:259]     Train net output #0: loss = 0.0212041 (* 1 = 0.0212041 loss)
I0708 15:06:48.192353 31135 solver.cpp:590] Iteration 62480, lr = 4.17605e-05
I0708 15:07:10.815939 31135 solver.cpp:243] Iteration 62590, loss = 0.00514403
I0708 15:07:10.816443 31135 solver.cpp:259]     Train net output #0: loss = 0.00514592 (* 1 = 0.00514592 loss)
I0708 15:07:10.816460 31135 solver.cpp:590] Iteration 62590, lr = 4.13597e-05
I0708 15:07:17.186063 31135 solver.cpp:347] Iteration 62622, Testing net (#0)
I0708 15:07:40.332548 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0969952
I0708 15:07:40.332574 31135 solver.cpp:415]     Test net output #1: loss = 6.45958 (* 1 = 6.45958 loss)
I0708 15:07:56.539973 31135 solver.cpp:243] Iteration 62700, loss = 0.0276006
I0708 15:07:56.540063 31135 solver.cpp:259]     Train net output #0: loss = 0.0276025 (* 1 = 0.0276025 loss)
I0708 15:07:56.540081 31135 solver.cpp:590] Iteration 62700, lr = 4.09627e-05
I0708 15:08:19.162391 31135 solver.cpp:243] Iteration 62810, loss = 0.000443354
I0708 15:08:19.162421 31135 solver.cpp:259]     Train net output #0: loss = 0.00044524 (* 1 = 0.00044524 loss)
I0708 15:08:19.162430 31135 solver.cpp:590] Iteration 62810, lr = 4.05695e-05
I0708 15:08:41.802335 31135 solver.cpp:243] Iteration 62920, loss = 0.000235023
I0708 15:08:41.802403 31135 solver.cpp:259]     Train net output #0: loss = 0.000236908 (* 1 = 0.000236908 loss)
I0708 15:08:41.802419 31135 solver.cpp:590] Iteration 62920, lr = 4.01801e-05
I0708 15:09:04.469156 31135 solver.cpp:243] Iteration 63030, loss = 0.00989201
I0708 15:09:04.469177 31135 solver.cpp:259]     Train net output #0: loss = 0.00989384 (* 1 = 0.00989384 loss)
I0708 15:09:04.469183 31135 solver.cpp:590] Iteration 63030, lr = 3.97944e-05
I0708 15:09:27.114740 31135 solver.cpp:243] Iteration 63140, loss = 0.00393839
I0708 15:09:27.114838 31135 solver.cpp:259]     Train net output #0: loss = 0.00394024 (* 1 = 0.00394024 loss)
I0708 15:09:27.114846 31135 solver.cpp:590] Iteration 63140, lr = 3.94124e-05
I0708 15:09:49.744688 31135 solver.cpp:243] Iteration 63250, loss = 0.00038768
I0708 15:09:49.744714 31135 solver.cpp:259]     Train net output #0: loss = 0.000389504 (* 1 = 0.000389504 loss)
I0708 15:09:49.744719 31135 solver.cpp:590] Iteration 63250, lr = 3.90341e-05
I0708 15:10:12.377856 31135 solver.cpp:243] Iteration 63360, loss = 0.0273743
I0708 15:10:12.377940 31135 solver.cpp:259]     Train net output #0: loss = 0.0273761 (* 1 = 0.0273761 loss)
I0708 15:10:12.377946 31135 solver.cpp:590] Iteration 63360, lr = 3.86595e-05
I0708 15:10:35.045517 31135 solver.cpp:243] Iteration 63470, loss = 0.0130433
I0708 15:10:35.045545 31135 solver.cpp:259]     Train net output #0: loss = 0.0130451 (* 1 = 0.0130451 loss)
I0708 15:10:35.045553 31135 solver.cpp:590] Iteration 63470, lr = 3.82884e-05
I0708 15:10:41.845100 31135 solver.cpp:347] Iteration 63504, Testing net (#0)
I0708 15:11:04.218098 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0967548
I0708 15:11:04.218235 31135 solver.cpp:415]     Test net output #1: loss = 6.46384 (* 1 = 6.46384 loss)
I0708 15:11:20.035122 31135 solver.cpp:243] Iteration 63580, loss = 0.0124555
I0708 15:11:20.035145 31135 solver.cpp:259]     Train net output #0: loss = 0.0124573 (* 1 = 0.0124573 loss)
I0708 15:11:20.035151 31135 solver.cpp:590] Iteration 63580, lr = 3.79209e-05
I0708 15:11:42.677566 31135 solver.cpp:243] Iteration 63690, loss = 0.0012763
I0708 15:11:42.677662 31135 solver.cpp:259]     Train net output #0: loss = 0.00127817 (* 1 = 0.00127817 loss)
I0708 15:11:42.677670 31135 solver.cpp:590] Iteration 63690, lr = 3.75569e-05
I0708 15:12:05.306262 31135 solver.cpp:243] Iteration 63800, loss = 0.00176495
I0708 15:12:05.306287 31135 solver.cpp:259]     Train net output #0: loss = 0.0017668 (* 1 = 0.0017668 loss)
I0708 15:12:05.306293 31135 solver.cpp:590] Iteration 63800, lr = 3.71964e-05
I0708 15:12:27.917742 31135 solver.cpp:243] Iteration 63910, loss = 0.00131335
I0708 15:12:27.917820 31135 solver.cpp:259]     Train net output #0: loss = 0.00131523 (* 1 = 0.00131523 loss)
I0708 15:12:27.917837 31135 solver.cpp:590] Iteration 63910, lr = 3.68393e-05
I0708 15:12:50.567725 31135 solver.cpp:243] Iteration 64020, loss = 0.0079792
I0708 15:12:50.567757 31135 solver.cpp:259]     Train net output #0: loss = 0.00798113 (* 1 = 0.00798113 loss)
I0708 15:12:50.567765 31135 solver.cpp:590] Iteration 64020, lr = 3.64857e-05
I0708 15:13:13.197129 31135 solver.cpp:243] Iteration 64130, loss = 0.00179773
I0708 15:13:13.197535 31135 solver.cpp:259]     Train net output #0: loss = 0.00179969 (* 1 = 0.00179969 loss)
I0708 15:13:13.197545 31135 solver.cpp:590] Iteration 64130, lr = 3.61355e-05
I0708 15:13:35.808761 31135 solver.cpp:243] Iteration 64240, loss = 0.00366365
I0708 15:13:35.808787 31135 solver.cpp:259]     Train net output #0: loss = 0.00366558 (* 1 = 0.00366558 loss)
I0708 15:13:35.808794 31135 solver.cpp:590] Iteration 64240, lr = 3.57887e-05
I0708 15:13:58.416877 31135 solver.cpp:243] Iteration 64350, loss = 0.0364318
I0708 15:13:58.416970 31135 solver.cpp:259]     Train net output #0: loss = 0.0364337 (* 1 = 0.0364337 loss)
I0708 15:13:58.416985 31135 solver.cpp:590] Iteration 64350, lr = 3.54451e-05
I0708 15:14:05.614312 31135 solver.cpp:347] Iteration 64386, Testing net (#0)
I0708 15:14:29.828588 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0966346
I0708 15:14:29.828665 31135 solver.cpp:415]     Test net output #1: loss = 6.46176 (* 1 = 6.46176 loss)
I0708 15:14:45.208263 31135 solver.cpp:243] Iteration 64460, loss = 0.018843
I0708 15:14:45.208284 31135 solver.cpp:259]     Train net output #0: loss = 0.0188449 (* 1 = 0.0188449 loss)
I0708 15:14:45.208290 31135 solver.cpp:590] Iteration 64460, lr = 3.51049e-05
I0708 15:15:07.844637 31135 solver.cpp:243] Iteration 64570, loss = 0.0996865
I0708 15:15:07.844728 31135 solver.cpp:259]     Train net output #0: loss = 0.0996884 (* 1 = 0.0996884 loss)
I0708 15:15:07.844738 31135 solver.cpp:590] Iteration 64570, lr = 3.47679e-05
I0708 15:15:30.486404 31135 solver.cpp:243] Iteration 64680, loss = 0.00013791
I0708 15:15:30.486428 31135 solver.cpp:259]     Train net output #0: loss = 0.000139797 (* 1 = 0.000139797 loss)
I0708 15:15:30.486434 31135 solver.cpp:590] Iteration 64680, lr = 3.44342e-05
I0708 15:15:53.106173 31135 solver.cpp:243] Iteration 64790, loss = 0.00222338
I0708 15:15:53.106263 31135 solver.cpp:259]     Train net output #0: loss = 0.00222529 (* 1 = 0.00222529 loss)
I0708 15:15:53.106271 31135 solver.cpp:590] Iteration 64790, lr = 3.41037e-05
I0708 15:16:15.693413 31135 solver.cpp:243] Iteration 64900, loss = 0.0178958
I0708 15:16:15.693439 31135 solver.cpp:259]     Train net output #0: loss = 0.0178977 (* 1 = 0.0178977 loss)
I0708 15:16:15.693444 31135 solver.cpp:590] Iteration 64900, lr = 3.37763e-05
I0708 15:16:38.351156 31135 solver.cpp:243] Iteration 65010, loss = 0.0736125
I0708 15:16:38.351236 31135 solver.cpp:259]     Train net output #0: loss = 0.0736144 (* 1 = 0.0736144 loss)
I0708 15:16:38.351251 31135 solver.cpp:590] Iteration 65010, lr = 3.34521e-05
I0708 15:17:00.991283 31135 solver.cpp:243] Iteration 65120, loss = 0.00144054
I0708 15:17:00.991307 31135 solver.cpp:259]     Train net output #0: loss = 0.00144247 (* 1 = 0.00144247 loss)
I0708 15:17:00.991313 31135 solver.cpp:590] Iteration 65120, lr = 3.3131e-05
I0708 15:17:23.588124 31135 solver.cpp:243] Iteration 65230, loss = 0.000203636
I0708 15:17:23.588258 31135 solver.cpp:259]     Train net output #0: loss = 0.000205556 (* 1 = 0.000205556 loss)
I0708 15:17:23.588275 31135 solver.cpp:590] Iteration 65230, lr = 3.2813e-05
I0708 15:17:31.193295 31135 solver.cpp:347] Iteration 65268, Testing net (#0)
I0708 15:17:36.678848 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 15:17:53.310127 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0963942
I0708 15:17:53.310153 31135 solver.cpp:415]     Test net output #1: loss = 6.46165 (* 1 = 6.46165 loss)
I0708 15:18:08.278429 31135 solver.cpp:243] Iteration 65340, loss = 0.00440011
I0708 15:18:08.278564 31135 solver.cpp:259]     Train net output #0: loss = 0.00440199 (* 1 = 0.00440199 loss)
I0708 15:18:08.278573 31135 solver.cpp:590] Iteration 65340, lr = 3.24981e-05
I0708 15:18:30.898847 31135 solver.cpp:243] Iteration 65450, loss = 0.000679761
I0708 15:18:30.898870 31135 solver.cpp:259]     Train net output #0: loss = 0.000681605 (* 1 = 0.000681605 loss)
I0708 15:18:30.898876 31135 solver.cpp:590] Iteration 65450, lr = 3.21861e-05
I0708 15:18:53.532743 31135 solver.cpp:243] Iteration 65560, loss = 0.000863146
I0708 15:18:53.533288 31135 solver.cpp:259]     Train net output #0: loss = 0.000864983 (* 1 = 0.000864983 loss)
I0708 15:18:53.533298 31135 solver.cpp:590] Iteration 65560, lr = 3.18772e-05
I0708 15:19:16.190599 31135 solver.cpp:243] Iteration 65670, loss = 0.019628
I0708 15:19:16.190623 31135 solver.cpp:259]     Train net output #0: loss = 0.0196299 (* 1 = 0.0196299 loss)
I0708 15:19:16.190629 31135 solver.cpp:590] Iteration 65670, lr = 3.15712e-05
I0708 15:19:38.825884 31135 solver.cpp:243] Iteration 65780, loss = 0.106888
I0708 15:19:38.825983 31135 solver.cpp:259]     Train net output #0: loss = 0.10689 (* 1 = 0.10689 loss)
I0708 15:19:38.825999 31135 solver.cpp:590] Iteration 65780, lr = 3.12682e-05
I0708 15:20:01.463408 31135 solver.cpp:243] Iteration 65890, loss = 0.00146756
I0708 15:20:01.463431 31135 solver.cpp:259]     Train net output #0: loss = 0.0014694 (* 1 = 0.0014694 loss)
I0708 15:20:01.463438 31135 solver.cpp:590] Iteration 65890, lr = 3.0968e-05
I0708 15:20:24.116917 31135 solver.cpp:243] Iteration 66000, loss = 0.0107208
I0708 15:20:24.117007 31135 solver.cpp:259]     Train net output #0: loss = 0.0107226 (* 1 = 0.0107226 loss)
I0708 15:20:24.117013 31135 solver.cpp:590] Iteration 66000, lr = 3.06708e-05
I0708 15:20:46.783143 31135 solver.cpp:243] Iteration 66110, loss = 0.00277675
I0708 15:20:46.783165 31135 solver.cpp:259]     Train net output #0: loss = 0.00277857 (* 1 = 0.00277857 loss)
I0708 15:20:46.783171 31135 solver.cpp:590] Iteration 66110, lr = 3.03764e-05
I0708 15:20:54.817751 31135 solver.cpp:347] Iteration 66150, Testing net (#0)
I0708 15:21:17.245055 31135 solver.cpp:415]     Test net output #0: accuracy = 0.096274
I0708 15:21:17.245080 31135 solver.cpp:415]     Test net output #1: loss = 6.46114 (* 1 = 6.46114 loss)
I0708 15:21:31.811352 31135 solver.cpp:243] Iteration 66220, loss = 0.00115518
I0708 15:21:31.811453 31135 solver.cpp:259]     Train net output #0: loss = 0.00115698 (* 1 = 0.00115698 loss)
I0708 15:21:31.811461 31135 solver.cpp:590] Iteration 66220, lr = 3.00848e-05
I0708 15:21:54.452103 31135 solver.cpp:243] Iteration 66330, loss = 0.0175353
I0708 15:21:54.452128 31135 solver.cpp:259]     Train net output #0: loss = 0.0175372 (* 1 = 0.0175372 loss)
I0708 15:21:54.452136 31135 solver.cpp:590] Iteration 66330, lr = 2.9796e-05
I0708 15:22:17.098623 31135 solver.cpp:243] Iteration 66440, loss = 0.0157685
I0708 15:22:17.098711 31135 solver.cpp:259]     Train net output #0: loss = 0.0157703 (* 1 = 0.0157703 loss)
I0708 15:22:17.098728 31135 solver.cpp:590] Iteration 66440, lr = 2.951e-05
I0708 15:22:39.746094 31135 solver.cpp:243] Iteration 66550, loss = 0.00023561
I0708 15:22:39.746119 31135 solver.cpp:259]     Train net output #0: loss = 0.00023745 (* 1 = 0.00023745 loss)
I0708 15:22:39.746124 31135 solver.cpp:590] Iteration 66550, lr = 2.92268e-05
I0708 15:23:02.408586 31135 solver.cpp:243] Iteration 66660, loss = 0.0176861
I0708 15:23:02.408666 31135 solver.cpp:259]     Train net output #0: loss = 0.017688 (* 1 = 0.017688 loss)
I0708 15:23:02.408682 31135 solver.cpp:590] Iteration 66660, lr = 2.89462e-05
I0708 15:23:25.063079 31135 solver.cpp:243] Iteration 66770, loss = 0.0229108
I0708 15:23:25.063102 31135 solver.cpp:259]     Train net output #0: loss = 0.0229127 (* 1 = 0.0229127 loss)
I0708 15:23:25.063108 31135 solver.cpp:590] Iteration 66770, lr = 2.86684e-05
I0708 15:23:47.709456 31135 solver.cpp:243] Iteration 66880, loss = 0.0679385
I0708 15:23:47.709553 31135 solver.cpp:259]     Train net output #0: loss = 0.0679404 (* 1 = 0.0679404 loss)
I0708 15:23:47.709560 31135 solver.cpp:590] Iteration 66880, lr = 2.83932e-05
I0708 15:24:10.350576 31135 solver.cpp:243] Iteration 66990, loss = 0.0190704
I0708 15:24:10.350600 31135 solver.cpp:259]     Train net output #0: loss = 0.0190724 (* 1 = 0.0190724 loss)
I0708 15:24:10.350606 31135 solver.cpp:590] Iteration 66990, lr = 2.81207e-05
I0708 15:24:18.790376 31135 solver.cpp:347] Iteration 67032, Testing net (#0)
I0708 15:24:42.592545 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0959135
I0708 15:24:42.592571 31135 solver.cpp:415]     Test net output #1: loss = 6.46298 (* 1 = 6.46298 loss)
I0708 15:24:56.756261 31135 solver.cpp:243] Iteration 67100, loss = 0.0304966
I0708 15:24:56.756583 31135 solver.cpp:259]     Train net output #0: loss = 0.0304985 (* 1 = 0.0304985 loss)
I0708 15:24:56.756592 31135 solver.cpp:590] Iteration 67100, lr = 2.78507e-05
I0708 15:25:19.406630 31135 solver.cpp:243] Iteration 67210, loss = 0.000105937
I0708 15:25:19.406653 31135 solver.cpp:259]     Train net output #0: loss = 0.000107876 (* 1 = 0.000107876 loss)
I0708 15:25:19.406658 31135 solver.cpp:590] Iteration 67210, lr = 2.75834e-05
I0708 15:25:42.054117 31135 solver.cpp:243] Iteration 67320, loss = 0.0190057
I0708 15:25:42.054483 31135 solver.cpp:259]     Train net output #0: loss = 0.0190076 (* 1 = 0.0190076 loss)
I0708 15:25:42.054491 31135 solver.cpp:590] Iteration 67320, lr = 2.73186e-05
I0708 15:26:04.721537 31135 solver.cpp:243] Iteration 67430, loss = 0.000683449
I0708 15:26:04.721561 31135 solver.cpp:259]     Train net output #0: loss = 0.000685361 (* 1 = 0.000685361 loss)
I0708 15:26:04.721568 31135 solver.cpp:590] Iteration 67430, lr = 2.70564e-05
I0708 15:26:27.376009 31135 solver.cpp:243] Iteration 67540, loss = 0.00055308
I0708 15:26:27.376101 31135 solver.cpp:259]     Train net output #0: loss = 0.000554984 (* 1 = 0.000554984 loss)
I0708 15:26:27.376109 31135 solver.cpp:590] Iteration 67540, lr = 2.67967e-05
I0708 15:26:50.036953 31135 solver.cpp:243] Iteration 67650, loss = 0.00060954
I0708 15:26:50.036978 31135 solver.cpp:259]     Train net output #0: loss = 0.000611435 (* 1 = 0.000611435 loss)
I0708 15:26:50.036983 31135 solver.cpp:590] Iteration 67650, lr = 2.65395e-05
I0708 15:27:12.684933 31135 solver.cpp:243] Iteration 67760, loss = 0.0321204
I0708 15:27:12.685096 31135 solver.cpp:259]     Train net output #0: loss = 0.0321223 (* 1 = 0.0321223 loss)
I0708 15:27:12.685104 31135 solver.cpp:590] Iteration 67760, lr = 2.62848e-05
I0708 15:27:35.354357 31135 solver.cpp:243] Iteration 67870, loss = 0.00149687
I0708 15:27:35.354382 31135 solver.cpp:259]     Train net output #0: loss = 0.00149874 (* 1 = 0.00149874 loss)
I0708 15:27:35.354387 31135 solver.cpp:590] Iteration 67870, lr = 2.60325e-05
I0708 15:27:44.216264 31135 solver.cpp:347] Iteration 67914, Testing net (#0)
I0708 15:28:08.415976 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0963942
I0708 15:28:08.416000 31135 solver.cpp:415]     Test net output #1: loss = 6.46079 (* 1 = 6.46079 loss)
I0708 15:28:22.167589 31135 solver.cpp:243] Iteration 67980, loss = 0.0639643
I0708 15:28:22.167675 31135 solver.cpp:259]     Train net output #0: loss = 0.0639663 (* 1 = 0.0639663 loss)
I0708 15:28:22.167683 31135 solver.cpp:590] Iteration 67980, lr = 2.57826e-05
I0708 15:28:44.812417 31135 solver.cpp:243] Iteration 68090, loss = 0.0357296
I0708 15:28:44.812441 31135 solver.cpp:259]     Train net output #0: loss = 0.0357315 (* 1 = 0.0357315 loss)
I0708 15:28:44.812448 31135 solver.cpp:590] Iteration 68090, lr = 2.55351e-05
I0708 15:29:07.469298 31135 solver.cpp:243] Iteration 68200, loss = 0.00026603
I0708 15:29:07.469427 31135 solver.cpp:259]     Train net output #0: loss = 0.000268015 (* 1 = 0.000268015 loss)
I0708 15:29:07.469445 31135 solver.cpp:590] Iteration 68200, lr = 2.529e-05
I0708 15:29:30.111698 31135 solver.cpp:243] Iteration 68310, loss = 0.000189289
I0708 15:29:30.111722 31135 solver.cpp:259]     Train net output #0: loss = 0.000191292 (* 1 = 0.000191292 loss)
I0708 15:29:30.111728 31135 solver.cpp:590] Iteration 68310, lr = 2.50472e-05
I0708 15:29:52.756700 31135 solver.cpp:243] Iteration 68420, loss = 0.00294019
I0708 15:29:52.756808 31135 solver.cpp:259]     Train net output #0: loss = 0.00294218 (* 1 = 0.00294218 loss)
I0708 15:29:52.756824 31135 solver.cpp:590] Iteration 68420, lr = 2.48068e-05
I0708 15:30:15.397721 31135 solver.cpp:243] Iteration 68530, loss = 0.00224447
I0708 15:30:15.397743 31135 solver.cpp:259]     Train net output #0: loss = 0.00224649 (* 1 = 0.00224649 loss)
I0708 15:30:15.397749 31135 solver.cpp:590] Iteration 68530, lr = 2.45687e-05
I0708 15:30:38.046011 31135 solver.cpp:243] Iteration 68640, loss = 0.0698616
I0708 15:30:38.046324 31135 solver.cpp:259]     Train net output #0: loss = 0.0698635 (* 1 = 0.0698635 loss)
I0708 15:30:38.046334 31135 solver.cpp:590] Iteration 68640, lr = 2.43329e-05
I0708 15:31:00.697777 31135 solver.cpp:243] Iteration 68750, loss = 0.0921781
I0708 15:31:00.697803 31135 solver.cpp:259]     Train net output #0: loss = 0.0921801 (* 1 = 0.0921801 loss)
I0708 15:31:00.697808 31135 solver.cpp:590] Iteration 68750, lr = 2.40993e-05
I0708 15:31:09.958716 31135 solver.cpp:347] Iteration 68796, Testing net (#0)
I0708 15:31:13.525920 31135 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 15:31:14.076089 31152 blocking_queue.cpp:50] Waiting for data
I0708 15:31:33.015313 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0961538
I0708 15:31:33.015338 31135 solver.cpp:415]     Test net output #1: loss = 6.46085 (* 1 = 6.46085 loss)
I0708 15:31:46.368777 31135 solver.cpp:243] Iteration 68860, loss = 0.0119937
I0708 15:31:46.368909 31135 solver.cpp:259]     Train net output #0: loss = 0.0119957 (* 1 = 0.0119957 loss)
I0708 15:31:46.368917 31135 solver.cpp:590] Iteration 68860, lr = 2.3868e-05
I0708 15:32:09.012229 31135 solver.cpp:243] Iteration 68970, loss = 0.000783626
I0708 15:32:09.012254 31135 solver.cpp:259]     Train net output #0: loss = 0.000785716 (* 1 = 0.000785716 loss)
I0708 15:32:09.012260 31135 solver.cpp:590] Iteration 68970, lr = 2.36389e-05
I0708 15:32:31.666244 31135 solver.cpp:243] Iteration 69080, loss = 0.0204729
I0708 15:32:31.666400 31135 solver.cpp:259]     Train net output #0: loss = 0.020475 (* 1 = 0.020475 loss)
I0708 15:32:31.666415 31135 solver.cpp:590] Iteration 69080, lr = 2.3412e-05
I0708 15:32:54.313766 31135 solver.cpp:243] Iteration 69190, loss = 0.00202893
I0708 15:32:54.313789 31135 solver.cpp:259]     Train net output #0: loss = 0.00203104 (* 1 = 0.00203104 loss)
I0708 15:32:54.313794 31135 solver.cpp:590] Iteration 69190, lr = 2.31873e-05
I0708 15:33:16.941715 31135 solver.cpp:243] Iteration 69300, loss = 0.000775066
I0708 15:33:16.941803 31135 solver.cpp:259]     Train net output #0: loss = 0.000777179 (* 1 = 0.000777179 loss)
I0708 15:33:16.941810 31135 solver.cpp:590] Iteration 69300, lr = 2.29647e-05
I0708 15:33:39.561336 31135 solver.cpp:243] Iteration 69410, loss = 0.00398687
I0708 15:33:39.561357 31135 solver.cpp:259]     Train net output #0: loss = 0.00398902 (* 1 = 0.00398902 loss)
I0708 15:33:39.561362 31135 solver.cpp:590] Iteration 69410, lr = 2.27443e-05
I0708 15:34:02.218724 31135 solver.cpp:243] Iteration 69520, loss = 0.00109678
I0708 15:34:02.218811 31135 solver.cpp:259]     Train net output #0: loss = 0.00109892 (* 1 = 0.00109892 loss)
I0708 15:34:02.218819 31135 solver.cpp:590] Iteration 69520, lr = 2.2526e-05
I0708 15:34:24.870898 31135 solver.cpp:243] Iteration 69630, loss = 0.00114828
I0708 15:34:24.870921 31135 solver.cpp:259]     Train net output #0: loss = 0.00115045 (* 1 = 0.00115045 loss)
I0708 15:34:24.870928 31135 solver.cpp:590] Iteration 69630, lr = 2.23097e-05
I0708 15:34:34.534808 31135 solver.cpp:347] Iteration 69678, Testing net (#0)
I0708 15:34:59.469066 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0960337
I0708 15:34:59.469094 31135 solver.cpp:415]     Test net output #1: loss = 6.45952 (* 1 = 6.45952 loss)
I0708 15:35:12.409122 31135 solver.cpp:243] Iteration 69740, loss = 0.0275793
I0708 15:35:12.409271 31135 solver.cpp:259]     Train net output #0: loss = 0.0275815 (* 1 = 0.0275815 loss)
I0708 15:35:12.409283 31135 solver.cpp:590] Iteration 69740, lr = 2.20956e-05
I0708 15:35:35.038085 31135 solver.cpp:243] Iteration 69850, loss = 0.110476
I0708 15:35:35.038110 31135 solver.cpp:259]     Train net output #0: loss = 0.110478 (* 1 = 0.110478 loss)
I0708 15:35:35.038115 31135 solver.cpp:590] Iteration 69850, lr = 2.18835e-05
I0708 15:35:57.681078 31135 solver.cpp:243] Iteration 69960, loss = 0.0130904
I0708 15:35:57.681761 31135 solver.cpp:259]     Train net output #0: loss = 0.0130925 (* 1 = 0.0130925 loss)
I0708 15:35:57.681771 31135 solver.cpp:590] Iteration 69960, lr = 2.16735e-05
I0708 15:36:20.345310 31135 solver.cpp:243] Iteration 70070, loss = 0.000197157
I0708 15:36:20.345332 31135 solver.cpp:259]     Train net output #0: loss = 0.000199272 (* 1 = 0.000199272 loss)
I0708 15:36:20.345338 31135 solver.cpp:590] Iteration 70070, lr = 2.14654e-05
I0708 15:36:42.982188 31135 solver.cpp:243] Iteration 70180, loss = 0.0334329
I0708 15:36:42.982564 31135 solver.cpp:259]     Train net output #0: loss = 0.0334351 (* 1 = 0.0334351 loss)
I0708 15:36:42.982573 31135 solver.cpp:590] Iteration 70180, lr = 2.12594e-05
I0708 15:37:05.592223 31135 solver.cpp:243] Iteration 70290, loss = 0.0259245
I0708 15:37:05.592247 31135 solver.cpp:259]     Train net output #0: loss = 0.0259266 (* 1 = 0.0259266 loss)
I0708 15:37:05.592253 31135 solver.cpp:590] Iteration 70290, lr = 2.10553e-05
I0708 15:37:28.220607 31135 solver.cpp:243] Iteration 70400, loss = 0.18711
I0708 15:37:28.220964 31135 solver.cpp:259]     Train net output #0: loss = 0.187112 (* 1 = 0.187112 loss)
I0708 15:37:28.220973 31135 solver.cpp:590] Iteration 70400, lr = 2.08532e-05
I0708 15:37:50.847498 31135 solver.cpp:243] Iteration 70510, loss = 0.00196561
I0708 15:37:50.847522 31135 solver.cpp:259]     Train net output #0: loss = 0.00196767 (* 1 = 0.00196767 loss)
I0708 15:37:50.847528 31135 solver.cpp:590] Iteration 70510, lr = 2.06531e-05
I0708 15:38:00.934376 31135 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_70560.caffemodel
I0708 15:38:11.433351 31135 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_70560.solverstate
I0708 15:38:13.603698 31135 solver.cpp:347] Iteration 70560, Testing net (#0)
I0708 15:38:41.666692 31135 solver.cpp:415]     Test net output #0: accuracy = 0.0959135
I0708 15:38:41.666929 31135 solver.cpp:415]     Test net output #1: loss = 6.45885 (* 1 = 6.45885 loss)
I0708 15:38:41.666944 31135 solver.cpp:332] Optimization Done.
I0708 15:38:41.666946 31135 caffe.cpp:223] Optimization Done.
