I0708 00:31:24.760131 24447 caffe.cpp:192] Using GPUs 0
I0708 00:31:24.945261 24447 solver.cpp:54] Initializing solver from parameters:
test_iter: 260
test_interval: 221
base_lr: 0.01
display: 27
max_iter: 22100
lr_policy: "exp"
gamma: 0.99976796
momentum: 0.9
weight_decay: 0.0001
snapshot: 2210
snapshot_prefix: "snapshot"
solver_mode: GPU
device_id: 0
random_seed: 0
net: "train_val.prototxt"
solver_type: SGD
I0708 00:31:24.945751 24447 solver.cpp:97] Creating training net from net file: train_val.prototxt
I0708 00:31:24.946322 24447 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer val-data
I0708 00:31:24.946337 24447 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0708 00:31:24.946436 24447 net.cpp:52] Initializing net from parameters:
state {
phase: TRAIN
}
layer {
name: "train-data"
type: "Data"
top: "data"
top: "label"
include {
phase: TRAIN
}
transform_param {
mirror: true
crop_size: 227
mean_file: "/home/ffw/scratch/digits/jobs/20160624-120053-bb9a/mean.binaryproto"
}
data_param {
source: "/home/ffw/scratch/digits/jobs/20160624-120053-bb9a/train_db"
batch_size: 128
backend: LMDB
}
}
layer {
name: "conv1"
type: "Convolution"
bottom: "data"
top: "conv1"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 11
stride: 4
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu1"
type: "ReLU"
bottom: "conv1"
top: "conv1"
}
layer {
name: "norm1"
type: "LRN"
bottom: "conv1"
top: "norm1"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool1"
type: "Pooling"
bottom: "norm1"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv2"
type: "Convolution"
bottom: "pool1"
top: "conv2"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 2
kernel_size: 5
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu2"
type: "ReLU"
bottom: "conv2"
top: "conv2"
}
layer {
name: "norm2"
type: "LRN"
bottom: "conv2"
top: "norm2"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool2"
type: "Pooling"
bottom: "norm2"
top: "pool2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool2"
top: "conv3"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "conv4"
type: "Convolution"
bottom: "conv3"
top: "conv4"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu4"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "conv5"
type: "Convolution"
bottom: "conv4"
top: "conv5"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "conv5"
top: "conv5"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "conv5"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fc6"
type: "InnerProduct"
bottom: "pool5"
top: "fc6"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "fc6"
top: "fc6"
}
layer {
name: "drop6"
type: "Dropout"
bottom: "fc6"
top: "fc6"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc7"
type: "InnerProduct"
bottom: "fc6"
top: "fc7"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "fc7"
top: "fc7"
}
layer {
name: "drop7"
type: "Dropout"
bottom: "fc7"
top: "fc7"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc8_clean"
type: "InnerProduct"
bottom: "fc7"
top: "fc8_clean"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 967
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "fc8_clean"
bottom: "label"
top: "loss"
}
I0708 00:31:24.946501 24447 layer_factory.hpp:76] Creating layer train-data
I0708 00:31:24.946594 24447 net.cpp:109] Creating Layer train-data
I0708 00:31:24.946599 24447 net.cpp:414] train-data -> data
I0708 00:31:24.946609 24447 net.cpp:414] train-data -> label
I0708 00:31:24.946614 24447 data_transformer.cpp:25] Loading mean file from: /home/ffw/scratch/digits/jobs/20160624-120053-bb9a/mean.binaryproto
I0708 00:31:24.950260 24459 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/digits/jobs/20160624-120053-bb9a/train_db
I0708 00:31:24.956181 24447 data_layer.cpp:45] output data size: 128,3,227,227
I0708 00:31:25.042346 24447 net.cpp:153] Setting up train-data
I0708 00:31:25.042374 24447 net.cpp:160] Top shape: 128 3 227 227 (19787136)
I0708 00:31:25.042382 24447 net.cpp:160] Top shape: 128 (128)
I0708 00:31:25.042385 24447 net.cpp:168] Memory required for data: 79149056
I0708 00:31:25.042392 24447 layer_factory.hpp:76] Creating layer conv1
I0708 00:31:25.042410 24447 net.cpp:109] Creating Layer conv1
I0708 00:31:25.042413 24447 net.cpp:457] conv1 <- data
I0708 00:31:25.042420 24447 net.cpp:414] conv1 -> conv1
I0708 00:31:25.044020 24447 net.cpp:153] Setting up conv1
I0708 00:31:25.044028 24447 net.cpp:160] Top shape: 128 96 55 55 (37171200)
I0708 00:31:25.044030 24447 net.cpp:168] Memory required for data: 227833856
I0708 00:31:25.044039 24447 layer_factory.hpp:76] Creating layer relu1
I0708 00:31:25.044044 24447 net.cpp:109] Creating Layer relu1
I0708 00:31:25.044046 24447 net.cpp:457] relu1 <- conv1
I0708 00:31:25.044049 24447 net.cpp:400] relu1 -> conv1 (in-place)
I0708 00:31:25.044060 24447 net.cpp:153] Setting up relu1
I0708 00:31:25.044064 24447 net.cpp:160] Top shape: 128 96 55 55 (37171200)
I0708 00:31:25.044064 24447 net.cpp:168] Memory required for data: 376518656
I0708 00:31:25.044066 24447 layer_factory.hpp:76] Creating layer norm1
I0708 00:31:25.044070 24447 net.cpp:109] Creating Layer norm1
I0708 00:31:25.044072 24447 net.cpp:457] norm1 <- conv1
I0708 00:31:25.044076 24447 net.cpp:414] norm1 -> norm1
I0708 00:31:25.044118 24447 net.cpp:153] Setting up norm1
I0708 00:31:25.044124 24447 net.cpp:160] Top shape: 128 96 55 55 (37171200)
I0708 00:31:25.044126 24447 net.cpp:168] Memory required for data: 525203456
I0708 00:31:25.044128 24447 layer_factory.hpp:76] Creating layer pool1
I0708 00:31:25.044133 24447 net.cpp:109] Creating Layer pool1
I0708 00:31:25.044137 24447 net.cpp:457] pool1 <- norm1
I0708 00:31:25.044162 24447 net.cpp:414] pool1 -> pool1
I0708 00:31:25.044191 24447 net.cpp:153] Setting up pool1
I0708 00:31:25.044205 24447 net.cpp:160] Top shape: 128 96 27 27 (8957952)
I0708 00:31:25.044208 24447 net.cpp:168] Memory required for data: 561035264
I0708 00:31:25.044209 24447 layer_factory.hpp:76] Creating layer conv2
I0708 00:31:25.044214 24447 net.cpp:109] Creating Layer conv2
I0708 00:31:25.044215 24447 net.cpp:457] conv2 <- pool1
I0708 00:31:25.044219 24447 net.cpp:414] conv2 -> conv2
I0708 00:31:25.053372 24447 net.cpp:153] Setting up conv2
I0708 00:31:25.053386 24447 net.cpp:160] Top shape: 128 256 27 27 (23887872)
I0708 00:31:25.053388 24447 net.cpp:168] Memory required for data: 656586752
I0708 00:31:25.053401 24447 layer_factory.hpp:76] Creating layer relu2
I0708 00:31:25.053412 24447 net.cpp:109] Creating Layer relu2
I0708 00:31:25.053417 24447 net.cpp:457] relu2 <- conv2
I0708 00:31:25.053423 24447 net.cpp:400] relu2 -> conv2 (in-place)
I0708 00:31:25.053432 24447 net.cpp:153] Setting up relu2
I0708 00:31:25.053437 24447 net.cpp:160] Top shape: 128 256 27 27 (23887872)
I0708 00:31:25.053439 24447 net.cpp:168] Memory required for data: 752138240
I0708 00:31:25.053442 24447 layer_factory.hpp:76] Creating layer norm2
I0708 00:31:25.053447 24447 net.cpp:109] Creating Layer norm2
I0708 00:31:25.053449 24447 net.cpp:457] norm2 <- conv2
I0708 00:31:25.053452 24447 net.cpp:414] norm2 -> norm2
I0708 00:31:25.053488 24447 net.cpp:153] Setting up norm2
I0708 00:31:25.053491 24447 net.cpp:160] Top shape: 128 256 27 27 (23887872)
I0708 00:31:25.053493 24447 net.cpp:168] Memory required for data: 847689728
I0708 00:31:25.053495 24447 layer_factory.hpp:76] Creating layer pool2
I0708 00:31:25.053499 24447 net.cpp:109] Creating Layer pool2
I0708 00:31:25.053501 24447 net.cpp:457] pool2 <- norm2
I0708 00:31:25.053504 24447 net.cpp:414] pool2 -> pool2
I0708 00:31:25.053522 24447 net.cpp:153] Setting up pool2
I0708 00:31:25.053524 24447 net.cpp:160] Top shape: 128 256 13 13 (5537792)
I0708 00:31:25.053526 24447 net.cpp:168] Memory required for data: 869840896
I0708 00:31:25.053529 24447 layer_factory.hpp:76] Creating layer conv3
I0708 00:31:25.053532 24447 net.cpp:109] Creating Layer conv3
I0708 00:31:25.053534 24447 net.cpp:457] conv3 <- pool2
I0708 00:31:25.053539 24447 net.cpp:414] conv3 -> conv3
I0708 00:31:25.073210 24447 net.cpp:153] Setting up conv3
I0708 00:31:25.073225 24447 net.cpp:160] Top shape: 128 384 13 13 (8306688)
I0708 00:31:25.073230 24447 net.cpp:168] Memory required for data: 903067648
I0708 00:31:25.073240 24447 layer_factory.hpp:76] Creating layer relu3
I0708 00:31:25.073251 24447 net.cpp:109] Creating Layer relu3
I0708 00:31:25.073256 24447 net.cpp:457] relu3 <- conv3
I0708 00:31:25.073262 24447 net.cpp:400] relu3 -> conv3 (in-place)
I0708 00:31:25.073271 24447 net.cpp:153] Setting up relu3
I0708 00:31:25.073277 24447 net.cpp:160] Top shape: 128 384 13 13 (8306688)
I0708 00:31:25.073281 24447 net.cpp:168] Memory required for data: 936294400
I0708 00:31:25.073283 24447 layer_factory.hpp:76] Creating layer conv4
I0708 00:31:25.073293 24447 net.cpp:109] Creating Layer conv4
I0708 00:31:25.073297 24447 net.cpp:457] conv4 <- conv3
I0708 00:31:25.073302 24447 net.cpp:414] conv4 -> conv4
I0708 00:31:25.087790 24447 net.cpp:153] Setting up conv4
I0708 00:31:25.087806 24447 net.cpp:160] Top shape: 128 384 13 13 (8306688)
I0708 00:31:25.087810 24447 net.cpp:168] Memory required for data: 969521152
I0708 00:31:25.087815 24447 layer_factory.hpp:76] Creating layer relu4
I0708 00:31:25.087821 24447 net.cpp:109] Creating Layer relu4
I0708 00:31:25.087823 24447 net.cpp:457] relu4 <- conv4
I0708 00:31:25.087827 24447 net.cpp:400] relu4 -> conv4 (in-place)
I0708 00:31:25.087833 24447 net.cpp:153] Setting up relu4
I0708 00:31:25.087836 24447 net.cpp:160] Top shape: 128 384 13 13 (8306688)
I0708 00:31:25.087838 24447 net.cpp:168] Memory required for data: 1002747904
I0708 00:31:25.087841 24447 layer_factory.hpp:76] Creating layer conv5
I0708 00:31:25.087846 24447 net.cpp:109] Creating Layer conv5
I0708 00:31:25.087865 24447 net.cpp:457] conv5 <- conv4
I0708 00:31:25.087873 24447 net.cpp:414] conv5 -> conv5
I0708 00:31:25.097410 24447 net.cpp:153] Setting up conv5
I0708 00:31:25.097430 24447 net.cpp:160] Top shape: 128 256 13 13 (5537792)
I0708 00:31:25.097434 24447 net.cpp:168] Memory required for data: 1024899072
I0708 00:31:25.097450 24447 layer_factory.hpp:76] Creating layer relu5
I0708 00:31:25.097462 24447 net.cpp:109] Creating Layer relu5
I0708 00:31:25.097468 24447 net.cpp:457] relu5 <- conv5
I0708 00:31:25.097478 24447 net.cpp:400] relu5 -> conv5 (in-place)
I0708 00:31:25.097488 24447 net.cpp:153] Setting up relu5
I0708 00:31:25.097492 24447 net.cpp:160] Top shape: 128 256 13 13 (5537792)
I0708 00:31:25.097496 24447 net.cpp:168] Memory required for data: 1047050240
I0708 00:31:25.097499 24447 layer_factory.hpp:76] Creating layer pool5
I0708 00:31:25.097506 24447 net.cpp:109] Creating Layer pool5
I0708 00:31:25.097508 24447 net.cpp:457] pool5 <- conv5
I0708 00:31:25.097513 24447 net.cpp:414] pool5 -> pool5
I0708 00:31:25.097553 24447 net.cpp:153] Setting up pool5
I0708 00:31:25.097555 24447 net.cpp:160] Top shape: 128 256 6 6 (1179648)
I0708 00:31:25.097558 24447 net.cpp:168] Memory required for data: 1051768832
I0708 00:31:25.097559 24447 layer_factory.hpp:76] Creating layer fc6
I0708 00:31:25.097565 24447 net.cpp:109] Creating Layer fc6
I0708 00:31:25.097568 24447 net.cpp:457] fc6 <- pool5
I0708 00:31:25.097570 24447 net.cpp:414] fc6 -> fc6
I0708 00:31:25.795276 24447 net.cpp:153] Setting up fc6
I0708 00:31:25.795295 24447 net.cpp:160] Top shape: 128 4096 (524288)
I0708 00:31:25.795297 24447 net.cpp:168] Memory required for data: 1053865984
I0708 00:31:25.795302 24447 layer_factory.hpp:76] Creating layer relu6
I0708 00:31:25.795308 24447 net.cpp:109] Creating Layer relu6
I0708 00:31:25.795310 24447 net.cpp:457] relu6 <- fc6
I0708 00:31:25.795315 24447 net.cpp:400] relu6 -> fc6 (in-place)
I0708 00:31:25.795320 24447 net.cpp:153] Setting up relu6
I0708 00:31:25.795322 24447 net.cpp:160] Top shape: 128 4096 (524288)
I0708 00:31:25.795325 24447 net.cpp:168] Memory required for data: 1055963136
I0708 00:31:25.795325 24447 layer_factory.hpp:76] Creating layer drop6
I0708 00:31:25.795334 24447 net.cpp:109] Creating Layer drop6
I0708 00:31:25.795336 24447 net.cpp:457] drop6 <- fc6
I0708 00:31:25.795338 24447 net.cpp:400] drop6 -> fc6 (in-place)
I0708 00:31:25.795348 24447 net.cpp:153] Setting up drop6
I0708 00:31:25.795351 24447 net.cpp:160] Top shape: 128 4096 (524288)
I0708 00:31:25.795352 24447 net.cpp:168] Memory required for data: 1058060288
I0708 00:31:25.795354 24447 layer_factory.hpp:76] Creating layer fc7
I0708 00:31:25.795358 24447 net.cpp:109] Creating Layer fc7
I0708 00:31:25.795361 24447 net.cpp:457] fc7 <- fc6
I0708 00:31:25.795362 24447 net.cpp:414] fc7 -> fc7
I0708 00:31:26.102121 24447 net.cpp:153] Setting up fc7
I0708 00:31:26.102140 24447 net.cpp:160] Top shape: 128 4096 (524288)
I0708 00:31:26.102144 24447 net.cpp:168] Memory required for data: 1060157440
I0708 00:31:26.102150 24447 layer_factory.hpp:76] Creating layer relu7
I0708 00:31:26.102156 24447 net.cpp:109] Creating Layer relu7
I0708 00:31:26.102160 24447 net.cpp:457] relu7 <- fc7
I0708 00:31:26.102164 24447 net.cpp:400] relu7 -> fc7 (in-place)
I0708 00:31:26.102171 24447 net.cpp:153] Setting up relu7
I0708 00:31:26.102174 24447 net.cpp:160] Top shape: 128 4096 (524288)
I0708 00:31:26.102176 24447 net.cpp:168] Memory required for data: 1062254592
I0708 00:31:26.102179 24447 layer_factory.hpp:76] Creating layer drop7
I0708 00:31:26.102183 24447 net.cpp:109] Creating Layer drop7
I0708 00:31:26.102186 24447 net.cpp:457] drop7 <- fc7
I0708 00:31:26.102188 24447 net.cpp:400] drop7 -> fc7 (in-place)
I0708 00:31:26.102202 24447 net.cpp:153] Setting up drop7
I0708 00:31:26.102205 24447 net.cpp:160] Top shape: 128 4096 (524288)
I0708 00:31:26.102206 24447 net.cpp:168] Memory required for data: 1064351744
I0708 00:31:26.102208 24447 layer_factory.hpp:76] Creating layer fc8_clean
I0708 00:31:26.102213 24447 net.cpp:109] Creating Layer fc8_clean
I0708 00:31:26.102232 24447 net.cpp:457] fc8_clean <- fc7
I0708 00:31:26.102236 24447 net.cpp:414] fc8_clean -> fc8_clean
I0708 00:31:26.173805 24447 net.cpp:153] Setting up fc8_clean
I0708 00:31:26.173822 24447 net.cpp:160] Top shape: 128 967 (123776)
I0708 00:31:26.173825 24447 net.cpp:168] Memory required for data: 1064846848
I0708 00:31:26.173830 24447 layer_factory.hpp:76] Creating layer loss
I0708 00:31:26.173845 24447 net.cpp:109] Creating Layer loss
I0708 00:31:26.173847 24447 net.cpp:457] loss <- fc8_clean
I0708 00:31:26.173851 24447 net.cpp:457] loss <- label
I0708 00:31:26.173854 24447 net.cpp:414] loss -> loss
I0708 00:31:26.173861 24447 layer_factory.hpp:76] Creating layer loss
I0708 00:31:26.174321 24447 net.cpp:153] Setting up loss
I0708 00:31:26.174329 24447 net.cpp:160] Top shape: (1)
I0708 00:31:26.174330 24447 net.cpp:163]     with loss weight 1
I0708 00:31:26.174345 24447 net.cpp:168] Memory required for data: 1064846852
I0708 00:31:26.174346 24447 net.cpp:229] loss needs backward computation.
I0708 00:31:26.174350 24447 net.cpp:229] fc8_clean needs backward computation.
I0708 00:31:26.174351 24447 net.cpp:231] drop7 does not need backward computation.
I0708 00:31:26.174353 24447 net.cpp:231] relu7 does not need backward computation.
I0708 00:31:26.174355 24447 net.cpp:231] fc7 does not need backward computation.
I0708 00:31:26.174357 24447 net.cpp:231] drop6 does not need backward computation.
I0708 00:31:26.174358 24447 net.cpp:231] relu6 does not need backward computation.
I0708 00:31:26.174360 24447 net.cpp:231] fc6 does not need backward computation.
I0708 00:31:26.174362 24447 net.cpp:231] pool5 does not need backward computation.
I0708 00:31:26.174365 24447 net.cpp:231] relu5 does not need backward computation.
I0708 00:31:26.174366 24447 net.cpp:231] conv5 does not need backward computation.
I0708 00:31:26.174368 24447 net.cpp:231] relu4 does not need backward computation.
I0708 00:31:26.174371 24447 net.cpp:231] conv4 does not need backward computation.
I0708 00:31:26.174372 24447 net.cpp:231] relu3 does not need backward computation.
I0708 00:31:26.174374 24447 net.cpp:231] conv3 does not need backward computation.
I0708 00:31:26.174376 24447 net.cpp:231] pool2 does not need backward computation.
I0708 00:31:26.174378 24447 net.cpp:231] norm2 does not need backward computation.
I0708 00:31:26.174381 24447 net.cpp:231] relu2 does not need backward computation.
I0708 00:31:26.174382 24447 net.cpp:231] conv2 does not need backward computation.
I0708 00:31:26.174384 24447 net.cpp:231] pool1 does not need backward computation.
I0708 00:31:26.174386 24447 net.cpp:231] norm1 does not need backward computation.
I0708 00:31:26.174388 24447 net.cpp:231] relu1 does not need backward computation.
I0708 00:31:26.174391 24447 net.cpp:231] conv1 does not need backward computation.
I0708 00:31:26.174392 24447 net.cpp:231] train-data does not need backward computation.
I0708 00:31:26.174394 24447 net.cpp:273] This network produces output loss
I0708 00:31:26.174401 24447 net.cpp:286] Network initialization done.
I0708 00:31:26.174835 24447 solver.cpp:187] Creating test net (#0) specified by net file: train_val.prototxt
I0708 00:31:26.174871 24447 net.cpp:325] The NetState phase (1) differed from the phase (0) specified by a rule in layer train-data
I0708 00:31:26.174973 24447 net.cpp:52] Initializing net from parameters:
state {
phase: TEST
}
layer {
name: "val-data"
type: "Data"
top: "data"
top: "label"
include {
phase: TEST
}
transform_param {
crop_size: 227
mean_file: "/home/ffw/scratch/digits/jobs/20160624-120053-bb9a/mean.binaryproto"
}
data_param {
source: "/home/ffw/scratch/digits/jobs/20160624-120053-bb9a/val_db"
batch_size: 32
backend: LMDB
}
}
layer {
name: "conv1"
type: "Convolution"
bottom: "data"
top: "conv1"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 11
stride: 4
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu1"
type: "ReLU"
bottom: "conv1"
top: "conv1"
}
layer {
name: "norm1"
type: "LRN"
bottom: "conv1"
top: "norm1"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool1"
type: "Pooling"
bottom: "norm1"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv2"
type: "Convolution"
bottom: "pool1"
top: "conv2"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 2
kernel_size: 5
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu2"
type: "ReLU"
bottom: "conv2"
top: "conv2"
}
layer {
name: "norm2"
type: "LRN"
bottom: "conv2"
top: "norm2"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool2"
type: "Pooling"
bottom: "norm2"
top: "pool2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool2"
top: "conv3"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "conv4"
type: "Convolution"
bottom: "conv3"
top: "conv4"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu4"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "conv5"
type: "Convolution"
bottom: "conv4"
top: "conv5"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "conv5"
top: "conv5"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "conv5"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fc6"
type: "InnerProduct"
bottom: "pool5"
top: "fc6"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "fc6"
top: "fc6"
}
layer {
name: "drop6"
type: "Dropout"
bottom: "fc6"
top: "fc6"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc7"
type: "InnerProduct"
bottom: "fc6"
top: "fc7"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "fc7"
top: "fc7"
}
layer {
name: "drop7"
type: "Dropout"
bottom: "fc7"
top: "fc7"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc8_clean"
type: "InnerProduct"
bottom: "fc7"
top: "fc8_clean"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 967
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "accuracy"
type: "Accuracy"
bottom: "fc8_clean"
bottom: "label"
top: "accuracy"
include {
phase: TEST
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "fc8_clean"
bottom: "label"
top: "loss"
}
I0708 00:31:26.175046 24447 layer_factory.hpp:76] Creating layer val-data
I0708 00:31:26.175096 24447 net.cpp:109] Creating Layer val-data
I0708 00:31:26.175110 24447 net.cpp:414] val-data -> data
I0708 00:31:26.175115 24447 net.cpp:414] val-data -> label
I0708 00:31:26.175119 24447 data_transformer.cpp:25] Loading mean file from: /home/ffw/scratch/digits/jobs/20160624-120053-bb9a/mean.binaryproto
I0708 00:31:26.177656 24463 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/digits/jobs/20160624-120053-bb9a/val_db
I0708 00:31:26.182046 24447 data_layer.cpp:45] output data size: 32,3,227,227
I0708 00:31:26.204002 24447 net.cpp:153] Setting up val-data
I0708 00:31:26.204021 24447 net.cpp:160] Top shape: 32 3 227 227 (4946784)
I0708 00:31:26.204026 24447 net.cpp:160] Top shape: 32 (32)
I0708 00:31:26.204028 24447 net.cpp:168] Memory required for data: 19787264
I0708 00:31:26.204032 24447 layer_factory.hpp:76] Creating layer label_val-data_1_split
I0708 00:31:26.204041 24447 net.cpp:109] Creating Layer label_val-data_1_split
I0708 00:31:26.204043 24447 net.cpp:457] label_val-data_1_split <- label
I0708 00:31:26.204048 24447 net.cpp:414] label_val-data_1_split -> label_val-data_1_split_0
I0708 00:31:26.204054 24447 net.cpp:414] label_val-data_1_split -> label_val-data_1_split_1
I0708 00:31:26.204149 24447 net.cpp:153] Setting up label_val-data_1_split
I0708 00:31:26.204154 24447 net.cpp:160] Top shape: 32 (32)
I0708 00:31:26.204157 24447 net.cpp:160] Top shape: 32 (32)
I0708 00:31:26.204159 24447 net.cpp:168] Memory required for data: 19787520
I0708 00:31:26.204161 24447 layer_factory.hpp:76] Creating layer conv1
I0708 00:31:26.204169 24447 net.cpp:109] Creating Layer conv1
I0708 00:31:26.204171 24447 net.cpp:457] conv1 <- data
I0708 00:31:26.204175 24447 net.cpp:414] conv1 -> conv1
I0708 00:31:26.205116 24447 net.cpp:153] Setting up conv1
I0708 00:31:26.205123 24447 net.cpp:160] Top shape: 32 96 55 55 (9292800)
I0708 00:31:26.205126 24447 net.cpp:168] Memory required for data: 56958720
I0708 00:31:26.205132 24447 layer_factory.hpp:76] Creating layer relu1
I0708 00:31:26.205137 24447 net.cpp:109] Creating Layer relu1
I0708 00:31:26.205139 24447 net.cpp:457] relu1 <- conv1
I0708 00:31:26.205142 24447 net.cpp:400] relu1 -> conv1 (in-place)
I0708 00:31:26.205152 24447 net.cpp:153] Setting up relu1
I0708 00:31:26.205154 24447 net.cpp:160] Top shape: 32 96 55 55 (9292800)
I0708 00:31:26.205155 24447 net.cpp:168] Memory required for data: 94129920
I0708 00:31:26.205157 24447 layer_factory.hpp:76] Creating layer norm1
I0708 00:31:26.205163 24447 net.cpp:109] Creating Layer norm1
I0708 00:31:26.205164 24447 net.cpp:457] norm1 <- conv1
I0708 00:31:26.205168 24447 net.cpp:414] norm1 -> norm1
I0708 00:31:26.205190 24447 net.cpp:153] Setting up norm1
I0708 00:31:26.205193 24447 net.cpp:160] Top shape: 32 96 55 55 (9292800)
I0708 00:31:26.205195 24447 net.cpp:168] Memory required for data: 131301120
I0708 00:31:26.205196 24447 layer_factory.hpp:76] Creating layer pool1
I0708 00:31:26.205200 24447 net.cpp:109] Creating Layer pool1
I0708 00:31:26.205204 24447 net.cpp:457] pool1 <- norm1
I0708 00:31:26.205205 24447 net.cpp:414] pool1 -> pool1
I0708 00:31:26.205224 24447 net.cpp:153] Setting up pool1
I0708 00:31:26.205226 24447 net.cpp:160] Top shape: 32 96 27 27 (2239488)
I0708 00:31:26.205227 24447 net.cpp:168] Memory required for data: 140259072
I0708 00:31:26.205229 24447 layer_factory.hpp:76] Creating layer conv2
I0708 00:31:26.205234 24447 net.cpp:109] Creating Layer conv2
I0708 00:31:26.205235 24447 net.cpp:457] conv2 <- pool1
I0708 00:31:26.205238 24447 net.cpp:414] conv2 -> conv2
I0708 00:31:26.211336 24447 net.cpp:153] Setting up conv2
I0708 00:31:26.211350 24447 net.cpp:160] Top shape: 32 256 27 27 (5971968)
I0708 00:31:26.211352 24447 net.cpp:168] Memory required for data: 164146944
I0708 00:31:26.211375 24447 layer_factory.hpp:76] Creating layer relu2
I0708 00:31:26.211382 24447 net.cpp:109] Creating Layer relu2
I0708 00:31:26.211385 24447 net.cpp:457] relu2 <- conv2
I0708 00:31:26.211390 24447 net.cpp:400] relu2 -> conv2 (in-place)
I0708 00:31:26.211395 24447 net.cpp:153] Setting up relu2
I0708 00:31:26.211398 24447 net.cpp:160] Top shape: 32 256 27 27 (5971968)
I0708 00:31:26.211400 24447 net.cpp:168] Memory required for data: 188034816
I0708 00:31:26.211402 24447 layer_factory.hpp:76] Creating layer norm2
I0708 00:31:26.211407 24447 net.cpp:109] Creating Layer norm2
I0708 00:31:26.211410 24447 net.cpp:457] norm2 <- conv2
I0708 00:31:26.211413 24447 net.cpp:414] norm2 -> norm2
I0708 00:31:26.211449 24447 net.cpp:153] Setting up norm2
I0708 00:31:26.211454 24447 net.cpp:160] Top shape: 32 256 27 27 (5971968)
I0708 00:31:26.211457 24447 net.cpp:168] Memory required for data: 211922688
I0708 00:31:26.211458 24447 layer_factory.hpp:76] Creating layer pool2
I0708 00:31:26.211467 24447 net.cpp:109] Creating Layer pool2
I0708 00:31:26.211469 24447 net.cpp:457] pool2 <- norm2
I0708 00:31:26.211472 24447 net.cpp:414] pool2 -> pool2
I0708 00:31:26.211495 24447 net.cpp:153] Setting up pool2
I0708 00:31:26.211498 24447 net.cpp:160] Top shape: 32 256 13 13 (1384448)
I0708 00:31:26.211500 24447 net.cpp:168] Memory required for data: 217460480
I0708 00:31:26.211503 24447 layer_factory.hpp:76] Creating layer conv3
I0708 00:31:26.211508 24447 net.cpp:109] Creating Layer conv3
I0708 00:31:26.211509 24447 net.cpp:457] conv3 <- pool2
I0708 00:31:26.211511 24447 net.cpp:414] conv3 -> conv3
I0708 00:31:26.228442 24447 net.cpp:153] Setting up conv3
I0708 00:31:26.228457 24447 net.cpp:160] Top shape: 32 384 13 13 (2076672)
I0708 00:31:26.228461 24447 net.cpp:168] Memory required for data: 225767168
I0708 00:31:26.228467 24447 layer_factory.hpp:76] Creating layer relu3
I0708 00:31:26.228476 24447 net.cpp:109] Creating Layer relu3
I0708 00:31:26.228478 24447 net.cpp:457] relu3 <- conv3
I0708 00:31:26.228482 24447 net.cpp:400] relu3 -> conv3 (in-place)
I0708 00:31:26.228489 24447 net.cpp:153] Setting up relu3
I0708 00:31:26.228492 24447 net.cpp:160] Top shape: 32 384 13 13 (2076672)
I0708 00:31:26.228493 24447 net.cpp:168] Memory required for data: 234073856
I0708 00:31:26.228495 24447 layer_factory.hpp:76] Creating layer conv4
I0708 00:31:26.228502 24447 net.cpp:109] Creating Layer conv4
I0708 00:31:26.228503 24447 net.cpp:457] conv4 <- conv3
I0708 00:31:26.228507 24447 net.cpp:414] conv4 -> conv4
I0708 00:31:26.241186 24447 net.cpp:153] Setting up conv4
I0708 00:31:26.241201 24447 net.cpp:160] Top shape: 32 384 13 13 (2076672)
I0708 00:31:26.241204 24447 net.cpp:168] Memory required for data: 242380544
I0708 00:31:26.241209 24447 layer_factory.hpp:76] Creating layer relu4
I0708 00:31:26.241214 24447 net.cpp:109] Creating Layer relu4
I0708 00:31:26.241216 24447 net.cpp:457] relu4 <- conv4
I0708 00:31:26.241220 24447 net.cpp:400] relu4 -> conv4 (in-place)
I0708 00:31:26.241225 24447 net.cpp:153] Setting up relu4
I0708 00:31:26.241228 24447 net.cpp:160] Top shape: 32 384 13 13 (2076672)
I0708 00:31:26.241230 24447 net.cpp:168] Memory required for data: 250687232
I0708 00:31:26.241231 24447 layer_factory.hpp:76] Creating layer conv5
I0708 00:31:26.241236 24447 net.cpp:109] Creating Layer conv5
I0708 00:31:26.241237 24447 net.cpp:457] conv5 <- conv4
I0708 00:31:26.241241 24447 net.cpp:414] conv5 -> conv5
I0708 00:31:26.249861 24447 net.cpp:153] Setting up conv5
I0708 00:31:26.249872 24447 net.cpp:160] Top shape: 32 256 13 13 (1384448)
I0708 00:31:26.249874 24447 net.cpp:168] Memory required for data: 256225024
I0708 00:31:26.249881 24447 layer_factory.hpp:76] Creating layer relu5
I0708 00:31:26.249887 24447 net.cpp:109] Creating Layer relu5
I0708 00:31:26.249891 24447 net.cpp:457] relu5 <- conv5
I0708 00:31:26.249894 24447 net.cpp:400] relu5 -> conv5 (in-place)
I0708 00:31:26.249899 24447 net.cpp:153] Setting up relu5
I0708 00:31:26.249902 24447 net.cpp:160] Top shape: 32 256 13 13 (1384448)
I0708 00:31:26.249917 24447 net.cpp:168] Memory required for data: 261762816
I0708 00:31:26.249918 24447 layer_factory.hpp:76] Creating layer pool5
I0708 00:31:26.249924 24447 net.cpp:109] Creating Layer pool5
I0708 00:31:26.249927 24447 net.cpp:457] pool5 <- conv5
I0708 00:31:26.249929 24447 net.cpp:414] pool5 -> pool5
I0708 00:31:26.249955 24447 net.cpp:153] Setting up pool5
I0708 00:31:26.249958 24447 net.cpp:160] Top shape: 32 256 6 6 (294912)
I0708 00:31:26.249959 24447 net.cpp:168] Memory required for data: 262942464
I0708 00:31:26.249961 24447 layer_factory.hpp:76] Creating layer fc6
I0708 00:31:26.249965 24447 net.cpp:109] Creating Layer fc6
I0708 00:31:26.249968 24447 net.cpp:457] fc6 <- pool5
I0708 00:31:26.249970 24447 net.cpp:414] fc6 -> fc6
I0708 00:31:27.254317 24447 net.cpp:153] Setting up fc6
I0708 00:31:27.254339 24447 net.cpp:160] Top shape: 32 4096 (131072)
I0708 00:31:27.254343 24447 net.cpp:168] Memory required for data: 263466752
I0708 00:31:27.254351 24447 layer_factory.hpp:76] Creating layer relu6
I0708 00:31:27.254360 24447 net.cpp:109] Creating Layer relu6
I0708 00:31:27.254365 24447 net.cpp:457] relu6 <- fc6
I0708 00:31:27.254372 24447 net.cpp:400] relu6 -> fc6 (in-place)
I0708 00:31:27.254381 24447 net.cpp:153] Setting up relu6
I0708 00:31:27.254385 24447 net.cpp:160] Top shape: 32 4096 (131072)
I0708 00:31:27.254387 24447 net.cpp:168] Memory required for data: 263991040
I0708 00:31:27.254390 24447 layer_factory.hpp:76] Creating layer drop6
I0708 00:31:27.254396 24447 net.cpp:109] Creating Layer drop6
I0708 00:31:27.254400 24447 net.cpp:457] drop6 <- fc6
I0708 00:31:27.254403 24447 net.cpp:400] drop6 -> fc6 (in-place)
I0708 00:31:27.254426 24447 net.cpp:153] Setting up drop6
I0708 00:31:27.254431 24447 net.cpp:160] Top shape: 32 4096 (131072)
I0708 00:31:27.254433 24447 net.cpp:168] Memory required for data: 264515328
I0708 00:31:27.254436 24447 layer_factory.hpp:76] Creating layer fc7
I0708 00:31:27.254441 24447 net.cpp:109] Creating Layer fc7
I0708 00:31:27.254444 24447 net.cpp:457] fc7 <- fc6
I0708 00:31:27.254448 24447 net.cpp:414] fc7 -> fc7
I0708 00:31:27.578943 24447 net.cpp:153] Setting up fc7
I0708 00:31:27.578963 24447 net.cpp:160] Top shape: 32 4096 (131072)
I0708 00:31:27.578965 24447 net.cpp:168] Memory required for data: 265039616
I0708 00:31:27.578970 24447 layer_factory.hpp:76] Creating layer relu7
I0708 00:31:27.578977 24447 net.cpp:109] Creating Layer relu7
I0708 00:31:27.578980 24447 net.cpp:457] relu7 <- fc7
I0708 00:31:27.578985 24447 net.cpp:400] relu7 -> fc7 (in-place)
I0708 00:31:27.578994 24447 net.cpp:153] Setting up relu7
I0708 00:31:27.578996 24447 net.cpp:160] Top shape: 32 4096 (131072)
I0708 00:31:27.578997 24447 net.cpp:168] Memory required for data: 265563904
I0708 00:31:27.579000 24447 layer_factory.hpp:76] Creating layer drop7
I0708 00:31:27.579005 24447 net.cpp:109] Creating Layer drop7
I0708 00:31:27.579006 24447 net.cpp:457] drop7 <- fc7
I0708 00:31:27.579010 24447 net.cpp:400] drop7 -> fc7 (in-place)
I0708 00:31:27.579027 24447 net.cpp:153] Setting up drop7
I0708 00:31:27.579030 24447 net.cpp:160] Top shape: 32 4096 (131072)
I0708 00:31:27.579032 24447 net.cpp:168] Memory required for data: 266088192
I0708 00:31:27.579035 24447 layer_factory.hpp:76] Creating layer fc8_clean
I0708 00:31:27.579038 24447 net.cpp:109] Creating Layer fc8_clean
I0708 00:31:27.579041 24447 net.cpp:457] fc8_clean <- fc7
I0708 00:31:27.579043 24447 net.cpp:414] fc8_clean -> fc8_clean
I0708 00:31:27.650621 24447 net.cpp:153] Setting up fc8_clean
I0708 00:31:27.650640 24447 net.cpp:160] Top shape: 32 967 (30944)
I0708 00:31:27.650641 24447 net.cpp:168] Memory required for data: 266211968
I0708 00:31:27.650646 24447 layer_factory.hpp:76] Creating layer fc8_clean_fc8_clean_0_split
I0708 00:31:27.650653 24447 net.cpp:109] Creating Layer fc8_clean_fc8_clean_0_split
I0708 00:31:27.650656 24447 net.cpp:457] fc8_clean_fc8_clean_0_split <- fc8_clean
I0708 00:31:27.650661 24447 net.cpp:414] fc8_clean_fc8_clean_0_split -> fc8_clean_fc8_clean_0_split_0
I0708 00:31:27.650666 24447 net.cpp:414] fc8_clean_fc8_clean_0_split -> fc8_clean_fc8_clean_0_split_1
I0708 00:31:27.650712 24447 net.cpp:153] Setting up fc8_clean_fc8_clean_0_split
I0708 00:31:27.650715 24447 net.cpp:160] Top shape: 32 967 (30944)
I0708 00:31:27.650717 24447 net.cpp:160] Top shape: 32 967 (30944)
I0708 00:31:27.650719 24447 net.cpp:168] Memory required for data: 266459520
I0708 00:31:27.650722 24447 layer_factory.hpp:76] Creating layer accuracy
I0708 00:31:27.650725 24447 net.cpp:109] Creating Layer accuracy
I0708 00:31:27.650727 24447 net.cpp:457] accuracy <- fc8_clean_fc8_clean_0_split_0
I0708 00:31:27.650730 24447 net.cpp:457] accuracy <- label_val-data_1_split_0
I0708 00:31:27.650733 24447 net.cpp:414] accuracy -> accuracy
I0708 00:31:27.650738 24447 net.cpp:153] Setting up accuracy
I0708 00:31:27.650739 24447 net.cpp:160] Top shape: (1)
I0708 00:31:27.650741 24447 net.cpp:168] Memory required for data: 266459524
I0708 00:31:27.650743 24447 layer_factory.hpp:76] Creating layer loss
I0708 00:31:27.650746 24447 net.cpp:109] Creating Layer loss
I0708 00:31:27.650748 24447 net.cpp:457] loss <- fc8_clean_fc8_clean_0_split_1
I0708 00:31:27.650750 24447 net.cpp:457] loss <- label_val-data_1_split_1
I0708 00:31:27.650753 24447 net.cpp:414] loss -> loss
I0708 00:31:27.650758 24447 layer_factory.hpp:76] Creating layer loss
I0708 00:31:27.650840 24447 net.cpp:153] Setting up loss
I0708 00:31:27.650845 24447 net.cpp:160] Top shape: (1)
I0708 00:31:27.650846 24447 net.cpp:163]     with loss weight 1
I0708 00:31:27.650852 24447 net.cpp:168] Memory required for data: 266459528
I0708 00:31:27.650854 24447 net.cpp:229] loss needs backward computation.
I0708 00:31:27.650856 24447 net.cpp:231] accuracy does not need backward computation.
I0708 00:31:27.650858 24447 net.cpp:229] fc8_clean_fc8_clean_0_split needs backward computation.
I0708 00:31:27.650861 24447 net.cpp:229] fc8_clean needs backward computation.
I0708 00:31:27.650862 24447 net.cpp:231] drop7 does not need backward computation.
I0708 00:31:27.650864 24447 net.cpp:231] relu7 does not need backward computation.
I0708 00:31:27.650866 24447 net.cpp:231] fc7 does not need backward computation.
I0708 00:31:27.650868 24447 net.cpp:231] drop6 does not need backward computation.
I0708 00:31:27.650869 24447 net.cpp:231] relu6 does not need backward computation.
I0708 00:31:27.650871 24447 net.cpp:231] fc6 does not need backward computation.
I0708 00:31:27.650873 24447 net.cpp:231] pool5 does not need backward computation.
I0708 00:31:27.650876 24447 net.cpp:231] relu5 does not need backward computation.
I0708 00:31:27.650877 24447 net.cpp:231] conv5 does not need backward computation.
I0708 00:31:27.650879 24447 net.cpp:231] relu4 does not need backward computation.
I0708 00:31:27.650881 24447 net.cpp:231] conv4 does not need backward computation.
I0708 00:31:27.650882 24447 net.cpp:231] relu3 does not need backward computation.
I0708 00:31:27.650884 24447 net.cpp:231] conv3 does not need backward computation.
I0708 00:31:27.650887 24447 net.cpp:231] pool2 does not need backward computation.
I0708 00:31:27.650888 24447 net.cpp:231] norm2 does not need backward computation.
I0708 00:31:27.650890 24447 net.cpp:231] relu2 does not need backward computation.
I0708 00:31:27.650892 24447 net.cpp:231] conv2 does not need backward computation.
I0708 00:31:27.650894 24447 net.cpp:231] pool1 does not need backward computation.
I0708 00:31:27.650897 24447 net.cpp:231] norm1 does not need backward computation.
I0708 00:31:27.650898 24447 net.cpp:231] relu1 does not need backward computation.
I0708 00:31:27.650900 24447 net.cpp:231] conv1 does not need backward computation.
I0708 00:31:27.650902 24447 net.cpp:231] label_val-data_1_split does not need backward computation.
I0708 00:31:27.650905 24447 net.cpp:231] val-data does not need backward computation.
I0708 00:31:27.650907 24447 net.cpp:273] This network produces output accuracy
I0708 00:31:27.650908 24447 net.cpp:273] This network produces output loss
I0708 00:31:27.650918 24447 net.cpp:286] Network initialization done.
I0708 00:31:27.650977 24447 solver.cpp:66] Solver scaffolding done.
I0708 00:31:27.651329 24447 caffe.cpp:135] Finetuning from /home/ffw/workspace/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0708 00:31:28.849041 24447 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: /home/ffw/workspace/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0708 00:31:28.849059 24447 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W0708 00:31:28.849063 24447 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0708 00:31:28.849150 24447 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ffw/workspace/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0708 00:31:30.409469 24447 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
I0708 00:31:30.748631 24447 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: /home/ffw/workspace/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0708 00:31:30.748661 24447 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W0708 00:31:30.748677 24447 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0708 00:31:30.748688 24447 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ffw/workspace/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0708 00:31:53.476375 24447 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
I0708 00:31:53.519543 24447 caffe.cpp:220] Starting Optimization
I0708 00:31:53.519565 24447 solver.cpp:294] Solving
I0708 00:31:53.519567 24447 solver.cpp:295] Learning Rate Policy: exp
I0708 00:31:53.524865 24447 solver.cpp:347] Iteration 0, Testing net (#0)
I0708 00:31:53.755198 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 00:32:12.876574 24447 solver.cpp:415]     Test net output #0: accuracy = 0.000961538
I0708 00:32:12.876629 24447 solver.cpp:415]     Test net output #1: loss = 7.1858 (* 1 = 7.1858 loss)
I0708 00:32:12.999747 24447 solver.cpp:243] Iteration 0, loss = 7.80699
I0708 00:32:12.999769 24447 solver.cpp:259]     Train net output #0: loss = 7.80699 (* 1 = 7.80699 loss)
I0708 00:32:12.999781 24447 solver.cpp:590] Iteration 0, lr = 0.01
I0708 00:32:20.150169 24447 solver.cpp:243] Iteration 27, loss = 6.90063
I0708 00:32:20.150193 24447 solver.cpp:259]     Train net output #0: loss = 6.90063 (* 1 = 6.90063 loss)
I0708 00:32:20.150199 24447 solver.cpp:590] Iteration 27, lr = 0.00993754
I0708 00:32:27.901404 24447 solver.cpp:243] Iteration 54, loss = 6.02285
I0708 00:32:27.901429 24447 solver.cpp:259]     Train net output #0: loss = 6.02285 (* 1 = 6.02285 loss)
I0708 00:32:27.901435 24447 solver.cpp:590] Iteration 54, lr = 0.00987547
I0708 00:32:35.617874 24447 solver.cpp:243] Iteration 81, loss = 6.48417
I0708 00:32:35.617900 24447 solver.cpp:259]     Train net output #0: loss = 6.48417 (* 1 = 6.48417 loss)
I0708 00:32:35.617907 24447 solver.cpp:590] Iteration 81, lr = 0.00981378
I0708 00:32:43.374766 24447 solver.cpp:243] Iteration 108, loss = 6.08563
I0708 00:32:43.374864 24447 solver.cpp:259]     Train net output #0: loss = 6.08563 (* 1 = 6.08563 loss)
I0708 00:32:43.374881 24447 solver.cpp:590] Iteration 108, lr = 0.00975248
I0708 00:32:51.111593 24447 solver.cpp:243] Iteration 135, loss = 5.59878
I0708 00:32:51.111618 24447 solver.cpp:259]     Train net output #0: loss = 5.59878 (* 1 = 5.59878 loss)
I0708 00:32:51.111624 24447 solver.cpp:590] Iteration 135, lr = 0.00969157
I0708 00:32:58.879801 24447 solver.cpp:243] Iteration 162, loss = 5.58232
I0708 00:32:58.879825 24447 solver.cpp:259]     Train net output #0: loss = 5.58232 (* 1 = 5.58232 loss)
I0708 00:32:58.879832 24447 solver.cpp:590] Iteration 162, lr = 0.00963103
I0708 00:33:06.662696 24447 solver.cpp:243] Iteration 189, loss = 6.11662
I0708 00:33:06.662721 24447 solver.cpp:259]     Train net output #0: loss = 6.11662 (* 1 = 6.11662 loss)
I0708 00:33:06.662727 24447 solver.cpp:590] Iteration 189, lr = 0.00957087
I0708 00:33:14.601742 24447 solver.cpp:243] Iteration 216, loss = 5.30866
I0708 00:33:14.601871 24447 solver.cpp:259]     Train net output #0: loss = 5.30866 (* 1 = 5.30866 loss)
I0708 00:33:14.601891 24447 solver.cpp:590] Iteration 216, lr = 0.00951109
I0708 00:33:15.757448 24447 solver.cpp:347] Iteration 221, Testing net (#0)
I0708 00:33:35.291592 24447 solver.cpp:415]     Test net output #0: accuracy = 0.221755
I0708 00:33:35.291618 24447 solver.cpp:415]     Test net output #1: loss = 4.45743 (* 1 = 4.45743 loss)
I0708 00:33:41.117712 24447 solver.cpp:243] Iteration 243, loss = 4.58082
I0708 00:33:41.117736 24447 solver.cpp:259]     Train net output #0: loss = 4.58082 (* 1 = 4.58082 loss)
I0708 00:33:41.117743 24447 solver.cpp:590] Iteration 243, lr = 0.00945168
I0708 00:33:49.377563 24447 solver.cpp:243] Iteration 270, loss = 5.15646
I0708 00:33:49.377648 24447 solver.cpp:259]     Train net output #0: loss = 5.15646 (* 1 = 5.15646 loss)
I0708 00:33:49.377655 24447 solver.cpp:590] Iteration 270, lr = 0.00939264
I0708 00:33:57.084450 24447 solver.cpp:243] Iteration 297, loss = 4.49118
I0708 00:33:57.084475 24447 solver.cpp:259]     Train net output #0: loss = 4.49118 (* 1 = 4.49118 loss)
I0708 00:33:57.084481 24447 solver.cpp:590] Iteration 297, lr = 0.00933397
I0708 00:34:04.793871 24447 solver.cpp:243] Iteration 324, loss = 4.90498
I0708 00:34:04.793910 24447 solver.cpp:259]     Train net output #0: loss = 4.90498 (* 1 = 4.90498 loss)
I0708 00:34:04.793916 24447 solver.cpp:590] Iteration 324, lr = 0.00927567
I0708 00:34:12.466151 24447 solver.cpp:243] Iteration 351, loss = 4.28144
I0708 00:34:12.466177 24447 solver.cpp:259]     Train net output #0: loss = 4.28144 (* 1 = 4.28144 loss)
I0708 00:34:12.466183 24447 solver.cpp:590] Iteration 351, lr = 0.00921773
I0708 00:34:20.174201 24447 solver.cpp:243] Iteration 378, loss = 4.33556
I0708 00:34:20.174266 24447 solver.cpp:259]     Train net output #0: loss = 4.33556 (* 1 = 4.33556 loss)
I0708 00:34:20.174283 24447 solver.cpp:590] Iteration 378, lr = 0.00916016
I0708 00:34:27.884838 24447 solver.cpp:243] Iteration 405, loss = 4.70833
I0708 00:34:27.884860 24447 solver.cpp:259]     Train net output #0: loss = 4.70833 (* 1 = 4.70833 loss)
I0708 00:34:27.884865 24447 solver.cpp:590] Iteration 405, lr = 0.00910294
I0708 00:34:35.564263 24447 solver.cpp:243] Iteration 432, loss = 4.68607
I0708 00:34:35.564288 24447 solver.cpp:259]     Train net output #0: loss = 4.68607 (* 1 = 4.68607 loss)
I0708 00:34:35.564294 24447 solver.cpp:590] Iteration 432, lr = 0.00904608
I0708 00:34:38.256090 24447 solver.cpp:347] Iteration 442, Testing net (#0)
I0708 00:34:42.324076 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 00:34:57.675736 24447 solver.cpp:415]     Test net output #0: accuracy = 0.260337
I0708 00:34:57.675811 24447 solver.cpp:415]     Test net output #1: loss = 4.18186 (* 1 = 4.18186 loss)
I0708 00:35:02.256870 24447 solver.cpp:243] Iteration 459, loss = 4.3715
I0708 00:35:02.256906 24447 solver.cpp:259]     Train net output #0: loss = 4.3715 (* 1 = 4.3715 loss)
I0708 00:35:02.256917 24447 solver.cpp:590] Iteration 459, lr = 0.00898958
I0708 00:35:10.434782 24447 solver.cpp:243] Iteration 486, loss = 4.29357
I0708 00:35:10.434811 24447 solver.cpp:259]     Train net output #0: loss = 4.29357 (* 1 = 4.29357 loss)
I0708 00:35:10.434819 24447 solver.cpp:590] Iteration 486, lr = 0.00893343
I0708 00:35:18.569532 24447 solver.cpp:243] Iteration 513, loss = 4.61488
I0708 00:35:18.569562 24447 solver.cpp:259]     Train net output #0: loss = 4.61488 (* 1 = 4.61488 loss)
I0708 00:35:18.569571 24447 solver.cpp:590] Iteration 513, lr = 0.00887763
I0708 00:35:26.706027 24447 solver.cpp:243] Iteration 540, loss = 4.09203
I0708 00:35:26.706056 24447 solver.cpp:259]     Train net output #0: loss = 4.09203 (* 1 = 4.09203 loss)
I0708 00:35:26.706064 24447 solver.cpp:590] Iteration 540, lr = 0.00882217
I0708 00:35:34.831670 24447 solver.cpp:243] Iteration 567, loss = 3.54861
I0708 00:35:34.831801 24447 solver.cpp:259]     Train net output #0: loss = 3.54861 (* 1 = 3.54861 loss)
I0708 00:35:34.831811 24447 solver.cpp:590] Iteration 567, lr = 0.00876707
I0708 00:35:43.068150 24447 solver.cpp:243] Iteration 594, loss = 3.90692
I0708 00:35:43.068172 24447 solver.cpp:259]     Train net output #0: loss = 3.90692 (* 1 = 3.90692 loss)
I0708 00:35:43.068179 24447 solver.cpp:590] Iteration 594, lr = 0.00871231
I0708 00:35:51.214674 24447 solver.cpp:243] Iteration 621, loss = 4.51362
I0708 00:35:51.214700 24447 solver.cpp:259]     Train net output #0: loss = 4.51362 (* 1 = 4.51362 loss)
I0708 00:35:51.214705 24447 solver.cpp:590] Iteration 621, lr = 0.00865789
I0708 00:35:59.376215 24447 solver.cpp:243] Iteration 648, loss = 4.55242
I0708 00:35:59.376241 24447 solver.cpp:259]     Train net output #0: loss = 4.55242 (* 1 = 4.55242 loss)
I0708 00:35:59.376247 24447 solver.cpp:590] Iteration 648, lr = 0.00860381
I0708 00:36:03.754951 24447 solver.cpp:347] Iteration 663, Testing net (#0)
I0708 00:36:22.921494 24447 solver.cpp:415]     Test net output #0: accuracy = 0.279687
I0708 00:36:22.921569 24447 solver.cpp:415]     Test net output #1: loss = 4.11518 (* 1 = 4.11518 loss)
I0708 00:36:25.809218 24447 solver.cpp:243] Iteration 675, loss = 4.08063
I0708 00:36:25.809245 24447 solver.cpp:259]     Train net output #0: loss = 4.08063 (* 1 = 4.08063 loss)
I0708 00:36:25.809252 24447 solver.cpp:590] Iteration 675, lr = 0.00855007
I0708 00:36:33.514453 24447 solver.cpp:243] Iteration 702, loss = 4.01765
I0708 00:36:33.514479 24447 solver.cpp:259]     Train net output #0: loss = 4.01765 (* 1 = 4.01765 loss)
I0708 00:36:33.514485 24447 solver.cpp:590] Iteration 702, lr = 0.00849666
I0708 00:36:41.442842 24447 solver.cpp:243] Iteration 729, loss = 4.59823
I0708 00:36:41.442868 24447 solver.cpp:259]     Train net output #0: loss = 4.59823 (* 1 = 4.59823 loss)
I0708 00:36:41.442874 24447 solver.cpp:590] Iteration 729, lr = 0.00844359
I0708 00:36:49.919986 24447 solver.cpp:243] Iteration 756, loss = 4.11119
I0708 00:36:49.920011 24447 solver.cpp:259]     Train net output #0: loss = 4.11119 (* 1 = 4.11119 loss)
I0708 00:36:49.920017 24447 solver.cpp:590] Iteration 756, lr = 0.00839085
I0708 00:36:58.408545 24447 solver.cpp:243] Iteration 783, loss = 3.77582
I0708 00:36:58.408597 24447 solver.cpp:259]     Train net output #0: loss = 3.77582 (* 1 = 3.77582 loss)
I0708 00:36:58.408603 24447 solver.cpp:590] Iteration 783, lr = 0.00833844
I0708 00:37:06.443552 24447 solver.cpp:243] Iteration 810, loss = 4.23571
I0708 00:37:06.443578 24447 solver.cpp:259]     Train net output #0: loss = 4.23571 (* 1 = 4.23571 loss)
I0708 00:37:06.443583 24447 solver.cpp:590] Iteration 810, lr = 0.00828636
I0708 00:37:14.204300 24447 solver.cpp:243] Iteration 837, loss = 3.79453
I0708 00:37:14.204325 24447 solver.cpp:259]     Train net output #0: loss = 3.79453 (* 1 = 3.79453 loss)
I0708 00:37:14.204331 24447 solver.cpp:590] Iteration 837, lr = 0.0082346
I0708 00:37:22.278787 24447 solver.cpp:243] Iteration 864, loss = 3.72263
I0708 00:37:22.278808 24447 solver.cpp:259]     Train net output #0: loss = 3.72263 (* 1 = 3.72263 loss)
I0708 00:37:22.278815 24447 solver.cpp:590] Iteration 864, lr = 0.00818316
I0708 00:37:28.148077 24447 solver.cpp:347] Iteration 884, Testing net (#0)
I0708 00:37:35.930294 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 00:37:47.289428 24447 solver.cpp:415]     Test net output #0: accuracy = 0.298918
I0708 00:37:47.289453 24447 solver.cpp:415]     Test net output #1: loss = 4.00957 (* 1 = 4.00957 loss)
I0708 00:37:48.765163 24447 solver.cpp:243] Iteration 891, loss = 3.36423
I0708 00:37:48.765188 24447 solver.cpp:259]     Train net output #0: loss = 3.36423 (* 1 = 3.36423 loss)
I0708 00:37:48.765193 24447 solver.cpp:590] Iteration 891, lr = 0.00813205
I0708 00:37:56.899260 24447 solver.cpp:243] Iteration 918, loss = 3.91189
I0708 00:37:56.899286 24447 solver.cpp:259]     Train net output #0: loss = 3.91189 (* 1 = 3.91189 loss)
I0708 00:37:56.899296 24447 solver.cpp:590] Iteration 918, lr = 0.00808125
I0708 00:38:04.883703 24447 solver.cpp:243] Iteration 945, loss = 3.26981
I0708 00:38:04.883730 24447 solver.cpp:259]     Train net output #0: loss = 3.26981 (* 1 = 3.26981 loss)
I0708 00:38:04.883736 24447 solver.cpp:590] Iteration 945, lr = 0.00803078
I0708 00:38:12.961204 24447 solver.cpp:243] Iteration 972, loss = 3.85771
I0708 00:38:12.961323 24447 solver.cpp:259]     Train net output #0: loss = 3.85771 (* 1 = 3.85771 loss)
I0708 00:38:12.961330 24447 solver.cpp:590] Iteration 972, lr = 0.00798061
I0708 00:38:21.133280 24447 solver.cpp:243] Iteration 999, loss = 3.45874
I0708 00:38:21.133306 24447 solver.cpp:259]     Train net output #0: loss = 3.45874 (* 1 = 3.45874 loss)
I0708 00:38:21.133311 24447 solver.cpp:590] Iteration 999, lr = 0.00793076
I0708 00:38:29.442762 24447 solver.cpp:243] Iteration 1026, loss = 4.0206
I0708 00:38:29.442788 24447 solver.cpp:259]     Train net output #0: loss = 4.0206 (* 1 = 4.0206 loss)
I0708 00:38:29.442793 24447 solver.cpp:590] Iteration 1026, lr = 0.00788123
I0708 00:38:37.864745 24447 solver.cpp:243] Iteration 1053, loss = 3.98899
I0708 00:38:37.864770 24447 solver.cpp:259]     Train net output #0: loss = 3.98899 (* 1 = 3.98899 loss)
I0708 00:38:37.864776 24447 solver.cpp:590] Iteration 1053, lr = 0.007832
I0708 00:38:46.299824 24447 solver.cpp:243] Iteration 1080, loss = 3.41425
I0708 00:38:46.299891 24447 solver.cpp:259]     Train net output #0: loss = 3.41425 (* 1 = 3.41425 loss)
I0708 00:38:46.299898 24447 solver.cpp:590] Iteration 1080, lr = 0.00778308
I0708 00:38:53.738986 24447 solver.cpp:347] Iteration 1105, Testing net (#0)
I0708 00:39:13.034986 24447 solver.cpp:415]     Test net output #0: accuracy = 0.313101
I0708 00:39:13.035012 24447 solver.cpp:415]     Test net output #1: loss = 3.9304 (* 1 = 3.9304 loss)
I0708 00:39:13.235262 24447 solver.cpp:243] Iteration 1107, loss = 3.06763
I0708 00:39:13.235296 24447 solver.cpp:259]     Train net output #0: loss = 3.06763 (* 1 = 3.06763 loss)
I0708 00:39:13.235303 24447 solver.cpp:590] Iteration 1107, lr = 0.00773446
I0708 00:39:20.768141 24447 solver.cpp:243] Iteration 1134, loss = 3.20857
I0708 00:39:20.768206 24447 solver.cpp:259]     Train net output #0: loss = 3.20857 (* 1 = 3.20857 loss)
I0708 00:39:20.768223 24447 solver.cpp:590] Iteration 1134, lr = 0.00768615
I0708 00:39:28.455126 24447 solver.cpp:243] Iteration 1161, loss = 3.27019
I0708 00:39:28.455162 24447 solver.cpp:259]     Train net output #0: loss = 3.27019 (* 1 = 3.27019 loss)
I0708 00:39:28.455168 24447 solver.cpp:590] Iteration 1161, lr = 0.00763814
I0708 00:39:36.146868 24447 solver.cpp:243] Iteration 1188, loss = 3.79661
I0708 00:39:36.146894 24447 solver.cpp:259]     Train net output #0: loss = 3.79661 (* 1 = 3.79661 loss)
I0708 00:39:36.146900 24447 solver.cpp:590] Iteration 1188, lr = 0.00759043
I0708 00:39:44.515444 24447 solver.cpp:243] Iteration 1215, loss = 2.95742
I0708 00:39:44.515473 24447 solver.cpp:259]     Train net output #0: loss = 2.95742 (* 1 = 2.95742 loss)
I0708 00:39:44.515481 24447 solver.cpp:590] Iteration 1215, lr = 0.00754302
I0708 00:39:52.209923 24447 solver.cpp:243] Iteration 1242, loss = 3.3991
I0708 00:39:52.209976 24447 solver.cpp:259]     Train net output #0: loss = 3.3991 (* 1 = 3.3991 loss)
I0708 00:39:52.209983 24447 solver.cpp:590] Iteration 1242, lr = 0.0074959
I0708 00:39:59.925525 24447 solver.cpp:243] Iteration 1269, loss = 3.12795
I0708 00:39:59.925552 24447 solver.cpp:259]     Train net output #0: loss = 3.12795 (* 1 = 3.12795 loss)
I0708 00:39:59.925559 24447 solver.cpp:590] Iteration 1269, lr = 0.00744908
I0708 00:40:07.613811 24447 solver.cpp:243] Iteration 1296, loss = 3.43159
I0708 00:40:07.613837 24447 solver.cpp:259]     Train net output #0: loss = 3.43159 (* 1 = 3.43159 loss)
I0708 00:40:07.613844 24447 solver.cpp:590] Iteration 1296, lr = 0.00740256
I0708 00:40:15.288517 24447 solver.cpp:243] Iteration 1323, loss = 3.11394
I0708 00:40:15.288542 24447 solver.cpp:259]     Train net output #0: loss = 3.11394 (* 1 = 3.11394 loss)
I0708 00:40:15.288548 24447 solver.cpp:590] Iteration 1323, lr = 0.00735632
I0708 00:40:15.855464 24447 solver.cpp:347] Iteration 1326, Testing net (#0)
I0708 00:40:27.551717 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 00:40:35.613780 24447 solver.cpp:415]     Test net output #0: accuracy = 0.320433
I0708 00:40:35.613806 24447 solver.cpp:415]     Test net output #1: loss = 3.86832 (* 1 = 3.86832 loss)
I0708 00:40:41.931133 24447 solver.cpp:243] Iteration 1350, loss = 3.09243
I0708 00:40:41.931159 24447 solver.cpp:259]     Train net output #0: loss = 3.09243 (* 1 = 3.09243 loss)
I0708 00:40:41.931165 24447 solver.cpp:590] Iteration 1350, lr = 0.00731037
I0708 00:40:49.614043 24447 solver.cpp:243] Iteration 1377, loss = 3.00025
I0708 00:40:49.614069 24447 solver.cpp:259]     Train net output #0: loss = 3.00025 (* 1 = 3.00025 loss)
I0708 00:40:49.614075 24447 solver.cpp:590] Iteration 1377, lr = 0.0072647
I0708 00:40:57.300057 24447 solver.cpp:243] Iteration 1404, loss = 3.45885
I0708 00:40:57.300082 24447 solver.cpp:259]     Train net output #0: loss = 3.45885 (* 1 = 3.45885 loss)
I0708 00:40:57.300088 24447 solver.cpp:590] Iteration 1404, lr = 0.00721933
I0708 00:41:05.660940 24447 solver.cpp:243] Iteration 1431, loss = 3.49368
I0708 00:41:05.661005 24447 solver.cpp:259]     Train net output #0: loss = 3.49368 (* 1 = 3.49368 loss)
I0708 00:41:05.661011 24447 solver.cpp:590] Iteration 1431, lr = 0.00717423
I0708 00:41:13.336488 24447 solver.cpp:243] Iteration 1458, loss = 3.2736
I0708 00:41:13.336513 24447 solver.cpp:259]     Train net output #0: loss = 3.2736 (* 1 = 3.2736 loss)
I0708 00:41:13.336519 24447 solver.cpp:590] Iteration 1458, lr = 0.00712942
I0708 00:41:21.046092 24447 solver.cpp:243] Iteration 1485, loss = 3.34624
I0708 00:41:21.046119 24447 solver.cpp:259]     Train net output #0: loss = 3.34624 (* 1 = 3.34624 loss)
I0708 00:41:21.046126 24447 solver.cpp:590] Iteration 1485, lr = 0.00708489
I0708 00:41:28.728031 24447 solver.cpp:243] Iteration 1512, loss = 3.40559
I0708 00:41:28.728060 24447 solver.cpp:259]     Train net output #0: loss = 3.40559 (* 1 = 3.40559 loss)
I0708 00:41:28.728076 24447 solver.cpp:590] Iteration 1512, lr = 0.00704064
I0708 00:41:36.732213 24447 solver.cpp:243] Iteration 1539, loss = 3.42867
I0708 00:41:36.732270 24447 solver.cpp:259]     Train net output #0: loss = 3.42867 (* 1 = 3.42867 loss)
I0708 00:41:36.732277 24447 solver.cpp:590] Iteration 1539, lr = 0.00699666
I0708 00:41:39.146930 24447 solver.cpp:347] Iteration 1547, Testing net (#0)
I0708 00:41:58.898663 24447 solver.cpp:415]     Test net output #0: accuracy = 0.325
I0708 00:41:58.898685 24447 solver.cpp:415]     Test net output #1: loss = 3.83579 (* 1 = 3.83579 loss)
I0708 00:42:03.798606 24447 solver.cpp:243] Iteration 1566, loss = 2.96573
I0708 00:42:03.798634 24447 solver.cpp:259]     Train net output #0: loss = 2.96573 (* 1 = 2.96573 loss)
I0708 00:42:03.798640 24447 solver.cpp:590] Iteration 1566, lr = 0.00695296
I0708 00:42:11.541142 24447 solver.cpp:243] Iteration 1593, loss = 2.92966
I0708 00:42:11.541201 24447 solver.cpp:259]     Train net output #0: loss = 2.92966 (* 1 = 2.92966 loss)
I0708 00:42:11.541208 24447 solver.cpp:590] Iteration 1593, lr = 0.00690953
I0708 00:42:19.299332 24447 solver.cpp:243] Iteration 1620, loss = 2.9248
I0708 00:42:19.299357 24447 solver.cpp:259]     Train net output #0: loss = 2.9248 (* 1 = 2.9248 loss)
I0708 00:42:19.299363 24447 solver.cpp:590] Iteration 1620, lr = 0.00686637
I0708 00:42:27.091125 24447 solver.cpp:243] Iteration 1647, loss = 2.97596
I0708 00:42:27.091150 24447 solver.cpp:259]     Train net output #0: loss = 2.97596 (* 1 = 2.97596 loss)
I0708 00:42:27.091156 24447 solver.cpp:590] Iteration 1647, lr = 0.00682348
I0708 00:42:34.817387 24447 solver.cpp:243] Iteration 1674, loss = 2.70924
I0708 00:42:34.817414 24447 solver.cpp:259]     Train net output #0: loss = 2.70924 (* 1 = 2.70924 loss)
I0708 00:42:34.817420 24447 solver.cpp:590] Iteration 1674, lr = 0.00678086
I0708 00:42:42.550838 24447 solver.cpp:243] Iteration 1701, loss = 3.25043
I0708 00:42:42.550921 24447 solver.cpp:259]     Train net output #0: loss = 3.25043 (* 1 = 3.25043 loss)
I0708 00:42:42.550928 24447 solver.cpp:590] Iteration 1701, lr = 0.0067385
I0708 00:42:50.277343 24447 solver.cpp:243] Iteration 1728, loss = 3.27454
I0708 00:42:50.277367 24447 solver.cpp:259]     Train net output #0: loss = 3.27454 (* 1 = 3.27454 loss)
I0708 00:42:50.277374 24447 solver.cpp:590] Iteration 1728, lr = 0.00669641
I0708 00:42:58.035212 24447 solver.cpp:243] Iteration 1755, loss = 2.96109
I0708 00:42:58.035238 24447 solver.cpp:259]     Train net output #0: loss = 2.96109 (* 1 = 2.96109 loss)
I0708 00:42:58.035243 24447 solver.cpp:590] Iteration 1755, lr = 0.00665458
I0708 00:43:01.480383 24447 solver.cpp:347] Iteration 1768, Testing net (#0)
I0708 00:43:17.138085 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 00:43:20.864423 24447 solver.cpp:415]     Test net output #0: accuracy = 0.336298
I0708 00:43:20.864447 24447 solver.cpp:415]     Test net output #1: loss = 3.83689 (* 1 = 3.83689 loss)
I0708 00:43:24.348578 24447 solver.cpp:243] Iteration 1782, loss = 2.94243
I0708 00:43:24.348603 24447 solver.cpp:259]     Train net output #0: loss = 2.94243 (* 1 = 2.94243 loss)
I0708 00:43:24.348610 24447 solver.cpp:590] Iteration 1782, lr = 0.00661302
I0708 00:43:32.066514 24447 solver.cpp:243] Iteration 1809, loss = 3.38607
I0708 00:43:32.066540 24447 solver.cpp:259]     Train net output #0: loss = 3.38607 (* 1 = 3.38607 loss)
I0708 00:43:32.066545 24447 solver.cpp:590] Iteration 1809, lr = 0.00657171
I0708 00:43:39.771042 24447 solver.cpp:243] Iteration 1836, loss = 2.42072
I0708 00:43:39.771069 24447 solver.cpp:259]     Train net output #0: loss = 2.42072 (* 1 = 2.42072 loss)
I0708 00:43:39.771075 24447 solver.cpp:590] Iteration 1836, lr = 0.00653066
I0708 00:43:47.491365 24447 solver.cpp:243] Iteration 1863, loss = 2.60917
I0708 00:43:47.491453 24447 solver.cpp:259]     Train net output #0: loss = 2.60917 (* 1 = 2.60917 loss)
I0708 00:43:47.491461 24447 solver.cpp:590] Iteration 1863, lr = 0.00648987
I0708 00:43:55.225411 24447 solver.cpp:243] Iteration 1890, loss = 2.7245
I0708 00:43:55.225438 24447 solver.cpp:259]     Train net output #0: loss = 2.7245 (* 1 = 2.7245 loss)
I0708 00:43:55.225445 24447 solver.cpp:590] Iteration 1890, lr = 0.00644933
I0708 00:44:03.001721 24447 solver.cpp:243] Iteration 1917, loss = 2.63922
I0708 00:44:03.001745 24447 solver.cpp:259]     Train net output #0: loss = 2.63922 (* 1 = 2.63922 loss)
I0708 00:44:03.001751 24447 solver.cpp:590] Iteration 1917, lr = 0.00640905
I0708 00:44:10.787384 24447 solver.cpp:243] Iteration 1944, loss = 3.03671
I0708 00:44:10.787411 24447 solver.cpp:259]     Train net output #0: loss = 3.03671 (* 1 = 3.03671 loss)
I0708 00:44:10.787417 24447 solver.cpp:590] Iteration 1944, lr = 0.00636902
I0708 00:44:18.550478 24447 solver.cpp:243] Iteration 1971, loss = 2.82788
I0708 00:44:18.550549 24447 solver.cpp:259]     Train net output #0: loss = 2.82788 (* 1 = 2.82788 loss)
I0708 00:44:18.550566 24447 solver.cpp:590] Iteration 1971, lr = 0.00632924
I0708 00:44:23.433229 24447 solver.cpp:347] Iteration 1989, Testing net (#0)
I0708 00:44:42.666764 24447 solver.cpp:415]     Test net output #0: accuracy = 0.340625
I0708 00:44:42.666790 24447 solver.cpp:415]     Test net output #1: loss = 3.78771 (* 1 = 3.78771 loss)
I0708 00:44:44.745632 24447 solver.cpp:243] Iteration 1998, loss = 2.99917
I0708 00:44:44.745658 24447 solver.cpp:259]     Train net output #0: loss = 2.99917 (* 1 = 2.99917 loss)
I0708 00:44:44.745664 24447 solver.cpp:590] Iteration 1998, lr = 0.0062897
I0708 00:44:52.498047 24447 solver.cpp:243] Iteration 2025, loss = 2.80296
I0708 00:44:52.498128 24447 solver.cpp:259]     Train net output #0: loss = 2.80296 (* 1 = 2.80296 loss)
I0708 00:44:52.498136 24447 solver.cpp:590] Iteration 2025, lr = 0.00625041
I0708 00:45:00.274664 24447 solver.cpp:243] Iteration 2052, loss = 2.72109
I0708 00:45:00.274690 24447 solver.cpp:259]     Train net output #0: loss = 2.72109 (* 1 = 2.72109 loss)
I0708 00:45:00.274695 24447 solver.cpp:590] Iteration 2052, lr = 0.00621137
I0708 00:45:08.046805 24447 solver.cpp:243] Iteration 2079, loss = 2.61691
I0708 00:45:08.046831 24447 solver.cpp:259]     Train net output #0: loss = 2.61691 (* 1 = 2.61691 loss)
I0708 00:45:08.046838 24447 solver.cpp:590] Iteration 2079, lr = 0.00617258
I0708 00:45:15.775952 24447 solver.cpp:243] Iteration 2106, loss = 2.52505
I0708 00:45:15.775976 24447 solver.cpp:259]     Train net output #0: loss = 2.52505 (* 1 = 2.52505 loss)
I0708 00:45:15.775982 24447 solver.cpp:590] Iteration 2106, lr = 0.00613402
I0708 00:45:23.534621 24447 solver.cpp:243] Iteration 2133, loss = 3.13753
I0708 00:45:23.534723 24447 solver.cpp:259]     Train net output #0: loss = 3.13753 (* 1 = 3.13753 loss)
I0708 00:45:23.534730 24447 solver.cpp:590] Iteration 2133, lr = 0.00609571
I0708 00:45:31.325984 24447 solver.cpp:243] Iteration 2160, loss = 2.32919
I0708 00:45:31.326009 24447 solver.cpp:259]     Train net output #0: loss = 2.32919 (* 1 = 2.32919 loss)
I0708 00:45:31.326015 24447 solver.cpp:590] Iteration 2160, lr = 0.00605763
I0708 00:45:39.026527 24447 solver.cpp:243] Iteration 2187, loss = 3.13689
I0708 00:45:39.026553 24447 solver.cpp:259]     Train net output #0: loss = 3.13689 (* 1 = 3.13689 loss)
I0708 00:45:39.026559 24447 solver.cpp:590] Iteration 2187, lr = 0.00601979
I0708 00:45:45.292747 24447 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_2210.caffemodel
I0708 00:45:50.085230 24447 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_2210.solverstate
I0708 00:45:51.080502 24447 solver.cpp:347] Iteration 2210, Testing net (#0)
I0708 00:46:10.598258 24447 solver.cpp:415]     Test net output #0: accuracy = 0.346514
I0708 00:46:10.598311 24447 solver.cpp:415]     Test net output #1: loss = 3.72558 (* 1 = 3.72558 loss)
I0708 00:46:11.235373 24447 solver.cpp:243] Iteration 2214, loss = 2.95984
I0708 00:46:11.235397 24447 solver.cpp:259]     Train net output #0: loss = 2.95984 (* 1 = 2.95984 loss)
I0708 00:46:11.235404 24447 solver.cpp:590] Iteration 2214, lr = 0.00598219
I0708 00:46:11.807597 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 00:46:18.912968 24447 solver.cpp:243] Iteration 2241, loss = 2.79228
I0708 00:46:18.912994 24447 solver.cpp:259]     Train net output #0: loss = 2.79228 (* 1 = 2.79228 loss)
I0708 00:46:18.913002 24447 solver.cpp:590] Iteration 2241, lr = 0.00594483
I0708 00:46:26.600841 24447 solver.cpp:243] Iteration 2268, loss = 3.27808
I0708 00:46:26.600864 24447 solver.cpp:259]     Train net output #0: loss = 3.27808 (* 1 = 3.27808 loss)
I0708 00:46:26.600870 24447 solver.cpp:590] Iteration 2268, lr = 0.00590769
I0708 00:46:34.297397 24447 solver.cpp:243] Iteration 2295, loss = 2.28286
I0708 00:46:34.297422 24447 solver.cpp:259]     Train net output #0: loss = 2.28286 (* 1 = 2.28286 loss)
I0708 00:46:34.297428 24447 solver.cpp:590] Iteration 2295, lr = 0.00587079
I0708 00:46:42.004689 24447 solver.cpp:243] Iteration 2322, loss = 2.61074
I0708 00:46:42.004746 24447 solver.cpp:259]     Train net output #0: loss = 2.61074 (* 1 = 2.61074 loss)
I0708 00:46:42.004753 24447 solver.cpp:590] Iteration 2322, lr = 0.00583412
I0708 00:46:49.694337 24447 solver.cpp:243] Iteration 2349, loss = 2.74344
I0708 00:46:49.694363 24447 solver.cpp:259]     Train net output #0: loss = 2.74344 (* 1 = 2.74344 loss)
I0708 00:46:49.694370 24447 solver.cpp:590] Iteration 2349, lr = 0.00579768
I0708 00:46:57.407640 24447 solver.cpp:243] Iteration 2376, loss = 2.38528
I0708 00:46:57.407666 24447 solver.cpp:259]     Train net output #0: loss = 2.38528 (* 1 = 2.38528 loss)
I0708 00:46:57.407672 24447 solver.cpp:590] Iteration 2376, lr = 0.00576147
I0708 00:47:05.072242 24447 solver.cpp:243] Iteration 2403, loss = 2.28821
I0708 00:47:05.072268 24447 solver.cpp:259]     Train net output #0: loss = 2.28821 (* 1 = 2.28821 loss)
I0708 00:47:05.072273 24447 solver.cpp:590] Iteration 2403, lr = 0.00572548
I0708 00:47:12.734383 24447 solver.cpp:243] Iteration 2430, loss = 2.0153
I0708 00:47:12.734490 24447 solver.cpp:259]     Train net output #0: loss = 2.0153 (* 1 = 2.0153 loss)
I0708 00:47:12.734498 24447 solver.cpp:590] Iteration 2430, lr = 0.00568972
I0708 00:47:12.734712 24447 solver.cpp:347] Iteration 2431, Testing net (#0)
I0708 00:47:31.868593 24447 solver.cpp:415]     Test net output #0: accuracy = 0.346514
I0708 00:47:31.868618 24447 solver.cpp:415]     Test net output #1: loss = 3.6913 (* 1 = 3.6913 loss)
I0708 00:47:38.749646 24447 solver.cpp:243] Iteration 2457, loss = 2.37973
I0708 00:47:38.749673 24447 solver.cpp:259]     Train net output #0: loss = 2.37973 (* 1 = 2.37973 loss)
I0708 00:47:38.749680 24447 solver.cpp:590] Iteration 2457, lr = 0.00565418
I0708 00:47:46.424343 24447 solver.cpp:243] Iteration 2484, loss = 2.68187
I0708 00:47:46.424399 24447 solver.cpp:259]     Train net output #0: loss = 2.68187 (* 1 = 2.68187 loss)
I0708 00:47:46.424406 24447 solver.cpp:590] Iteration 2484, lr = 0.00561886
I0708 00:47:54.112967 24447 solver.cpp:243] Iteration 2511, loss = 2.0044
I0708 00:47:54.112993 24447 solver.cpp:259]     Train net output #0: loss = 2.0044 (* 1 = 2.0044 loss)
I0708 00:47:54.112999 24447 solver.cpp:590] Iteration 2511, lr = 0.00558376
I0708 00:48:01.929731 24447 solver.cpp:243] Iteration 2538, loss = 2.65126
I0708 00:48:01.929759 24447 solver.cpp:259]     Train net output #0: loss = 2.65126 (* 1 = 2.65126 loss)
I0708 00:48:01.929764 24447 solver.cpp:590] Iteration 2538, lr = 0.00554888
I0708 00:48:09.695509 24447 solver.cpp:243] Iteration 2565, loss = 2.8641
I0708 00:48:09.695535 24447 solver.cpp:259]     Train net output #0: loss = 2.8641 (* 1 = 2.8641 loss)
I0708 00:48:09.695541 24447 solver.cpp:590] Iteration 2565, lr = 0.00551422
I0708 00:48:17.415472 24447 solver.cpp:243] Iteration 2592, loss = 2.74
I0708 00:48:17.415529 24447 solver.cpp:259]     Train net output #0: loss = 2.74 (* 1 = 2.74 loss)
I0708 00:48:17.415537 24447 solver.cpp:590] Iteration 2592, lr = 0.00547978
I0708 00:48:25.138597 24447 solver.cpp:243] Iteration 2619, loss = 1.96944
I0708 00:48:25.138622 24447 solver.cpp:259]     Train net output #0: loss = 1.96944 (* 1 = 1.96944 loss)
I0708 00:48:25.138628 24447 solver.cpp:590] Iteration 2619, lr = 0.00544555
I0708 00:48:32.905309 24447 solver.cpp:243] Iteration 2646, loss = 2.4745
I0708 00:48:32.905335 24447 solver.cpp:259]     Train net output #0: loss = 2.4745 (* 1 = 2.4745 loss)
I0708 00:48:32.905342 24447 solver.cpp:590] Iteration 2646, lr = 0.00541154
I0708 00:48:34.333838 24447 solver.cpp:347] Iteration 2652, Testing net (#0)
I0708 00:48:53.462121 24447 solver.cpp:415]     Test net output #0: accuracy = 0.345433
I0708 00:48:53.462178 24447 solver.cpp:415]     Test net output #1: loss = 3.72099 (* 1 = 3.72099 loss)
I0708 00:48:59.150732 24447 solver.cpp:243] Iteration 2673, loss = 1.75552
I0708 00:48:59.150758 24447 solver.cpp:259]     Train net output #0: loss = 1.75552 (* 1 = 1.75552 loss)
I0708 00:48:59.150764 24447 solver.cpp:590] Iteration 2673, lr = 0.00537774
I0708 00:49:07.122570 24447 solver.cpp:243] Iteration 2700, loss = 2.21738
I0708 00:49:07.122596 24447 solver.cpp:259]     Train net output #0: loss = 2.21738 (* 1 = 2.21738 loss)
I0708 00:49:07.122601 24447 solver.cpp:590] Iteration 2700, lr = 0.00534415
I0708 00:49:10.622148 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 00:49:16.547739 24447 solver.cpp:243] Iteration 2727, loss = 2.23319
I0708 00:49:16.547762 24447 solver.cpp:259]     Train net output #0: loss = 2.23319 (* 1 = 2.23319 loss)
I0708 00:49:16.547767 24447 solver.cpp:590] Iteration 2727, lr = 0.00531077
I0708 00:49:25.815311 24447 solver.cpp:243] Iteration 2754, loss = 2.27279
I0708 00:49:25.815383 24447 solver.cpp:259]     Train net output #0: loss = 2.27279 (* 1 = 2.27279 loss)
I0708 00:49:25.815393 24447 solver.cpp:590] Iteration 2754, lr = 0.00527759
I0708 00:49:35.056113 24447 solver.cpp:243] Iteration 2781, loss = 2.06687
I0708 00:49:35.056139 24447 solver.cpp:259]     Train net output #0: loss = 2.06687 (* 1 = 2.06687 loss)
I0708 00:49:35.056146 24447 solver.cpp:590] Iteration 2781, lr = 0.00524463
I0708 00:49:43.199240 24447 solver.cpp:243] Iteration 2808, loss = 2.6385
I0708 00:49:43.199267 24447 solver.cpp:259]     Train net output #0: loss = 2.6385 (* 1 = 2.6385 loss)
I0708 00:49:43.199275 24447 solver.cpp:590] Iteration 2808, lr = 0.00521187
I0708 00:49:52.204026 24447 solver.cpp:243] Iteration 2835, loss = 2.52128
I0708 00:49:52.204053 24447 solver.cpp:259]     Train net output #0: loss = 2.52128 (* 1 = 2.52128 loss)
I0708 00:49:52.204059 24447 solver.cpp:590] Iteration 2835, lr = 0.00517932
I0708 00:50:00.403767 24447 solver.cpp:243] Iteration 2862, loss = 2.09198
I0708 00:50:00.403846 24447 solver.cpp:259]     Train net output #0: loss = 2.09198 (* 1 = 2.09198 loss)
I0708 00:50:00.403853 24447 solver.cpp:590] Iteration 2862, lr = 0.00514696
I0708 00:50:03.519575 24447 solver.cpp:347] Iteration 2873, Testing net (#0)
I0708 00:50:22.903810 24447 solver.cpp:415]     Test net output #0: accuracy = 0.352644
I0708 00:50:22.903832 24447 solver.cpp:415]     Test net output #1: loss = 3.62733 (* 1 = 3.62733 loss)
I0708 00:50:27.853945 24447 solver.cpp:243] Iteration 2889, loss = 2.33663
I0708 00:50:27.853971 24447 solver.cpp:259]     Train net output #0: loss = 2.33663 (* 1 = 2.33663 loss)
I0708 00:50:27.853976 24447 solver.cpp:590] Iteration 2889, lr = 0.00511481
I0708 00:50:36.163172 24447 solver.cpp:243] Iteration 2916, loss = 1.91785
I0708 00:50:36.163228 24447 solver.cpp:259]     Train net output #0: loss = 1.91785 (* 1 = 1.91785 loss)
I0708 00:50:36.163235 24447 solver.cpp:590] Iteration 2916, lr = 0.00508287
I0708 00:50:44.141162 24447 solver.cpp:243] Iteration 2943, loss = 1.99547
I0708 00:50:44.141188 24447 solver.cpp:259]     Train net output #0: loss = 1.99547 (* 1 = 1.99547 loss)
I0708 00:50:44.141194 24447 solver.cpp:590] Iteration 2943, lr = 0.00505112
I0708 00:50:52.308466 24447 solver.cpp:243] Iteration 2970, loss = 2.53522
I0708 00:50:52.308492 24447 solver.cpp:259]     Train net output #0: loss = 2.53522 (* 1 = 2.53522 loss)
I0708 00:50:52.308498 24447 solver.cpp:590] Iteration 2970, lr = 0.00501957
I0708 00:51:00.601642 24447 solver.cpp:243] Iteration 2997, loss = 2.49915
I0708 00:51:00.601668 24447 solver.cpp:259]     Train net output #0: loss = 2.49915 (* 1 = 2.49915 loss)
I0708 00:51:00.601675 24447 solver.cpp:590] Iteration 2997, lr = 0.00498821
I0708 00:51:08.684999 24447 solver.cpp:243] Iteration 3024, loss = 2.20631
I0708 00:51:08.685058 24447 solver.cpp:259]     Train net output #0: loss = 2.20631 (* 1 = 2.20631 loss)
I0708 00:51:08.685066 24447 solver.cpp:590] Iteration 3024, lr = 0.00495706
I0708 00:51:16.923158 24447 solver.cpp:243] Iteration 3051, loss = 2.16455
I0708 00:51:16.923180 24447 solver.cpp:259]     Train net output #0: loss = 2.16455 (* 1 = 2.16455 loss)
I0708 00:51:16.923187 24447 solver.cpp:590] Iteration 3051, lr = 0.00492609
I0708 00:51:25.148075 24447 solver.cpp:243] Iteration 3078, loss = 2.27019
I0708 00:51:25.148102 24447 solver.cpp:259]     Train net output #0: loss = 2.27019 (* 1 = 2.27019 loss)
I0708 00:51:25.148108 24447 solver.cpp:590] Iteration 3078, lr = 0.00489532
I0708 00:51:29.752852 24447 solver.cpp:347] Iteration 3094, Testing net (#0)
I0708 00:51:49.154963 24447 solver.cpp:415]     Test net output #0: accuracy = 0.359495
I0708 00:51:49.155017 24447 solver.cpp:415]     Test net output #1: loss = 3.63922 (* 1 = 3.63922 loss)
I0708 00:51:51.836134 24447 solver.cpp:243] Iteration 3105, loss = 2.22065
I0708 00:51:51.836160 24447 solver.cpp:259]     Train net output #0: loss = 2.22065 (* 1 = 2.22065 loss)
I0708 00:51:51.836166 24447 solver.cpp:590] Iteration 3105, lr = 0.00486475
I0708 00:52:01.187688 24447 solver.cpp:243] Iteration 3132, loss = 2.19859
I0708 00:52:01.187714 24447 solver.cpp:259]     Train net output #0: loss = 2.19859 (* 1 = 2.19859 loss)
I0708 00:52:01.187721 24447 solver.cpp:590] Iteration 3132, lr = 0.00483436
I0708 00:52:10.421705 24447 solver.cpp:243] Iteration 3159, loss = 1.74656
I0708 00:52:10.421731 24447 solver.cpp:259]     Train net output #0: loss = 1.74656 (* 1 = 1.74656 loss)
I0708 00:52:10.421738 24447 solver.cpp:590] Iteration 3159, lr = 0.00480416
I0708 00:52:19.931921 24447 solver.cpp:243] Iteration 3186, loss = 2.63075
I0708 00:52:19.931993 24447 solver.cpp:259]     Train net output #0: loss = 2.63075 (* 1 = 2.63075 loss)
I0708 00:52:19.932000 24447 solver.cpp:590] Iteration 3186, lr = 0.00477416
I0708 00:52:25.448909 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 00:52:29.111627 24447 solver.cpp:243] Iteration 3213, loss = 2.06617
I0708 00:52:29.111649 24447 solver.cpp:259]     Train net output #0: loss = 2.06617 (* 1 = 2.06617 loss)
I0708 00:52:29.111655 24447 solver.cpp:590] Iteration 3213, lr = 0.00474433
I0708 00:52:38.024580 24447 solver.cpp:243] Iteration 3240, loss = 2.07027
I0708 00:52:38.024605 24447 solver.cpp:259]     Train net output #0: loss = 2.07027 (* 1 = 2.07027 loss)
I0708 00:52:38.024611 24447 solver.cpp:590] Iteration 3240, lr = 0.0047147
I0708 00:52:47.277410 24447 solver.cpp:243] Iteration 3267, loss = 2.43611
I0708 00:52:47.277436 24447 solver.cpp:259]     Train net output #0: loss = 2.43611 (* 1 = 2.43611 loss)
I0708 00:52:47.277442 24447 solver.cpp:590] Iteration 3267, lr = 0.00468525
I0708 00:52:55.971611 24447 solver.cpp:243] Iteration 3294, loss = 2.08734
I0708 00:52:55.971665 24447 solver.cpp:259]     Train net output #0: loss = 2.08734 (* 1 = 2.08734 loss)
I0708 00:52:55.971673 24447 solver.cpp:590] Iteration 3294, lr = 0.00465599
I0708 00:53:02.768484 24447 solver.cpp:347] Iteration 3315, Testing net (#0)
I0708 00:53:22.241205 24447 solver.cpp:415]     Test net output #0: accuracy = 0.361298
I0708 00:53:22.241230 24447 solver.cpp:415]     Test net output #1: loss = 3.53552 (* 1 = 3.53552 loss)
I0708 00:53:23.435044 24447 solver.cpp:243] Iteration 3321, loss = 1.99464
I0708 00:53:23.435070 24447 solver.cpp:259]     Train net output #0: loss = 1.99464 (* 1 = 1.99464 loss)
I0708 00:53:23.435076 24447 solver.cpp:590] Iteration 3321, lr = 0.0046269
I0708 00:53:31.110353 24447 solver.cpp:243] Iteration 3348, loss = 1.76491
I0708 00:53:31.110409 24447 solver.cpp:259]     Train net output #0: loss = 1.76491 (* 1 = 1.76491 loss)
I0708 00:53:31.110416 24447 solver.cpp:590] Iteration 3348, lr = 0.004598
I0708 00:53:38.799388 24447 solver.cpp:243] Iteration 3375, loss = 2.1303
I0708 00:53:38.799413 24447 solver.cpp:259]     Train net output #0: loss = 2.1303 (* 1 = 2.1303 loss)
I0708 00:53:38.799418 24447 solver.cpp:590] Iteration 3375, lr = 0.00456928
I0708 00:53:46.481015 24447 solver.cpp:243] Iteration 3402, loss = 1.96317
I0708 00:53:46.481042 24447 solver.cpp:259]     Train net output #0: loss = 1.96317 (* 1 = 1.96317 loss)
I0708 00:53:46.481050 24447 solver.cpp:590] Iteration 3402, lr = 0.00454074
I0708 00:53:54.727656 24447 solver.cpp:243] Iteration 3429, loss = 1.95746
I0708 00:53:54.727682 24447 solver.cpp:259]     Train net output #0: loss = 1.95746 (* 1 = 1.95746 loss)
I0708 00:53:54.727689 24447 solver.cpp:590] Iteration 3429, lr = 0.00451238
I0708 00:54:03.721736 24447 solver.cpp:243] Iteration 3456, loss = 2.07285
I0708 00:54:03.721791 24447 solver.cpp:259]     Train net output #0: loss = 2.07285 (* 1 = 2.07285 loss)
I0708 00:54:03.721796 24447 solver.cpp:590] Iteration 3456, lr = 0.00448419
I0708 00:54:12.731609 24447 solver.cpp:243] Iteration 3483, loss = 2.18948
I0708 00:54:12.731633 24447 solver.cpp:259]     Train net output #0: loss = 2.18948 (* 1 = 2.18948 loss)
I0708 00:54:12.731639 24447 solver.cpp:590] Iteration 3483, lr = 0.00445618
I0708 00:54:21.736920 24447 solver.cpp:243] Iteration 3510, loss = 2.20609
I0708 00:54:21.736943 24447 solver.cpp:259]     Train net output #0: loss = 2.20609 (* 1 = 2.20609 loss)
I0708 00:54:21.736948 24447 solver.cpp:590] Iteration 3510, lr = 0.00442835
I0708 00:54:30.216168 24447 solver.cpp:347] Iteration 3536, Testing net (#0)
I0708 00:54:49.309283 24447 solver.cpp:415]     Test net output #0: accuracy = 0.369712
I0708 00:54:49.309363 24447 solver.cpp:415]     Test net output #1: loss = 3.54387 (* 1 = 3.54387 loss)
I0708 00:54:49.438145 24447 solver.cpp:243] Iteration 3537, loss = 2.367
I0708 00:54:49.438174 24447 solver.cpp:259]     Train net output #0: loss = 2.367 (* 1 = 2.367 loss)
I0708 00:54:49.438180 24447 solver.cpp:590] Iteration 3537, lr = 0.00440069
I0708 00:54:56.754314 24447 solver.cpp:243] Iteration 3564, loss = 1.89528
I0708 00:54:56.754340 24447 solver.cpp:259]     Train net output #0: loss = 1.89528 (* 1 = 1.89528 loss)
I0708 00:54:56.754348 24447 solver.cpp:590] Iteration 3564, lr = 0.0043732
I0708 00:55:04.437433 24447 solver.cpp:243] Iteration 3591, loss = 1.50917
I0708 00:55:04.437460 24447 solver.cpp:259]     Train net output #0: loss = 1.50917 (* 1 = 1.50917 loss)
I0708 00:55:04.437466 24447 solver.cpp:590] Iteration 3591, lr = 0.00434589
I0708 00:55:13.070404 24447 solver.cpp:243] Iteration 3618, loss = 1.89222
I0708 00:55:13.070435 24447 solver.cpp:259]     Train net output #0: loss = 1.89222 (* 1 = 1.89222 loss)
I0708 00:55:13.070441 24447 solver.cpp:590] Iteration 3618, lr = 0.00431874
I0708 00:55:21.798478 24447 solver.cpp:243] Iteration 3645, loss = 2.01799
I0708 00:55:21.798532 24447 solver.cpp:259]     Train net output #0: loss = 2.01799 (* 1 = 2.01799 loss)
I0708 00:55:21.798538 24447 solver.cpp:590] Iteration 3645, lr = 0.00429176
I0708 00:55:30.860334 24447 solver.cpp:243] Iteration 3672, loss = 1.87597
I0708 00:55:30.860359 24447 solver.cpp:259]     Train net output #0: loss = 1.87597 (* 1 = 1.87597 loss)
I0708 00:55:30.860365 24447 solver.cpp:590] Iteration 3672, lr = 0.00426496
I0708 00:55:39.044482 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 00:55:40.119158 24447 solver.cpp:243] Iteration 3699, loss = 2.18165
I0708 00:55:40.119186 24447 solver.cpp:259]     Train net output #0: loss = 2.18165 (* 1 = 2.18165 loss)
I0708 00:55:40.119192 24447 solver.cpp:590] Iteration 3699, lr = 0.00423832
I0708 00:55:48.943861 24447 solver.cpp:243] Iteration 3726, loss = 2.02684
I0708 00:55:48.943886 24447 solver.cpp:259]     Train net output #0: loss = 2.02684 (* 1 = 2.02684 loss)
I0708 00:55:48.943892 24447 solver.cpp:590] Iteration 3726, lr = 0.00421184
I0708 00:55:58.111574 24447 solver.cpp:243] Iteration 3753, loss = 1.99917
I0708 00:55:58.111644 24447 solver.cpp:259]     Train net output #0: loss = 1.99917 (* 1 = 1.99917 loss)
I0708 00:55:58.111661 24447 solver.cpp:590] Iteration 3753, lr = 0.00418554
I0708 00:55:58.968309 24447 solver.cpp:347] Iteration 3757, Testing net (#0)
I0708 00:56:18.078078 24447 solver.cpp:415]     Test net output #0: accuracy = 0.370192
I0708 00:56:18.078101 24447 solver.cpp:415]     Test net output #1: loss = 3.49058 (* 1 = 3.49058 loss)
I0708 00:56:24.137444 24447 solver.cpp:243] Iteration 3780, loss = 2.28559
I0708 00:56:24.137471 24447 solver.cpp:259]     Train net output #0: loss = 2.28559 (* 1 = 2.28559 loss)
I0708 00:56:24.137477 24447 solver.cpp:590] Iteration 3780, lr = 0.00415939
I0708 00:56:31.820809 24447 solver.cpp:243] Iteration 3807, loss = 2.16466
I0708 00:56:31.820878 24447 solver.cpp:259]     Train net output #0: loss = 2.16466 (* 1 = 2.16466 loss)
I0708 00:56:31.820895 24447 solver.cpp:590] Iteration 3807, lr = 0.00413341
I0708 00:56:39.984422 24447 solver.cpp:243] Iteration 3834, loss = 1.96198
I0708 00:56:39.984450 24447 solver.cpp:259]     Train net output #0: loss = 1.96198 (* 1 = 1.96198 loss)
I0708 00:56:39.984457 24447 solver.cpp:590] Iteration 3834, lr = 0.00410759
I0708 00:56:48.717382 24447 solver.cpp:243] Iteration 3861, loss = 1.49701
I0708 00:56:48.717408 24447 solver.cpp:259]     Train net output #0: loss = 1.49701 (* 1 = 1.49701 loss)
I0708 00:56:48.717414 24447 solver.cpp:590] Iteration 3861, lr = 0.00408194
I0708 00:56:57.376844 24447 solver.cpp:243] Iteration 3888, loss = 2.16359
I0708 00:56:57.376873 24447 solver.cpp:259]     Train net output #0: loss = 2.16359 (* 1 = 2.16359 loss)
I0708 00:56:57.376879 24447 solver.cpp:590] Iteration 3888, lr = 0.00405644
I0708 00:57:05.915860 24447 solver.cpp:243] Iteration 3915, loss = 2.04286
I0708 00:57:05.915973 24447 solver.cpp:259]     Train net output #0: loss = 2.04286 (* 1 = 2.04286 loss)
I0708 00:57:05.915995 24447 solver.cpp:590] Iteration 3915, lr = 0.0040311
I0708 00:57:15.096855 24447 solver.cpp:243] Iteration 3942, loss = 1.97994
I0708 00:57:15.096881 24447 solver.cpp:259]     Train net output #0: loss = 1.97994 (* 1 = 1.97994 loss)
I0708 00:57:15.096887 24447 solver.cpp:590] Iteration 3942, lr = 0.00400592
I0708 00:57:23.535763 24447 solver.cpp:243] Iteration 3969, loss = 2.03586
I0708 00:57:23.535790 24447 solver.cpp:259]     Train net output #0: loss = 2.03586 (* 1 = 2.03586 loss)
I0708 00:57:23.535796 24447 solver.cpp:590] Iteration 3969, lr = 0.0039809
I0708 00:57:26.064291 24447 solver.cpp:347] Iteration 3978, Testing net (#0)
I0708 00:57:45.491519 24447 solver.cpp:415]     Test net output #0: accuracy = 0.373197
I0708 00:57:45.491598 24447 solver.cpp:415]     Test net output #1: loss = 3.45006 (* 1 = 3.45006 loss)
I0708 00:57:50.110448 24447 solver.cpp:243] Iteration 3996, loss = 1.63506
I0708 00:57:50.110476 24447 solver.cpp:259]     Train net output #0: loss = 1.63506 (* 1 = 1.63506 loss)
I0708 00:57:50.110482 24447 solver.cpp:590] Iteration 3996, lr = 0.00395603
I0708 00:57:57.798475 24447 solver.cpp:243] Iteration 4023, loss = 2.2702
I0708 00:57:57.798499 24447 solver.cpp:259]     Train net output #0: loss = 2.2702 (* 1 = 2.2702 loss)
I0708 00:57:57.798506 24447 solver.cpp:590] Iteration 4023, lr = 0.00393132
I0708 00:58:05.598603 24447 solver.cpp:243] Iteration 4050, loss = 1.63
I0708 00:58:05.598628 24447 solver.cpp:259]     Train net output #0: loss = 1.63 (* 1 = 1.63 loss)
I0708 00:58:05.598634 24447 solver.cpp:590] Iteration 4050, lr = 0.00390677
I0708 00:58:13.313068 24447 solver.cpp:243] Iteration 4077, loss = 1.62364
I0708 00:58:13.313091 24447 solver.cpp:259]     Train net output #0: loss = 1.62364 (* 1 = 1.62364 loss)
I0708 00:58:13.313097 24447 solver.cpp:590] Iteration 4077, lr = 0.00388237
I0708 00:58:21.029908 24447 solver.cpp:243] Iteration 4104, loss = 1.71912
I0708 00:58:21.029978 24447 solver.cpp:259]     Train net output #0: loss = 1.71912 (* 1 = 1.71912 loss)
I0708 00:58:21.029994 24447 solver.cpp:590] Iteration 4104, lr = 0.00385812
I0708 00:58:28.802973 24447 solver.cpp:243] Iteration 4131, loss = 2.0805
I0708 00:58:28.802997 24447 solver.cpp:259]     Train net output #0: loss = 2.0805 (* 1 = 2.0805 loss)
I0708 00:58:28.803004 24447 solver.cpp:590] Iteration 4131, lr = 0.00383402
I0708 00:58:36.532716 24447 solver.cpp:243] Iteration 4158, loss = 1.77098
I0708 00:58:36.532743 24447 solver.cpp:259]     Train net output #0: loss = 1.77098 (* 1 = 1.77098 loss)
I0708 00:58:36.532750 24447 solver.cpp:590] Iteration 4158, lr = 0.00381007
I0708 00:58:44.294090 24447 solver.cpp:243] Iteration 4185, loss = 1.928
I0708 00:58:44.294116 24447 solver.cpp:259]     Train net output #0: loss = 1.928 (* 1 = 1.928 loss)
I0708 00:58:44.294122 24447 solver.cpp:590] Iteration 4185, lr = 0.00378627
I0708 00:58:45.783530 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 00:58:48.045444 24447 solver.cpp:347] Iteration 4199, Testing net (#0)
I0708 00:59:07.396075 24447 solver.cpp:415]     Test net output #0: accuracy = 0.371514
I0708 00:59:07.396124 24447 solver.cpp:415]     Test net output #1: loss = 3.46152 (* 1 = 3.46152 loss)
I0708 00:59:10.600214 24447 solver.cpp:243] Iteration 4212, loss = 1.92128
I0708 00:59:10.600240 24447 solver.cpp:259]     Train net output #0: loss = 1.92128 (* 1 = 1.92128 loss)
I0708 00:59:10.600246 24447 solver.cpp:590] Iteration 4212, lr = 0.00376262
I0708 00:59:18.348153 24447 solver.cpp:243] Iteration 4239, loss = 1.83531
I0708 00:59:18.348179 24447 solver.cpp:259]     Train net output #0: loss = 1.83531 (* 1 = 1.83531 loss)
I0708 00:59:18.348184 24447 solver.cpp:590] Iteration 4239, lr = 0.00373912
I0708 00:59:26.347846 24447 solver.cpp:243] Iteration 4266, loss = 2.07926
I0708 00:59:26.347872 24447 solver.cpp:259]     Train net output #0: loss = 2.07926 (* 1 = 2.07926 loss)
I0708 00:59:26.347877 24447 solver.cpp:590] Iteration 4266, lr = 0.00371576
I0708 00:59:34.536907 24447 solver.cpp:243] Iteration 4293, loss = 1.86487
I0708 00:59:34.536932 24447 solver.cpp:259]     Train net output #0: loss = 1.86487 (* 1 = 1.86487 loss)
I0708 00:59:34.536937 24447 solver.cpp:590] Iteration 4293, lr = 0.00369255
I0708 00:59:42.594893 24447 solver.cpp:243] Iteration 4320, loss = 1.75327
I0708 00:59:42.594972 24447 solver.cpp:259]     Train net output #0: loss = 1.75327 (* 1 = 1.75327 loss)
I0708 00:59:42.594980 24447 solver.cpp:590] Iteration 4320, lr = 0.00366949
I0708 00:59:50.782063 24447 solver.cpp:243] Iteration 4347, loss = 1.87005
I0708 00:59:50.782090 24447 solver.cpp:259]     Train net output #0: loss = 1.87005 (* 1 = 1.87005 loss)
I0708 00:59:50.782097 24447 solver.cpp:590] Iteration 4347, lr = 0.00364657
I0708 00:59:59.000195 24447 solver.cpp:243] Iteration 4374, loss = 1.77025
I0708 00:59:59.000221 24447 solver.cpp:259]     Train net output #0: loss = 1.77025 (* 1 = 1.77025 loss)
I0708 00:59:59.000227 24447 solver.cpp:590] Iteration 4374, lr = 0.00362379
I0708 01:00:07.165163 24447 solver.cpp:243] Iteration 4401, loss = 1.86234
I0708 01:00:07.165190 24447 solver.cpp:259]     Train net output #0: loss = 1.86234 (* 1 = 1.86234 loss)
I0708 01:00:07.165196 24447 solver.cpp:590] Iteration 4401, lr = 0.00360116
I0708 01:00:12.575377 24447 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_4420.caffemodel
I0708 01:00:17.315537 24447 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_4420.solverstate
I0708 01:00:18.373934 24447 solver.cpp:347] Iteration 4420, Testing net (#0)
I0708 01:00:37.507836 24447 solver.cpp:415]     Test net output #0: accuracy = 0.370913
I0708 01:00:37.507863 24447 solver.cpp:415]     Test net output #1: loss = 3.44166 (* 1 = 3.44166 loss)
I0708 01:00:39.274418 24447 solver.cpp:243] Iteration 4428, loss = 1.40833
I0708 01:00:39.274443 24447 solver.cpp:259]     Train net output #0: loss = 1.40833 (* 1 = 1.40833 loss)
I0708 01:00:39.274449 24447 solver.cpp:590] Iteration 4428, lr = 0.00357866
I0708 01:00:46.956265 24447 solver.cpp:243] Iteration 4455, loss = 1.90451
I0708 01:00:46.956292 24447 solver.cpp:259]     Train net output #0: loss = 1.90451 (* 1 = 1.90451 loss)
I0708 01:00:46.956298 24447 solver.cpp:590] Iteration 4455, lr = 0.00355631
I0708 01:00:54.643421 24447 solver.cpp:243] Iteration 4482, loss = 2.06104
I0708 01:00:54.643479 24447 solver.cpp:259]     Train net output #0: loss = 2.06104 (* 1 = 2.06104 loss)
I0708 01:00:54.643486 24447 solver.cpp:590] Iteration 4482, lr = 0.00353409
I0708 01:01:02.339921 24447 solver.cpp:243] Iteration 4509, loss = 1.71574
I0708 01:01:02.339948 24447 solver.cpp:259]     Train net output #0: loss = 1.71574 (* 1 = 1.71574 loss)
I0708 01:01:02.339954 24447 solver.cpp:590] Iteration 4509, lr = 0.00351202
I0708 01:01:10.009325 24447 solver.cpp:243] Iteration 4536, loss = 1.80225
I0708 01:01:10.009351 24447 solver.cpp:259]     Train net output #0: loss = 1.80225 (* 1 = 1.80225 loss)
I0708 01:01:10.009356 24447 solver.cpp:590] Iteration 4536, lr = 0.00349008
I0708 01:01:17.712466 24447 solver.cpp:243] Iteration 4563, loss = 1.60007
I0708 01:01:17.712492 24447 solver.cpp:259]     Train net output #0: loss = 1.60007 (* 1 = 1.60007 loss)
I0708 01:01:17.712498 24447 solver.cpp:590] Iteration 4563, lr = 0.00346828
I0708 01:01:25.415050 24447 solver.cpp:243] Iteration 4590, loss = 1.55834
I0708 01:01:25.415132 24447 solver.cpp:259]     Train net output #0: loss = 1.55834 (* 1 = 1.55834 loss)
I0708 01:01:25.415140 24447 solver.cpp:590] Iteration 4590, lr = 0.00344662
I0708 01:01:33.093802 24447 solver.cpp:243] Iteration 4617, loss = 1.58615
I0708 01:01:33.093829 24447 solver.cpp:259]     Train net output #0: loss = 1.58615 (* 1 = 1.58615 loss)
I0708 01:01:33.093835 24447 solver.cpp:590] Iteration 4617, lr = 0.00342509
I0708 01:01:39.610455 24447 solver.cpp:347] Iteration 4641, Testing net (#0)
I0708 01:01:43.426846 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:02:01.008522 24447 solver.cpp:415]     Test net output #0: accuracy = 0.377885
I0708 01:02:01.008633 24447 solver.cpp:415]     Test net output #1: loss = 3.41237 (* 1 = 3.41237 loss)
I0708 01:02:01.357908 24447 solver.cpp:243] Iteration 4644, loss = 1.40249
I0708 01:02:01.357933 24447 solver.cpp:259]     Train net output #0: loss = 1.40249 (* 1 = 1.40249 loss)
I0708 01:02:01.357939 24447 solver.cpp:590] Iteration 4644, lr = 0.0034037
I0708 01:02:09.092334 24447 solver.cpp:243] Iteration 4671, loss = 2.13705
I0708 01:02:09.092358 24447 solver.cpp:259]     Train net output #0: loss = 2.13705 (* 1 = 2.13705 loss)
I0708 01:02:09.092365 24447 solver.cpp:590] Iteration 4671, lr = 0.00338244
I0708 01:02:16.806609 24447 solver.cpp:243] Iteration 4698, loss = 1.31185
I0708 01:02:16.806633 24447 solver.cpp:259]     Train net output #0: loss = 1.31185 (* 1 = 1.31185 loss)
I0708 01:02:16.806639 24447 solver.cpp:590] Iteration 4698, lr = 0.00336131
I0708 01:02:24.560902 24447 solver.cpp:243] Iteration 4725, loss = 1.59989
I0708 01:02:24.560930 24447 solver.cpp:259]     Train net output #0: loss = 1.59989 (* 1 = 1.59989 loss)
I0708 01:02:24.560935 24447 solver.cpp:590] Iteration 4725, lr = 0.00334031
I0708 01:02:32.320060 24447 solver.cpp:243] Iteration 4752, loss = 1.50448
I0708 01:02:32.320160 24447 solver.cpp:259]     Train net output #0: loss = 1.50448 (* 1 = 1.50448 loss)
I0708 01:02:32.320178 24447 solver.cpp:590] Iteration 4752, lr = 0.00331945
I0708 01:02:40.056784 24447 solver.cpp:243] Iteration 4779, loss = 1.4959
I0708 01:02:40.056810 24447 solver.cpp:259]     Train net output #0: loss = 1.4959 (* 1 = 1.4959 loss)
I0708 01:02:40.056816 24447 solver.cpp:590] Iteration 4779, lr = 0.00329871
I0708 01:02:47.825666 24447 solver.cpp:243] Iteration 4806, loss = 2.02477
I0708 01:02:47.825691 24447 solver.cpp:259]     Train net output #0: loss = 2.02477 (* 1 = 2.02477 loss)
I0708 01:02:47.825697 24447 solver.cpp:590] Iteration 4806, lr = 0.00327811
I0708 01:02:55.521426 24447 solver.cpp:243] Iteration 4833, loss = 1.82284
I0708 01:02:55.521453 24447 solver.cpp:259]     Train net output #0: loss = 1.82284 (* 1 = 1.82284 loss)
I0708 01:02:55.521461 24447 solver.cpp:590] Iteration 4833, lr = 0.00325763
I0708 01:03:03.218776 24447 solver.cpp:243] Iteration 4860, loss = 1.70294
I0708 01:03:03.218847 24447 solver.cpp:259]     Train net output #0: loss = 1.70294 (* 1 = 1.70294 loss)
I0708 01:03:03.218853 24447 solver.cpp:590] Iteration 4860, lr = 0.00323729
I0708 01:03:03.501850 24447 solver.cpp:347] Iteration 4862, Testing net (#0)
I0708 01:03:22.781582 24447 solver.cpp:415]     Test net output #0: accuracy = 0.38149
I0708 01:03:22.781606 24447 solver.cpp:415]     Test net output #1: loss = 3.36439 (* 1 = 3.36439 loss)
I0708 01:03:29.823745 24447 solver.cpp:243] Iteration 4887, loss = 1.71517
I0708 01:03:29.823776 24447 solver.cpp:259]     Train net output #0: loss = 1.71517 (* 1 = 1.71517 loss)
I0708 01:03:29.823783 24447 solver.cpp:590] Iteration 4887, lr = 0.00321707
I0708 01:03:38.015884 24447 solver.cpp:243] Iteration 4914, loss = 1.78102
I0708 01:03:38.016003 24447 solver.cpp:259]     Train net output #0: loss = 1.78102 (* 1 = 1.78102 loss)
I0708 01:03:38.016013 24447 solver.cpp:590] Iteration 4914, lr = 0.00319697
I0708 01:03:46.179070 24447 solver.cpp:243] Iteration 4941, loss = 1.53644
I0708 01:03:46.179100 24447 solver.cpp:259]     Train net output #0: loss = 1.53644 (* 1 = 1.53644 loss)
I0708 01:03:46.179108 24447 solver.cpp:590] Iteration 4941, lr = 0.003177
I0708 01:03:54.337602 24447 solver.cpp:243] Iteration 4968, loss = 1.72455
I0708 01:03:54.337632 24447 solver.cpp:259]     Train net output #0: loss = 1.72455 (* 1 = 1.72455 loss)
I0708 01:03:54.337641 24447 solver.cpp:590] Iteration 4968, lr = 0.00315716
I0708 01:04:02.535935 24447 solver.cpp:243] Iteration 4995, loss = 1.59949
I0708 01:04:02.535966 24447 solver.cpp:259]     Train net output #0: loss = 1.59949 (* 1 = 1.59949 loss)
I0708 01:04:02.535974 24447 solver.cpp:590] Iteration 4995, lr = 0.00313744
I0708 01:04:10.744540 24447 solver.cpp:243] Iteration 5022, loss = 1.42794
I0708 01:04:10.744668 24447 solver.cpp:259]     Train net output #0: loss = 1.42794 (* 1 = 1.42794 loss)
I0708 01:04:10.744676 24447 solver.cpp:590] Iteration 5022, lr = 0.00311784
I0708 01:04:18.867622 24447 solver.cpp:243] Iteration 5049, loss = 1.82587
I0708 01:04:18.867653 24447 solver.cpp:259]     Train net output #0: loss = 1.82587 (* 1 = 1.82587 loss)
I0708 01:04:18.867661 24447 solver.cpp:590] Iteration 5049, lr = 0.00309837
I0708 01:04:26.882182 24447 solver.cpp:243] Iteration 5076, loss = 1.65805
I0708 01:04:26.882208 24447 solver.cpp:259]     Train net output #0: loss = 1.65805 (* 1 = 1.65805 loss)
I0708 01:04:26.882215 24447 solver.cpp:590] Iteration 5076, lr = 0.00307901
I0708 01:04:28.602928 24447 solver.cpp:347] Iteration 5083, Testing net (#0)
I0708 01:04:35.864980 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:04:47.736233 24447 solver.cpp:415]     Test net output #0: accuracy = 0.383534
I0708 01:04:47.736332 24447 solver.cpp:415]     Test net output #1: loss = 3.36997 (* 1 = 3.36997 loss)
I0708 01:04:52.998445 24447 solver.cpp:243] Iteration 5103, loss = 2.01999
I0708 01:04:52.998468 24447 solver.cpp:259]     Train net output #0: loss = 2.01999 (* 1 = 2.01999 loss)
I0708 01:04:52.998474 24447 solver.cpp:590] Iteration 5103, lr = 0.00305978
I0708 01:05:01.408555 24447 solver.cpp:243] Iteration 5130, loss = 1.86815
I0708 01:05:01.408581 24447 solver.cpp:259]     Train net output #0: loss = 1.86815 (* 1 = 1.86815 loss)
I0708 01:05:01.408588 24447 solver.cpp:590] Iteration 5130, lr = 0.00304067
I0708 01:05:09.194020 24447 solver.cpp:243] Iteration 5157, loss = 2.24931
I0708 01:05:09.194042 24447 solver.cpp:259]     Train net output #0: loss = 2.24931 (* 1 = 2.24931 loss)
I0708 01:05:09.194048 24447 solver.cpp:590] Iteration 5157, lr = 0.00302168
I0708 01:05:17.911959 24447 solver.cpp:243] Iteration 5184, loss = 1.6627
I0708 01:05:17.912030 24447 solver.cpp:259]     Train net output #0: loss = 1.6627 (* 1 = 1.6627 loss)
I0708 01:05:17.912041 24447 solver.cpp:590] Iteration 5184, lr = 0.0030028
I0708 01:05:25.637349 24447 solver.cpp:243] Iteration 5211, loss = 1.96143
I0708 01:05:25.637375 24447 solver.cpp:259]     Train net output #0: loss = 1.96143 (* 1 = 1.96143 loss)
I0708 01:05:25.637382 24447 solver.cpp:590] Iteration 5211, lr = 0.00298404
I0708 01:05:34.027801 24447 solver.cpp:243] Iteration 5238, loss = 2.13243
I0708 01:05:34.027827 24447 solver.cpp:259]     Train net output #0: loss = 2.13243 (* 1 = 2.13243 loss)
I0708 01:05:34.027833 24447 solver.cpp:590] Iteration 5238, lr = 0.00296541
I0708 01:05:43.089572 24447 solver.cpp:243] Iteration 5265, loss = 1.7113
I0708 01:05:43.089596 24447 solver.cpp:259]     Train net output #0: loss = 1.7113 (* 1 = 1.7113 loss)
I0708 01:05:43.089602 24447 solver.cpp:590] Iteration 5265, lr = 0.00294688
I0708 01:05:52.161381 24447 solver.cpp:243] Iteration 5292, loss = 1.37061
I0708 01:05:52.161514 24447 solver.cpp:259]     Train net output #0: loss = 1.37061 (* 1 = 1.37061 loss)
I0708 01:05:52.161521 24447 solver.cpp:590] Iteration 5292, lr = 0.00292848
I0708 01:05:55.341482 24447 solver.cpp:347] Iteration 5304, Testing net (#0)
I0708 01:06:14.492527 24447 solver.cpp:415]     Test net output #0: accuracy = 0.382572
I0708 01:06:14.492552 24447 solver.cpp:415]     Test net output #1: loss = 3.35744 (* 1 = 3.35744 loss)
I0708 01:06:18.273397 24447 solver.cpp:243] Iteration 5319, loss = 1.67365
I0708 01:06:18.273424 24447 solver.cpp:259]     Train net output #0: loss = 1.67365 (* 1 = 1.67365 loss)
I0708 01:06:18.273432 24447 solver.cpp:590] Iteration 5319, lr = 0.00291018
I0708 01:06:26.017640 24447 solver.cpp:243] Iteration 5346, loss = 1.71835
I0708 01:06:26.017693 24447 solver.cpp:259]     Train net output #0: loss = 1.71835 (* 1 = 1.71835 loss)
I0708 01:06:26.017700 24447 solver.cpp:590] Iteration 5346, lr = 0.00289201
I0708 01:06:33.722952 24447 solver.cpp:243] Iteration 5373, loss = 1.72245
I0708 01:06:33.722980 24447 solver.cpp:259]     Train net output #0: loss = 1.72245 (* 1 = 1.72245 loss)
I0708 01:06:33.722985 24447 solver.cpp:590] Iteration 5373, lr = 0.00287394
I0708 01:06:41.448814 24447 solver.cpp:243] Iteration 5400, loss = 1.42339
I0708 01:06:41.448839 24447 solver.cpp:259]     Train net output #0: loss = 1.42339 (* 1 = 1.42339 loss)
I0708 01:06:41.448846 24447 solver.cpp:590] Iteration 5400, lr = 0.00285599
I0708 01:06:49.169533 24447 solver.cpp:243] Iteration 5427, loss = 1.61856
I0708 01:06:49.169559 24447 solver.cpp:259]     Train net output #0: loss = 1.61856 (* 1 = 1.61856 loss)
I0708 01:06:49.169565 24447 solver.cpp:590] Iteration 5427, lr = 0.00283815
I0708 01:06:56.982082 24447 solver.cpp:243] Iteration 5454, loss = 1.36382
I0708 01:06:56.982218 24447 solver.cpp:259]     Train net output #0: loss = 1.36382 (* 1 = 1.36382 loss)
I0708 01:06:56.982226 24447 solver.cpp:590] Iteration 5454, lr = 0.00282042
I0708 01:07:04.763559 24447 solver.cpp:243] Iteration 5481, loss = 1.91756
I0708 01:07:04.763584 24447 solver.cpp:259]     Train net output #0: loss = 1.91756 (* 1 = 1.91756 loss)
I0708 01:07:04.763591 24447 solver.cpp:590] Iteration 5481, lr = 0.00280281
I0708 01:07:12.583245 24447 solver.cpp:243] Iteration 5508, loss = 1.71569
I0708 01:07:12.583271 24447 solver.cpp:259]     Train net output #0: loss = 1.71569 (* 1 = 1.71569 loss)
I0708 01:07:12.583278 24447 solver.cpp:590] Iteration 5508, lr = 0.0027853
I0708 01:07:17.126312 24447 solver.cpp:347] Iteration 5525, Testing net (#0)
I0708 01:07:28.242033 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:07:36.279605 24447 solver.cpp:415]     Test net output #0: accuracy = 0.388221
I0708 01:07:36.279633 24447 solver.cpp:415]     Test net output #1: loss = 3.32251 (* 1 = 3.32251 loss)
I0708 01:07:38.646567 24447 solver.cpp:243] Iteration 5535, loss = 1.66008
I0708 01:07:38.646591 24447 solver.cpp:259]     Train net output #0: loss = 1.66008 (* 1 = 1.66008 loss)
I0708 01:07:38.646597 24447 solver.cpp:590] Iteration 5535, lr = 0.0027679
I0708 01:07:46.416267 24447 solver.cpp:243] Iteration 5562, loss = 1.3171
I0708 01:07:46.416290 24447 solver.cpp:259]     Train net output #0: loss = 1.3171 (* 1 = 1.3171 loss)
I0708 01:07:46.416296 24447 solver.cpp:590] Iteration 5562, lr = 0.00275061
I0708 01:07:54.191457 24447 solver.cpp:243] Iteration 5589, loss = 1.34033
I0708 01:07:54.191483 24447 solver.cpp:259]     Train net output #0: loss = 1.34033 (* 1 = 1.34033 loss)
I0708 01:07:54.191488 24447 solver.cpp:590] Iteration 5589, lr = 0.00273343
I0708 01:08:01.959383 24447 solver.cpp:243] Iteration 5616, loss = 1.89467
I0708 01:08:01.959499 24447 solver.cpp:259]     Train net output #0: loss = 1.89467 (* 1 = 1.89467 loss)
I0708 01:08:01.959507 24447 solver.cpp:590] Iteration 5616, lr = 0.00271636
I0708 01:08:09.718154 24447 solver.cpp:243] Iteration 5643, loss = 1.68686
I0708 01:08:09.718181 24447 solver.cpp:259]     Train net output #0: loss = 1.68686 (* 1 = 1.68686 loss)
I0708 01:08:09.718188 24447 solver.cpp:590] Iteration 5643, lr = 0.00269939
I0708 01:08:17.488049 24447 solver.cpp:243] Iteration 5670, loss = 1.45816
I0708 01:08:17.488075 24447 solver.cpp:259]     Train net output #0: loss = 1.45816 (* 1 = 1.45816 loss)
I0708 01:08:17.488080 24447 solver.cpp:590] Iteration 5670, lr = 0.00268253
I0708 01:08:25.200043 24447 solver.cpp:243] Iteration 5697, loss = 1.56857
I0708 01:08:25.200094 24447 solver.cpp:259]     Train net output #0: loss = 1.56857 (* 1 = 1.56857 loss)
I0708 01:08:25.200103 24447 solver.cpp:590] Iteration 5697, lr = 0.00266577
I0708 01:08:32.900815 24447 solver.cpp:243] Iteration 5724, loss = 1.86614
I0708 01:08:32.900881 24447 solver.cpp:259]     Train net output #0: loss = 1.86614 (* 1 = 1.86614 loss)
I0708 01:08:32.900888 24447 solver.cpp:590] Iteration 5724, lr = 0.00264912
I0708 01:08:38.877888 24447 solver.cpp:347] Iteration 5746, Testing net (#0)
I0708 01:08:58.008641 24447 solver.cpp:415]     Test net output #0: accuracy = 0.390264
I0708 01:08:58.008664 24447 solver.cpp:415]     Test net output #1: loss = 3.29935 (* 1 = 3.29935 loss)
I0708 01:08:58.928947 24447 solver.cpp:243] Iteration 5751, loss = 1.49376
I0708 01:08:58.928972 24447 solver.cpp:259]     Train net output #0: loss = 1.49376 (* 1 = 1.49376 loss)
I0708 01:08:58.928979 24447 solver.cpp:590] Iteration 5751, lr = 0.00263258
I0708 01:09:06.682763 24447 solver.cpp:243] Iteration 5778, loss = 1.52995
I0708 01:09:06.682842 24447 solver.cpp:259]     Train net output #0: loss = 1.52995 (* 1 = 1.52995 loss)
I0708 01:09:06.682850 24447 solver.cpp:590] Iteration 5778, lr = 0.00261613
I0708 01:09:14.452687 24447 solver.cpp:243] Iteration 5805, loss = 1.67787
I0708 01:09:14.452711 24447 solver.cpp:259]     Train net output #0: loss = 1.67787 (* 1 = 1.67787 loss)
I0708 01:09:14.452718 24447 solver.cpp:590] Iteration 5805, lr = 0.00259979
I0708 01:09:22.197726 24447 solver.cpp:243] Iteration 5832, loss = 1.27056
I0708 01:09:22.197751 24447 solver.cpp:259]     Train net output #0: loss = 1.27056 (* 1 = 1.27056 loss)
I0708 01:09:22.197757 24447 solver.cpp:590] Iteration 5832, lr = 0.00258355
I0708 01:09:29.895639 24447 solver.cpp:243] Iteration 5859, loss = 1.25146
I0708 01:09:29.895664 24447 solver.cpp:259]     Train net output #0: loss = 1.25146 (* 1 = 1.25146 loss)
I0708 01:09:29.895671 24447 solver.cpp:590] Iteration 5859, lr = 0.00256742
I0708 01:09:37.642211 24447 solver.cpp:243] Iteration 5886, loss = 2.10386
I0708 01:09:37.642293 24447 solver.cpp:259]     Train net output #0: loss = 2.10386 (* 1 = 2.10386 loss)
I0708 01:09:37.642300 24447 solver.cpp:590] Iteration 5886, lr = 0.00255138
I0708 01:09:45.395150 24447 solver.cpp:243] Iteration 5913, loss = 1.24403
I0708 01:09:45.395177 24447 solver.cpp:259]     Train net output #0: loss = 1.24403 (* 1 = 1.24403 loss)
I0708 01:09:45.395184 24447 solver.cpp:590] Iteration 5913, lr = 0.00253544
I0708 01:09:53.152565 24447 solver.cpp:243] Iteration 5940, loss = 1.64862
I0708 01:09:53.152593 24447 solver.cpp:259]     Train net output #0: loss = 1.64862 (* 1 = 1.64862 loss)
I0708 01:09:53.152601 24447 solver.cpp:590] Iteration 5940, lr = 0.00251961
I0708 01:10:00.599539 24447 solver.cpp:347] Iteration 5967, Testing net (#0)
I0708 01:10:15.570266 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:10:19.740438 24447 solver.cpp:415]     Test net output #0: accuracy = 0.391106
I0708 01:10:19.740466 24447 solver.cpp:415]     Test net output #1: loss = 3.29746 (* 1 = 3.29746 loss)
I0708 01:10:19.797693 24447 solver.cpp:243] Iteration 5967, loss = 1.23016
I0708 01:10:19.797722 24447 solver.cpp:259]     Train net output #0: loss = 1.23016 (* 1 = 1.23016 loss)
I0708 01:10:19.797731 24447 solver.cpp:590] Iteration 5967, lr = 0.00250387
I0708 01:10:26.999131 24447 solver.cpp:243] Iteration 5994, loss = 1.57223
I0708 01:10:26.999156 24447 solver.cpp:259]     Train net output #0: loss = 1.57223 (* 1 = 1.57223 loss)
I0708 01:10:26.999162 24447 solver.cpp:590] Iteration 5994, lr = 0.00248823
I0708 01:10:34.740648 24447 solver.cpp:243] Iteration 6021, loss = 1.4657
I0708 01:10:34.740676 24447 solver.cpp:259]     Train net output #0: loss = 1.4657 (* 1 = 1.4657 loss)
I0708 01:10:34.740682 24447 solver.cpp:590] Iteration 6021, lr = 0.00247269
I0708 01:10:42.435364 24447 solver.cpp:243] Iteration 6048, loss = 1.55478
I0708 01:10:42.435390 24447 solver.cpp:259]     Train net output #0: loss = 1.55478 (* 1 = 1.55478 loss)
I0708 01:10:42.435396 24447 solver.cpp:590] Iteration 6048, lr = 0.00245724
I0708 01:10:50.118280 24447 solver.cpp:243] Iteration 6075, loss = 1.61863
I0708 01:10:50.118341 24447 solver.cpp:259]     Train net output #0: loss = 1.61863 (* 1 = 1.61863 loss)
I0708 01:10:50.118348 24447 solver.cpp:590] Iteration 6075, lr = 0.00244189
I0708 01:10:57.834005 24447 solver.cpp:243] Iteration 6102, loss = 1.45063
I0708 01:10:57.834033 24447 solver.cpp:259]     Train net output #0: loss = 1.45063 (* 1 = 1.45063 loss)
I0708 01:10:57.834039 24447 solver.cpp:590] Iteration 6102, lr = 0.00242664
I0708 01:11:05.550606 24447 solver.cpp:243] Iteration 6129, loss = 1.41992
I0708 01:11:05.550631 24447 solver.cpp:259]     Train net output #0: loss = 1.41992 (* 1 = 1.41992 loss)
I0708 01:11:05.550637 24447 solver.cpp:590] Iteration 6129, lr = 0.00241148
I0708 01:11:13.256379 24447 solver.cpp:243] Iteration 6156, loss = 1.28735
I0708 01:11:13.256404 24447 solver.cpp:259]     Train net output #0: loss = 1.28735 (* 1 = 1.28735 loss)
I0708 01:11:13.256410 24447 solver.cpp:590] Iteration 6156, lr = 0.00239642
I0708 01:11:20.968628 24447 solver.cpp:243] Iteration 6183, loss = 1.37455
I0708 01:11:20.968731 24447 solver.cpp:259]     Train net output #0: loss = 1.37455 (* 1 = 1.37455 loss)
I0708 01:11:20.968739 24447 solver.cpp:590] Iteration 6183, lr = 0.00238145
I0708 01:11:22.116482 24447 solver.cpp:347] Iteration 6188, Testing net (#0)
I0708 01:11:41.184419 24447 solver.cpp:415]     Test net output #0: accuracy = 0.396274
I0708 01:11:41.184445 24447 solver.cpp:415]     Test net output #1: loss = 3.26416 (* 1 = 3.26416 loss)
I0708 01:11:46.997550 24447 solver.cpp:243] Iteration 6210, loss = 1.5938
I0708 01:11:46.997575 24447 solver.cpp:259]     Train net output #0: loss = 1.5938 (* 1 = 1.5938 loss)
I0708 01:11:46.997581 24447 solver.cpp:590] Iteration 6210, lr = 0.00236658
I0708 01:11:54.769326 24447 solver.cpp:243] Iteration 6237, loss = 1.26208
I0708 01:11:54.769412 24447 solver.cpp:259]     Train net output #0: loss = 1.26208 (* 1 = 1.26208 loss)
I0708 01:11:54.769428 24447 solver.cpp:590] Iteration 6237, lr = 0.00235179
I0708 01:12:02.537102 24447 solver.cpp:243] Iteration 6264, loss = 1.43845
I0708 01:12:02.537127 24447 solver.cpp:259]     Train net output #0: loss = 1.43845 (* 1 = 1.43845 loss)
I0708 01:12:02.537133 24447 solver.cpp:590] Iteration 6264, lr = 0.0023371
I0708 01:12:10.318558 24447 solver.cpp:243] Iteration 6291, loss = 1.43063
I0708 01:12:10.318591 24447 solver.cpp:259]     Train net output #0: loss = 1.43063 (* 1 = 1.43063 loss)
I0708 01:12:10.318608 24447 solver.cpp:590] Iteration 6291, lr = 0.00232251
I0708 01:12:18.098842 24447 solver.cpp:243] Iteration 6318, loss = 1.44209
I0708 01:12:18.098868 24447 solver.cpp:259]     Train net output #0: loss = 1.44209 (* 1 = 1.44209 loss)
I0708 01:12:18.098873 24447 solver.cpp:590] Iteration 6318, lr = 0.002308
I0708 01:12:25.884871 24447 solver.cpp:243] Iteration 6345, loss = 1.33474
I0708 01:12:25.884927 24447 solver.cpp:259]     Train net output #0: loss = 1.33474 (* 1 = 1.33474 loss)
I0708 01:12:25.884933 24447 solver.cpp:590] Iteration 6345, lr = 0.00229358
I0708 01:12:33.629546 24447 solver.cpp:243] Iteration 6372, loss = 1.59212
I0708 01:12:33.629571 24447 solver.cpp:259]     Train net output #0: loss = 1.59212 (* 1 = 1.59212 loss)
I0708 01:12:33.629577 24447 solver.cpp:590] Iteration 6372, lr = 0.00227926
I0708 01:12:41.392091 24447 solver.cpp:243] Iteration 6399, loss = 1.46379
I0708 01:12:41.392117 24447 solver.cpp:259]     Train net output #0: loss = 1.46379 (* 1 = 1.46379 loss)
I0708 01:12:41.392122 24447 solver.cpp:590] Iteration 6399, lr = 0.00226502
I0708 01:12:43.972744 24447 solver.cpp:347] Iteration 6409, Testing net (#0)
I0708 01:13:02.750968 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:13:03.041888 24447 solver.cpp:415]     Test net output #0: accuracy = 0.391827
I0708 01:13:03.041913 24447 solver.cpp:415]     Test net output #1: loss = 3.25046 (* 1 = 3.25046 loss)
I0708 01:13:07.379279 24447 solver.cpp:243] Iteration 6426, loss = 1.35652
I0708 01:13:07.379309 24447 solver.cpp:259]     Train net output #0: loss = 1.35652 (* 1 = 1.35652 loss)
I0708 01:13:07.379315 24447 solver.cpp:590] Iteration 6426, lr = 0.00225087
I0708 01:13:15.082059 24447 solver.cpp:243] Iteration 6453, loss = 1.58542
I0708 01:13:15.082085 24447 solver.cpp:259]     Train net output #0: loss = 1.58542 (* 1 = 1.58542 loss)
I0708 01:13:15.082092 24447 solver.cpp:590] Iteration 6453, lr = 0.00223681
I0708 01:13:22.814668 24447 solver.cpp:243] Iteration 6480, loss = 1.41703
I0708 01:13:22.814692 24447 solver.cpp:259]     Train net output #0: loss = 1.41703 (* 1 = 1.41703 loss)
I0708 01:13:22.814699 24447 solver.cpp:590] Iteration 6480, lr = 0.00222284
I0708 01:13:30.572717 24447 solver.cpp:243] Iteration 6507, loss = 1.46065
I0708 01:13:30.572743 24447 solver.cpp:259]     Train net output #0: loss = 1.46065 (* 1 = 1.46065 loss)
I0708 01:13:30.572749 24447 solver.cpp:590] Iteration 6507, lr = 0.00220896
I0708 01:13:38.296528 24447 solver.cpp:243] Iteration 6534, loss = 1.31637
I0708 01:13:38.296636 24447 solver.cpp:259]     Train net output #0: loss = 1.31637 (* 1 = 1.31637 loss)
I0708 01:13:38.296644 24447 solver.cpp:590] Iteration 6534, lr = 0.00219516
I0708 01:13:46.015568 24447 solver.cpp:243] Iteration 6561, loss = 1.05992
I0708 01:13:46.015593 24447 solver.cpp:259]     Train net output #0: loss = 1.05992 (* 1 = 1.05992 loss)
I0708 01:13:46.015599 24447 solver.cpp:590] Iteration 6561, lr = 0.00218145
I0708 01:13:53.692108 24447 solver.cpp:243] Iteration 6588, loss = 1.42839
I0708 01:13:53.692134 24447 solver.cpp:259]     Train net output #0: loss = 1.42839 (* 1 = 1.42839 loss)
I0708 01:13:53.692142 24447 solver.cpp:590] Iteration 6588, lr = 0.00216782
I0708 01:14:01.385301 24447 solver.cpp:243] Iteration 6615, loss = 1.16512
I0708 01:14:01.385327 24447 solver.cpp:259]     Train net output #0: loss = 1.16512 (* 1 = 1.16512 loss)
I0708 01:14:01.385334 24447 solver.cpp:590] Iteration 6615, lr = 0.00215428
I0708 01:14:05.365428 24447 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_6630.caffemodel
I0708 01:14:08.055152 24447 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_6630.solverstate
I0708 01:14:09.150452 24447 solver.cpp:347] Iteration 6630, Testing net (#0)
I0708 01:14:28.313966 24447 solver.cpp:415]     Test net output #0: accuracy = 0.395673
I0708 01:14:28.313990 24447 solver.cpp:415]     Test net output #1: loss = 3.24206 (* 1 = 3.24206 loss)
I0708 01:14:31.286039 24447 solver.cpp:243] Iteration 6642, loss = 1.40522
I0708 01:14:31.286067 24447 solver.cpp:259]     Train net output #0: loss = 1.40522 (* 1 = 1.40522 loss)
I0708 01:14:31.286073 24447 solver.cpp:590] Iteration 6642, lr = 0.00214082
I0708 01:14:38.991122 24447 solver.cpp:243] Iteration 6669, loss = 1.31125
I0708 01:14:38.991149 24447 solver.cpp:259]     Train net output #0: loss = 1.31125 (* 1 = 1.31125 loss)
I0708 01:14:38.991155 24447 solver.cpp:590] Iteration 6669, lr = 0.00212745
I0708 01:14:46.697924 24447 solver.cpp:243] Iteration 6696, loss = 1.14912
I0708 01:14:46.698009 24447 solver.cpp:259]     Train net output #0: loss = 1.14912 (* 1 = 1.14912 loss)
I0708 01:14:46.698015 24447 solver.cpp:590] Iteration 6696, lr = 0.00211416
I0708 01:14:54.426663 24447 solver.cpp:243] Iteration 6723, loss = 1.24249
I0708 01:14:54.426690 24447 solver.cpp:259]     Train net output #0: loss = 1.24249 (* 1 = 1.24249 loss)
I0708 01:14:54.426697 24447 solver.cpp:590] Iteration 6723, lr = 0.00210096
I0708 01:15:02.145474 24447 solver.cpp:243] Iteration 6750, loss = 1.31036
I0708 01:15:02.145499 24447 solver.cpp:259]     Train net output #0: loss = 1.31036 (* 1 = 1.31036 loss)
I0708 01:15:02.145505 24447 solver.cpp:590] Iteration 6750, lr = 0.00208783
I0708 01:15:09.916067 24447 solver.cpp:243] Iteration 6777, loss = 1.41034
I0708 01:15:09.916093 24447 solver.cpp:259]     Train net output #0: loss = 1.41034 (* 1 = 1.41034 loss)
I0708 01:15:09.916100 24447 solver.cpp:590] Iteration 6777, lr = 0.00207479
I0708 01:15:17.673122 24447 solver.cpp:243] Iteration 6804, loss = 1.11354
I0708 01:15:17.673195 24447 solver.cpp:259]     Train net output #0: loss = 1.11354 (* 1 = 1.11354 loss)
I0708 01:15:17.673213 24447 solver.cpp:590] Iteration 6804, lr = 0.00206183
I0708 01:15:25.418776 24447 solver.cpp:243] Iteration 6831, loss = 1.30813
I0708 01:15:25.418812 24447 solver.cpp:259]     Train net output #0: loss = 1.30813 (* 1 = 1.30813 loss)
I0708 01:15:25.418817 24447 solver.cpp:590] Iteration 6831, lr = 0.00204895
I0708 01:15:30.846959 24447 solver.cpp:347] Iteration 6851, Testing net (#0)
I0708 01:15:49.981941 24447 solver.cpp:415]     Test net output #0: accuracy = 0.396995
I0708 01:15:49.981997 24447 solver.cpp:415]     Test net output #1: loss = 3.23434 (* 1 = 3.23434 loss)
I0708 01:15:51.468705 24447 solver.cpp:243] Iteration 6858, loss = 1.13797
I0708 01:15:51.468732 24447 solver.cpp:259]     Train net output #0: loss = 1.13797 (* 1 = 1.13797 loss)
I0708 01:15:51.468739 24447 solver.cpp:590] Iteration 6858, lr = 0.00203616
I0708 01:15:59.172093 24447 solver.cpp:243] Iteration 6885, loss = 1.10058
I0708 01:15:59.172119 24447 solver.cpp:259]     Train net output #0: loss = 1.10058 (* 1 = 1.10058 loss)
I0708 01:15:59.172125 24447 solver.cpp:590] Iteration 6885, lr = 0.00202344
I0708 01:16:03.734736 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:16:06.871688 24447 solver.cpp:243] Iteration 6912, loss = 1.16704
I0708 01:16:06.871714 24447 solver.cpp:259]     Train net output #0: loss = 1.16704 (* 1 = 1.16704 loss)
I0708 01:16:06.871721 24447 solver.cpp:590] Iteration 6912, lr = 0.0020108
I0708 01:16:14.615954 24447 solver.cpp:243] Iteration 6939, loss = 1.40381
I0708 01:16:14.615980 24447 solver.cpp:259]     Train net output #0: loss = 1.40381 (* 1 = 1.40381 loss)
I0708 01:16:14.615988 24447 solver.cpp:590] Iteration 6939, lr = 0.00199824
I0708 01:16:22.331665 24447 solver.cpp:243] Iteration 6966, loss = 1.46072
I0708 01:16:22.331774 24447 solver.cpp:259]     Train net output #0: loss = 1.46072 (* 1 = 1.46072 loss)
I0708 01:16:22.331782 24447 solver.cpp:590] Iteration 6966, lr = 0.00198576
I0708 01:16:30.633534 24447 solver.cpp:243] Iteration 6993, loss = 1.52313
I0708 01:16:30.633563 24447 solver.cpp:259]     Train net output #0: loss = 1.52313 (* 1 = 1.52313 loss)
I0708 01:16:30.633579 24447 solver.cpp:590] Iteration 6993, lr = 0.00197335
I0708 01:16:38.324062 24447 solver.cpp:243] Iteration 7020, loss = 1.2306
I0708 01:16:38.324087 24447 solver.cpp:259]     Train net output #0: loss = 1.2306 (* 1 = 1.2306 loss)
I0708 01:16:38.324093 24447 solver.cpp:590] Iteration 7020, lr = 0.00196103
I0708 01:16:46.001008 24447 solver.cpp:243] Iteration 7047, loss = 1.44802
I0708 01:16:46.001032 24447 solver.cpp:259]     Train net output #0: loss = 1.44802 (* 1 = 1.44802 loss)
I0708 01:16:46.001039 24447 solver.cpp:590] Iteration 7047, lr = 0.00194878
I0708 01:16:52.812037 24447 solver.cpp:347] Iteration 7072, Testing net (#0)
I0708 01:17:11.945739 24447 solver.cpp:415]     Test net output #0: accuracy = 0.397957
I0708 01:17:11.945765 24447 solver.cpp:415]     Test net output #1: loss = 3.22714 (* 1 = 3.22714 loss)
I0708 01:17:12.147258 24447 solver.cpp:243] Iteration 7074, loss = 1.34493
I0708 01:17:12.147282 24447 solver.cpp:259]     Train net output #0: loss = 1.34493 (* 1 = 1.34493 loss)
I0708 01:17:12.147292 24447 solver.cpp:590] Iteration 7074, lr = 0.00193661
I0708 01:17:19.684193 24447 solver.cpp:243] Iteration 7101, loss = 1.14484
I0708 01:17:19.684218 24447 solver.cpp:259]     Train net output #0: loss = 1.14484 (* 1 = 1.14484 loss)
I0708 01:17:19.684224 24447 solver.cpp:590] Iteration 7101, lr = 0.00192451
I0708 01:17:27.372017 24447 solver.cpp:243] Iteration 7128, loss = 1.32075
I0708 01:17:27.372087 24447 solver.cpp:259]     Train net output #0: loss = 1.32075 (* 1 = 1.32075 loss)
I0708 01:17:27.372094 24447 solver.cpp:590] Iteration 7128, lr = 0.00191249
I0708 01:17:35.076930 24447 solver.cpp:243] Iteration 7155, loss = 1.11159
I0708 01:17:35.076956 24447 solver.cpp:259]     Train net output #0: loss = 1.11159 (* 1 = 1.11159 loss)
I0708 01:17:35.076962 24447 solver.cpp:590] Iteration 7155, lr = 0.00190054
I0708 01:17:42.752820 24447 solver.cpp:243] Iteration 7182, loss = 1.35972
I0708 01:17:42.752845 24447 solver.cpp:259]     Train net output #0: loss = 1.35972 (* 1 = 1.35972 loss)
I0708 01:17:42.752851 24447 solver.cpp:590] Iteration 7182, lr = 0.00188867
I0708 01:17:50.477291 24447 solver.cpp:243] Iteration 7209, loss = 1.35179
I0708 01:17:50.477318 24447 solver.cpp:259]     Train net output #0: loss = 1.35179 (* 1 = 1.35179 loss)
I0708 01:17:50.477324 24447 solver.cpp:590] Iteration 7209, lr = 0.00187688
I0708 01:17:58.178297 24447 solver.cpp:243] Iteration 7236, loss = 1.33197
I0708 01:17:58.178354 24447 solver.cpp:259]     Train net output #0: loss = 1.33197 (* 1 = 1.33197 loss)
I0708 01:17:58.178360 24447 solver.cpp:590] Iteration 7236, lr = 0.00186515
I0708 01:18:05.918057 24447 solver.cpp:243] Iteration 7263, loss = 1.12551
I0708 01:18:05.918082 24447 solver.cpp:259]     Train net output #0: loss = 1.12551 (* 1 = 1.12551 loss)
I0708 01:18:05.918089 24447 solver.cpp:590] Iteration 7263, lr = 0.0018535
I0708 01:18:13.626569 24447 solver.cpp:243] Iteration 7290, loss = 1.16393
I0708 01:18:13.626598 24447 solver.cpp:259]     Train net output #0: loss = 1.16393 (* 1 = 1.16393 loss)
I0708 01:18:13.626605 24447 solver.cpp:590] Iteration 7290, lr = 0.00184192
I0708 01:18:14.203351 24447 solver.cpp:347] Iteration 7293, Testing net (#0)
I0708 01:18:33.365406 24447 solver.cpp:415]     Test net output #0: accuracy = 0.396034
I0708 01:18:33.365484 24447 solver.cpp:415]     Test net output #1: loss = 3.21215 (* 1 = 3.21215 loss)
I0708 01:18:39.690923 24447 solver.cpp:243] Iteration 7317, loss = 1.00082
I0708 01:18:39.690950 24447 solver.cpp:259]     Train net output #0: loss = 1.00082 (* 1 = 1.00082 loss)
I0708 01:18:39.690956 24447 solver.cpp:590] Iteration 7317, lr = 0.00183042
I0708 01:18:47.394435 24447 solver.cpp:243] Iteration 7344, loss = 1.15723
I0708 01:18:47.394460 24447 solver.cpp:259]     Train net output #0: loss = 1.15723 (* 1 = 1.15723 loss)
I0708 01:18:47.394466 24447 solver.cpp:590] Iteration 7344, lr = 0.00181899
I0708 01:18:55.137697 24447 solver.cpp:243] Iteration 7371, loss = 1.55431
I0708 01:18:55.137722 24447 solver.cpp:259]     Train net output #0: loss = 1.55431 (* 1 = 1.55431 loss)
I0708 01:18:55.137729 24447 solver.cpp:590] Iteration 7371, lr = 0.00180762
I0708 01:19:01.976904 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:19:02.824715 24447 solver.cpp:243] Iteration 7398, loss = 1.26078
I0708 01:19:02.824740 24447 solver.cpp:259]     Train net output #0: loss = 1.26078 (* 1 = 1.26078 loss)
I0708 01:19:02.824748 24447 solver.cpp:590] Iteration 7398, lr = 0.00179633
I0708 01:19:10.554311 24447 solver.cpp:243] Iteration 7425, loss = 1.05571
I0708 01:19:10.554370 24447 solver.cpp:259]     Train net output #0: loss = 1.05571 (* 1 = 1.05571 loss)
I0708 01:19:10.554378 24447 solver.cpp:590] Iteration 7425, lr = 0.00178511
I0708 01:19:18.275372 24447 solver.cpp:243] Iteration 7452, loss = 1.36325
I0708 01:19:18.275395 24447 solver.cpp:259]     Train net output #0: loss = 1.36325 (* 1 = 1.36325 loss)
I0708 01:19:18.275401 24447 solver.cpp:590] Iteration 7452, lr = 0.00177396
I0708 01:19:26.013092 24447 solver.cpp:243] Iteration 7479, loss = 1.22323
I0708 01:19:26.013115 24447 solver.cpp:259]     Train net output #0: loss = 1.22323 (* 1 = 1.22323 loss)
I0708 01:19:26.013123 24447 solver.cpp:590] Iteration 7479, lr = 0.00176288
I0708 01:19:33.699817 24447 solver.cpp:243] Iteration 7506, loss = 1.13213
I0708 01:19:33.699838 24447 solver.cpp:259]     Train net output #0: loss = 1.13213 (* 1 = 1.13213 loss)
I0708 01:19:33.699844 24447 solver.cpp:590] Iteration 7506, lr = 0.00175187
I0708 01:19:35.706578 24447 solver.cpp:347] Iteration 7514, Testing net (#0)
I0708 01:19:54.824636 24447 solver.cpp:415]     Test net output #0: accuracy = 0.396274
I0708 01:19:54.824708 24447 solver.cpp:415]     Test net output #1: loss = 3.19992 (* 1 = 3.19992 loss)
I0708 01:19:59.735478 24447 solver.cpp:243] Iteration 7533, loss = 1.16178
I0708 01:19:59.735503 24447 solver.cpp:259]     Train net output #0: loss = 1.16178 (* 1 = 1.16178 loss)
I0708 01:19:59.735509 24447 solver.cpp:590] Iteration 7533, lr = 0.00174093
I0708 01:20:07.489989 24447 solver.cpp:243] Iteration 7560, loss = 1.71188
I0708 01:20:07.490015 24447 solver.cpp:259]     Train net output #0: loss = 1.71188 (* 1 = 1.71188 loss)
I0708 01:20:07.490021 24447 solver.cpp:590] Iteration 7560, lr = 0.00173005
I0708 01:20:15.258191 24447 solver.cpp:243] Iteration 7587, loss = 1.14001
I0708 01:20:15.258218 24447 solver.cpp:259]     Train net output #0: loss = 1.14001 (* 1 = 1.14001 loss)
I0708 01:20:15.258224 24447 solver.cpp:590] Iteration 7587, lr = 0.00171925
I0708 01:20:23.030745 24447 solver.cpp:243] Iteration 7614, loss = 1.29511
I0708 01:20:23.030773 24447 solver.cpp:259]     Train net output #0: loss = 1.29511 (* 1 = 1.29511 loss)
I0708 01:20:23.030781 24447 solver.cpp:590] Iteration 7614, lr = 0.00170851
I0708 01:20:30.809983 24447 solver.cpp:243] Iteration 7641, loss = 1.2653
I0708 01:20:30.810075 24447 solver.cpp:259]     Train net output #0: loss = 1.2653 (* 1 = 1.2653 loss)
I0708 01:20:30.810091 24447 solver.cpp:590] Iteration 7641, lr = 0.00169784
I0708 01:20:38.527133 24447 solver.cpp:243] Iteration 7668, loss = 1.28129
I0708 01:20:38.527160 24447 solver.cpp:259]     Train net output #0: loss = 1.28129 (* 1 = 1.28129 loss)
I0708 01:20:38.527168 24447 solver.cpp:590] Iteration 7668, lr = 0.00168723
I0708 01:20:46.198709 24447 solver.cpp:243] Iteration 7695, loss = 1.07599
I0708 01:20:46.198734 24447 solver.cpp:259]     Train net output #0: loss = 1.07599 (* 1 = 1.07599 loss)
I0708 01:20:46.198740 24447 solver.cpp:590] Iteration 7695, lr = 0.00167669
I0708 01:20:53.875397 24447 solver.cpp:243] Iteration 7722, loss = 1.24293
I0708 01:20:53.875424 24447 solver.cpp:259]     Train net output #0: loss = 1.24293 (* 1 = 1.24293 loss)
I0708 01:20:53.875430 24447 solver.cpp:590] Iteration 7722, lr = 0.00166622
I0708 01:20:57.335088 24447 solver.cpp:347] Iteration 7735, Testing net (#0)
I0708 01:21:16.522634 24447 solver.cpp:415]     Test net output #0: accuracy = 0.400361
I0708 01:21:16.522685 24447 solver.cpp:415]     Test net output #1: loss = 3.18272 (* 1 = 3.18272 loss)
I0708 01:21:20.016335 24447 solver.cpp:243] Iteration 7749, loss = 1.41602
I0708 01:21:20.016361 24447 solver.cpp:259]     Train net output #0: loss = 1.41602 (* 1 = 1.41602 loss)
I0708 01:21:20.016367 24447 solver.cpp:590] Iteration 7749, lr = 0.00165581
I0708 01:21:27.796782 24447 solver.cpp:243] Iteration 7776, loss = 1.1045
I0708 01:21:27.796823 24447 solver.cpp:259]     Train net output #0: loss = 1.1045 (* 1 = 1.1045 loss)
I0708 01:21:27.796831 24447 solver.cpp:590] Iteration 7776, lr = 0.00164547
I0708 01:21:35.580466 24447 solver.cpp:243] Iteration 7803, loss = 1.64393
I0708 01:21:35.580492 24447 solver.cpp:259]     Train net output #0: loss = 1.64393 (* 1 = 1.64393 loss)
I0708 01:21:35.580497 24447 solver.cpp:590] Iteration 7803, lr = 0.00163519
I0708 01:21:43.344815 24447 solver.cpp:243] Iteration 7830, loss = 1.3593
I0708 01:21:43.344843 24447 solver.cpp:259]     Train net output #0: loss = 1.3593 (* 1 = 1.3593 loss)
I0708 01:21:43.344861 24447 solver.cpp:590] Iteration 7830, lr = 0.00162498
I0708 01:21:51.061959 24447 solver.cpp:243] Iteration 7857, loss = 1.33708
I0708 01:21:51.062033 24447 solver.cpp:259]     Train net output #0: loss = 1.33708 (* 1 = 1.33708 loss)
I0708 01:21:51.062049 24447 solver.cpp:590] Iteration 7857, lr = 0.00161483
I0708 01:21:58.837927 24447 solver.cpp:243] Iteration 7884, loss = 1.29049
I0708 01:21:58.837954 24447 solver.cpp:259]     Train net output #0: loss = 1.29049 (* 1 = 1.29049 loss)
I0708 01:21:58.837960 24447 solver.cpp:590] Iteration 7884, lr = 0.00160474
I0708 01:22:00.271298 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:22:06.675276 24447 solver.cpp:243] Iteration 7911, loss = 1.26148
I0708 01:22:06.675304 24447 solver.cpp:259]     Train net output #0: loss = 1.26148 (* 1 = 1.26148 loss)
I0708 01:22:06.675310 24447 solver.cpp:590] Iteration 7911, lr = 0.00159472
I0708 01:22:14.486387 24447 solver.cpp:243] Iteration 7938, loss = 1.01584
I0708 01:22:14.486414 24447 solver.cpp:259]     Train net output #0: loss = 1.01584 (* 1 = 1.01584 loss)
I0708 01:22:14.486420 24447 solver.cpp:590] Iteration 7938, lr = 0.00158476
I0708 01:22:19.401360 24447 solver.cpp:347] Iteration 7956, Testing net (#0)
I0708 01:22:38.520187 24447 solver.cpp:415]     Test net output #0: accuracy = 0.400962
I0708 01:22:38.520248 24447 solver.cpp:415]     Test net output #1: loss = 3.18691 (* 1 = 3.18691 loss)
I0708 01:22:40.577714 24447 solver.cpp:243] Iteration 7965, loss = 1.15944
I0708 01:22:40.577749 24447 solver.cpp:259]     Train net output #0: loss = 1.15944 (* 1 = 1.15944 loss)
I0708 01:22:40.577756 24447 solver.cpp:590] Iteration 7965, lr = 0.00157486
I0708 01:22:48.406503 24447 solver.cpp:243] Iteration 7992, loss = 1.31909
I0708 01:22:48.406527 24447 solver.cpp:259]     Train net output #0: loss = 1.31909 (* 1 = 1.31909 loss)
I0708 01:22:48.406533 24447 solver.cpp:590] Iteration 7992, lr = 0.00156502
I0708 01:22:56.276808 24447 solver.cpp:243] Iteration 8019, loss = 1.37352
I0708 01:22:56.276837 24447 solver.cpp:259]     Train net output #0: loss = 1.37352 (* 1 = 1.37352 loss)
I0708 01:22:56.276844 24447 solver.cpp:590] Iteration 8019, lr = 0.00155525
I0708 01:23:04.131980 24447 solver.cpp:243] Iteration 8046, loss = 0.87562
I0708 01:23:04.132009 24447 solver.cpp:259]     Train net output #0: loss = 0.87562 (* 1 = 0.87562 loss)
I0708 01:23:04.132014 24447 solver.cpp:590] Iteration 8046, lr = 0.00154553
I0708 01:23:11.950292 24447 solver.cpp:243] Iteration 8073, loss = 1.25014
I0708 01:23:11.950399 24447 solver.cpp:259]     Train net output #0: loss = 1.25014 (* 1 = 1.25014 loss)
I0708 01:23:11.950407 24447 solver.cpp:590] Iteration 8073, lr = 0.00153588
I0708 01:23:19.810854 24447 solver.cpp:243] Iteration 8100, loss = 1.2176
I0708 01:23:19.810880 24447 solver.cpp:259]     Train net output #0: loss = 1.2176 (* 1 = 1.2176 loss)
I0708 01:23:19.810886 24447 solver.cpp:590] Iteration 8100, lr = 0.00152628
I0708 01:23:27.644598 24447 solver.cpp:243] Iteration 8127, loss = 1.7064
I0708 01:23:27.644637 24447 solver.cpp:259]     Train net output #0: loss = 1.7064 (* 1 = 1.7064 loss)
I0708 01:23:27.644644 24447 solver.cpp:590] Iteration 8127, lr = 0.00151675
I0708 01:23:35.401325 24447 solver.cpp:243] Iteration 8154, loss = 1.23005
I0708 01:23:35.401351 24447 solver.cpp:259]     Train net output #0: loss = 1.23005 (* 1 = 1.23005 loss)
I0708 01:23:35.401358 24447 solver.cpp:590] Iteration 8154, lr = 0.00150728
I0708 01:23:41.699097 24447 solver.cpp:347] Iteration 8177, Testing net (#0)
I0708 01:24:00.863385 24447 solver.cpp:415]     Test net output #0: accuracy = 0.398438
I0708 01:24:00.863483 24447 solver.cpp:415]     Test net output #1: loss = 3.17724 (* 1 = 3.17724 loss)
I0708 01:24:01.495458 24447 solver.cpp:243] Iteration 8181, loss = 1.25823
I0708 01:24:01.495484 24447 solver.cpp:259]     Train net output #0: loss = 1.25823 (* 1 = 1.25823 loss)
I0708 01:24:01.495491 24447 solver.cpp:590] Iteration 8181, lr = 0.00149786
I0708 01:24:09.307212 24447 solver.cpp:243] Iteration 8208, loss = 1.3416
I0708 01:24:09.307240 24447 solver.cpp:259]     Train net output #0: loss = 1.3416 (* 1 = 1.3416 loss)
I0708 01:24:09.307245 24447 solver.cpp:590] Iteration 8208, lr = 0.00148851
I0708 01:24:17.081957 24447 solver.cpp:243] Iteration 8235, loss = 1.23547
I0708 01:24:17.081984 24447 solver.cpp:259]     Train net output #0: loss = 1.23547 (* 1 = 1.23547 loss)
I0708 01:24:17.081990 24447 solver.cpp:590] Iteration 8235, lr = 0.00147921
I0708 01:24:24.798895 24447 solver.cpp:243] Iteration 8262, loss = 1.05254
I0708 01:24:24.798920 24447 solver.cpp:259]     Train net output #0: loss = 1.05254 (* 1 = 1.05254 loss)
I0708 01:24:24.798926 24447 solver.cpp:590] Iteration 8262, lr = 0.00146997
I0708 01:24:32.656713 24447 solver.cpp:243] Iteration 8289, loss = 1.10841
I0708 01:24:32.656780 24447 solver.cpp:259]     Train net output #0: loss = 1.10841 (* 1 = 1.10841 loss)
I0708 01:24:32.656786 24447 solver.cpp:590] Iteration 8289, lr = 0.00146079
I0708 01:24:40.376709 24447 solver.cpp:243] Iteration 8316, loss = 1.22106
I0708 01:24:40.376736 24447 solver.cpp:259]     Train net output #0: loss = 1.22106 (* 1 = 1.22106 loss)
I0708 01:24:40.376744 24447 solver.cpp:590] Iteration 8316, lr = 0.00145166
I0708 01:24:48.109755 24447 solver.cpp:243] Iteration 8343, loss = 1.03237
I0708 01:24:48.109779 24447 solver.cpp:259]     Train net output #0: loss = 1.03237 (* 1 = 1.03237 loss)
I0708 01:24:48.109786 24447 solver.cpp:590] Iteration 8343, lr = 0.00144259
I0708 01:24:55.796067 24447 solver.cpp:243] Iteration 8370, loss = 1.18321
I0708 01:24:55.796092 24447 solver.cpp:259]     Train net output #0: loss = 1.18321 (* 1 = 1.18321 loss)
I0708 01:24:55.796098 24447 solver.cpp:590] Iteration 8370, lr = 0.00143358
I0708 01:24:59.479121 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:25:03.465677 24447 solver.cpp:243] Iteration 8397, loss = 1.38715
I0708 01:25:03.465795 24447 solver.cpp:259]     Train net output #0: loss = 1.38715 (* 1 = 1.38715 loss)
I0708 01:25:03.465802 24447 solver.cpp:590] Iteration 8397, lr = 0.00142463
I0708 01:25:03.466014 24447 solver.cpp:347] Iteration 8398, Testing net (#0)
I0708 01:25:23.871803 24447 solver.cpp:415]     Test net output #0: accuracy = 0.40024
I0708 01:25:23.871825 24447 solver.cpp:415]     Test net output #1: loss = 3.18005 (* 1 = 3.18005 loss)
I0708 01:25:30.786342 24447 solver.cpp:243] Iteration 8424, loss = 1.47486
I0708 01:25:30.786370 24447 solver.cpp:259]     Train net output #0: loss = 1.47486 (* 1 = 1.47486 loss)
I0708 01:25:30.786376 24447 solver.cpp:590] Iteration 8424, lr = 0.00141573
I0708 01:25:38.992115 24447 solver.cpp:243] Iteration 8451, loss = 1.33737
I0708 01:25:38.992197 24447 solver.cpp:259]     Train net output #0: loss = 1.33737 (* 1 = 1.33737 loss)
I0708 01:25:38.992204 24447 solver.cpp:590] Iteration 8451, lr = 0.00140689
I0708 01:25:47.263901 24447 solver.cpp:243] Iteration 8478, loss = 1.15302
I0708 01:25:47.263939 24447 solver.cpp:259]     Train net output #0: loss = 1.15302 (* 1 = 1.15302 loss)
I0708 01:25:47.263945 24447 solver.cpp:590] Iteration 8478, lr = 0.0013981
I0708 01:25:56.005540 24447 solver.cpp:243] Iteration 8505, loss = 1.31028
I0708 01:25:56.005565 24447 solver.cpp:259]     Train net output #0: loss = 1.31028 (* 1 = 1.31028 loss)
I0708 01:25:56.005573 24447 solver.cpp:590] Iteration 8505, lr = 0.00138937
I0708 01:26:03.885447 24447 solver.cpp:243] Iteration 8532, loss = 1.5219
I0708 01:26:03.885473 24447 solver.cpp:259]     Train net output #0: loss = 1.5219 (* 1 = 1.5219 loss)
I0708 01:26:03.885479 24447 solver.cpp:590] Iteration 8532, lr = 0.00138069
I0708 01:26:11.790618 24447 solver.cpp:243] Iteration 8559, loss = 1.35259
I0708 01:26:11.790675 24447 solver.cpp:259]     Train net output #0: loss = 1.35259 (* 1 = 1.35259 loss)
I0708 01:26:11.790683 24447 solver.cpp:590] Iteration 8559, lr = 0.00137206
I0708 01:26:19.618126 24447 solver.cpp:243] Iteration 8586, loss = 1.24869
I0708 01:26:19.618152 24447 solver.cpp:259]     Train net output #0: loss = 1.24869 (* 1 = 1.24869 loss)
I0708 01:26:19.618158 24447 solver.cpp:590] Iteration 8586, lr = 0.00136349
I0708 01:26:27.435813 24447 solver.cpp:243] Iteration 8613, loss = 1.18747
I0708 01:26:27.435838 24447 solver.cpp:259]     Train net output #0: loss = 1.18747 (* 1 = 1.18747 loss)
I0708 01:26:27.435844 24447 solver.cpp:590] Iteration 8613, lr = 0.00135498
I0708 01:26:28.868343 24447 solver.cpp:347] Iteration 8619, Testing net (#0)
I0708 01:26:48.024026 24447 solver.cpp:415]     Test net output #0: accuracy = 0.398438
I0708 01:26:48.024083 24447 solver.cpp:415]     Test net output #1: loss = 3.17217 (* 1 = 3.17217 loss)
I0708 01:26:53.569248 24447 solver.cpp:243] Iteration 8640, loss = 1.15053
I0708 01:26:53.569272 24447 solver.cpp:259]     Train net output #0: loss = 1.15053 (* 1 = 1.15053 loss)
I0708 01:26:53.569278 24447 solver.cpp:590] Iteration 8640, lr = 0.00134651
I0708 01:27:01.269126 24447 solver.cpp:243] Iteration 8667, loss = 1.45209
I0708 01:27:01.269150 24447 solver.cpp:259]     Train net output #0: loss = 1.45209 (* 1 = 1.45209 loss)
I0708 01:27:01.269155 24447 solver.cpp:590] Iteration 8667, lr = 0.0013381
I0708 01:27:09.098625 24447 solver.cpp:243] Iteration 8694, loss = 1.48658
I0708 01:27:09.098651 24447 solver.cpp:259]     Train net output #0: loss = 1.48658 (* 1 = 1.48658 loss)
I0708 01:27:09.098657 24447 solver.cpp:590] Iteration 8694, lr = 0.00132975
I0708 01:27:16.787385 24447 solver.cpp:243] Iteration 8721, loss = 1.28886
I0708 01:27:16.787412 24447 solver.cpp:259]     Train net output #0: loss = 1.28886 (* 1 = 1.28886 loss)
I0708 01:27:16.787418 24447 solver.cpp:590] Iteration 8721, lr = 0.00132144
I0708 01:27:24.714624 24447 solver.cpp:243] Iteration 8748, loss = 0.839031
I0708 01:27:24.714696 24447 solver.cpp:259]     Train net output #0: loss = 0.839031 (* 1 = 0.839031 loss)
I0708 01:27:24.714714 24447 solver.cpp:590] Iteration 8748, lr = 0.00131319
I0708 01:27:32.510251 24447 solver.cpp:243] Iteration 8775, loss = 1.06907
I0708 01:27:32.510277 24447 solver.cpp:259]     Train net output #0: loss = 1.06907 (* 1 = 1.06907 loss)
I0708 01:27:32.510283 24447 solver.cpp:590] Iteration 8775, lr = 0.00130498
I0708 01:27:40.251749 24447 solver.cpp:243] Iteration 8802, loss = 1.26076
I0708 01:27:40.251773 24447 solver.cpp:259]     Train net output #0: loss = 1.26076 (* 1 = 1.26076 loss)
I0708 01:27:40.251780 24447 solver.cpp:590] Iteration 8802, lr = 0.00129683
I0708 01:27:47.937387 24447 solver.cpp:243] Iteration 8829, loss = 1.19257
I0708 01:27:47.937412 24447 solver.cpp:259]     Train net output #0: loss = 1.19257 (* 1 = 1.19257 loss)
I0708 01:27:47.937418 24447 solver.cpp:590] Iteration 8829, lr = 0.00128873
I0708 01:27:50.795655 24447 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_8840.caffemodel
I0708 01:27:52.931151 24447 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_8840.solverstate
I0708 01:27:53.957126 24447 solver.cpp:347] Iteration 8840, Testing net (#0)
I0708 01:27:56.891472 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:28:13.084779 24447 solver.cpp:415]     Test net output #0: accuracy = 0.403846
I0708 01:28:13.084805 24447 solver.cpp:415]     Test net output #1: loss = 3.15817 (* 1 = 3.15817 loss)
I0708 01:28:17.179703 24447 solver.cpp:243] Iteration 8856, loss = 1.2693
I0708 01:28:17.179728 24447 solver.cpp:259]     Train net output #0: loss = 1.2693 (* 1 = 1.2693 loss)
I0708 01:28:17.179733 24447 solver.cpp:590] Iteration 8856, lr = 0.00128068
I0708 01:28:24.926667 24447 solver.cpp:243] Iteration 8883, loss = 1.30575
I0708 01:28:24.926694 24447 solver.cpp:259]     Train net output #0: loss = 1.30575 (* 1 = 1.30575 loss)
I0708 01:28:24.926702 24447 solver.cpp:590] Iteration 8883, lr = 0.00127268
I0708 01:28:32.636843 24447 solver.cpp:243] Iteration 8910, loss = 1.35268
I0708 01:28:32.636930 24447 solver.cpp:259]     Train net output #0: loss = 1.35268 (* 1 = 1.35268 loss)
I0708 01:28:32.636939 24447 solver.cpp:590] Iteration 8910, lr = 0.00126473
I0708 01:28:40.329223 24447 solver.cpp:243] Iteration 8937, loss = 1.1201
I0708 01:28:40.329248 24447 solver.cpp:259]     Train net output #0: loss = 1.1201 (* 1 = 1.1201 loss)
I0708 01:28:40.329254 24447 solver.cpp:590] Iteration 8937, lr = 0.00125683
I0708 01:28:48.032397 24447 solver.cpp:243] Iteration 8964, loss = 1.21996
I0708 01:28:48.032423 24447 solver.cpp:259]     Train net output #0: loss = 1.21996 (* 1 = 1.21996 loss)
I0708 01:28:48.032431 24447 solver.cpp:590] Iteration 8964, lr = 0.00124898
I0708 01:28:55.734472 24447 solver.cpp:243] Iteration 8991, loss = 1.32759
I0708 01:28:55.734498 24447 solver.cpp:259]     Train net output #0: loss = 1.32759 (* 1 = 1.32759 loss)
I0708 01:28:55.734504 24447 solver.cpp:590] Iteration 8991, lr = 0.00124118
I0708 01:29:03.427182 24447 solver.cpp:243] Iteration 9018, loss = 1.2969
I0708 01:29:03.427242 24447 solver.cpp:259]     Train net output #0: loss = 1.2969 (* 1 = 1.2969 loss)
I0708 01:29:03.427248 24447 solver.cpp:590] Iteration 9018, lr = 0.00123343
I0708 01:29:11.121132 24447 solver.cpp:243] Iteration 9045, loss = 1.18434
I0708 01:29:11.121158 24447 solver.cpp:259]     Train net output #0: loss = 1.18434 (* 1 = 1.18434 loss)
I0708 01:29:11.121165 24447 solver.cpp:590] Iteration 9045, lr = 0.00122572
I0708 01:29:15.389050 24447 solver.cpp:347] Iteration 9061, Testing net (#0)
I0708 01:29:34.512130 24447 solver.cpp:415]     Test net output #0: accuracy = 0.403726
I0708 01:29:34.512186 24447 solver.cpp:415]     Test net output #1: loss = 3.14058 (* 1 = 3.14058 loss)
I0708 01:29:37.131958 24447 solver.cpp:243] Iteration 9072, loss = 0.988769
I0708 01:29:37.131983 24447 solver.cpp:259]     Train net output #0: loss = 0.988769 (* 1 = 0.988769 loss)
I0708 01:29:37.131989 24447 solver.cpp:590] Iteration 9072, lr = 0.00121807
I0708 01:29:44.824079 24447 solver.cpp:243] Iteration 9099, loss = 1.35817
I0708 01:29:44.824107 24447 solver.cpp:259]     Train net output #0: loss = 1.35817 (* 1 = 1.35817 loss)
I0708 01:29:44.824113 24447 solver.cpp:590] Iteration 9099, lr = 0.00121046
I0708 01:29:52.530701 24447 solver.cpp:243] Iteration 9126, loss = 1.09494
I0708 01:29:52.530726 24447 solver.cpp:259]     Train net output #0: loss = 1.09494 (* 1 = 1.09494 loss)
I0708 01:29:52.530732 24447 solver.cpp:590] Iteration 9126, lr = 0.0012029
I0708 01:30:00.231184 24447 solver.cpp:243] Iteration 9153, loss = 1.17099
I0708 01:30:00.231209 24447 solver.cpp:259]     Train net output #0: loss = 1.17099 (* 1 = 1.17099 loss)
I0708 01:30:00.231215 24447 solver.cpp:590] Iteration 9153, lr = 0.00119539
I0708 01:30:07.995226 24447 solver.cpp:243] Iteration 9180, loss = 0.95399
I0708 01:30:07.995321 24447 solver.cpp:259]     Train net output #0: loss = 0.95399 (* 1 = 0.95399 loss)
I0708 01:30:07.995339 24447 solver.cpp:590] Iteration 9180, lr = 0.00118792
I0708 01:30:15.738064 24447 solver.cpp:243] Iteration 9207, loss = 1.40184
I0708 01:30:15.738091 24447 solver.cpp:259]     Train net output #0: loss = 1.40184 (* 1 = 1.40184 loss)
I0708 01:30:15.738098 24447 solver.cpp:590] Iteration 9207, lr = 0.0011805
I0708 01:30:23.430006 24447 solver.cpp:243] Iteration 9234, loss = 1.0114
I0708 01:30:23.430032 24447 solver.cpp:259]     Train net output #0: loss = 1.0114 (* 1 = 1.0114 loss)
I0708 01:30:23.430037 24447 solver.cpp:590] Iteration 9234, lr = 0.00117312
I0708 01:30:31.145264 24447 solver.cpp:243] Iteration 9261, loss = 1.07653
I0708 01:30:31.145290 24447 solver.cpp:259]     Train net output #0: loss = 1.07653 (* 1 = 1.07653 loss)
I0708 01:30:31.145297 24447 solver.cpp:590] Iteration 9261, lr = 0.0011658
I0708 01:30:36.885555 24447 solver.cpp:347] Iteration 9282, Testing net (#0)
I0708 01:30:43.683827 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:30:55.980876 24447 solver.cpp:415]     Test net output #0: accuracy = 0.400481
I0708 01:30:55.980901 24447 solver.cpp:415]     Test net output #1: loss = 3.1518 (* 1 = 3.1518 loss)
I0708 01:30:57.184381 24447 solver.cpp:243] Iteration 9288, loss = 1.06006
I0708 01:30:57.184407 24447 solver.cpp:259]     Train net output #0: loss = 1.06006 (* 1 = 1.06006 loss)
I0708 01:30:57.184413 24447 solver.cpp:590] Iteration 9288, lr = 0.00115852
I0708 01:31:04.915833 24447 solver.cpp:243] Iteration 9315, loss = 1.2889
I0708 01:31:04.915858 24447 solver.cpp:259]     Train net output #0: loss = 1.2889 (* 1 = 1.2889 loss)
I0708 01:31:04.915864 24447 solver.cpp:590] Iteration 9315, lr = 0.00115128
I0708 01:31:12.661638 24447 solver.cpp:243] Iteration 9342, loss = 1.53935
I0708 01:31:12.661664 24447 solver.cpp:259]     Train net output #0: loss = 1.53935 (* 1 = 1.53935 loss)
I0708 01:31:12.661670 24447 solver.cpp:590] Iteration 9342, lr = 0.00114409
I0708 01:31:20.367933 24447 solver.cpp:243] Iteration 9369, loss = 1.19422
I0708 01:31:20.367990 24447 solver.cpp:259]     Train net output #0: loss = 1.19422 (* 1 = 1.19422 loss)
I0708 01:31:20.367997 24447 solver.cpp:590] Iteration 9369, lr = 0.00113694
I0708 01:31:28.090780 24447 solver.cpp:243] Iteration 9396, loss = 1.16634
I0708 01:31:28.090803 24447 solver.cpp:259]     Train net output #0: loss = 1.16634 (* 1 = 1.16634 loss)
I0708 01:31:28.090811 24447 solver.cpp:590] Iteration 9396, lr = 0.00112984
I0708 01:31:35.817653 24447 solver.cpp:243] Iteration 9423, loss = 1.10269
I0708 01:31:35.817682 24447 solver.cpp:259]     Train net output #0: loss = 1.10269 (* 1 = 1.10269 loss)
I0708 01:31:35.817687 24447 solver.cpp:590] Iteration 9423, lr = 0.00112278
I0708 01:31:43.503113 24447 solver.cpp:243] Iteration 9450, loss = 1.2082
I0708 01:31:43.503137 24447 solver.cpp:259]     Train net output #0: loss = 1.2082 (* 1 = 1.2082 loss)
I0708 01:31:43.503144 24447 solver.cpp:590] Iteration 9450, lr = 0.00111577
I0708 01:31:51.181555 24447 solver.cpp:243] Iteration 9477, loss = 1.08165
I0708 01:31:51.181613 24447 solver.cpp:259]     Train net output #0: loss = 1.08165 (* 1 = 1.08165 loss)
I0708 01:31:51.181620 24447 solver.cpp:590] Iteration 9477, lr = 0.0011088
I0708 01:31:58.284639 24447 solver.cpp:347] Iteration 9503, Testing net (#0)
I0708 01:32:18.735510 24447 solver.cpp:415]     Test net output #0: accuracy = 0.403486
I0708 01:32:18.735535 24447 solver.cpp:415]     Test net output #1: loss = 3.14927 (* 1 = 3.14927 loss)
I0708 01:32:18.864264 24447 solver.cpp:243] Iteration 9504, loss = 1.30269
I0708 01:32:18.864289 24447 solver.cpp:259]     Train net output #0: loss = 1.30269 (* 1 = 1.30269 loss)
I0708 01:32:18.864295 24447 solver.cpp:590] Iteration 9504, lr = 0.00110187
I0708 01:32:26.209004 24447 solver.cpp:243] Iteration 9531, loss = 1.16013
I0708 01:32:26.209087 24447 solver.cpp:259]     Train net output #0: loss = 1.16013 (* 1 = 1.16013 loss)
I0708 01:32:26.209095 24447 solver.cpp:590] Iteration 9531, lr = 0.00109499
I0708 01:32:33.886832 24447 solver.cpp:243] Iteration 9558, loss = 1.00757
I0708 01:32:33.886858 24447 solver.cpp:259]     Train net output #0: loss = 1.00757 (* 1 = 1.00757 loss)
I0708 01:32:33.886864 24447 solver.cpp:590] Iteration 9558, lr = 0.00108815
I0708 01:32:41.588786 24447 solver.cpp:243] Iteration 9585, loss = 0.848843
I0708 01:32:41.588812 24447 solver.cpp:259]     Train net output #0: loss = 0.848843 (* 1 = 0.848843 loss)
I0708 01:32:41.588819 24447 solver.cpp:590] Iteration 9585, lr = 0.00108136
I0708 01:32:49.273042 24447 solver.cpp:243] Iteration 9612, loss = 1.10432
I0708 01:32:49.273068 24447 solver.cpp:259]     Train net output #0: loss = 1.10432 (* 1 = 1.10432 loss)
I0708 01:32:49.273074 24447 solver.cpp:590] Iteration 9612, lr = 0.0010746
I0708 01:32:56.977754 24447 solver.cpp:243] Iteration 9639, loss = 1.53881
I0708 01:32:56.977819 24447 solver.cpp:259]     Train net output #0: loss = 1.53881 (* 1 = 1.53881 loss)
I0708 01:32:56.977828 24447 solver.cpp:590] Iteration 9639, lr = 0.00106789
I0708 01:33:04.671674 24447 solver.cpp:243] Iteration 9666, loss = 1.30957
I0708 01:33:04.671699 24447 solver.cpp:259]     Train net output #0: loss = 1.30957 (* 1 = 1.30957 loss)
I0708 01:33:04.671705 24447 solver.cpp:590] Iteration 9666, lr = 0.00106122
I0708 01:33:12.353669 24447 solver.cpp:243] Iteration 9693, loss = 0.788829
I0708 01:33:12.353695 24447 solver.cpp:259]     Train net output #0: loss = 0.788829 (* 1 = 0.788829 loss)
I0708 01:33:12.353703 24447 solver.cpp:590] Iteration 9693, lr = 0.00105459
I0708 01:33:20.016335 24447 solver.cpp:243] Iteration 9720, loss = 1.1013
I0708 01:33:20.016360 24447 solver.cpp:259]     Train net output #0: loss = 1.1013 (* 1 = 1.1013 loss)
I0708 01:33:20.016366 24447 solver.cpp:590] Iteration 9720, lr = 0.001048
I0708 01:33:20.867874 24447 solver.cpp:347] Iteration 9724, Testing net (#0)
I0708 01:33:32.053634 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:33:40.750589 24447 solver.cpp:415]     Test net output #0: accuracy = 0.404928
I0708 01:33:40.750615 24447 solver.cpp:415]     Test net output #1: loss = 3.12505 (* 1 = 3.12505 loss)
I0708 01:33:46.802079 24447 solver.cpp:243] Iteration 9747, loss = 1.1021
I0708 01:33:46.802105 24447 solver.cpp:259]     Train net output #0: loss = 1.1021 (* 1 = 1.1021 loss)
I0708 01:33:46.802112 24447 solver.cpp:590] Iteration 9747, lr = 0.00104146
I0708 01:33:54.491510 24447 solver.cpp:243] Iteration 9774, loss = 1.04176
I0708 01:33:54.491535 24447 solver.cpp:259]     Train net output #0: loss = 1.04176 (* 1 = 1.04176 loss)
I0708 01:33:54.491541 24447 solver.cpp:590] Iteration 9774, lr = 0.00103495
I0708 01:34:02.189843 24447 solver.cpp:243] Iteration 9801, loss = 1.42915
I0708 01:34:02.189913 24447 solver.cpp:259]     Train net output #0: loss = 1.42915 (* 1 = 1.42915 loss)
I0708 01:34:02.189929 24447 solver.cpp:590] Iteration 9801, lr = 0.00102849
I0708 01:34:09.862797 24447 solver.cpp:243] Iteration 9828, loss = 1.12623
I0708 01:34:09.862840 24447 solver.cpp:259]     Train net output #0: loss = 1.12623 (* 1 = 1.12623 loss)
I0708 01:34:09.862848 24447 solver.cpp:590] Iteration 9828, lr = 0.00102206
I0708 01:34:17.578953 24447 solver.cpp:243] Iteration 9855, loss = 1.02469
I0708 01:34:17.578979 24447 solver.cpp:259]     Train net output #0: loss = 1.02469 (* 1 = 1.02469 loss)
I0708 01:34:17.578985 24447 solver.cpp:590] Iteration 9855, lr = 0.00101568
I0708 01:34:25.265441 24447 solver.cpp:243] Iteration 9882, loss = 1.10617
I0708 01:34:25.265465 24447 solver.cpp:259]     Train net output #0: loss = 1.10617 (* 1 = 1.10617 loss)
I0708 01:34:25.265471 24447 solver.cpp:590] Iteration 9882, lr = 0.00100933
I0708 01:34:32.942517 24447 solver.cpp:243] Iteration 9909, loss = 1.38513
I0708 01:34:32.942638 24447 solver.cpp:259]     Train net output #0: loss = 1.38513 (* 1 = 1.38513 loss)
I0708 01:34:32.942646 24447 solver.cpp:590] Iteration 9909, lr = 0.00100303
I0708 01:34:40.601757 24447 solver.cpp:243] Iteration 9936, loss = 1.19096
I0708 01:34:40.601783 24447 solver.cpp:259]     Train net output #0: loss = 1.19096 (* 1 = 1.19096 loss)
I0708 01:34:40.601789 24447 solver.cpp:590] Iteration 9936, lr = 0.000996765
I0708 01:34:42.881999 24447 solver.cpp:347] Iteration 9945, Testing net (#0)
I0708 01:35:01.988622 24447 solver.cpp:415]     Test net output #0: accuracy = 0.407452
I0708 01:35:01.988647 24447 solver.cpp:415]     Test net output #1: loss = 3.12278 (* 1 = 3.12278 loss)
I0708 01:35:06.605656 24447 solver.cpp:243] Iteration 9963, loss = 0.996492
I0708 01:35:06.605715 24447 solver.cpp:259]     Train net output #0: loss = 0.996492 (* 1 = 0.996492 loss)
I0708 01:35:06.605722 24447 solver.cpp:590] Iteration 9963, lr = 0.000990539
I0708 01:35:14.297570 24447 solver.cpp:243] Iteration 9990, loss = 1.29114
I0708 01:35:14.297595 24447 solver.cpp:259]     Train net output #0: loss = 1.29114 (* 1 = 1.29114 loss)
I0708 01:35:14.297600 24447 solver.cpp:590] Iteration 9990, lr = 0.000984351
I0708 01:35:22.004535 24447 solver.cpp:243] Iteration 10017, loss = 0.948981
I0708 01:35:22.004562 24447 solver.cpp:259]     Train net output #0: loss = 0.948981 (* 1 = 0.948981 loss)
I0708 01:35:22.004567 24447 solver.cpp:590] Iteration 10017, lr = 0.000978203
I0708 01:35:29.723503 24447 solver.cpp:243] Iteration 10044, loss = 0.898907
I0708 01:35:29.723531 24447 solver.cpp:259]     Train net output #0: loss = 0.898907 (* 1 = 0.898907 loss)
I0708 01:35:29.723538 24447 solver.cpp:590] Iteration 10044, lr = 0.000972093
I0708 01:35:37.469796 24447 solver.cpp:243] Iteration 10071, loss = 1.0315
I0708 01:35:37.469849 24447 solver.cpp:259]     Train net output #0: loss = 1.0315 (* 1 = 1.0315 loss)
I0708 01:35:37.469856 24447 solver.cpp:590] Iteration 10071, lr = 0.000966021
I0708 01:35:45.190971 24447 solver.cpp:243] Iteration 10098, loss = 1.30149
I0708 01:35:45.190999 24447 solver.cpp:259]     Train net output #0: loss = 1.30149 (* 1 = 1.30149 loss)
I0708 01:35:45.191005 24447 solver.cpp:590] Iteration 10098, lr = 0.000959987
I0708 01:35:52.891782 24447 solver.cpp:243] Iteration 10125, loss = 1.11525
I0708 01:35:52.891806 24447 solver.cpp:259]     Train net output #0: loss = 1.11525 (* 1 = 1.11525 loss)
I0708 01:35:52.891813 24447 solver.cpp:590] Iteration 10125, lr = 0.000953991
I0708 01:36:00.598894 24447 solver.cpp:243] Iteration 10152, loss = 1.16776
I0708 01:36:00.598922 24447 solver.cpp:259]     Train net output #0: loss = 1.16776 (* 1 = 1.16776 loss)
I0708 01:36:00.598928 24447 solver.cpp:590] Iteration 10152, lr = 0.000948032
I0708 01:36:04.327545 24447 solver.cpp:347] Iteration 10166, Testing net (#0)
I0708 01:36:19.183809 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:36:23.804524 24447 solver.cpp:415]     Test net output #0: accuracy = 0.406611
I0708 01:36:23.804548 24447 solver.cpp:415]     Test net output #1: loss = 3.12363 (* 1 = 3.12363 loss)
I0708 01:36:27.042737 24447 solver.cpp:243] Iteration 10179, loss = 1.41395
I0708 01:36:27.042783 24447 solver.cpp:259]     Train net output #0: loss = 1.41395 (* 1 = 1.41395 loss)
I0708 01:36:27.042793 24447 solver.cpp:590] Iteration 10179, lr = 0.00094211
I0708 01:36:34.867609 24447 solver.cpp:243] Iteration 10206, loss = 1.05443
I0708 01:36:34.867633 24447 solver.cpp:259]     Train net output #0: loss = 1.05443 (* 1 = 1.05443 loss)
I0708 01:36:34.867640 24447 solver.cpp:590] Iteration 10206, lr = 0.000936225
I0708 01:36:42.644139 24447 solver.cpp:243] Iteration 10233, loss = 1.23096
I0708 01:36:42.644165 24447 solver.cpp:259]     Train net output #0: loss = 1.23096 (* 1 = 1.23096 loss)
I0708 01:36:42.644170 24447 solver.cpp:590] Iteration 10233, lr = 0.000930378
I0708 01:36:50.757884 24447 solver.cpp:243] Iteration 10260, loss = 1.23283
I0708 01:36:50.757963 24447 solver.cpp:259]     Train net output #0: loss = 1.23283 (* 1 = 1.23283 loss)
I0708 01:36:50.757971 24447 solver.cpp:590] Iteration 10260, lr = 0.000924566
I0708 01:36:58.539633 24447 solver.cpp:243] Iteration 10287, loss = 1.26093
I0708 01:36:58.539661 24447 solver.cpp:259]     Train net output #0: loss = 1.26093 (* 1 = 1.26093 loss)
I0708 01:36:58.539669 24447 solver.cpp:590] Iteration 10287, lr = 0.000918791
I0708 01:37:06.268821 24447 solver.cpp:243] Iteration 10314, loss = 1.14605
I0708 01:37:06.268846 24447 solver.cpp:259]     Train net output #0: loss = 1.14605 (* 1 = 1.14605 loss)
I0708 01:37:06.268852 24447 solver.cpp:590] Iteration 10314, lr = 0.000913052
I0708 01:37:14.019062 24447 solver.cpp:243] Iteration 10341, loss = 0.954649
I0708 01:37:14.019088 24447 solver.cpp:259]     Train net output #0: loss = 0.954649 (* 1 = 0.954649 loss)
I0708 01:37:14.019093 24447 solver.cpp:590] Iteration 10341, lr = 0.000907349
I0708 01:37:21.707291 24447 solver.cpp:243] Iteration 10368, loss = 1.15768
I0708 01:37:21.707391 24447 solver.cpp:259]     Train net output #0: loss = 1.15768 (* 1 = 1.15768 loss)
I0708 01:37:21.707398 24447 solver.cpp:590] Iteration 10368, lr = 0.000901681
I0708 01:37:26.875581 24447 solver.cpp:347] Iteration 10387, Testing net (#0)
I0708 01:37:46.105957 24447 solver.cpp:415]     Test net output #0: accuracy = 0.409014
I0708 01:37:46.105981 24447 solver.cpp:415]     Test net output #1: loss = 3.10602 (* 1 = 3.10602 loss)
I0708 01:37:47.876873 24447 solver.cpp:243] Iteration 10395, loss = 1.20128
I0708 01:37:47.876899 24447 solver.cpp:259]     Train net output #0: loss = 1.20128 (* 1 = 1.20128 loss)
I0708 01:37:47.876906 24447 solver.cpp:590] Iteration 10395, lr = 0.000896049
I0708 01:37:55.564932 24447 solver.cpp:243] Iteration 10422, loss = 1.11664
I0708 01:37:55.565006 24447 solver.cpp:259]     Train net output #0: loss = 1.11664 (* 1 = 1.11664 loss)
I0708 01:37:55.565022 24447 solver.cpp:590] Iteration 10422, lr = 0.000890452
I0708 01:38:03.252259 24447 solver.cpp:243] Iteration 10449, loss = 1.14354
I0708 01:38:03.252286 24447 solver.cpp:259]     Train net output #0: loss = 1.14354 (* 1 = 1.14354 loss)
I0708 01:38:03.252292 24447 solver.cpp:590] Iteration 10449, lr = 0.00088489
I0708 01:38:10.942734 24447 solver.cpp:243] Iteration 10476, loss = 1.40988
I0708 01:38:10.942760 24447 solver.cpp:259]     Train net output #0: loss = 1.40988 (* 1 = 1.40988 loss)
I0708 01:38:10.942766 24447 solver.cpp:590] Iteration 10476, lr = 0.000879363
I0708 01:38:18.651804 24447 solver.cpp:243] Iteration 10503, loss = 1.09083
I0708 01:38:18.651830 24447 solver.cpp:259]     Train net output #0: loss = 1.09083 (* 1 = 1.09083 loss)
I0708 01:38:18.651837 24447 solver.cpp:590] Iteration 10503, lr = 0.00087387
I0708 01:38:26.422585 24447 solver.cpp:243] Iteration 10530, loss = 0.94773
I0708 01:38:26.422668 24447 solver.cpp:259]     Train net output #0: loss = 0.94773 (* 1 = 0.94773 loss)
I0708 01:38:26.422677 24447 solver.cpp:590] Iteration 10530, lr = 0.000868412
I0708 01:38:34.085438 24447 solver.cpp:243] Iteration 10557, loss = 1.25519
I0708 01:38:34.085464 24447 solver.cpp:259]     Train net output #0: loss = 1.25519 (* 1 = 1.25519 loss)
I0708 01:38:34.085471 24447 solver.cpp:590] Iteration 10557, lr = 0.000862988
I0708 01:38:41.747493 24447 solver.cpp:243] Iteration 10584, loss = 1.20862
I0708 01:38:41.747520 24447 solver.cpp:259]     Train net output #0: loss = 1.20862 (* 1 = 1.20862 loss)
I0708 01:38:41.747526 24447 solver.cpp:590] Iteration 10584, lr = 0.000857597
I0708 01:38:48.281563 24447 solver.cpp:347] Iteration 10608, Testing net (#0)
I0708 01:39:06.736368 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:39:07.480365 24447 solver.cpp:415]     Test net output #0: accuracy = 0.408774
I0708 01:39:07.480391 24447 solver.cpp:415]     Test net output #1: loss = 3.10324 (* 1 = 3.10324 loss)
I0708 01:39:07.830683 24447 solver.cpp:243] Iteration 10611, loss = 1.15999
I0708 01:39:07.830709 24447 solver.cpp:259]     Train net output #0: loss = 1.15999 (* 1 = 1.15999 loss)
I0708 01:39:07.830715 24447 solver.cpp:590] Iteration 10611, lr = 0.000852241
I0708 01:39:15.516628 24447 solver.cpp:243] Iteration 10638, loss = 1.1421
I0708 01:39:15.516654 24447 solver.cpp:259]     Train net output #0: loss = 1.1421 (* 1 = 1.1421 loss)
I0708 01:39:15.516661 24447 solver.cpp:590] Iteration 10638, lr = 0.000846917
I0708 01:39:23.212252 24447 solver.cpp:243] Iteration 10665, loss = 1.04198
I0708 01:39:23.212276 24447 solver.cpp:259]     Train net output #0: loss = 1.04198 (* 1 = 1.04198 loss)
I0708 01:39:23.212282 24447 solver.cpp:590] Iteration 10665, lr = 0.000841627
I0708 01:39:30.911679 24447 solver.cpp:243] Iteration 10692, loss = 0.949249
I0708 01:39:30.911705 24447 solver.cpp:259]     Train net output #0: loss = 0.949249 (* 1 = 0.949249 loss)
I0708 01:39:30.911712 24447 solver.cpp:590] Iteration 10692, lr = 0.00083637
I0708 01:39:38.596243 24447 solver.cpp:243] Iteration 10719, loss = 1.16859
I0708 01:39:38.596324 24447 solver.cpp:259]     Train net output #0: loss = 1.16859 (* 1 = 1.16859 loss)
I0708 01:39:38.596333 24447 solver.cpp:590] Iteration 10719, lr = 0.000831146
I0708 01:39:46.301764 24447 solver.cpp:243] Iteration 10746, loss = 1.07285
I0708 01:39:46.301790 24447 solver.cpp:259]     Train net output #0: loss = 1.07285 (* 1 = 1.07285 loss)
I0708 01:39:46.301800 24447 solver.cpp:590] Iteration 10746, lr = 0.000825954
I0708 01:39:53.982583 24447 solver.cpp:243] Iteration 10773, loss = 1.04616
I0708 01:39:53.982607 24447 solver.cpp:259]     Train net output #0: loss = 1.04616 (* 1 = 1.04616 loss)
I0708 01:39:53.982614 24447 solver.cpp:590] Iteration 10773, lr = 0.000820795
I0708 01:40:01.648943 24447 solver.cpp:243] Iteration 10800, loss = 1.09287
I0708 01:40:01.648972 24447 solver.cpp:259]     Train net output #0: loss = 1.09287 (* 1 = 1.09287 loss)
I0708 01:40:01.648990 24447 solver.cpp:590] Iteration 10800, lr = 0.000815668
I0708 01:40:09.323174 24447 solver.cpp:243] Iteration 10827, loss = 1.10792
I0708 01:40:09.323233 24447 solver.cpp:259]     Train net output #0: loss = 1.10792 (* 1 = 1.10792 loss)
I0708 01:40:09.323240 24447 solver.cpp:590] Iteration 10827, lr = 0.000810574
I0708 01:40:09.609237 24447 solver.cpp:347] Iteration 10829, Testing net (#0)
I0708 01:40:28.879645 24447 solver.cpp:415]     Test net output #0: accuracy = 0.407933
I0708 01:40:28.879670 24447 solver.cpp:415]     Test net output #1: loss = 3.09648 (* 1 = 3.09648 loss)
I0708 01:40:35.497395 24447 solver.cpp:243] Iteration 10854, loss = 1.11101
I0708 01:40:35.497421 24447 solver.cpp:259]     Train net output #0: loss = 1.11101 (* 1 = 1.11101 loss)
I0708 01:40:35.497427 24447 solver.cpp:590] Iteration 10854, lr = 0.000805511
I0708 01:40:43.179581 24447 solver.cpp:243] Iteration 10881, loss = 0.883851
I0708 01:40:43.179656 24447 solver.cpp:259]     Train net output #0: loss = 0.883851 (* 1 = 0.883851 loss)
I0708 01:40:43.179673 24447 solver.cpp:590] Iteration 10881, lr = 0.000800479
I0708 01:40:50.885691 24447 solver.cpp:243] Iteration 10908, loss = 1.16629
I0708 01:40:50.885717 24447 solver.cpp:259]     Train net output #0: loss = 1.16629 (* 1 = 1.16629 loss)
I0708 01:40:50.885725 24447 solver.cpp:590] Iteration 10908, lr = 0.000795479
I0708 01:40:58.564474 24447 solver.cpp:243] Iteration 10935, loss = 1.05201
I0708 01:40:58.564499 24447 solver.cpp:259]     Train net output #0: loss = 1.05201 (* 1 = 1.05201 loss)
I0708 01:40:58.564507 24447 solver.cpp:590] Iteration 10935, lr = 0.00079051
I0708 01:41:06.273648 24447 solver.cpp:243] Iteration 10962, loss = 0.878941
I0708 01:41:06.273674 24447 solver.cpp:259]     Train net output #0: loss = 0.878941 (* 1 = 0.878941 loss)
I0708 01:41:06.273681 24447 solver.cpp:590] Iteration 10962, lr = 0.000785573
I0708 01:41:13.948221 24447 solver.cpp:243] Iteration 10989, loss = 1.06804
I0708 01:41:13.948276 24447 solver.cpp:259]     Train net output #0: loss = 1.06804 (* 1 = 1.06804 loss)
I0708 01:41:13.948284 24447 solver.cpp:590] Iteration 10989, lr = 0.000780666
I0708 01:41:21.619719 24447 solver.cpp:243] Iteration 11016, loss = 1.21581
I0708 01:41:21.619741 24447 solver.cpp:259]     Train net output #0: loss = 1.21581 (* 1 = 1.21581 loss)
I0708 01:41:21.619747 24447 solver.cpp:590] Iteration 11016, lr = 0.00077579
I0708 01:41:29.279855 24447 solver.cpp:243] Iteration 11043, loss = 0.959074
I0708 01:41:29.279881 24447 solver.cpp:259]     Train net output #0: loss = 0.959074 (* 1 = 0.959074 loss)
I0708 01:41:29.279888 24447 solver.cpp:590] Iteration 11043, lr = 0.000770944
I0708 01:41:30.990559 24447 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_11050.caffemodel
I0708 01:41:33.427775 24447 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_11050.solverstate
I0708 01:41:34.523315 24447 solver.cpp:347] Iteration 11050, Testing net (#0)
I0708 01:41:53.990381 24447 solver.cpp:415]     Test net output #0: accuracy = 0.408413
I0708 01:41:53.990469 24447 solver.cpp:415]     Test net output #1: loss = 3.10302 (* 1 = 3.10302 loss)
I0708 01:41:59.209976 24447 solver.cpp:243] Iteration 11070, loss = 0.859437
I0708 01:41:59.210002 24447 solver.cpp:259]     Train net output #0: loss = 0.859437 (* 1 = 0.859437 loss)
I0708 01:41:59.210008 24447 solver.cpp:590] Iteration 11070, lr = 0.000766128
I0708 01:42:06.415613 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:42:07.007503 24447 solver.cpp:243] Iteration 11097, loss = 1.08415
I0708 01:42:07.007529 24447 solver.cpp:259]     Train net output #0: loss = 1.08415 (* 1 = 1.08415 loss)
I0708 01:42:07.007535 24447 solver.cpp:590] Iteration 11097, lr = 0.000761343
I0708 01:42:14.863678 24447 solver.cpp:243] Iteration 11124, loss = 1.1034
I0708 01:42:14.863704 24447 solver.cpp:259]     Train net output #0: loss = 1.1034 (* 1 = 1.1034 loss)
I0708 01:42:14.863713 24447 solver.cpp:590] Iteration 11124, lr = 0.000756587
I0708 01:42:22.671658 24447 solver.cpp:243] Iteration 11151, loss = 1.17623
I0708 01:42:22.671684 24447 solver.cpp:259]     Train net output #0: loss = 1.17623 (* 1 = 1.17623 loss)
I0708 01:42:22.671689 24447 solver.cpp:590] Iteration 11151, lr = 0.000751862
I0708 01:42:30.481963 24447 solver.cpp:243] Iteration 11178, loss = 0.87363
I0708 01:42:30.482041 24447 solver.cpp:259]     Train net output #0: loss = 0.87363 (* 1 = 0.87363 loss)
I0708 01:42:30.482059 24447 solver.cpp:590] Iteration 11178, lr = 0.000747165
I0708 01:42:38.179884 24447 solver.cpp:243] Iteration 11205, loss = 1.07007
I0708 01:42:38.179910 24447 solver.cpp:259]     Train net output #0: loss = 1.07007 (* 1 = 1.07007 loss)
I0708 01:42:38.179916 24447 solver.cpp:590] Iteration 11205, lr = 0.000742498
I0708 01:42:45.854261 24447 solver.cpp:243] Iteration 11232, loss = 1.27047
I0708 01:42:45.854286 24447 solver.cpp:259]     Train net output #0: loss = 1.27047 (* 1 = 1.27047 loss)
I0708 01:42:45.854292 24447 solver.cpp:590] Iteration 11232, lr = 0.00073786
I0708 01:42:53.513288 24447 solver.cpp:243] Iteration 11259, loss = 1.05729
I0708 01:42:53.513314 24447 solver.cpp:259]     Train net output #0: loss = 1.05729 (* 1 = 1.05729 loss)
I0708 01:42:53.513320 24447 solver.cpp:590] Iteration 11259, lr = 0.000733252
I0708 01:42:56.638514 24447 solver.cpp:347] Iteration 11271, Testing net (#0)
I0708 01:43:15.984354 24447 solver.cpp:415]     Test net output #0: accuracy = 0.407572
I0708 01:43:15.984413 24447 solver.cpp:415]     Test net output #1: loss = 3.09009 (* 1 = 3.09009 loss)
I0708 01:43:19.815860 24447 solver.cpp:243] Iteration 11286, loss = 1.01993
I0708 01:43:19.815886 24447 solver.cpp:259]     Train net output #0: loss = 1.01993 (* 1 = 1.01993 loss)
I0708 01:43:19.815891 24447 solver.cpp:590] Iteration 11286, lr = 0.000728672
I0708 01:43:28.950489 24447 solver.cpp:243] Iteration 11313, loss = 1.04535
I0708 01:43:28.950515 24447 solver.cpp:259]     Train net output #0: loss = 1.04535 (* 1 = 1.04535 loss)
I0708 01:43:28.950521 24447 solver.cpp:590] Iteration 11313, lr = 0.00072412
I0708 01:43:38.266932 24447 solver.cpp:243] Iteration 11340, loss = 1.20936
I0708 01:43:38.266966 24447 solver.cpp:259]     Train net output #0: loss = 1.20936 (* 1 = 1.20936 loss)
I0708 01:43:38.266973 24447 solver.cpp:590] Iteration 11340, lr = 0.000719597
I0708 01:43:47.035918 24447 solver.cpp:243] Iteration 11367, loss = 1.09754
I0708 01:43:47.036062 24447 solver.cpp:259]     Train net output #0: loss = 1.09754 (* 1 = 1.09754 loss)
I0708 01:43:47.036069 24447 solver.cpp:590] Iteration 11367, lr = 0.000715102
I0708 01:43:55.210276 24447 solver.cpp:243] Iteration 11394, loss = 1.11711
I0708 01:43:55.210302 24447 solver.cpp:259]     Train net output #0: loss = 1.11711 (* 1 = 1.11711 loss)
I0708 01:43:55.210309 24447 solver.cpp:590] Iteration 11394, lr = 0.000710636
I0708 01:44:04.138655 24447 solver.cpp:243] Iteration 11421, loss = 1.20222
I0708 01:44:04.138682 24447 solver.cpp:259]     Train net output #0: loss = 1.20222 (* 1 = 1.20222 loss)
I0708 01:44:04.138689 24447 solver.cpp:590] Iteration 11421, lr = 0.000706197
I0708 01:44:13.280189 24447 solver.cpp:243] Iteration 11448, loss = 1.2763
I0708 01:44:13.280215 24447 solver.cpp:259]     Train net output #0: loss = 1.2763 (* 1 = 1.2763 loss)
I0708 01:44:13.280222 24447 solver.cpp:590] Iteration 11448, lr = 0.000701786
I0708 01:44:22.489064 24447 solver.cpp:243] Iteration 11475, loss = 1.014
I0708 01:44:22.489114 24447 solver.cpp:259]     Train net output #0: loss = 1.014 (* 1 = 1.014 loss)
I0708 01:44:22.489120 24447 solver.cpp:590] Iteration 11475, lr = 0.000697402
I0708 01:44:27.312499 24447 solver.cpp:347] Iteration 11492, Testing net (#0)
I0708 01:44:46.463686 24447 solver.cpp:415]     Test net output #0: accuracy = 0.408293
I0708 01:44:46.463711 24447 solver.cpp:415]     Test net output #1: loss = 3.0837 (* 1 = 3.0837 loss)
I0708 01:44:48.812110 24447 solver.cpp:243] Iteration 11502, loss = 1.04369
I0708 01:44:48.812135 24447 solver.cpp:259]     Train net output #0: loss = 1.04369 (* 1 = 1.04369 loss)
I0708 01:44:48.812141 24447 solver.cpp:590] Iteration 11502, lr = 0.000693046
I0708 01:44:56.633826 24447 solver.cpp:243] Iteration 11529, loss = 1.06584
I0708 01:44:56.633888 24447 solver.cpp:259]     Train net output #0: loss = 1.06584 (* 1 = 1.06584 loss)
I0708 01:44:56.633894 24447 solver.cpp:590] Iteration 11529, lr = 0.000688717
I0708 01:45:04.433195 24447 solver.cpp:243] Iteration 11556, loss = 1.15494
I0708 01:45:04.433223 24447 solver.cpp:259]     Train net output #0: loss = 1.15494 (* 1 = 1.15494 loss)
I0708 01:45:04.433228 24447 solver.cpp:590] Iteration 11556, lr = 0.000684415
I0708 01:45:12.251942 24447 solver.cpp:243] Iteration 11583, loss = 1.12316
I0708 01:45:12.251967 24447 solver.cpp:259]     Train net output #0: loss = 1.12316 (* 1 = 1.12316 loss)
I0708 01:45:12.251973 24447 solver.cpp:590] Iteration 11583, lr = 0.00068014
I0708 01:45:13.962013 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:45:20.030380 24447 solver.cpp:243] Iteration 11610, loss = 1.11791
I0708 01:45:20.030406 24447 solver.cpp:259]     Train net output #0: loss = 1.11791 (* 1 = 1.11791 loss)
I0708 01:45:20.030412 24447 solver.cpp:590] Iteration 11610, lr = 0.000675892
I0708 01:45:27.953809 24447 solver.cpp:243] Iteration 11637, loss = 1.15736
I0708 01:45:27.953863 24447 solver.cpp:259]     Train net output #0: loss = 1.15736 (* 1 = 1.15736 loss)
I0708 01:45:27.953871 24447 solver.cpp:590] Iteration 11637, lr = 0.00067167
I0708 01:45:35.823540 24447 solver.cpp:243] Iteration 11664, loss = 0.979336
I0708 01:45:35.823565 24447 solver.cpp:259]     Train net output #0: loss = 0.979336 (* 1 = 0.979336 loss)
I0708 01:45:35.823572 24447 solver.cpp:590] Iteration 11664, lr = 0.000667475
I0708 01:45:43.687005 24447 solver.cpp:243] Iteration 11691, loss = 1.09378
I0708 01:45:43.687029 24447 solver.cpp:259]     Train net output #0: loss = 1.09378 (* 1 = 1.09378 loss)
I0708 01:45:43.687036 24447 solver.cpp:590] Iteration 11691, lr = 0.000663305
I0708 01:45:49.782649 24447 solver.cpp:347] Iteration 11713, Testing net (#0)
I0708 01:46:08.973610 24447 solver.cpp:415]     Test net output #0: accuracy = 0.407212
I0708 01:46:08.973731 24447 solver.cpp:415]     Test net output #1: loss = 3.08552 (* 1 = 3.08552 loss)
I0708 01:46:09.893460 24447 solver.cpp:243] Iteration 11718, loss = 0.901471
I0708 01:46:09.893496 24447 solver.cpp:259]     Train net output #0: loss = 0.901471 (* 1 = 0.901471 loss)
I0708 01:46:09.893501 24447 solver.cpp:590] Iteration 11718, lr = 0.000659162
I0708 01:46:17.744602 24447 solver.cpp:243] Iteration 11745, loss = 1.24807
I0708 01:46:17.744627 24447 solver.cpp:259]     Train net output #0: loss = 1.24807 (* 1 = 1.24807 loss)
I0708 01:46:17.744634 24447 solver.cpp:590] Iteration 11745, lr = 0.000655045
I0708 01:46:25.682256 24447 solver.cpp:243] Iteration 11772, loss = 0.877186
I0708 01:46:25.682281 24447 solver.cpp:259]     Train net output #0: loss = 0.877186 (* 1 = 0.877186 loss)
I0708 01:46:25.682288 24447 solver.cpp:590] Iteration 11772, lr = 0.000650953
I0708 01:46:33.769649 24447 solver.cpp:243] Iteration 11799, loss = 1.14683
I0708 01:46:33.769675 24447 solver.cpp:259]     Train net output #0: loss = 1.14683 (* 1 = 1.14683 loss)
I0708 01:46:33.769682 24447 solver.cpp:590] Iteration 11799, lr = 0.000646887
I0708 01:46:41.689339 24447 solver.cpp:243] Iteration 11826, loss = 0.904522
I0708 01:46:41.689474 24447 solver.cpp:259]     Train net output #0: loss = 0.904522 (* 1 = 0.904522 loss)
I0708 01:46:41.689481 24447 solver.cpp:590] Iteration 11826, lr = 0.000642847
I0708 01:46:49.500643 24447 solver.cpp:243] Iteration 11853, loss = 1.38061
I0708 01:46:49.500670 24447 solver.cpp:259]     Train net output #0: loss = 1.38061 (* 1 = 1.38061 loss)
I0708 01:46:49.500676 24447 solver.cpp:590] Iteration 11853, lr = 0.000638831
I0708 01:46:57.495362 24447 solver.cpp:243] Iteration 11880, loss = 0.799636
I0708 01:46:57.495388 24447 solver.cpp:259]     Train net output #0: loss = 0.799636 (* 1 = 0.799636 loss)
I0708 01:46:57.495393 24447 solver.cpp:590] Iteration 11880, lr = 0.000634841
I0708 01:47:05.329104 24447 solver.cpp:243] Iteration 11907, loss = 0.85816
I0708 01:47:05.329144 24447 solver.cpp:259]     Train net output #0: loss = 0.85816 (* 1 = 0.85816 loss)
I0708 01:47:05.329151 24447 solver.cpp:590] Iteration 11907, lr = 0.000630876
I0708 01:47:13.114534 24447 solver.cpp:347] Iteration 11934, Testing net (#0)
I0708 01:47:32.402673 24447 solver.cpp:415]     Test net output #0: accuracy = 0.409976
I0708 01:47:32.402696 24447 solver.cpp:415]     Test net output #1: loss = 3.07813 (* 1 = 3.07813 loss)
I0708 01:47:32.459184 24447 solver.cpp:243] Iteration 11934, loss = 1.08942
I0708 01:47:32.459208 24447 solver.cpp:259]     Train net output #0: loss = 1.08942 (* 1 = 1.08942 loss)
I0708 01:47:32.459214 24447 solver.cpp:590] Iteration 11934, lr = 0.000626935
I0708 01:47:39.960755 24447 solver.cpp:243] Iteration 11961, loss = 0.989359
I0708 01:47:39.960780 24447 solver.cpp:259]     Train net output #0: loss = 0.989359 (* 1 = 0.989359 loss)
I0708 01:47:39.960786 24447 solver.cpp:590] Iteration 11961, lr = 0.000623019
I0708 01:47:47.969435 24447 solver.cpp:243] Iteration 11988, loss = 1.05203
I0708 01:47:47.969490 24447 solver.cpp:259]     Train net output #0: loss = 1.05203 (* 1 = 1.05203 loss)
I0708 01:47:47.969496 24447 solver.cpp:590] Iteration 11988, lr = 0.000619128
I0708 01:47:55.987107 24447 solver.cpp:243] Iteration 12015, loss = 1.26747
I0708 01:47:55.987131 24447 solver.cpp:259]     Train net output #0: loss = 1.26747 (* 1 = 1.26747 loss)
I0708 01:47:55.987138 24447 solver.cpp:590] Iteration 12015, lr = 0.00061526
I0708 01:48:03.735160 24447 solver.cpp:243] Iteration 12042, loss = 1.17504
I0708 01:48:03.735188 24447 solver.cpp:259]     Train net output #0: loss = 1.17504 (* 1 = 1.17504 loss)
I0708 01:48:03.735193 24447 solver.cpp:590] Iteration 12042, lr = 0.000611417
I0708 01:48:11.462250 24447 solver.cpp:243] Iteration 12069, loss = 1.19944
I0708 01:48:11.462278 24447 solver.cpp:259]     Train net output #0: loss = 1.19944 (* 1 = 1.19944 loss)
I0708 01:48:11.462285 24447 solver.cpp:590] Iteration 12069, lr = 0.000607598
I0708 01:48:15.455915 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:48:19.167045 24447 solver.cpp:243] Iteration 12096, loss = 1.16056
I0708 01:48:19.167126 24447 solver.cpp:259]     Train net output #0: loss = 1.16056 (* 1 = 1.16056 loss)
I0708 01:48:19.167134 24447 solver.cpp:590] Iteration 12096, lr = 0.000603803
I0708 01:48:26.870654 24447 solver.cpp:243] Iteration 12123, loss = 1.07812
I0708 01:48:26.870681 24447 solver.cpp:259]     Train net output #0: loss = 1.07812 (* 1 = 1.07812 loss)
I0708 01:48:26.870687 24447 solver.cpp:590] Iteration 12123, lr = 0.000600032
I0708 01:48:34.553710 24447 solver.cpp:243] Iteration 12150, loss = 1.19671
I0708 01:48:34.553737 24447 solver.cpp:259]     Train net output #0: loss = 1.19671 (* 1 = 1.19671 loss)
I0708 01:48:34.553746 24447 solver.cpp:590] Iteration 12150, lr = 0.000596284
I0708 01:48:35.685731 24447 solver.cpp:347] Iteration 12155, Testing net (#0)
I0708 01:48:54.840061 24447 solver.cpp:415]     Test net output #0: accuracy = 0.412019
I0708 01:48:54.840121 24447 solver.cpp:415]     Test net output #1: loss = 3.0759 (* 1 = 3.0759 loss)
I0708 01:49:00.602583 24447 solver.cpp:243] Iteration 12177, loss = 1.07611
I0708 01:49:00.602612 24447 solver.cpp:259]     Train net output #0: loss = 1.07611 (* 1 = 1.07611 loss)
I0708 01:49:00.602617 24447 solver.cpp:590] Iteration 12177, lr = 0.000592559
I0708 01:49:08.612774 24447 solver.cpp:243] Iteration 12204, loss = 1.29379
I0708 01:49:08.612802 24447 solver.cpp:259]     Train net output #0: loss = 1.29379 (* 1 = 1.29379 loss)
I0708 01:49:08.612807 24447 solver.cpp:590] Iteration 12204, lr = 0.000588858
I0708 01:49:17.110535 24447 solver.cpp:243] Iteration 12231, loss = 1.12372
I0708 01:49:17.110559 24447 solver.cpp:259]     Train net output #0: loss = 1.12372 (* 1 = 1.12372 loss)
I0708 01:49:17.110565 24447 solver.cpp:590] Iteration 12231, lr = 0.00058518
I0708 01:49:26.409523 24447 solver.cpp:243] Iteration 12258, loss = 1.13565
I0708 01:49:26.409577 24447 solver.cpp:259]     Train net output #0: loss = 1.13565 (* 1 = 1.13565 loss)
I0708 01:49:26.409584 24447 solver.cpp:590] Iteration 12258, lr = 0.000581525
I0708 01:49:35.865759 24447 solver.cpp:243] Iteration 12285, loss = 1.14344
I0708 01:49:35.865785 24447 solver.cpp:259]     Train net output #0: loss = 1.14344 (* 1 = 1.14344 loss)
I0708 01:49:35.865792 24447 solver.cpp:590] Iteration 12285, lr = 0.000577892
I0708 01:49:44.888643 24447 solver.cpp:243] Iteration 12312, loss = 1.13941
I0708 01:49:44.888669 24447 solver.cpp:259]     Train net output #0: loss = 1.13941 (* 1 = 1.13941 loss)
I0708 01:49:44.888674 24447 solver.cpp:590] Iteration 12312, lr = 0.000574283
I0708 01:49:54.041407 24447 solver.cpp:243] Iteration 12339, loss = 1.0731
I0708 01:49:54.041432 24447 solver.cpp:259]     Train net output #0: loss = 1.0731 (* 1 = 1.0731 loss)
I0708 01:49:54.041440 24447 solver.cpp:590] Iteration 12339, lr = 0.000570695
I0708 01:50:02.907333 24447 solver.cpp:243] Iteration 12366, loss = 1.09432
I0708 01:50:02.907389 24447 solver.cpp:259]     Train net output #0: loss = 1.09432 (* 1 = 1.09432 loss)
I0708 01:50:02.907395 24447 solver.cpp:590] Iteration 12366, lr = 0.000567131
I0708 01:50:06.002233 24447 solver.cpp:347] Iteration 12376, Testing net (#0)
I0708 01:50:25.296007 24447 solver.cpp:415]     Test net output #0: accuracy = 0.408173
I0708 01:50:25.296033 24447 solver.cpp:415]     Test net output #1: loss = 3.08143 (* 1 = 3.08143 loss)
I0708 01:50:29.714257 24447 solver.cpp:243] Iteration 12393, loss = 1.14014
I0708 01:50:29.714301 24447 solver.cpp:259]     Train net output #0: loss = 1.14014 (* 1 = 1.14014 loss)
I0708 01:50:29.714313 24447 solver.cpp:590] Iteration 12393, lr = 0.000563588
I0708 01:50:37.741363 24447 solver.cpp:243] Iteration 12420, loss = 1.07077
I0708 01:50:37.741420 24447 solver.cpp:259]     Train net output #0: loss = 1.07077 (* 1 = 1.07077 loss)
I0708 01:50:37.741426 24447 solver.cpp:590] Iteration 12420, lr = 0.000560068
I0708 01:50:45.591575 24447 solver.cpp:243] Iteration 12447, loss = 1.02557
I0708 01:50:45.591601 24447 solver.cpp:259]     Train net output #0: loss = 1.02557 (* 1 = 1.02557 loss)
I0708 01:50:45.591609 24447 solver.cpp:590] Iteration 12447, lr = 0.00055657
I0708 01:50:53.715795 24447 solver.cpp:243] Iteration 12474, loss = 1.28863
I0708 01:50:53.715821 24447 solver.cpp:259]     Train net output #0: loss = 1.28863 (* 1 = 1.28863 loss)
I0708 01:50:53.715827 24447 solver.cpp:590] Iteration 12474, lr = 0.000553093
I0708 01:51:01.647058 24447 solver.cpp:243] Iteration 12501, loss = 0.974548
I0708 01:51:01.647083 24447 solver.cpp:259]     Train net output #0: loss = 0.974548 (* 1 = 0.974548 loss)
I0708 01:51:01.647090 24447 solver.cpp:590] Iteration 12501, lr = 0.000549638
I0708 01:51:09.904204 24447 solver.cpp:243] Iteration 12528, loss = 1.07764
I0708 01:51:09.904295 24447 solver.cpp:259]     Train net output #0: loss = 1.07764 (* 1 = 1.07764 loss)
I0708 01:51:09.904304 24447 solver.cpp:590] Iteration 12528, lr = 0.000546205
I0708 01:51:17.860007 24447 solver.cpp:243] Iteration 12555, loss = 1.10734
I0708 01:51:17.860031 24447 solver.cpp:259]     Train net output #0: loss = 1.10734 (* 1 = 1.10734 loss)
I0708 01:51:17.860038 24447 solver.cpp:590] Iteration 12555, lr = 0.000542794
I0708 01:51:24.404764 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:51:25.894026 24447 solver.cpp:243] Iteration 12582, loss = 0.992594
I0708 01:51:25.894052 24447 solver.cpp:259]     Train net output #0: loss = 0.992594 (* 1 = 0.992594 loss)
I0708 01:51:25.894058 24447 solver.cpp:590] Iteration 12582, lr = 0.000539403
I0708 01:51:30.032642 24447 solver.cpp:347] Iteration 12597, Testing net (#0)
I0708 01:51:49.504775 24447 solver.cpp:415]     Test net output #0: accuracy = 0.411298
I0708 01:51:49.504851 24447 solver.cpp:415]     Test net output #1: loss = 3.0753 (* 1 = 3.0753 loss)
I0708 01:51:52.476387 24447 solver.cpp:243] Iteration 12609, loss = 1.23075
I0708 01:51:52.476413 24447 solver.cpp:259]     Train net output #0: loss = 1.23075 (* 1 = 1.23075 loss)
I0708 01:51:52.476419 24447 solver.cpp:590] Iteration 12609, lr = 0.000536034
I0708 01:52:00.308480 24447 solver.cpp:243] Iteration 12636, loss = 0.78606
I0708 01:52:00.308507 24447 solver.cpp:259]     Train net output #0: loss = 0.78606 (* 1 = 0.78606 loss)
I0708 01:52:00.308513 24447 solver.cpp:590] Iteration 12636, lr = 0.000532686
I0708 01:52:08.163521 24447 solver.cpp:243] Iteration 12663, loss = 0.950808
I0708 01:52:08.163547 24447 solver.cpp:259]     Train net output #0: loss = 0.950808 (* 1 = 0.950808 loss)
I0708 01:52:08.163553 24447 solver.cpp:590] Iteration 12663, lr = 0.000529358
I0708 01:52:16.048460 24447 solver.cpp:243] Iteration 12690, loss = 0.981866
I0708 01:52:16.048506 24447 solver.cpp:259]     Train net output #0: loss = 0.981866 (* 1 = 0.981866 loss)
I0708 01:52:16.048512 24447 solver.cpp:590] Iteration 12690, lr = 0.000526052
I0708 01:52:23.755910 24447 solver.cpp:243] Iteration 12717, loss = 1.1123
I0708 01:52:23.755965 24447 solver.cpp:259]     Train net output #0: loss = 1.1123 (* 1 = 1.1123 loss)
I0708 01:52:23.755972 24447 solver.cpp:590] Iteration 12717, lr = 0.000522766
I0708 01:52:31.450671 24447 solver.cpp:243] Iteration 12744, loss = 1.32515
I0708 01:52:31.450714 24447 solver.cpp:259]     Train net output #0: loss = 1.32515 (* 1 = 1.32515 loss)
I0708 01:52:31.450726 24447 solver.cpp:590] Iteration 12744, lr = 0.000519501
I0708 01:52:39.123368 24447 solver.cpp:243] Iteration 12771, loss = 1.0251
I0708 01:52:39.123394 24447 solver.cpp:259]     Train net output #0: loss = 1.0251 (* 1 = 1.0251 loss)
I0708 01:52:39.123400 24447 solver.cpp:590] Iteration 12771, lr = 0.000516256
I0708 01:52:46.779283 24447 solver.cpp:243] Iteration 12798, loss = 0.669971
I0708 01:52:46.779312 24447 solver.cpp:259]     Train net output #0: loss = 0.669971 (* 1 = 0.669971 loss)
I0708 01:52:46.779319 24447 solver.cpp:590] Iteration 12798, lr = 0.000513031
I0708 01:52:52.193816 24447 solver.cpp:347] Iteration 12818, Testing net (#0)
I0708 01:53:11.419293 24447 solver.cpp:415]     Test net output #0: accuracy = 0.409615
I0708 01:53:11.419366 24447 solver.cpp:415]     Test net output #1: loss = 3.07532 (* 1 = 3.07532 loss)
I0708 01:53:12.921512 24447 solver.cpp:243] Iteration 12825, loss = 0.978018
I0708 01:53:12.921540 24447 solver.cpp:259]     Train net output #0: loss = 0.978018 (* 1 = 0.978018 loss)
I0708 01:53:12.921545 24447 solver.cpp:590] Iteration 12825, lr = 0.000509827
I0708 01:53:20.652331 24447 solver.cpp:243] Iteration 12852, loss = 1.06418
I0708 01:53:20.652357 24447 solver.cpp:259]     Train net output #0: loss = 1.06418 (* 1 = 1.06418 loss)
I0708 01:53:20.652364 24447 solver.cpp:590] Iteration 12852, lr = 0.000506642
I0708 01:53:28.377560 24447 solver.cpp:243] Iteration 12879, loss = 0.897372
I0708 01:53:28.377589 24447 solver.cpp:259]     Train net output #0: loss = 0.897372 (* 1 = 0.897372 loss)
I0708 01:53:28.377595 24447 solver.cpp:590] Iteration 12879, lr = 0.000503478
I0708 01:53:36.065949 24447 solver.cpp:243] Iteration 12906, loss = 1.18552
I0708 01:53:36.065976 24447 solver.cpp:259]     Train net output #0: loss = 1.18552 (* 1 = 1.18552 loss)
I0708 01:53:36.065984 24447 solver.cpp:590] Iteration 12906, lr = 0.000500333
I0708 01:53:43.830684 24447 solver.cpp:243] Iteration 12933, loss = 1.10842
I0708 01:53:43.830760 24447 solver.cpp:259]     Train net output #0: loss = 1.10842 (* 1 = 1.10842 loss)
I0708 01:53:43.830766 24447 solver.cpp:590] Iteration 12933, lr = 0.000497207
I0708 01:53:51.764801 24447 solver.cpp:243] Iteration 12960, loss = 0.730911
I0708 01:53:51.764827 24447 solver.cpp:259]     Train net output #0: loss = 0.730911 (* 1 = 0.730911 loss)
I0708 01:53:51.764834 24447 solver.cpp:590] Iteration 12960, lr = 0.000494102
I0708 01:53:59.452724 24447 solver.cpp:243] Iteration 12987, loss = 1.21338
I0708 01:53:59.452754 24447 solver.cpp:259]     Train net output #0: loss = 1.21338 (* 1 = 1.21338 loss)
I0708 01:53:59.452759 24447 solver.cpp:590] Iteration 12987, lr = 0.000491015
I0708 01:54:07.111431 24447 solver.cpp:243] Iteration 13014, loss = 0.78819
I0708 01:54:07.111457 24447 solver.cpp:259]     Train net output #0: loss = 0.78819 (* 1 = 0.78819 loss)
I0708 01:54:07.111464 24447 solver.cpp:590] Iteration 13014, lr = 0.000487949
I0708 01:54:13.947651 24447 solver.cpp:347] Iteration 13039, Testing net (#0)
I0708 01:54:16.551756 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:54:33.130537 24447 solver.cpp:415]     Test net output #0: accuracy = 0.407813
I0708 01:54:33.130563 24447 solver.cpp:415]     Test net output #1: loss = 3.07126 (* 1 = 3.07126 loss)
I0708 01:54:33.330965 24447 solver.cpp:243] Iteration 13041, loss = 0.972537
I0708 01:54:33.330989 24447 solver.cpp:259]     Train net output #0: loss = 0.972537 (* 1 = 0.972537 loss)
I0708 01:54:33.330996 24447 solver.cpp:590] Iteration 13041, lr = 0.000484901
I0708 01:54:40.885354 24447 solver.cpp:243] Iteration 13068, loss = 1.0393
I0708 01:54:40.885380 24447 solver.cpp:259]     Train net output #0: loss = 1.0393 (* 1 = 1.0393 loss)
I0708 01:54:40.885386 24447 solver.cpp:590] Iteration 13068, lr = 0.000481872
I0708 01:54:48.577687 24447 solver.cpp:243] Iteration 13095, loss = 1.08658
I0708 01:54:48.577744 24447 solver.cpp:259]     Train net output #0: loss = 1.08658 (* 1 = 1.08658 loss)
I0708 01:54:48.577751 24447 solver.cpp:590] Iteration 13095, lr = 0.000478862
I0708 01:54:56.271543 24447 solver.cpp:243] Iteration 13122, loss = 0.97835
I0708 01:54:56.271569 24447 solver.cpp:259]     Train net output #0: loss = 0.97835 (* 1 = 0.97835 loss)
I0708 01:54:56.271574 24447 solver.cpp:590] Iteration 13122, lr = 0.000475871
I0708 01:55:03.979635 24447 solver.cpp:243] Iteration 13149, loss = 1.02204
I0708 01:55:03.979660 24447 solver.cpp:259]     Train net output #0: loss = 1.02204 (* 1 = 1.02204 loss)
I0708 01:55:03.979667 24447 solver.cpp:590] Iteration 13149, lr = 0.000472898
I0708 01:55:11.684836 24447 solver.cpp:243] Iteration 13176, loss = 0.948576
I0708 01:55:11.684862 24447 solver.cpp:259]     Train net output #0: loss = 0.948576 (* 1 = 0.948576 loss)
I0708 01:55:11.684870 24447 solver.cpp:590] Iteration 13176, lr = 0.000469945
I0708 01:55:19.354100 24447 solver.cpp:243] Iteration 13203, loss = 0.889553
I0708 01:55:19.354164 24447 solver.cpp:259]     Train net output #0: loss = 0.889553 (* 1 = 0.889553 loss)
I0708 01:55:19.354171 24447 solver.cpp:590] Iteration 13203, lr = 0.000467009
I0708 01:55:27.060644 24447 solver.cpp:243] Iteration 13230, loss = 1.02671
I0708 01:55:27.060667 24447 solver.cpp:259]     Train net output #0: loss = 1.02671 (* 1 = 1.02671 loss)
I0708 01:55:27.060672 24447 solver.cpp:590] Iteration 13230, lr = 0.000464092
I0708 01:55:34.742066 24447 solver.cpp:243] Iteration 13257, loss = 0.846445
I0708 01:55:34.742092 24447 solver.cpp:259]     Train net output #0: loss = 0.846445 (* 1 = 0.846445 loss)
I0708 01:55:34.742100 24447 solver.cpp:590] Iteration 13257, lr = 0.000461193
I0708 01:55:35.315644 24447 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_13260.caffemodel
I0708 01:55:38.339157 24447 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_13260.solverstate
I0708 01:55:39.381054 24447 solver.cpp:347] Iteration 13260, Testing net (#0)
I0708 01:55:59.053424 24447 solver.cpp:415]     Test net output #0: accuracy = 0.409014
I0708 01:55:59.053503 24447 solver.cpp:415]     Test net output #1: loss = 3.07462 (* 1 = 3.07462 loss)
I0708 01:56:05.387197 24447 solver.cpp:243] Iteration 13284, loss = 1.18145
I0708 01:56:05.387219 24447 solver.cpp:259]     Train net output #0: loss = 1.18145 (* 1 = 1.18145 loss)
I0708 01:56:05.387225 24447 solver.cpp:590] Iteration 13284, lr = 0.000458313
I0708 01:56:13.074323 24447 solver.cpp:243] Iteration 13311, loss = 1.20734
I0708 01:56:13.074349 24447 solver.cpp:259]     Train net output #0: loss = 1.20734 (* 1 = 1.20734 loss)
I0708 01:56:13.074357 24447 solver.cpp:590] Iteration 13311, lr = 0.00045545
I0708 01:56:20.787839 24447 solver.cpp:243] Iteration 13338, loss = 1.16416
I0708 01:56:20.787864 24447 solver.cpp:259]     Train net output #0: loss = 1.16416 (* 1 = 1.16416 loss)
I0708 01:56:20.787870 24447 solver.cpp:590] Iteration 13338, lr = 0.000452605
I0708 01:56:28.571593 24447 solver.cpp:243] Iteration 13365, loss = 0.903863
I0708 01:56:28.571619 24447 solver.cpp:259]     Train net output #0: loss = 0.903863 (* 1 = 0.903863 loss)
I0708 01:56:28.571625 24447 solver.cpp:590] Iteration 13365, lr = 0.000449778
I0708 01:56:36.290657 24447 solver.cpp:243] Iteration 13392, loss = 1.14294
I0708 01:56:36.290731 24447 solver.cpp:259]     Train net output #0: loss = 1.14294 (* 1 = 1.14294 loss)
I0708 01:56:36.290747 24447 solver.cpp:590] Iteration 13392, lr = 0.000446969
I0708 01:56:43.953259 24447 solver.cpp:243] Iteration 13419, loss = 1.17053
I0708 01:56:43.953285 24447 solver.cpp:259]     Train net output #0: loss = 1.17053 (* 1 = 1.17053 loss)
I0708 01:56:43.953291 24447 solver.cpp:590] Iteration 13419, lr = 0.000444177
I0708 01:56:51.639729 24447 solver.cpp:243] Iteration 13446, loss = 0.972767
I0708 01:56:51.639755 24447 solver.cpp:259]     Train net output #0: loss = 0.972767 (* 1 = 0.972767 loss)
I0708 01:56:51.639761 24447 solver.cpp:590] Iteration 13446, lr = 0.000441402
I0708 01:56:59.324193 24447 solver.cpp:243] Iteration 13473, loss = 0.947173
I0708 01:56:59.324219 24447 solver.cpp:259]     Train net output #0: loss = 0.947173 (* 1 = 0.947173 loss)
I0708 01:56:59.324226 24447 solver.cpp:590] Iteration 13473, lr = 0.000438645
I0708 01:57:01.315593 24447 solver.cpp:347] Iteration 13481, Testing net (#0)
I0708 01:57:07.773489 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 01:57:20.481544 24447 solver.cpp:415]     Test net output #0: accuracy = 0.408053
I0708 01:57:20.481570 24447 solver.cpp:415]     Test net output #1: loss = 3.07038 (* 1 = 3.07038 loss)
I0708 01:57:25.376448 24447 solver.cpp:243] Iteration 13500, loss = 1.03975
I0708 01:57:25.376476 24447 solver.cpp:259]     Train net output #0: loss = 1.03975 (* 1 = 1.03975 loss)
I0708 01:57:25.376482 24447 solver.cpp:590] Iteration 13500, lr = 0.000435905
I0708 01:57:33.067731 24447 solver.cpp:243] Iteration 13527, loss = 1.25091
I0708 01:57:33.067759 24447 solver.cpp:259]     Train net output #0: loss = 1.25091 (* 1 = 1.25091 loss)
I0708 01:57:33.067764 24447 solver.cpp:590] Iteration 13527, lr = 0.000433182
I0708 01:57:40.768018 24447 solver.cpp:243] Iteration 13554, loss = 1.17517
I0708 01:57:40.768126 24447 solver.cpp:259]     Train net output #0: loss = 1.17517 (* 1 = 1.17517 loss)
I0708 01:57:40.768132 24447 solver.cpp:590] Iteration 13554, lr = 0.000430477
I0708 01:57:48.451762 24447 solver.cpp:243] Iteration 13581, loss = 1.16961
I0708 01:57:48.451788 24447 solver.cpp:259]     Train net output #0: loss = 1.16961 (* 1 = 1.16961 loss)
I0708 01:57:48.451794 24447 solver.cpp:590] Iteration 13581, lr = 0.000427788
I0708 01:57:56.161983 24447 solver.cpp:243] Iteration 13608, loss = 1.10471
I0708 01:57:56.162009 24447 solver.cpp:259]     Train net output #0: loss = 1.10471 (* 1 = 1.10471 loss)
I0708 01:57:56.162014 24447 solver.cpp:590] Iteration 13608, lr = 0.000425116
I0708 01:58:03.834797 24447 solver.cpp:243] Iteration 13635, loss = 1.24697
I0708 01:58:03.834823 24447 solver.cpp:259]     Train net output #0: loss = 1.24697 (* 1 = 1.24697 loss)
I0708 01:58:03.834830 24447 solver.cpp:590] Iteration 13635, lr = 0.00042246
I0708 01:58:11.512919 24447 solver.cpp:243] Iteration 13662, loss = 0.913547
I0708 01:58:11.513008 24447 solver.cpp:259]     Train net output #0: loss = 0.913547 (* 1 = 0.913547 loss)
I0708 01:58:11.513016 24447 solver.cpp:590] Iteration 13662, lr = 0.000419822
I0708 01:58:19.173949 24447 solver.cpp:243] Iteration 13689, loss = 1.10109
I0708 01:58:19.173975 24447 solver.cpp:259]     Train net output #0: loss = 1.10109 (* 1 = 1.10109 loss)
I0708 01:58:19.173982 24447 solver.cpp:590] Iteration 13689, lr = 0.000417199
I0708 01:58:22.583782 24447 solver.cpp:347] Iteration 13702, Testing net (#0)
I0708 01:58:41.740501 24447 solver.cpp:415]     Test net output #0: accuracy = 0.413942
I0708 01:58:41.740558 24447 solver.cpp:415]     Test net output #1: loss = 3.06431 (* 1 = 3.06431 loss)
I0708 01:58:45.224915 24447 solver.cpp:243] Iteration 13716, loss = 0.992701
I0708 01:58:45.224941 24447 solver.cpp:259]     Train net output #0: loss = 0.992701 (* 1 = 0.992701 loss)
I0708 01:58:45.224948 24447 solver.cpp:590] Iteration 13716, lr = 0.000414593
I0708 01:58:52.909277 24447 solver.cpp:243] Iteration 13743, loss = 0.848242
I0708 01:58:52.909304 24447 solver.cpp:259]     Train net output #0: loss = 0.848242 (* 1 = 0.848242 loss)
I0708 01:58:52.909310 24447 solver.cpp:590] Iteration 13743, lr = 0.000412004
I0708 01:59:00.613772 24447 solver.cpp:243] Iteration 13770, loss = 1.07919
I0708 01:59:00.613797 24447 solver.cpp:259]     Train net output #0: loss = 1.07919 (* 1 = 1.07919 loss)
I0708 01:59:00.613803 24447 solver.cpp:590] Iteration 13770, lr = 0.00040943
I0708 01:59:08.302192 24447 solver.cpp:243] Iteration 13797, loss = 1.01263
I0708 01:59:08.302219 24447 solver.cpp:259]     Train net output #0: loss = 1.01263 (* 1 = 1.01263 loss)
I0708 01:59:08.302225 24447 solver.cpp:590] Iteration 13797, lr = 0.000406873
I0708 01:59:16.005504 24447 solver.cpp:243] Iteration 13824, loss = 0.979499
I0708 01:59:16.005559 24447 solver.cpp:259]     Train net output #0: loss = 0.979499 (* 1 = 0.979499 loss)
I0708 01:59:16.005566 24447 solver.cpp:590] Iteration 13824, lr = 0.000404331
I0708 01:59:23.692652 24447 solver.cpp:243] Iteration 13851, loss = 1.18084
I0708 01:59:23.692680 24447 solver.cpp:259]     Train net output #0: loss = 1.18084 (* 1 = 1.18084 loss)
I0708 01:59:23.692687 24447 solver.cpp:590] Iteration 13851, lr = 0.000401806
I0708 01:59:31.368437 24447 solver.cpp:243] Iteration 13878, loss = 0.922956
I0708 01:59:31.368463 24447 solver.cpp:259]     Train net output #0: loss = 0.922956 (* 1 = 0.922956 loss)
I0708 01:59:31.368468 24447 solver.cpp:590] Iteration 13878, lr = 0.000399296
I0708 01:59:39.030218 24447 solver.cpp:243] Iteration 13905, loss = 0.902149
I0708 01:59:39.030246 24447 solver.cpp:259]     Train net output #0: loss = 0.902149 (* 1 = 0.902149 loss)
I0708 01:59:39.030251 24447 solver.cpp:590] Iteration 13905, lr = 0.000396802
I0708 01:59:43.865191 24447 solver.cpp:347] Iteration 13923, Testing net (#0)
I0708 01:59:54.177043 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:00:03.023561 24447 solver.cpp:415]     Test net output #0: accuracy = 0.411298
I0708 02:00:03.023586 24447 solver.cpp:415]     Test net output #1: loss = 3.06652 (* 1 = 3.06652 loss)
I0708 02:00:05.080080 24447 solver.cpp:243] Iteration 13932, loss = 1.18336
I0708 02:00:05.080104 24447 solver.cpp:259]     Train net output #0: loss = 1.18336 (* 1 = 1.18336 loss)
I0708 02:00:05.080111 24447 solver.cpp:590] Iteration 13932, lr = 0.000394323
I0708 02:00:12.788149 24447 solver.cpp:243] Iteration 13959, loss = 1.1357
I0708 02:00:12.788175 24447 solver.cpp:259]     Train net output #0: loss = 1.1357 (* 1 = 1.1357 loss)
I0708 02:00:12.788182 24447 solver.cpp:590] Iteration 13959, lr = 0.00039186
I0708 02:00:20.498270 24447 solver.cpp:243] Iteration 13986, loss = 1.23615
I0708 02:00:20.498318 24447 solver.cpp:259]     Train net output #0: loss = 1.23615 (* 1 = 1.23615 loss)
I0708 02:00:20.498327 24447 solver.cpp:590] Iteration 13986, lr = 0.000389413
I0708 02:00:28.205071 24447 solver.cpp:243] Iteration 14013, loss = 0.907951
I0708 02:00:28.205152 24447 solver.cpp:259]     Train net output #0: loss = 0.907951 (* 1 = 0.907951 loss)
I0708 02:00:28.205158 24447 solver.cpp:590] Iteration 14013, lr = 0.00038698
I0708 02:00:35.937695 24447 solver.cpp:243] Iteration 14040, loss = 0.963865
I0708 02:00:35.937721 24447 solver.cpp:259]     Train net output #0: loss = 0.963865 (* 1 = 0.963865 loss)
I0708 02:00:35.937727 24447 solver.cpp:590] Iteration 14040, lr = 0.000384563
I0708 02:00:43.658077 24447 solver.cpp:243] Iteration 14067, loss = 1.15766
I0708 02:00:43.658104 24447 solver.cpp:259]     Train net output #0: loss = 1.15766 (* 1 = 1.15766 loss)
I0708 02:00:43.658110 24447 solver.cpp:590] Iteration 14067, lr = 0.000382161
I0708 02:00:51.368476 24447 solver.cpp:243] Iteration 14094, loss = 0.867558
I0708 02:00:51.368504 24447 solver.cpp:259]     Train net output #0: loss = 0.867558 (* 1 = 0.867558 loss)
I0708 02:00:51.368510 24447 solver.cpp:590] Iteration 14094, lr = 0.000379774
I0708 02:00:59.063634 24447 solver.cpp:243] Iteration 14121, loss = 1.13602
I0708 02:00:59.063693 24447 solver.cpp:259]     Train net output #0: loss = 1.13602 (* 1 = 1.13602 loss)
I0708 02:00:59.063699 24447 solver.cpp:590] Iteration 14121, lr = 0.000377402
I0708 02:01:05.347038 24447 solver.cpp:347] Iteration 14144, Testing net (#0)
I0708 02:01:24.477447 24447 solver.cpp:415]     Test net output #0: accuracy = 0.410216
I0708 02:01:24.477473 24447 solver.cpp:415]     Test net output #1: loss = 3.06129 (* 1 = 3.06129 loss)
I0708 02:01:25.112316 24447 solver.cpp:243] Iteration 14148, loss = 1.07107
I0708 02:01:25.112344 24447 solver.cpp:259]     Train net output #0: loss = 1.07107 (* 1 = 1.07107 loss)
I0708 02:01:25.112349 24447 solver.cpp:590] Iteration 14148, lr = 0.000375045
I0708 02:01:32.801847 24447 solver.cpp:243] Iteration 14175, loss = 1.24224
I0708 02:01:32.801906 24447 solver.cpp:259]     Train net output #0: loss = 1.24224 (* 1 = 1.24224 loss)
I0708 02:01:32.801913 24447 solver.cpp:590] Iteration 14175, lr = 0.000372702
I0708 02:01:40.502873 24447 solver.cpp:243] Iteration 14202, loss = 0.777571
I0708 02:01:40.502899 24447 solver.cpp:259]     Train net output #0: loss = 0.777571 (* 1 = 0.777571 loss)
I0708 02:01:40.502905 24447 solver.cpp:590] Iteration 14202, lr = 0.000370374
I0708 02:01:48.175477 24447 solver.cpp:243] Iteration 14229, loss = 1.06954
I0708 02:01:48.175503 24447 solver.cpp:259]     Train net output #0: loss = 1.06954 (* 1 = 1.06954 loss)
I0708 02:01:48.175508 24447 solver.cpp:590] Iteration 14229, lr = 0.000368061
I0708 02:01:55.882457 24447 solver.cpp:243] Iteration 14256, loss = 1.19547
I0708 02:01:55.882483 24447 solver.cpp:259]     Train net output #0: loss = 1.19547 (* 1 = 1.19547 loss)
I0708 02:01:55.882489 24447 solver.cpp:590] Iteration 14256, lr = 0.000365762
I0708 02:02:03.580545 24447 solver.cpp:243] Iteration 14283, loss = 1.04317
I0708 02:02:03.580598 24447 solver.cpp:259]     Train net output #0: loss = 1.04317 (* 1 = 1.04317 loss)
I0708 02:02:03.580605 24447 solver.cpp:590] Iteration 14283, lr = 0.000363477
I0708 02:02:11.266366 24447 solver.cpp:243] Iteration 14310, loss = 0.930913
I0708 02:02:11.266393 24447 solver.cpp:259]     Train net output #0: loss = 0.930913 (* 1 = 0.930913 loss)
I0708 02:02:11.266401 24447 solver.cpp:590] Iteration 14310, lr = 0.000361207
I0708 02:02:18.916729 24447 solver.cpp:243] Iteration 14337, loss = 1.02268
I0708 02:02:18.916755 24447 solver.cpp:259]     Train net output #0: loss = 1.02268 (* 1 = 1.02268 loss)
I0708 02:02:18.916761 24447 solver.cpp:590] Iteration 14337, lr = 0.00035895
I0708 02:02:26.614490 24447 solver.cpp:243] Iteration 14364, loss = 0.98993
I0708 02:02:26.614516 24447 solver.cpp:259]     Train net output #0: loss = 0.98993 (* 1 = 0.98993 loss)
I0708 02:02:26.614521 24447 solver.cpp:590] Iteration 14364, lr = 0.000356708
I0708 02:02:26.614730 24447 solver.cpp:347] Iteration 14365, Testing net (#0)
I0708 02:02:40.847761 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:02:45.819294 24447 solver.cpp:415]     Test net output #0: accuracy = 0.409255
I0708 02:02:45.819319 24447 solver.cpp:415]     Test net output #1: loss = 3.06247 (* 1 = 3.06247 loss)
I0708 02:02:52.717346 24447 solver.cpp:243] Iteration 14391, loss = 0.756179
I0708 02:02:52.717373 24447 solver.cpp:259]     Train net output #0: loss = 0.756179 (* 1 = 0.756179 loss)
I0708 02:02:52.717380 24447 solver.cpp:590] Iteration 14391, lr = 0.00035448
I0708 02:03:00.410779 24447 solver.cpp:243] Iteration 14418, loss = 1.04444
I0708 02:03:00.410804 24447 solver.cpp:259]     Train net output #0: loss = 1.04444 (* 1 = 1.04444 loss)
I0708 02:03:00.410809 24447 solver.cpp:590] Iteration 14418, lr = 0.000352266
I0708 02:03:08.092214 24447 solver.cpp:243] Iteration 14445, loss = 1.12307
I0708 02:03:08.092237 24447 solver.cpp:259]     Train net output #0: loss = 1.12307 (* 1 = 1.12307 loss)
I0708 02:03:08.092242 24447 solver.cpp:590] Iteration 14445, lr = 0.000350066
I0708 02:03:15.793550 24447 solver.cpp:243] Iteration 14472, loss = 1.01739
I0708 02:03:15.793607 24447 solver.cpp:259]     Train net output #0: loss = 1.01739 (* 1 = 1.01739 loss)
I0708 02:03:15.793614 24447 solver.cpp:590] Iteration 14472, lr = 0.000347879
I0708 02:03:23.499899 24447 solver.cpp:243] Iteration 14499, loss = 0.845072
I0708 02:03:23.499927 24447 solver.cpp:259]     Train net output #0: loss = 0.845072 (* 1 = 0.845072 loss)
I0708 02:03:23.499934 24447 solver.cpp:590] Iteration 14499, lr = 0.000345706
I0708 02:03:31.165671 24447 solver.cpp:243] Iteration 14526, loss = 1.13617
I0708 02:03:31.165696 24447 solver.cpp:259]     Train net output #0: loss = 1.13617 (* 1 = 1.13617 loss)
I0708 02:03:31.165702 24447 solver.cpp:590] Iteration 14526, lr = 0.000343547
I0708 02:03:38.820255 24447 solver.cpp:243] Iteration 14553, loss = 1.1149
I0708 02:03:38.820281 24447 solver.cpp:259]     Train net output #0: loss = 1.1149 (* 1 = 1.1149 loss)
I0708 02:03:38.820287 24447 solver.cpp:590] Iteration 14553, lr = 0.000341401
I0708 02:03:46.498553 24447 solver.cpp:243] Iteration 14580, loss = 1.2498
I0708 02:03:46.498605 24447 solver.cpp:259]     Train net output #0: loss = 1.2498 (* 1 = 1.2498 loss)
I0708 02:03:46.498610 24447 solver.cpp:590] Iteration 14580, lr = 0.000339268
I0708 02:03:47.928122 24447 solver.cpp:347] Iteration 14586, Testing net (#0)
I0708 02:04:07.144898 24447 solver.cpp:415]     Test net output #0: accuracy = 0.411899
I0708 02:04:07.144924 24447 solver.cpp:415]     Test net output #1: loss = 3.05913 (* 1 = 3.05913 loss)
I0708 02:04:12.630190 24447 solver.cpp:243] Iteration 14607, loss = 0.859474
I0708 02:04:12.630218 24447 solver.cpp:259]     Train net output #0: loss = 0.859474 (* 1 = 0.859474 loss)
I0708 02:04:12.630225 24447 solver.cpp:590] Iteration 14607, lr = 0.000337149
I0708 02:04:20.338264 24447 solver.cpp:243] Iteration 14634, loss = 1.07388
I0708 02:04:20.338323 24447 solver.cpp:259]     Train net output #0: loss = 1.07388 (* 1 = 1.07388 loss)
I0708 02:04:20.338330 24447 solver.cpp:590] Iteration 14634, lr = 0.000335043
I0708 02:04:28.043391 24447 solver.cpp:243] Iteration 14661, loss = 1.3331
I0708 02:04:28.043417 24447 solver.cpp:259]     Train net output #0: loss = 1.3331 (* 1 = 1.3331 loss)
I0708 02:04:28.043424 24447 solver.cpp:590] Iteration 14661, lr = 0.000332951
I0708 02:04:35.752878 24447 solver.cpp:243] Iteration 14688, loss = 0.881623
I0708 02:04:35.752905 24447 solver.cpp:259]     Train net output #0: loss = 0.881623 (* 1 = 0.881623 loss)
I0708 02:04:35.752912 24447 solver.cpp:590] Iteration 14688, lr = 0.000330871
I0708 02:04:43.462390 24447 solver.cpp:243] Iteration 14715, loss = 1.05234
I0708 02:04:43.462415 24447 solver.cpp:259]     Train net output #0: loss = 1.05234 (* 1 = 1.05234 loss)
I0708 02:04:43.462420 24447 solver.cpp:590] Iteration 14715, lr = 0.000328804
I0708 02:04:51.122241 24447 solver.cpp:243] Iteration 14742, loss = 0.93193
I0708 02:04:51.122333 24447 solver.cpp:259]     Train net output #0: loss = 0.93193 (* 1 = 0.93193 loss)
I0708 02:04:51.122341 24447 solver.cpp:590] Iteration 14742, lr = 0.00032675
I0708 02:04:58.788547 24447 solver.cpp:243] Iteration 14769, loss = 0.835844
I0708 02:04:58.788573 24447 solver.cpp:259]     Train net output #0: loss = 0.835844 (* 1 = 0.835844 loss)
I0708 02:04:58.788579 24447 solver.cpp:590] Iteration 14769, lr = 0.000324709
I0708 02:05:06.453222 24447 solver.cpp:243] Iteration 14796, loss = 0.924975
I0708 02:05:06.453248 24447 solver.cpp:259]     Train net output #0: loss = 0.924975 (* 1 = 0.924975 loss)
I0708 02:05:06.453253 24447 solver.cpp:590] Iteration 14796, lr = 0.000322681
I0708 02:05:09.307868 24447 solver.cpp:347] Iteration 14807, Testing net (#0)
I0708 02:05:27.324940 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:05:28.440333 24447 solver.cpp:415]     Test net output #0: accuracy = 0.411899
I0708 02:05:28.440358 24447 solver.cpp:415]     Test net output #1: loss = 3.05518 (* 1 = 3.05518 loss)
I0708 02:05:32.494458 24447 solver.cpp:243] Iteration 14823, loss = 0.949803
I0708 02:05:32.494487 24447 solver.cpp:259]     Train net output #0: loss = 0.949803 (* 1 = 0.949803 loss)
I0708 02:05:32.494493 24447 solver.cpp:590] Iteration 14823, lr = 0.000320666
I0708 02:05:40.344926 24447 solver.cpp:243] Iteration 14850, loss = 1.05919
I0708 02:05:40.344952 24447 solver.cpp:259]     Train net output #0: loss = 1.05919 (* 1 = 1.05919 loss)
I0708 02:05:40.344959 24447 solver.cpp:590] Iteration 14850, lr = 0.000318663
I0708 02:05:48.060111 24447 solver.cpp:243] Iteration 14877, loss = 1.06808
I0708 02:05:48.060138 24447 solver.cpp:259]     Train net output #0: loss = 1.06808 (* 1 = 1.06808 loss)
I0708 02:05:48.060145 24447 solver.cpp:590] Iteration 14877, lr = 0.000316672
I0708 02:05:55.745982 24447 solver.cpp:243] Iteration 14904, loss = 1.14279
I0708 02:05:55.746007 24447 solver.cpp:259]     Train net output #0: loss = 1.14279 (* 1 = 1.14279 loss)
I0708 02:05:55.746013 24447 solver.cpp:590] Iteration 14904, lr = 0.000314694
I0708 02:06:03.453598 24447 solver.cpp:243] Iteration 14931, loss = 0.921668
I0708 02:06:03.453668 24447 solver.cpp:259]     Train net output #0: loss = 0.921668 (* 1 = 0.921668 loss)
I0708 02:06:03.453675 24447 solver.cpp:590] Iteration 14931, lr = 0.000312729
I0708 02:06:11.132098 24447 solver.cpp:243] Iteration 14958, loss = 1.20658
I0708 02:06:11.132125 24447 solver.cpp:259]     Train net output #0: loss = 1.20658 (* 1 = 1.20658 loss)
I0708 02:06:11.132131 24447 solver.cpp:590] Iteration 14958, lr = 0.000310775
I0708 02:06:18.793485 24447 solver.cpp:243] Iteration 14985, loss = 1.04247
I0708 02:06:18.793510 24447 solver.cpp:259]     Train net output #0: loss = 1.04247 (* 1 = 1.04247 loss)
I0708 02:06:18.793515 24447 solver.cpp:590] Iteration 14985, lr = 0.000308834
I0708 02:06:26.469142 24447 solver.cpp:243] Iteration 15012, loss = 0.929335
I0708 02:06:26.469169 24447 solver.cpp:259]     Train net output #0: loss = 0.929335 (* 1 = 0.929335 loss)
I0708 02:06:26.469175 24447 solver.cpp:590] Iteration 15012, lr = 0.000306905
I0708 02:06:30.739505 24447 solver.cpp:347] Iteration 15028, Testing net (#0)
I0708 02:06:49.963331 24447 solver.cpp:415]     Test net output #0: accuracy = 0.41226
I0708 02:06:49.963408 24447 solver.cpp:415]     Test net output #1: loss = 3.05276 (* 1 = 3.05276 loss)
I0708 02:06:52.590843 24447 solver.cpp:243] Iteration 15039, loss = 1.17386
I0708 02:06:52.590870 24447 solver.cpp:259]     Train net output #0: loss = 1.17386 (* 1 = 1.17386 loss)
I0708 02:06:52.590876 24447 solver.cpp:590] Iteration 15039, lr = 0.000304988
I0708 02:07:00.269557 24447 solver.cpp:243] Iteration 15066, loss = 0.892148
I0708 02:07:00.269587 24447 solver.cpp:259]     Train net output #0: loss = 0.892148 (* 1 = 0.892148 loss)
I0708 02:07:00.269593 24447 solver.cpp:590] Iteration 15066, lr = 0.000303083
I0708 02:07:07.976809 24447 solver.cpp:243] Iteration 15093, loss = 1.14079
I0708 02:07:07.976835 24447 solver.cpp:259]     Train net output #0: loss = 1.14079 (* 1 = 1.14079 loss)
I0708 02:07:07.976841 24447 solver.cpp:590] Iteration 15093, lr = 0.00030119
I0708 02:07:15.696244 24447 solver.cpp:243] Iteration 15120, loss = 1.10515
I0708 02:07:15.696271 24447 solver.cpp:259]     Train net output #0: loss = 1.10515 (* 1 = 1.10515 loss)
I0708 02:07:15.696277 24447 solver.cpp:590] Iteration 15120, lr = 0.000299309
I0708 02:07:23.488065 24447 solver.cpp:243] Iteration 15147, loss = 1.11547
I0708 02:07:23.488152 24447 solver.cpp:259]     Train net output #0: loss = 1.11547 (* 1 = 1.11547 loss)
I0708 02:07:23.488160 24447 solver.cpp:590] Iteration 15147, lr = 0.000297439
I0708 02:07:31.253964 24447 solver.cpp:243] Iteration 15174, loss = 0.918092
I0708 02:07:31.253991 24447 solver.cpp:259]     Train net output #0: loss = 0.918092 (* 1 = 0.918092 loss)
I0708 02:07:31.253998 24447 solver.cpp:590] Iteration 15174, lr = 0.000295581
I0708 02:07:39.011229 24447 solver.cpp:243] Iteration 15201, loss = 0.943664
I0708 02:07:39.011263 24447 solver.cpp:259]     Train net output #0: loss = 0.943664 (* 1 = 0.943664 loss)
I0708 02:07:39.011270 24447 solver.cpp:590] Iteration 15201, lr = 0.000293735
I0708 02:07:47.123970 24447 solver.cpp:243] Iteration 15228, loss = 0.678366
I0708 02:07:47.123996 24447 solver.cpp:259]     Train net output #0: loss = 0.678366 (* 1 = 0.678366 loss)
I0708 02:07:47.124001 24447 solver.cpp:590] Iteration 15228, lr = 0.0002919
I0708 02:07:53.074780 24447 solver.cpp:347] Iteration 15249, Testing net (#0)
I0708 02:08:12.190831 24447 solver.cpp:415]     Test net output #0: accuracy = 0.411178
I0708 02:08:12.190888 24447 solver.cpp:415]     Test net output #1: loss = 3.05387 (* 1 = 3.05387 loss)
I0708 02:08:13.395470 24447 solver.cpp:243] Iteration 15255, loss = 1.16463
I0708 02:08:13.395498 24447 solver.cpp:259]     Train net output #0: loss = 1.16463 (* 1 = 1.16463 loss)
I0708 02:08:13.395503 24447 solver.cpp:590] Iteration 15255, lr = 0.000290077
I0708 02:08:21.097124 24447 solver.cpp:243] Iteration 15282, loss = 0.977612
I0708 02:08:21.097153 24447 solver.cpp:259]     Train net output #0: loss = 0.977612 (* 1 = 0.977612 loss)
I0708 02:08:21.097159 24447 solver.cpp:590] Iteration 15282, lr = 0.000288265
I0708 02:08:22.814828 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:08:28.858011 24447 solver.cpp:243] Iteration 15309, loss = 0.992589
I0708 02:08:28.858033 24447 solver.cpp:259]     Train net output #0: loss = 0.992589 (* 1 = 0.992589 loss)
I0708 02:08:28.858039 24447 solver.cpp:590] Iteration 15309, lr = 0.000286464
I0708 02:08:36.625181 24447 solver.cpp:243] Iteration 15336, loss = 1.23502
I0708 02:08:36.625207 24447 solver.cpp:259]     Train net output #0: loss = 1.23502 (* 1 = 1.23502 loss)
I0708 02:08:36.625213 24447 solver.cpp:590] Iteration 15336, lr = 0.000284675
I0708 02:08:44.414400 24447 solver.cpp:243] Iteration 15363, loss = 1.22068
I0708 02:08:44.414455 24447 solver.cpp:259]     Train net output #0: loss = 1.22068 (* 1 = 1.22068 loss)
I0708 02:08:44.414463 24447 solver.cpp:590] Iteration 15363, lr = 0.000282897
I0708 02:08:52.110641 24447 solver.cpp:243] Iteration 15390, loss = 0.836311
I0708 02:08:52.110667 24447 solver.cpp:259]     Train net output #0: loss = 0.836311 (* 1 = 0.836311 loss)
I0708 02:08:52.110673 24447 solver.cpp:590] Iteration 15390, lr = 0.00028113
I0708 02:08:59.794904 24447 solver.cpp:243] Iteration 15417, loss = 0.937357
I0708 02:08:59.794932 24447 solver.cpp:259]     Train net output #0: loss = 0.937357 (* 1 = 0.937357 loss)
I0708 02:08:59.794939 24447 solver.cpp:590] Iteration 15417, lr = 0.000279374
I0708 02:09:07.545209 24447 solver.cpp:243] Iteration 15444, loss = 1.06324
I0708 02:09:07.545233 24447 solver.cpp:259]     Train net output #0: loss = 1.06324 (* 1 = 1.06324 loss)
I0708 02:09:07.545239 24447 solver.cpp:590] Iteration 15444, lr = 0.000277629
I0708 02:09:15.405581 24447 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_15470.caffemodel
I0708 02:09:18.573056 24447 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_15470.solverstate
I0708 02:09:19.588665 24447 solver.cpp:347] Iteration 15470, Testing net (#0)
I0708 02:09:38.647452 24447 solver.cpp:415]     Test net output #0: accuracy = 0.407332
I0708 02:09:38.647477 24447 solver.cpp:415]     Test net output #1: loss = 3.05609 (* 1 = 3.05609 loss)
I0708 02:09:38.778092 24447 solver.cpp:243] Iteration 15471, loss = 1.13525
I0708 02:09:38.778117 24447 solver.cpp:259]     Train net output #0: loss = 1.13525 (* 1 = 1.13525 loss)
I0708 02:09:38.778122 24447 solver.cpp:590] Iteration 15471, lr = 0.000275895
I0708 02:09:46.187585 24447 solver.cpp:243] Iteration 15498, loss = 1.38672
I0708 02:09:46.187679 24447 solver.cpp:259]     Train net output #0: loss = 1.38672 (* 1 = 1.38672 loss)
I0708 02:09:46.187685 24447 solver.cpp:590] Iteration 15498, lr = 0.000274171
I0708 02:09:53.938143 24447 solver.cpp:243] Iteration 15525, loss = 1.05357
I0708 02:09:53.938179 24447 solver.cpp:259]     Train net output #0: loss = 1.05357 (* 1 = 1.05357 loss)
I0708 02:09:53.938186 24447 solver.cpp:590] Iteration 15525, lr = 0.000272459
I0708 02:10:01.607007 24447 solver.cpp:243] Iteration 15552, loss = 0.830242
I0708 02:10:01.607033 24447 solver.cpp:259]     Train net output #0: loss = 0.830242 (* 1 = 0.830242 loss)
I0708 02:10:01.607039 24447 solver.cpp:590] Iteration 15552, lr = 0.000270757
I0708 02:10:09.342767 24447 solver.cpp:243] Iteration 15579, loss = 1.17802
I0708 02:10:09.342792 24447 solver.cpp:259]     Train net output #0: loss = 1.17802 (* 1 = 1.17802 loss)
I0708 02:10:09.342797 24447 solver.cpp:590] Iteration 15579, lr = 0.000269066
I0708 02:10:17.066715 24447 solver.cpp:243] Iteration 15606, loss = 0.970668
I0708 02:10:17.066768 24447 solver.cpp:259]     Train net output #0: loss = 0.970668 (* 1 = 0.970668 loss)
I0708 02:10:17.066776 24447 solver.cpp:590] Iteration 15606, lr = 0.000267385
I0708 02:10:24.812618 24447 solver.cpp:243] Iteration 15633, loss = 1.15719
I0708 02:10:24.812643 24447 solver.cpp:259]     Train net output #0: loss = 1.15719 (* 1 = 1.15719 loss)
I0708 02:10:24.812649 24447 solver.cpp:590] Iteration 15633, lr = 0.000265715
I0708 02:10:32.550154 24447 solver.cpp:243] Iteration 15660, loss = 0.881246
I0708 02:10:32.550189 24447 solver.cpp:259]     Train net output #0: loss = 0.881246 (* 1 = 0.881246 loss)
I0708 02:10:32.550195 24447 solver.cpp:590] Iteration 15660, lr = 0.000264055
I0708 02:10:40.327788 24447 solver.cpp:243] Iteration 15687, loss = 0.957681
I0708 02:10:40.327816 24447 solver.cpp:259]     Train net output #0: loss = 0.957681 (* 1 = 0.957681 loss)
I0708 02:10:40.327821 24447 solver.cpp:590] Iteration 15687, lr = 0.000262406
I0708 02:10:41.189177 24447 solver.cpp:347] Iteration 15691, Testing net (#0)
I0708 02:11:00.282111 24447 solver.cpp:415]     Test net output #0: accuracy = 0.409014
I0708 02:11:00.282225 24447 solver.cpp:415]     Test net output #1: loss = 3.05544 (* 1 = 3.05544 loss)
I0708 02:11:06.371285 24447 solver.cpp:243] Iteration 15714, loss = 0.980386
I0708 02:11:06.371318 24447 solver.cpp:259]     Train net output #0: loss = 0.980386 (* 1 = 0.980386 loss)
I0708 02:11:06.371325 24447 solver.cpp:590] Iteration 15714, lr = 0.000260767
I0708 02:11:14.102759 24447 solver.cpp:243] Iteration 15741, loss = 1.03698
I0708 02:11:14.102784 24447 solver.cpp:259]     Train net output #0: loss = 1.03698 (* 1 = 1.03698 loss)
I0708 02:11:14.102792 24447 solver.cpp:590] Iteration 15741, lr = 0.000259138
I0708 02:11:21.834427 24447 solver.cpp:243] Iteration 15768, loss = 1.02362
I0708 02:11:21.834451 24447 solver.cpp:259]     Train net output #0: loss = 1.02362 (* 1 = 1.02362 loss)
I0708 02:11:21.834457 24447 solver.cpp:590] Iteration 15768, lr = 0.000257519
I0708 02:11:25.831238 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:11:29.542652 24447 solver.cpp:243] Iteration 15795, loss = 1.04803
I0708 02:11:29.542677 24447 solver.cpp:259]     Train net output #0: loss = 1.04803 (* 1 = 1.04803 loss)
I0708 02:11:29.542685 24447 solver.cpp:590] Iteration 15795, lr = 0.000255911
I0708 02:11:37.262140 24447 solver.cpp:243] Iteration 15822, loss = 1.16252
I0708 02:11:37.262223 24447 solver.cpp:259]     Train net output #0: loss = 1.16252 (* 1 = 1.16252 loss)
I0708 02:11:37.262230 24447 solver.cpp:590] Iteration 15822, lr = 0.000254312
I0708 02:11:44.946877 24447 solver.cpp:243] Iteration 15849, loss = 1.05256
I0708 02:11:44.946904 24447 solver.cpp:259]     Train net output #0: loss = 1.05256 (* 1 = 1.05256 loss)
I0708 02:11:44.946910 24447 solver.cpp:590] Iteration 15849, lr = 0.000252724
I0708 02:11:52.614697 24447 solver.cpp:243] Iteration 15876, loss = 1.0449
I0708 02:11:52.614724 24447 solver.cpp:259]     Train net output #0: loss = 1.0449 (* 1 = 1.0449 loss)
I0708 02:11:52.614730 24447 solver.cpp:590] Iteration 15876, lr = 0.000251145
I0708 02:12:00.299227 24447 solver.cpp:243] Iteration 15903, loss = 1.17209
I0708 02:12:00.299255 24447 solver.cpp:259]     Train net output #0: loss = 1.17209 (* 1 = 1.17209 loss)
I0708 02:12:00.299263 24447 solver.cpp:590] Iteration 15903, lr = 0.000249577
I0708 02:12:02.582015 24447 solver.cpp:347] Iteration 15912, Testing net (#0)
I0708 02:12:21.706372 24447 solver.cpp:415]     Test net output #0: accuracy = 0.408654
I0708 02:12:21.706442 24447 solver.cpp:415]     Test net output #1: loss = 3.05331 (* 1 = 3.05331 loss)
I0708 02:12:26.325286 24447 solver.cpp:243] Iteration 15930, loss = 0.889152
I0708 02:12:26.325310 24447 solver.cpp:259]     Train net output #0: loss = 0.889152 (* 1 = 0.889152 loss)
I0708 02:12:26.325316 24447 solver.cpp:590] Iteration 15930, lr = 0.000248018
I0708 02:12:34.012657 24447 solver.cpp:243] Iteration 15957, loss = 0.951294
I0708 02:12:34.012683 24447 solver.cpp:259]     Train net output #0: loss = 0.951294 (* 1 = 0.951294 loss)
I0708 02:12:34.012689 24447 solver.cpp:590] Iteration 15957, lr = 0.000246469
I0708 02:12:41.736826 24447 solver.cpp:243] Iteration 15984, loss = 0.890829
I0708 02:12:41.736853 24447 solver.cpp:259]     Train net output #0: loss = 0.890829 (* 1 = 0.890829 loss)
I0708 02:12:41.736860 24447 solver.cpp:590] Iteration 15984, lr = 0.000244929
I0708 02:12:49.571913 24447 solver.cpp:243] Iteration 16011, loss = 0.987667
I0708 02:12:49.571938 24447 solver.cpp:259]     Train net output #0: loss = 0.987667 (* 1 = 0.987667 loss)
I0708 02:12:49.571943 24447 solver.cpp:590] Iteration 16011, lr = 0.000243399
I0708 02:12:57.300251 24447 solver.cpp:243] Iteration 16038, loss = 0.960585
I0708 02:12:57.300336 24447 solver.cpp:259]     Train net output #0: loss = 0.960585 (* 1 = 0.960585 loss)
I0708 02:12:57.300343 24447 solver.cpp:590] Iteration 16038, lr = 0.000241879
I0708 02:13:04.966214 24447 solver.cpp:243] Iteration 16065, loss = 0.831231
I0708 02:13:04.966241 24447 solver.cpp:259]     Train net output #0: loss = 0.831231 (* 1 = 0.831231 loss)
I0708 02:13:04.966246 24447 solver.cpp:590] Iteration 16065, lr = 0.000240368
I0708 02:13:12.687073 24447 solver.cpp:243] Iteration 16092, loss = 1.0086
I0708 02:13:12.687100 24447 solver.cpp:259]     Train net output #0: loss = 1.0086 (* 1 = 1.0086 loss)
I0708 02:13:12.687106 24447 solver.cpp:590] Iteration 16092, lr = 0.000238867
I0708 02:13:20.423797 24447 solver.cpp:243] Iteration 16119, loss = 0.952992
I0708 02:13:20.423823 24447 solver.cpp:259]     Train net output #0: loss = 0.952992 (* 1 = 0.952992 loss)
I0708 02:13:20.423830 24447 solver.cpp:590] Iteration 16119, lr = 0.000237375
I0708 02:13:24.175572 24447 solver.cpp:347] Iteration 16133, Testing net (#0)
I0708 02:13:43.388252 24447 solver.cpp:415]     Test net output #0: accuracy = 0.411058
I0708 02:13:43.388387 24447 solver.cpp:415]     Test net output #1: loss = 3.04919 (* 1 = 3.04919 loss)
I0708 02:13:46.586457 24447 solver.cpp:243] Iteration 16146, loss = 1.06576
I0708 02:13:46.586484 24447 solver.cpp:259]     Train net output #0: loss = 1.06576 (* 1 = 1.06576 loss)
I0708 02:13:46.586491 24447 solver.cpp:590] Iteration 16146, lr = 0.000235892
I0708 02:13:54.300390 24447 solver.cpp:243] Iteration 16173, loss = 1.03133
I0708 02:13:54.300415 24447 solver.cpp:259]     Train net output #0: loss = 1.03133 (* 1 = 1.03133 loss)
I0708 02:13:54.300429 24447 solver.cpp:590] Iteration 16173, lr = 0.000234418
I0708 02:14:02.007715 24447 solver.cpp:243] Iteration 16200, loss = 0.821132
I0708 02:14:02.007742 24447 solver.cpp:259]     Train net output #0: loss = 0.821132 (* 1 = 0.821132 loss)
I0708 02:14:02.007748 24447 solver.cpp:590] Iteration 16200, lr = 0.000232954
I0708 02:14:09.707425 24447 solver.cpp:243] Iteration 16227, loss = 0.921919
I0708 02:14:09.707450 24447 solver.cpp:259]     Train net output #0: loss = 0.921919 (* 1 = 0.921919 loss)
I0708 02:14:09.707456 24447 solver.cpp:590] Iteration 16227, lr = 0.000231499
I0708 02:14:17.428062 24447 solver.cpp:243] Iteration 16254, loss = 1.15803
I0708 02:14:17.428128 24447 solver.cpp:259]     Train net output #0: loss = 1.15803 (* 1 = 1.15803 loss)
I0708 02:14:17.428135 24447 solver.cpp:590] Iteration 16254, lr = 0.000230053
I0708 02:14:23.686614 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:14:25.104481 24447 solver.cpp:243] Iteration 16281, loss = 1.1199
I0708 02:14:25.104507 24447 solver.cpp:259]     Train net output #0: loss = 1.1199 (* 1 = 1.1199 loss)
I0708 02:14:25.104514 24447 solver.cpp:590] Iteration 16281, lr = 0.000228616
I0708 02:14:32.885617 24447 solver.cpp:243] Iteration 16308, loss = 0.890567
I0708 02:14:32.885643 24447 solver.cpp:259]     Train net output #0: loss = 0.890567 (* 1 = 0.890567 loss)
I0708 02:14:32.885650 24447 solver.cpp:590] Iteration 16308, lr = 0.000227188
I0708 02:14:40.581817 24447 solver.cpp:243] Iteration 16335, loss = 1.14747
I0708 02:14:40.581841 24447 solver.cpp:259]     Train net output #0: loss = 1.14747 (* 1 = 1.14747 loss)
I0708 02:14:40.581847 24447 solver.cpp:590] Iteration 16335, lr = 0.000225769
I0708 02:14:45.713062 24447 solver.cpp:347] Iteration 16354, Testing net (#0)
I0708 02:15:04.804947 24447 solver.cpp:415]     Test net output #0: accuracy = 0.408534
I0708 02:15:04.805011 24447 solver.cpp:415]     Test net output #1: loss = 3.05098 (* 1 = 3.05098 loss)
I0708 02:15:06.572012 24447 solver.cpp:243] Iteration 16362, loss = 0.978477
I0708 02:15:06.572039 24447 solver.cpp:259]     Train net output #0: loss = 0.978477 (* 1 = 0.978477 loss)
I0708 02:15:06.572046 24447 solver.cpp:590] Iteration 16362, lr = 0.000224359
I0708 02:15:14.315223 24447 solver.cpp:243] Iteration 16389, loss = 0.915664
I0708 02:15:14.315250 24447 solver.cpp:259]     Train net output #0: loss = 0.915664 (* 1 = 0.915664 loss)
I0708 02:15:14.315256 24447 solver.cpp:590] Iteration 16389, lr = 0.000222957
I0708 02:15:22.023514 24447 solver.cpp:243] Iteration 16416, loss = 0.810382
I0708 02:15:22.023540 24447 solver.cpp:259]     Train net output #0: loss = 0.810382 (* 1 = 0.810382 loss)
I0708 02:15:22.023545 24447 solver.cpp:590] Iteration 16416, lr = 0.000221565
I0708 02:15:29.731570 24447 solver.cpp:243] Iteration 16443, loss = 1.01977
I0708 02:15:29.731595 24447 solver.cpp:259]     Train net output #0: loss = 1.01977 (* 1 = 1.01977 loss)
I0708 02:15:29.731601 24447 solver.cpp:590] Iteration 16443, lr = 0.000220181
I0708 02:15:37.514900 24447 solver.cpp:243] Iteration 16470, loss = 0.965463
I0708 02:15:37.514989 24447 solver.cpp:259]     Train net output #0: loss = 0.965463 (* 1 = 0.965463 loss)
I0708 02:15:37.514997 24447 solver.cpp:590] Iteration 16470, lr = 0.000218806
I0708 02:15:45.253533 24447 solver.cpp:243] Iteration 16497, loss = 1.18987
I0708 02:15:45.253561 24447 solver.cpp:259]     Train net output #0: loss = 1.18987 (* 1 = 1.18987 loss)
I0708 02:15:45.253568 24447 solver.cpp:590] Iteration 16497, lr = 0.000217439
I0708 02:15:52.946796 24447 solver.cpp:243] Iteration 16524, loss = 1.18819
I0708 02:15:52.946823 24447 solver.cpp:259]     Train net output #0: loss = 1.18819 (* 1 = 1.18819 loss)
I0708 02:15:52.946830 24447 solver.cpp:590] Iteration 16524, lr = 0.000216081
I0708 02:16:00.636029 24447 solver.cpp:243] Iteration 16551, loss = 1.08419
I0708 02:16:00.636055 24447 solver.cpp:259]     Train net output #0: loss = 1.08419 (* 1 = 1.08419 loss)
I0708 02:16:00.636062 24447 solver.cpp:590] Iteration 16551, lr = 0.000214731
I0708 02:16:07.204704 24447 solver.cpp:347] Iteration 16575, Testing net (#0)
I0708 02:16:26.335485 24447 solver.cpp:415]     Test net output #0: accuracy = 0.41238
I0708 02:16:26.335636 24447 solver.cpp:415]     Test net output #1: loss = 3.05065 (* 1 = 3.05065 loss)
I0708 02:16:26.687572 24447 solver.cpp:243] Iteration 16578, loss = 0.918274
I0708 02:16:26.687599 24447 solver.cpp:259]     Train net output #0: loss = 0.918274 (* 1 = 0.918274 loss)
I0708 02:16:26.687605 24447 solver.cpp:590] Iteration 16578, lr = 0.00021339
I0708 02:16:34.366065 24447 solver.cpp:243] Iteration 16605, loss = 1.15945
I0708 02:16:34.366091 24447 solver.cpp:259]     Train net output #0: loss = 1.15945 (* 1 = 1.15945 loss)
I0708 02:16:34.366097 24447 solver.cpp:590] Iteration 16605, lr = 0.000212057
I0708 02:16:42.071440 24447 solver.cpp:243] Iteration 16632, loss = 0.901538
I0708 02:16:42.071470 24447 solver.cpp:259]     Train net output #0: loss = 0.901538 (* 1 = 0.901538 loss)
I0708 02:16:42.071476 24447 solver.cpp:590] Iteration 16632, lr = 0.000210732
I0708 02:16:49.754621 24447 solver.cpp:243] Iteration 16659, loss = 0.933263
I0708 02:16:49.754645 24447 solver.cpp:259]     Train net output #0: loss = 0.933263 (* 1 = 0.933263 loss)
I0708 02:16:49.754652 24447 solver.cpp:590] Iteration 16659, lr = 0.000209416
I0708 02:16:57.492804 24447 solver.cpp:243] Iteration 16686, loss = 1.04213
I0708 02:16:57.492887 24447 solver.cpp:259]     Train net output #0: loss = 1.04213 (* 1 = 1.04213 loss)
I0708 02:16:57.492893 24447 solver.cpp:590] Iteration 16686, lr = 0.000208108
I0708 02:17:05.217890 24447 solver.cpp:243] Iteration 16713, loss = 0.97866
I0708 02:17:05.217916 24447 solver.cpp:259]     Train net output #0: loss = 0.97866 (* 1 = 0.97866 loss)
I0708 02:17:05.217922 24447 solver.cpp:590] Iteration 16713, lr = 0.000206808
I0708 02:17:12.930469 24447 solver.cpp:243] Iteration 16740, loss = 1.11048
I0708 02:17:12.930493 24447 solver.cpp:259]     Train net output #0: loss = 1.11048 (* 1 = 1.11048 loss)
I0708 02:17:12.930500 24447 solver.cpp:590] Iteration 16740, lr = 0.000205516
I0708 02:17:20.656169 24447 solver.cpp:243] Iteration 16767, loss = 1.02225
I0708 02:17:20.656218 24447 solver.cpp:259]     Train net output #0: loss = 1.02225 (* 1 = 1.02225 loss)
I0708 02:17:20.656224 24447 solver.cpp:590] Iteration 16767, lr = 0.000204233
I0708 02:17:21.507114 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:17:28.341625 24447 solver.cpp:243] Iteration 16794, loss = 1.00917
I0708 02:17:28.341708 24447 solver.cpp:259]     Train net output #0: loss = 1.00917 (* 1 = 1.00917 loss)
I0708 02:17:28.341716 24447 solver.cpp:590] Iteration 16794, lr = 0.000202957
I0708 02:17:28.624305 24447 solver.cpp:347] Iteration 16796, Testing net (#0)
I0708 02:17:47.750890 24447 solver.cpp:415]     Test net output #0: accuracy = 0.412861
I0708 02:17:47.750913 24447 solver.cpp:415]     Test net output #1: loss = 3.04786 (* 1 = 3.04786 loss)
I0708 02:17:54.424944 24447 solver.cpp:243] Iteration 16821, loss = 1.01927
I0708 02:17:54.424968 24447 solver.cpp:259]     Train net output #0: loss = 1.01927 (* 1 = 1.01927 loss)
I0708 02:17:54.424974 24447 solver.cpp:590] Iteration 16821, lr = 0.000201689
I0708 02:18:02.195309 24447 solver.cpp:243] Iteration 16848, loss = 1.01854
I0708 02:18:02.195391 24447 solver.cpp:259]     Train net output #0: loss = 1.01854 (* 1 = 1.01854 loss)
I0708 02:18:02.195399 24447 solver.cpp:590] Iteration 16848, lr = 0.000200429
I0708 02:18:09.885263 24447 solver.cpp:243] Iteration 16875, loss = 1.05427
I0708 02:18:09.885288 24447 solver.cpp:259]     Train net output #0: loss = 1.05427 (* 1 = 1.05427 loss)
I0708 02:18:09.885293 24447 solver.cpp:590] Iteration 16875, lr = 0.000199177
I0708 02:18:17.582470 24447 solver.cpp:243] Iteration 16902, loss = 0.895465
I0708 02:18:17.582497 24447 solver.cpp:259]     Train net output #0: loss = 0.895465 (* 1 = 0.895465 loss)
I0708 02:18:17.582504 24447 solver.cpp:590] Iteration 16902, lr = 0.000197933
I0708 02:18:25.282658 24447 solver.cpp:243] Iteration 16929, loss = 1.08036
I0708 02:18:25.282685 24447 solver.cpp:259]     Train net output #0: loss = 1.08036 (* 1 = 1.08036 loss)
I0708 02:18:25.282691 24447 solver.cpp:590] Iteration 16929, lr = 0.000196697
I0708 02:18:32.971704 24447 solver.cpp:243] Iteration 16956, loss = 0.892156
I0708 02:18:32.971784 24447 solver.cpp:259]     Train net output #0: loss = 0.892156 (* 1 = 0.892156 loss)
I0708 02:18:32.971791 24447 solver.cpp:590] Iteration 16956, lr = 0.000195468
I0708 02:18:40.684458 24447 solver.cpp:243] Iteration 16983, loss = 1.07021
I0708 02:18:40.684483 24447 solver.cpp:259]     Train net output #0: loss = 1.07021 (* 1 = 1.07021 loss)
I0708 02:18:40.684489 24447 solver.cpp:590] Iteration 16983, lr = 0.000194247
I0708 02:18:48.426051 24447 solver.cpp:243] Iteration 17010, loss = 1.11185
I0708 02:18:48.426098 24447 solver.cpp:259]     Train net output #0: loss = 1.11185 (* 1 = 1.11185 loss)
I0708 02:18:48.426108 24447 solver.cpp:590] Iteration 17010, lr = 0.000193034
I0708 02:18:50.136474 24447 solver.cpp:347] Iteration 17017, Testing net (#0)
I0708 02:19:09.263677 24447 solver.cpp:415]     Test net output #0: accuracy = 0.410697
I0708 02:19:09.263737 24447 solver.cpp:415]     Test net output #1: loss = 3.04959 (* 1 = 3.04959 loss)
I0708 02:19:14.484882 24447 solver.cpp:243] Iteration 17037, loss = 1.18644
I0708 02:19:14.484908 24447 solver.cpp:259]     Train net output #0: loss = 1.18644 (* 1 = 1.18644 loss)
I0708 02:19:14.484915 24447 solver.cpp:590] Iteration 17037, lr = 0.000191828
I0708 02:19:22.234108 24447 solver.cpp:243] Iteration 17064, loss = 1.08496
I0708 02:19:22.234135 24447 solver.cpp:259]     Train net output #0: loss = 1.08496 (* 1 = 1.08496 loss)
I0708 02:19:22.234141 24447 solver.cpp:590] Iteration 17064, lr = 0.00019063
I0708 02:19:30.076589 24447 solver.cpp:243] Iteration 17091, loss = 1.01119
I0708 02:19:30.076617 24447 solver.cpp:259]     Train net output #0: loss = 1.01119 (* 1 = 1.01119 loss)
I0708 02:19:30.076622 24447 solver.cpp:590] Iteration 17091, lr = 0.000189439
I0708 02:19:37.883517 24447 solver.cpp:243] Iteration 17118, loss = 0.950016
I0708 02:19:37.883543 24447 solver.cpp:259]     Train net output #0: loss = 0.950016 (* 1 = 0.950016 loss)
I0708 02:19:37.883548 24447 solver.cpp:590] Iteration 17118, lr = 0.000188256
I0708 02:19:45.621238 24447 solver.cpp:243] Iteration 17145, loss = 0.824919
I0708 02:19:45.621297 24447 solver.cpp:259]     Train net output #0: loss = 0.824919 (* 1 = 0.824919 loss)
I0708 02:19:45.621304 24447 solver.cpp:590] Iteration 17145, lr = 0.00018708
I0708 02:19:53.291890 24447 solver.cpp:243] Iteration 17172, loss = 1.25925
I0708 02:19:53.291915 24447 solver.cpp:259]     Train net output #0: loss = 1.25925 (* 1 = 1.25925 loss)
I0708 02:19:53.291923 24447 solver.cpp:590] Iteration 17172, lr = 0.000185912
I0708 02:20:00.936925 24447 solver.cpp:243] Iteration 17199, loss = 0.965712
I0708 02:20:00.936951 24447 solver.cpp:259]     Train net output #0: loss = 0.965712 (* 1 = 0.965712 loss)
I0708 02:20:00.936957 24447 solver.cpp:590] Iteration 17199, lr = 0.00018475
I0708 02:20:08.616765 24447 solver.cpp:243] Iteration 17226, loss = 0.968977
I0708 02:20:08.616813 24447 solver.cpp:259]     Train net output #0: loss = 0.968977 (* 1 = 0.968977 loss)
I0708 02:20:08.616821 24447 solver.cpp:590] Iteration 17226, lr = 0.000183596
I0708 02:20:11.749562 24447 solver.cpp:347] Iteration 17238, Testing net (#0)
I0708 02:20:13.893291 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:20:30.871865 24447 solver.cpp:415]     Test net output #0: accuracy = 0.411538
I0708 02:20:30.871949 24447 solver.cpp:415]     Test net output #1: loss = 3.04947 (* 1 = 3.04947 loss)
I0708 02:20:34.642907 24447 solver.cpp:243] Iteration 17253, loss = 1.00282
I0708 02:20:34.642935 24447 solver.cpp:259]     Train net output #0: loss = 1.00282 (* 1 = 1.00282 loss)
I0708 02:20:34.642941 24447 solver.cpp:590] Iteration 17253, lr = 0.00018245
I0708 02:20:42.334691 24447 solver.cpp:243] Iteration 17280, loss = 1.04091
I0708 02:20:42.334713 24447 solver.cpp:259]     Train net output #0: loss = 1.04091 (* 1 = 1.04091 loss)
I0708 02:20:42.334719 24447 solver.cpp:590] Iteration 17280, lr = 0.00018131
I0708 02:20:50.024536 24447 solver.cpp:243] Iteration 17307, loss = 1.11514
I0708 02:20:50.024564 24447 solver.cpp:259]     Train net output #0: loss = 1.11514 (* 1 = 1.11514 loss)
I0708 02:20:50.024569 24447 solver.cpp:590] Iteration 17307, lr = 0.000180178
I0708 02:20:57.726120 24447 solver.cpp:243] Iteration 17334, loss = 0.893527
I0708 02:20:57.726145 24447 solver.cpp:259]     Train net output #0: loss = 0.893527 (* 1 = 0.893527 loss)
I0708 02:20:57.726150 24447 solver.cpp:590] Iteration 17334, lr = 0.000179052
I0708 02:21:05.428241 24447 solver.cpp:243] Iteration 17361, loss = 1.01846
I0708 02:21:05.428352 24447 solver.cpp:259]     Train net output #0: loss = 1.01846 (* 1 = 1.01846 loss)
I0708 02:21:05.428359 24447 solver.cpp:590] Iteration 17361, lr = 0.000177934
I0708 02:21:13.958858 24447 solver.cpp:243] Iteration 17388, loss = 0.859075
I0708 02:21:13.958885 24447 solver.cpp:259]     Train net output #0: loss = 0.859075 (* 1 = 0.859075 loss)
I0708 02:21:13.958891 24447 solver.cpp:590] Iteration 17388, lr = 0.000176822
I0708 02:21:23.252342 24447 solver.cpp:243] Iteration 17415, loss = 0.936883
I0708 02:21:23.252368 24447 solver.cpp:259]     Train net output #0: loss = 0.936883 (* 1 = 0.936883 loss)
I0708 02:21:23.252374 24447 solver.cpp:590] Iteration 17415, lr = 0.000175718
I0708 02:21:31.179803 24447 solver.cpp:243] Iteration 17442, loss = 0.887718
I0708 02:21:31.179829 24447 solver.cpp:259]     Train net output #0: loss = 0.887718 (* 1 = 0.887718 loss)
I0708 02:21:31.179836 24447 solver.cpp:590] Iteration 17442, lr = 0.00017462
I0708 02:21:36.431690 24447 solver.cpp:347] Iteration 17459, Testing net (#0)
I0708 02:21:55.701505 24447 solver.cpp:415]     Test net output #0: accuracy = 0.410457
I0708 02:21:55.701530 24447 solver.cpp:415]     Test net output #1: loss = 3.0495 (* 1 = 3.0495 loss)
I0708 02:21:58.040912 24447 solver.cpp:243] Iteration 17469, loss = 0.843896
I0708 02:21:58.040938 24447 solver.cpp:259]     Train net output #0: loss = 0.843896 (* 1 = 0.843896 loss)
I0708 02:21:58.040946 24447 solver.cpp:590] Iteration 17469, lr = 0.00017353
I0708 02:22:06.823266 24447 solver.cpp:243] Iteration 17496, loss = 1.09047
I0708 02:22:06.823330 24447 solver.cpp:259]     Train net output #0: loss = 1.09047 (* 1 = 1.09047 loss)
I0708 02:22:06.823338 24447 solver.cpp:590] Iteration 17496, lr = 0.000172446
I0708 02:22:16.115574 24447 solver.cpp:243] Iteration 17523, loss = 0.891667
I0708 02:22:16.115600 24447 solver.cpp:259]     Train net output #0: loss = 0.891667 (* 1 = 0.891667 loss)
I0708 02:22:16.115607 24447 solver.cpp:590] Iteration 17523, lr = 0.000171368
I0708 02:22:24.519510 24447 solver.cpp:243] Iteration 17550, loss = 1.07179
I0708 02:22:24.519534 24447 solver.cpp:259]     Train net output #0: loss = 1.07179 (* 1 = 1.07179 loss)
I0708 02:22:24.519541 24447 solver.cpp:590] Iteration 17550, lr = 0.000170298
I0708 02:22:33.743767 24447 solver.cpp:243] Iteration 17577, loss = 1.00933
I0708 02:22:33.743793 24447 solver.cpp:259]     Train net output #0: loss = 1.00933 (* 1 = 1.00933 loss)
I0708 02:22:33.743799 24447 solver.cpp:590] Iteration 17577, lr = 0.000169234
I0708 02:22:41.972396 24447 solver.cpp:243] Iteration 17604, loss = 1.20941
I0708 02:22:41.972479 24447 solver.cpp:259]     Train net output #0: loss = 1.20941 (* 1 = 1.20941 loss)
I0708 02:22:41.972486 24447 solver.cpp:590] Iteration 17604, lr = 0.000168177
I0708 02:22:50.311312 24447 solver.cpp:243] Iteration 17631, loss = 0.981022
I0708 02:22:50.311347 24447 solver.cpp:259]     Train net output #0: loss = 0.981022 (* 1 = 0.981022 loss)
I0708 02:22:50.311352 24447 solver.cpp:590] Iteration 17631, lr = 0.000167127
I0708 02:22:58.269139 24447 solver.cpp:243] Iteration 17658, loss = 1.15095
I0708 02:22:58.269165 24447 solver.cpp:259]     Train net output #0: loss = 1.15095 (* 1 = 1.15095 loss)
I0708 02:22:58.269171 24447 solver.cpp:590] Iteration 17658, lr = 0.000166083
I0708 02:23:04.741155 24447 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_17680.caffemodel
I0708 02:23:08.391826 24447 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_17680.solverstate
I0708 02:23:09.434614 24447 solver.cpp:347] Iteration 17680, Testing net (#0)
I0708 02:23:15.400328 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:23:28.507724 24447 solver.cpp:415]     Test net output #0: accuracy = 0.411298
I0708 02:23:28.507748 24447 solver.cpp:415]     Test net output #1: loss = 3.04694 (* 1 = 3.04694 loss)
I0708 02:23:29.421154 24447 solver.cpp:243] Iteration 17685, loss = 0.856209
I0708 02:23:29.421180 24447 solver.cpp:259]     Train net output #0: loss = 0.856209 (* 1 = 0.856209 loss)
I0708 02:23:29.421186 24447 solver.cpp:590] Iteration 17685, lr = 0.000165045
I0708 02:23:37.141806 24447 solver.cpp:243] Iteration 17712, loss = 1.08875
I0708 02:23:37.141830 24447 solver.cpp:259]     Train net output #0: loss = 1.08875 (* 1 = 1.08875 loss)
I0708 02:23:37.141836 24447 solver.cpp:590] Iteration 17712, lr = 0.000164015
I0708 02:23:44.860985 24447 solver.cpp:243] Iteration 17739, loss = 1.03783
I0708 02:23:44.861011 24447 solver.cpp:259]     Train net output #0: loss = 1.03783 (* 1 = 1.03783 loss)
I0708 02:23:44.861017 24447 solver.cpp:590] Iteration 17739, lr = 0.00016299
I0708 02:23:52.568436 24447 solver.cpp:243] Iteration 17766, loss = 1.0596
I0708 02:23:52.568572 24447 solver.cpp:259]     Train net output #0: loss = 1.0596 (* 1 = 1.0596 loss)
I0708 02:23:52.568580 24447 solver.cpp:590] Iteration 17766, lr = 0.000161972
I0708 02:24:00.321822 24447 solver.cpp:243] Iteration 17793, loss = 1.21126
I0708 02:24:00.321848 24447 solver.cpp:259]     Train net output #0: loss = 1.21126 (* 1 = 1.21126 loss)
I0708 02:24:00.321856 24447 solver.cpp:590] Iteration 17793, lr = 0.00016096
I0708 02:24:08.019528 24447 solver.cpp:243] Iteration 17820, loss = 0.929091
I0708 02:24:08.019554 24447 solver.cpp:259]     Train net output #0: loss = 0.929091 (* 1 = 0.929091 loss)
I0708 02:24:08.019561 24447 solver.cpp:590] Iteration 17820, lr = 0.000159955
I0708 02:24:15.738993 24447 solver.cpp:243] Iteration 17847, loss = 1.20602
I0708 02:24:15.739020 24447 solver.cpp:259]     Train net output #0: loss = 1.20602 (* 1 = 1.20602 loss)
I0708 02:24:15.739027 24447 solver.cpp:590] Iteration 17847, lr = 0.000158956
I0708 02:24:23.503361 24447 solver.cpp:243] Iteration 17874, loss = 0.963064
I0708 02:24:23.503429 24447 solver.cpp:259]     Train net output #0: loss = 0.963064 (* 1 = 0.963064 loss)
I0708 02:24:23.503437 24447 solver.cpp:590] Iteration 17874, lr = 0.000157963
I0708 02:24:31.007360 24447 solver.cpp:347] Iteration 17901, Testing net (#0)
I0708 02:24:50.153242 24447 solver.cpp:415]     Test net output #0: accuracy = 0.412981
I0708 02:24:50.153267 24447 solver.cpp:415]     Test net output #1: loss = 3.04444 (* 1 = 3.04444 loss)
I0708 02:24:50.210147 24447 solver.cpp:243] Iteration 17901, loss = 0.926544
I0708 02:24:50.210172 24447 solver.cpp:259]     Train net output #0: loss = 0.926544 (* 1 = 0.926544 loss)
I0708 02:24:50.210178 24447 solver.cpp:590] Iteration 17901, lr = 0.000156976
I0708 02:24:57.350527 24447 solver.cpp:243] Iteration 17928, loss = 1.06347
I0708 02:24:57.350610 24447 solver.cpp:259]     Train net output #0: loss = 1.06347 (* 1 = 1.06347 loss)
I0708 02:24:57.350616 24447 solver.cpp:590] Iteration 17928, lr = 0.000155996
I0708 02:25:05.118299 24447 solver.cpp:243] Iteration 17955, loss = 0.770093
I0708 02:25:05.118324 24447 solver.cpp:259]     Train net output #0: loss = 0.770093 (* 1 = 0.770093 loss)
I0708 02:25:05.118330 24447 solver.cpp:590] Iteration 17955, lr = 0.000155021
I0708 02:25:12.892904 24447 solver.cpp:243] Iteration 17982, loss = 1.08181
I0708 02:25:12.892930 24447 solver.cpp:259]     Train net output #0: loss = 1.08181 (* 1 = 1.08181 loss)
I0708 02:25:12.892936 24447 solver.cpp:590] Iteration 17982, lr = 0.000154053
I0708 02:25:20.657428 24447 solver.cpp:243] Iteration 18009, loss = 0.971089
I0708 02:25:20.657454 24447 solver.cpp:259]     Train net output #0: loss = 0.971089 (* 1 = 0.971089 loss)
I0708 02:25:20.657459 24447 solver.cpp:590] Iteration 18009, lr = 0.000153091
I0708 02:25:28.395035 24447 solver.cpp:243] Iteration 18036, loss = 0.803615
I0708 02:25:28.395119 24447 solver.cpp:259]     Train net output #0: loss = 0.803615 (* 1 = 0.803615 loss)
I0708 02:25:28.395126 24447 solver.cpp:590] Iteration 18036, lr = 0.000152135
I0708 02:25:36.073047 24447 solver.cpp:243] Iteration 18063, loss = 0.915421
I0708 02:25:36.073083 24447 solver.cpp:259]     Train net output #0: loss = 0.915421 (* 1 = 0.915421 loss)
I0708 02:25:36.073088 24447 solver.cpp:590] Iteration 18063, lr = 0.000151184
I0708 02:25:43.741013 24447 solver.cpp:243] Iteration 18090, loss = 0.750577
I0708 02:25:43.741039 24447 solver.cpp:259]     Train net output #0: loss = 0.750577 (* 1 = 0.750577 loss)
I0708 02:25:43.741045 24447 solver.cpp:590] Iteration 18090, lr = 0.00015024
I0708 02:25:51.423666 24447 solver.cpp:243] Iteration 18117, loss = 0.836945
I0708 02:25:51.423693 24447 solver.cpp:259]     Train net output #0: loss = 0.836945 (* 1 = 0.836945 loss)
I0708 02:25:51.423701 24447 solver.cpp:590] Iteration 18117, lr = 0.000149302
I0708 02:25:52.570619 24447 solver.cpp:347] Iteration 18122, Testing net (#0)
I0708 02:26:02.419857 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:26:11.695255 24447 solver.cpp:415]     Test net output #0: accuracy = 0.411298
I0708 02:26:11.695279 24447 solver.cpp:415]     Test net output #1: loss = 3.04665 (* 1 = 3.04665 loss)
I0708 02:26:17.486752 24447 solver.cpp:243] Iteration 18144, loss = 0.974243
I0708 02:26:17.486780 24447 solver.cpp:259]     Train net output #0: loss = 0.974243 (* 1 = 0.974243 loss)
I0708 02:26:17.486788 24447 solver.cpp:590] Iteration 18144, lr = 0.000148369
I0708 02:26:25.219426 24447 solver.cpp:243] Iteration 18171, loss = 1.00348
I0708 02:26:25.219454 24447 solver.cpp:259]     Train net output #0: loss = 1.00348 (* 1 = 1.00348 loss)
I0708 02:26:25.219458 24447 solver.cpp:590] Iteration 18171, lr = 0.000147442
I0708 02:26:32.900190 24447 solver.cpp:243] Iteration 18198, loss = 0.81745
I0708 02:26:32.900244 24447 solver.cpp:259]     Train net output #0: loss = 0.81745 (* 1 = 0.81745 loss)
I0708 02:26:32.900251 24447 solver.cpp:590] Iteration 18198, lr = 0.000146521
I0708 02:26:40.681886 24447 solver.cpp:243] Iteration 18225, loss = 0.979354
I0708 02:26:40.681918 24447 solver.cpp:259]     Train net output #0: loss = 0.979354 (* 1 = 0.979354 loss)
I0708 02:26:40.681927 24447 solver.cpp:590] Iteration 18225, lr = 0.000145606
I0708 02:26:48.438725 24447 solver.cpp:243] Iteration 18252, loss = 1.10328
I0708 02:26:48.438752 24447 solver.cpp:259]     Train net output #0: loss = 1.10328 (* 1 = 1.10328 loss)
I0708 02:26:48.438760 24447 solver.cpp:590] Iteration 18252, lr = 0.000144697
I0708 02:26:56.207759 24447 solver.cpp:243] Iteration 18279, loss = 1.27097
I0708 02:26:56.207785 24447 solver.cpp:259]     Train net output #0: loss = 1.27097 (* 1 = 1.27097 loss)
I0708 02:26:56.207792 24447 solver.cpp:590] Iteration 18279, lr = 0.000143793
I0708 02:27:03.908602 24447 solver.cpp:243] Iteration 18306, loss = 1.11405
I0708 02:27:03.908673 24447 solver.cpp:259]     Train net output #0: loss = 1.11405 (* 1 = 1.11405 loss)
I0708 02:27:03.908689 24447 solver.cpp:590] Iteration 18306, lr = 0.000142895
I0708 02:27:11.614279 24447 solver.cpp:243] Iteration 18333, loss = 0.997274
I0708 02:27:11.614305 24447 solver.cpp:259]     Train net output #0: loss = 0.997274 (* 1 = 0.997274 loss)
I0708 02:27:11.614311 24447 solver.cpp:590] Iteration 18333, lr = 0.000142002
I0708 02:27:14.178719 24447 solver.cpp:347] Iteration 18343, Testing net (#0)
I0708 02:27:33.298089 24447 solver.cpp:415]     Test net output #0: accuracy = 0.41226
I0708 02:27:33.298115 24447 solver.cpp:415]     Test net output #1: loss = 3.04482 (* 1 = 3.04482 loss)
I0708 02:27:37.675909 24447 solver.cpp:243] Iteration 18360, loss = 1.15206
I0708 02:27:37.676019 24447 solver.cpp:259]     Train net output #0: loss = 1.15206 (* 1 = 1.15206 loss)
I0708 02:27:37.676026 24447 solver.cpp:590] Iteration 18360, lr = 0.000141115
I0708 02:27:45.464468 24447 solver.cpp:243] Iteration 18387, loss = 0.876943
I0708 02:27:45.464495 24447 solver.cpp:259]     Train net output #0: loss = 0.876943 (* 1 = 0.876943 loss)
I0708 02:27:45.464501 24447 solver.cpp:590] Iteration 18387, lr = 0.000140234
I0708 02:27:53.146821 24447 solver.cpp:243] Iteration 18414, loss = 0.923137
I0708 02:27:53.146847 24447 solver.cpp:259]     Train net output #0: loss = 0.923137 (* 1 = 0.923137 loss)
I0708 02:27:53.146853 24447 solver.cpp:590] Iteration 18414, lr = 0.000139358
I0708 02:28:00.857687 24447 solver.cpp:243] Iteration 18441, loss = 0.848246
I0708 02:28:00.857713 24447 solver.cpp:259]     Train net output #0: loss = 0.848246 (* 1 = 0.848246 loss)
I0708 02:28:00.857720 24447 solver.cpp:590] Iteration 18441, lr = 0.000138487
I0708 02:28:08.559864 24447 solver.cpp:243] Iteration 18468, loss = 0.921263
I0708 02:28:08.559938 24447 solver.cpp:259]     Train net output #0: loss = 0.921263 (* 1 = 0.921263 loss)
I0708 02:28:08.559957 24447 solver.cpp:590] Iteration 18468, lr = 0.000137622
I0708 02:28:16.306787 24447 solver.cpp:243] Iteration 18495, loss = 0.958198
I0708 02:28:16.306814 24447 solver.cpp:259]     Train net output #0: loss = 0.958198 (* 1 = 0.958198 loss)
I0708 02:28:16.306819 24447 solver.cpp:590] Iteration 18495, lr = 0.000136763
I0708 02:28:24.046738 24447 solver.cpp:243] Iteration 18522, loss = 0.996335
I0708 02:28:24.046767 24447 solver.cpp:259]     Train net output #0: loss = 0.996335 (* 1 = 0.996335 loss)
I0708 02:28:24.046773 24447 solver.cpp:590] Iteration 18522, lr = 0.000135908
I0708 02:28:31.831490 24447 solver.cpp:243] Iteration 18549, loss = 0.899731
I0708 02:28:31.831513 24447 solver.cpp:259]     Train net output #0: loss = 0.899731 (* 1 = 0.899731 loss)
I0708 02:28:31.831521 24447 solver.cpp:590] Iteration 18549, lr = 0.000135059
I0708 02:28:35.869369 24447 solver.cpp:347] Iteration 18564, Testing net (#0)
I0708 02:28:49.574437 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:28:54.990661 24447 solver.cpp:415]     Test net output #0: accuracy = 0.413221
I0708 02:28:54.990686 24447 solver.cpp:415]     Test net output #1: loss = 3.0435 (* 1 = 3.0435 loss)
I0708 02:28:57.910221 24447 solver.cpp:243] Iteration 18576, loss = 0.786739
I0708 02:28:57.910245 24447 solver.cpp:259]     Train net output #0: loss = 0.786739 (* 1 = 0.786739 loss)
I0708 02:28:57.910253 24447 solver.cpp:590] Iteration 18576, lr = 0.000134216
I0708 02:29:05.644702 24447 solver.cpp:243] Iteration 18603, loss = 1.23201
I0708 02:29:05.644729 24447 solver.cpp:259]     Train net output #0: loss = 1.23201 (* 1 = 1.23201 loss)
I0708 02:29:05.644736 24447 solver.cpp:590] Iteration 18603, lr = 0.000133377
I0708 02:29:13.430675 24447 solver.cpp:243] Iteration 18630, loss = 0.895098
I0708 02:29:13.430701 24447 solver.cpp:259]     Train net output #0: loss = 0.895098 (* 1 = 0.895098 loss)
I0708 02:29:13.430706 24447 solver.cpp:590] Iteration 18630, lr = 0.000132544
I0708 02:29:21.218194 24447 solver.cpp:243] Iteration 18657, loss = 0.962793
I0708 02:29:21.218263 24447 solver.cpp:259]     Train net output #0: loss = 0.962793 (* 1 = 0.962793 loss)
I0708 02:29:21.218279 24447 solver.cpp:590] Iteration 18657, lr = 0.000131716
I0708 02:29:29.018080 24447 solver.cpp:243] Iteration 18684, loss = 1.02113
I0708 02:29:29.018106 24447 solver.cpp:259]     Train net output #0: loss = 1.02113 (* 1 = 1.02113 loss)
I0708 02:29:29.018112 24447 solver.cpp:590] Iteration 18684, lr = 0.000130894
I0708 02:29:36.775764 24447 solver.cpp:243] Iteration 18711, loss = 0.762188
I0708 02:29:36.775791 24447 solver.cpp:259]     Train net output #0: loss = 0.762188 (* 1 = 0.762188 loss)
I0708 02:29:36.775797 24447 solver.cpp:590] Iteration 18711, lr = 0.000130076
I0708 02:29:44.440194 24447 solver.cpp:243] Iteration 18738, loss = 0.730578
I0708 02:29:44.440220 24447 solver.cpp:259]     Train net output #0: loss = 0.730578 (* 1 = 0.730578 loss)
I0708 02:29:44.440227 24447 solver.cpp:590] Iteration 18738, lr = 0.000129264
I0708 02:29:52.130774 24447 solver.cpp:243] Iteration 18765, loss = 1.05078
I0708 02:29:52.130866 24447 solver.cpp:259]     Train net output #0: loss = 1.05078 (* 1 = 1.05078 loss)
I0708 02:29:52.130882 24447 solver.cpp:590] Iteration 18765, lr = 0.000128456
I0708 02:29:57.545972 24447 solver.cpp:347] Iteration 18785, Testing net (#0)
I0708 02:30:16.661026 24447 solver.cpp:415]     Test net output #0: accuracy = 0.413221
I0708 02:30:16.661058 24447 solver.cpp:415]     Test net output #1: loss = 3.04336 (* 1 = 3.04336 loss)
I0708 02:30:18.159195 24447 solver.cpp:243] Iteration 18792, loss = 1.04571
I0708 02:30:18.159222 24447 solver.cpp:259]     Train net output #0: loss = 1.04571 (* 1 = 1.04571 loss)
I0708 02:30:18.159229 24447 solver.cpp:590] Iteration 18792, lr = 0.000127654
I0708 02:30:25.853003 24447 solver.cpp:243] Iteration 18819, loss = 1.07931
I0708 02:30:25.853065 24447 solver.cpp:259]     Train net output #0: loss = 1.07931 (* 1 = 1.07931 loss)
I0708 02:30:25.853072 24447 solver.cpp:590] Iteration 18819, lr = 0.000126856
I0708 02:30:33.555892 24447 solver.cpp:243] Iteration 18846, loss = 0.893352
I0708 02:30:33.555919 24447 solver.cpp:259]     Train net output #0: loss = 0.893352 (* 1 = 0.893352 loss)
I0708 02:30:33.555925 24447 solver.cpp:590] Iteration 18846, lr = 0.000126064
I0708 02:30:41.303058 24447 solver.cpp:243] Iteration 18873, loss = 1.30172
I0708 02:30:41.303086 24447 solver.cpp:259]     Train net output #0: loss = 1.30172 (* 1 = 1.30172 loss)
I0708 02:30:41.303092 24447 solver.cpp:590] Iteration 18873, lr = 0.000125277
I0708 02:30:49.165072 24447 solver.cpp:243] Iteration 18900, loss = 1.18402
I0708 02:30:49.165099 24447 solver.cpp:259]     Train net output #0: loss = 1.18402 (* 1 = 1.18402 loss)
I0708 02:30:49.165104 24447 solver.cpp:590] Iteration 18900, lr = 0.000124494
I0708 02:30:56.893676 24447 solver.cpp:243] Iteration 18927, loss = 0.949973
I0708 02:30:56.893734 24447 solver.cpp:259]     Train net output #0: loss = 0.949973 (* 1 = 0.949973 loss)
I0708 02:30:56.893741 24447 solver.cpp:590] Iteration 18927, lr = 0.000123717
I0708 02:31:04.558691 24447 solver.cpp:243] Iteration 18954, loss = 1.13406
I0708 02:31:04.558715 24447 solver.cpp:259]     Train net output #0: loss = 1.13406 (* 1 = 1.13406 loss)
I0708 02:31:04.558722 24447 solver.cpp:590] Iteration 18954, lr = 0.000122944
I0708 02:31:12.217532 24447 solver.cpp:243] Iteration 18981, loss = 0.943871
I0708 02:31:12.217558 24447 solver.cpp:259]     Train net output #0: loss = 0.943871 (* 1 = 0.943871 loss)
I0708 02:31:12.217564 24447 solver.cpp:590] Iteration 18981, lr = 0.000122176
I0708 02:31:19.047524 24447 solver.cpp:347] Iteration 19006, Testing net (#0)
I0708 02:31:36.629659 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:31:38.185771 24447 solver.cpp:415]     Test net output #0: accuracy = 0.414183
I0708 02:31:38.185797 24447 solver.cpp:415]     Test net output #1: loss = 3.04226 (* 1 = 3.04226 loss)
I0708 02:31:38.386406 24447 solver.cpp:243] Iteration 19008, loss = 1.08546
I0708 02:31:38.386435 24447 solver.cpp:259]     Train net output #0: loss = 1.08546 (* 1 = 1.08546 loss)
I0708 02:31:38.386440 24447 solver.cpp:590] Iteration 19008, lr = 0.000121413
I0708 02:31:45.940731 24447 solver.cpp:243] Iteration 19035, loss = 1.07569
I0708 02:31:45.940757 24447 solver.cpp:259]     Train net output #0: loss = 1.07569 (* 1 = 1.07569 loss)
I0708 02:31:45.940763 24447 solver.cpp:590] Iteration 19035, lr = 0.000120654
I0708 02:31:53.647430 24447 solver.cpp:243] Iteration 19062, loss = 0.763416
I0708 02:31:53.647456 24447 solver.cpp:259]     Train net output #0: loss = 0.763416 (* 1 = 0.763416 loss)
I0708 02:31:53.647464 24447 solver.cpp:590] Iteration 19062, lr = 0.000119901
I0708 02:32:01.332552 24447 solver.cpp:243] Iteration 19089, loss = 1.02259
I0708 02:32:01.332579 24447 solver.cpp:259]     Train net output #0: loss = 1.02259 (* 1 = 1.02259 loss)
I0708 02:32:01.332586 24447 solver.cpp:590] Iteration 19089, lr = 0.000119152
I0708 02:32:09.036393 24447 solver.cpp:243] Iteration 19116, loss = 0.8436
I0708 02:32:09.036548 24447 solver.cpp:259]     Train net output #0: loss = 0.8436 (* 1 = 0.8436 loss)
I0708 02:32:09.036556 24447 solver.cpp:590] Iteration 19116, lr = 0.000118408
I0708 02:32:16.717052 24447 solver.cpp:243] Iteration 19143, loss = 1.18918
I0708 02:32:16.717079 24447 solver.cpp:259]     Train net output #0: loss = 1.18918 (* 1 = 1.18918 loss)
I0708 02:32:16.717085 24447 solver.cpp:590] Iteration 19143, lr = 0.000117668
I0708 02:32:24.392570 24447 solver.cpp:243] Iteration 19170, loss = 0.927264
I0708 02:32:24.392596 24447 solver.cpp:259]     Train net output #0: loss = 0.927264 (* 1 = 0.927264 loss)
I0708 02:32:24.392601 24447 solver.cpp:590] Iteration 19170, lr = 0.000116933
I0708 02:32:32.081683 24447 solver.cpp:243] Iteration 19197, loss = 0.872848
I0708 02:32:32.081710 24447 solver.cpp:259]     Train net output #0: loss = 0.872848 (* 1 = 0.872848 loss)
I0708 02:32:32.081717 24447 solver.cpp:590] Iteration 19197, lr = 0.000116203
I0708 02:32:39.798642 24447 solver.cpp:243] Iteration 19224, loss = 1.16154
I0708 02:32:39.798745 24447 solver.cpp:259]     Train net output #0: loss = 1.16154 (* 1 = 1.16154 loss)
I0708 02:32:39.798763 24447 solver.cpp:590] Iteration 19224, lr = 0.000115477
I0708 02:32:40.362968 24447 solver.cpp:347] Iteration 19227, Testing net (#0)
I0708 02:32:59.499204 24447 solver.cpp:415]     Test net output #0: accuracy = 0.413462
I0708 02:32:59.499228 24447 solver.cpp:415]     Test net output #1: loss = 3.04091 (* 1 = 3.04091 loss)
I0708 02:33:05.879125 24447 solver.cpp:243] Iteration 19251, loss = 0.888288
I0708 02:33:05.879153 24447 solver.cpp:259]     Train net output #0: loss = 0.888288 (* 1 = 0.888288 loss)
I0708 02:33:05.879158 24447 solver.cpp:590] Iteration 19251, lr = 0.000114755
I0708 02:33:13.666188 24447 solver.cpp:243] Iteration 19278, loss = 0.995152
I0708 02:33:13.666245 24447 solver.cpp:259]     Train net output #0: loss = 0.995152 (* 1 = 0.995152 loss)
I0708 02:33:13.666251 24447 solver.cpp:590] Iteration 19278, lr = 0.000114039
I0708 02:33:21.434902 24447 solver.cpp:243] Iteration 19305, loss = 1.06907
I0708 02:33:21.434926 24447 solver.cpp:259]     Train net output #0: loss = 1.06907 (* 1 = 1.06907 loss)
I0708 02:33:21.434933 24447 solver.cpp:590] Iteration 19305, lr = 0.000113326
I0708 02:33:29.221403 24447 solver.cpp:243] Iteration 19332, loss = 1.11278
I0708 02:33:29.221431 24447 solver.cpp:259]     Train net output #0: loss = 1.11278 (* 1 = 1.11278 loss)
I0708 02:33:29.221436 24447 solver.cpp:590] Iteration 19332, lr = 0.000112618
I0708 02:33:36.906275 24447 solver.cpp:243] Iteration 19359, loss = 0.768698
I0708 02:33:36.906302 24447 solver.cpp:259]     Train net output #0: loss = 0.768698 (* 1 = 0.768698 loss)
I0708 02:33:36.906308 24447 solver.cpp:590] Iteration 19359, lr = 0.000111915
I0708 02:33:44.621963 24447 solver.cpp:243] Iteration 19386, loss = 0.984083
I0708 02:33:44.622020 24447 solver.cpp:259]     Train net output #0: loss = 0.984083 (* 1 = 0.984083 loss)
I0708 02:33:44.622026 24447 solver.cpp:590] Iteration 19386, lr = 0.000111216
I0708 02:33:52.357946 24447 solver.cpp:243] Iteration 19413, loss = 0.804194
I0708 02:33:52.357971 24447 solver.cpp:259]     Train net output #0: loss = 0.804194 (* 1 = 0.804194 loss)
I0708 02:33:52.357976 24447 solver.cpp:590] Iteration 19413, lr = 0.000110521
I0708 02:34:00.137962 24447 solver.cpp:243] Iteration 19440, loss = 1.17201
I0708 02:34:00.137990 24447 solver.cpp:259]     Train net output #0: loss = 1.17201 (* 1 = 1.17201 loss)
I0708 02:34:00.137996 24447 solver.cpp:590] Iteration 19440, lr = 0.000109831
I0708 02:34:02.154289 24447 solver.cpp:347] Iteration 19448, Testing net (#0)
I0708 02:34:21.273087 24447 solver.cpp:415]     Test net output #0: accuracy = 0.41238
I0708 02:34:21.273167 24447 solver.cpp:415]     Test net output #1: loss = 3.04371 (* 1 = 3.04371 loss)
I0708 02:34:26.178385 24447 solver.cpp:243] Iteration 19467, loss = 0.978964
I0708 02:34:26.178412 24447 solver.cpp:259]     Train net output #0: loss = 0.978964 (* 1 = 0.978964 loss)
I0708 02:34:26.178419 24447 solver.cpp:590] Iteration 19467, lr = 0.000109145
I0708 02:34:30.168217 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:34:33.890686 24447 solver.cpp:243] Iteration 19494, loss = 0.967539
I0708 02:34:33.890714 24447 solver.cpp:259]     Train net output #0: loss = 0.967539 (* 1 = 0.967539 loss)
I0708 02:34:33.890720 24447 solver.cpp:590] Iteration 19494, lr = 0.000108463
I0708 02:34:41.565465 24447 solver.cpp:243] Iteration 19521, loss = 0.993598
I0708 02:34:41.565491 24447 solver.cpp:259]     Train net output #0: loss = 0.993598 (* 1 = 0.993598 loss)
I0708 02:34:41.565497 24447 solver.cpp:590] Iteration 19521, lr = 0.000107786
I0708 02:34:49.477931 24447 solver.cpp:243] Iteration 19548, loss = 0.842044
I0708 02:34:49.477958 24447 solver.cpp:259]     Train net output #0: loss = 0.842044 (* 1 = 0.842044 loss)
I0708 02:34:49.477965 24447 solver.cpp:590] Iteration 19548, lr = 0.000107112
I0708 02:34:57.175031 24447 solver.cpp:243] Iteration 19575, loss = 0.844626
I0708 02:34:57.175089 24447 solver.cpp:259]     Train net output #0: loss = 0.844626 (* 1 = 0.844626 loss)
I0708 02:34:57.175096 24447 solver.cpp:590] Iteration 19575, lr = 0.000106443
I0708 02:35:04.849603 24447 solver.cpp:243] Iteration 19602, loss = 1.16914
I0708 02:35:04.849628 24447 solver.cpp:259]     Train net output #0: loss = 1.16914 (* 1 = 1.16914 loss)
I0708 02:35:04.849634 24447 solver.cpp:590] Iteration 19602, lr = 0.000105778
I0708 02:35:12.501651 24447 solver.cpp:243] Iteration 19629, loss = 0.947817
I0708 02:35:12.501677 24447 solver.cpp:259]     Train net output #0: loss = 0.947817 (* 1 = 0.947817 loss)
I0708 02:35:12.501682 24447 solver.cpp:590] Iteration 19629, lr = 0.000105118
I0708 02:35:20.367485 24447 solver.cpp:243] Iteration 19656, loss = 0.961081
I0708 02:35:20.367525 24447 solver.cpp:259]     Train net output #0: loss = 0.961081 (* 1 = 0.961081 loss)
I0708 02:35:20.367533 24447 solver.cpp:590] Iteration 19656, lr = 0.000104461
I0708 02:35:23.955535 24447 solver.cpp:347] Iteration 19669, Testing net (#0)
I0708 02:35:43.205740 24447 solver.cpp:415]     Test net output #0: accuracy = 0.411538
I0708 02:35:43.205797 24447 solver.cpp:415]     Test net output #1: loss = 3.04397 (* 1 = 3.04397 loss)
I0708 02:35:46.821859 24447 solver.cpp:243] Iteration 19683, loss = 1.18034
I0708 02:35:46.821887 24447 solver.cpp:259]     Train net output #0: loss = 1.18034 (* 1 = 1.18034 loss)
I0708 02:35:46.821892 24447 solver.cpp:590] Iteration 19683, lr = 0.000103809
I0708 02:35:54.872357 24447 solver.cpp:243] Iteration 19710, loss = 0.925258
I0708 02:35:54.872385 24447 solver.cpp:259]     Train net output #0: loss = 0.925258 (* 1 = 0.925258 loss)
I0708 02:35:54.872392 24447 solver.cpp:590] Iteration 19710, lr = 0.00010316
I0708 02:36:02.999107 24447 solver.cpp:243] Iteration 19737, loss = 0.829114
I0708 02:36:02.999133 24447 solver.cpp:259]     Train net output #0: loss = 0.829114 (* 1 = 0.829114 loss)
I0708 02:36:02.999140 24447 solver.cpp:590] Iteration 19737, lr = 0.000102516
I0708 02:36:10.847635 24447 solver.cpp:243] Iteration 19764, loss = 1.22437
I0708 02:36:10.847661 24447 solver.cpp:259]     Train net output #0: loss = 1.22437 (* 1 = 1.22437 loss)
I0708 02:36:10.847666 24447 solver.cpp:590] Iteration 19764, lr = 0.000101876
I0708 02:36:18.719859 24447 solver.cpp:243] Iteration 19791, loss = 1.16885
I0708 02:36:18.719919 24447 solver.cpp:259]     Train net output #0: loss = 1.16885 (* 1 = 1.16885 loss)
I0708 02:36:18.719925 24447 solver.cpp:590] Iteration 19791, lr = 0.000101239
I0708 02:36:26.461163 24447 solver.cpp:243] Iteration 19818, loss = 0.994005
I0708 02:36:26.461190 24447 solver.cpp:259]     Train net output #0: loss = 0.994005 (* 1 = 0.994005 loss)
I0708 02:36:26.461197 24447 solver.cpp:590] Iteration 19818, lr = 0.000100607
I0708 02:36:34.207242 24447 solver.cpp:243] Iteration 19845, loss = 0.884497
I0708 02:36:34.207269 24447 solver.cpp:259]     Train net output #0: loss = 0.884497 (* 1 = 0.884497 loss)
I0708 02:36:34.207275 24447 solver.cpp:590] Iteration 19845, lr = 9.99785e-05
I0708 02:36:41.957211 24447 solver.cpp:243] Iteration 19872, loss = 1.07557
I0708 02:36:41.957231 24447 solver.cpp:259]     Train net output #0: loss = 1.07557 (* 1 = 1.07557 loss)
I0708 02:36:41.957237 24447 solver.cpp:590] Iteration 19872, lr = 9.9354e-05
I0708 02:36:46.788568 24447 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_19890.caffemodel
I0708 02:36:50.584125 24447 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_19890.solverstate
I0708 02:36:51.610378 24447 solver.cpp:347] Iteration 19890, Testing net (#0)
I0708 02:37:10.820850 24447 solver.cpp:415]     Test net output #0: accuracy = 0.41226
I0708 02:37:10.820876 24447 solver.cpp:415]     Test net output #1: loss = 3.04006 (* 1 = 3.04006 loss)
I0708 02:37:12.878228 24447 solver.cpp:243] Iteration 19899, loss = 0.972059
I0708 02:37:12.878252 24447 solver.cpp:259]     Train net output #0: loss = 0.972059 (* 1 = 0.972059 loss)
I0708 02:37:12.878258 24447 solver.cpp:590] Iteration 19899, lr = 9.87334e-05
I0708 02:37:20.629576 24447 solver.cpp:243] Iteration 19926, loss = 0.999737
I0708 02:37:20.629642 24447 solver.cpp:259]     Train net output #0: loss = 0.999737 (* 1 = 0.999737 loss)
I0708 02:37:20.629649 24447 solver.cpp:590] Iteration 19926, lr = 9.81167e-05
I0708 02:37:28.307518 24447 solver.cpp:243] Iteration 19953, loss = 0.742316
I0708 02:37:28.307543 24447 solver.cpp:259]     Train net output #0: loss = 0.742316 (* 1 = 0.742316 loss)
I0708 02:37:28.307549 24447 solver.cpp:590] Iteration 19953, lr = 9.75038e-05
I0708 02:37:34.588892 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:37:36.012362 24447 solver.cpp:243] Iteration 19980, loss = 0.917619
I0708 02:37:36.012387 24447 solver.cpp:259]     Train net output #0: loss = 0.917619 (* 1 = 0.917619 loss)
I0708 02:37:36.012393 24447 solver.cpp:590] Iteration 19980, lr = 9.68948e-05
I0708 02:37:43.731009 24447 solver.cpp:243] Iteration 20007, loss = 1.27394
I0708 02:37:43.731032 24447 solver.cpp:259]     Train net output #0: loss = 1.27394 (* 1 = 1.27394 loss)
I0708 02:37:43.731037 24447 solver.cpp:590] Iteration 20007, lr = 9.62895e-05
I0708 02:37:51.408049 24447 solver.cpp:243] Iteration 20034, loss = 0.91739
I0708 02:37:51.408110 24447 solver.cpp:259]     Train net output #0: loss = 0.91739 (* 1 = 0.91739 loss)
I0708 02:37:51.408118 24447 solver.cpp:590] Iteration 20034, lr = 9.56881e-05
I0708 02:37:59.141386 24447 solver.cpp:243] Iteration 20061, loss = 0.895976
I0708 02:37:59.141412 24447 solver.cpp:259]     Train net output #0: loss = 0.895976 (* 1 = 0.895976 loss)
I0708 02:37:59.141417 24447 solver.cpp:590] Iteration 20061, lr = 9.50904e-05
I0708 02:38:06.912842 24447 solver.cpp:243] Iteration 20088, loss = 0.897538
I0708 02:38:06.912868 24447 solver.cpp:259]     Train net output #0: loss = 0.897538 (* 1 = 0.897538 loss)
I0708 02:38:06.912873 24447 solver.cpp:590] Iteration 20088, lr = 9.44964e-05
I0708 02:38:13.285676 24447 solver.cpp:347] Iteration 20111, Testing net (#0)
I0708 02:38:32.395712 24447 solver.cpp:415]     Test net output #0: accuracy = 0.413221
I0708 02:38:32.395787 24447 solver.cpp:415]     Test net output #1: loss = 3.04162 (* 1 = 3.04162 loss)
I0708 02:38:33.033663 24447 solver.cpp:243] Iteration 20115, loss = 0.843775
I0708 02:38:33.033689 24447 solver.cpp:259]     Train net output #0: loss = 0.843775 (* 1 = 0.843775 loss)
I0708 02:38:33.033695 24447 solver.cpp:590] Iteration 20115, lr = 9.39062e-05
I0708 02:38:40.717157 24447 solver.cpp:243] Iteration 20142, loss = 0.817095
I0708 02:38:40.717185 24447 solver.cpp:259]     Train net output #0: loss = 0.817095 (* 1 = 0.817095 loss)
I0708 02:38:40.717190 24447 solver.cpp:590] Iteration 20142, lr = 9.33196e-05
I0708 02:38:48.414784 24447 solver.cpp:243] Iteration 20169, loss = 0.96827
I0708 02:38:48.414810 24447 solver.cpp:259]     Train net output #0: loss = 0.96827 (* 1 = 0.96827 loss)
I0708 02:38:48.414816 24447 solver.cpp:590] Iteration 20169, lr = 9.27367e-05
I0708 02:38:56.220091 24447 solver.cpp:243] Iteration 20196, loss = 1.01612
I0708 02:38:56.220116 24447 solver.cpp:259]     Train net output #0: loss = 1.01612 (* 1 = 1.01612 loss)
I0708 02:38:56.220123 24447 solver.cpp:590] Iteration 20196, lr = 9.21575e-05
I0708 02:39:04.004964 24447 solver.cpp:243] Iteration 20223, loss = 1.0188
I0708 02:39:04.005048 24447 solver.cpp:259]     Train net output #0: loss = 1.0188 (* 1 = 1.0188 loss)
I0708 02:39:04.005055 24447 solver.cpp:590] Iteration 20223, lr = 9.15818e-05
I0708 02:39:11.779592 24447 solver.cpp:243] Iteration 20250, loss = 0.785983
I0708 02:39:11.779620 24447 solver.cpp:259]     Train net output #0: loss = 0.785983 (* 1 = 0.785983 loss)
I0708 02:39:11.779628 24447 solver.cpp:590] Iteration 20250, lr = 9.10098e-05
I0708 02:39:19.461336 24447 solver.cpp:243] Iteration 20277, loss = 0.817672
I0708 02:39:19.461362 24447 solver.cpp:259]     Train net output #0: loss = 0.817672 (* 1 = 0.817672 loss)
I0708 02:39:19.461369 24447 solver.cpp:590] Iteration 20277, lr = 9.04413e-05
I0708 02:39:27.168328 24447 solver.cpp:243] Iteration 20304, loss = 1.09113
I0708 02:39:27.168354 24447 solver.cpp:259]     Train net output #0: loss = 1.09113 (* 1 = 1.09113 loss)
I0708 02:39:27.168359 24447 solver.cpp:590] Iteration 20304, lr = 8.98764e-05
I0708 02:39:34.898397 24447 solver.cpp:243] Iteration 20331, loss = 0.914154
I0708 02:39:34.898453 24447 solver.cpp:259]     Train net output #0: loss = 0.914154 (* 1 = 0.914154 loss)
I0708 02:39:34.898459 24447 solver.cpp:590] Iteration 20331, lr = 8.9315e-05
I0708 02:39:34.898674 24447 solver.cpp:347] Iteration 20332, Testing net (#0)
I0708 02:39:54.053639 24447 solver.cpp:415]     Test net output #0: accuracy = 0.411659
I0708 02:39:54.053664 24447 solver.cpp:415]     Test net output #1: loss = 3.04092 (* 1 = 3.04092 loss)
I0708 02:40:00.957648 24447 solver.cpp:243] Iteration 20358, loss = 1.06866
I0708 02:40:00.957671 24447 solver.cpp:259]     Train net output #0: loss = 1.06866 (* 1 = 1.06866 loss)
I0708 02:40:00.957676 24447 solver.cpp:590] Iteration 20358, lr = 8.87571e-05
I0708 02:40:08.657574 24447 solver.cpp:243] Iteration 20385, loss = 1.16754
I0708 02:40:08.657644 24447 solver.cpp:259]     Train net output #0: loss = 1.16754 (* 1 = 1.16754 loss)
I0708 02:40:08.657650 24447 solver.cpp:590] Iteration 20385, lr = 8.82027e-05
I0708 02:40:16.363437 24447 solver.cpp:243] Iteration 20412, loss = 0.963085
I0708 02:40:16.363463 24447 solver.cpp:259]     Train net output #0: loss = 0.963085 (* 1 = 0.963085 loss)
I0708 02:40:16.363471 24447 solver.cpp:590] Iteration 20412, lr = 8.76518e-05
I0708 02:40:24.102967 24447 solver.cpp:243] Iteration 20439, loss = 0.8454
I0708 02:40:24.102990 24447 solver.cpp:259]     Train net output #0: loss = 0.8454 (* 1 = 0.8454 loss)
I0708 02:40:24.102996 24447 solver.cpp:590] Iteration 20439, lr = 8.71043e-05
I0708 02:40:31.776234 24447 solver.cpp:243] Iteration 20466, loss = 0.924209
I0708 02:40:31.776262 24447 solver.cpp:259]     Train net output #0: loss = 0.924209 (* 1 = 0.924209 loss)
I0708 02:40:31.776268 24447 solver.cpp:590] Iteration 20466, lr = 8.65602e-05
I0708 02:40:32.631353 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:40:39.475178 24447 solver.cpp:243] Iteration 20493, loss = 0.98541
I0708 02:40:39.475265 24447 solver.cpp:259]     Train net output #0: loss = 0.98541 (* 1 = 0.98541 loss)
I0708 02:40:39.475273 24447 solver.cpp:590] Iteration 20493, lr = 8.60196e-05
I0708 02:40:47.150461 24447 solver.cpp:243] Iteration 20520, loss = 0.867463
I0708 02:40:47.150486 24447 solver.cpp:259]     Train net output #0: loss = 0.867463 (* 1 = 0.867463 loss)
I0708 02:40:47.150493 24447 solver.cpp:590] Iteration 20520, lr = 8.54823e-05
I0708 02:40:54.859411 24447 solver.cpp:243] Iteration 20547, loss = 1.18119
I0708 02:40:54.859437 24447 solver.cpp:259]     Train net output #0: loss = 1.18119 (* 1 = 1.18119 loss)
I0708 02:40:54.859443 24447 solver.cpp:590] Iteration 20547, lr = 8.49483e-05
I0708 02:40:56.340446 24447 solver.cpp:347] Iteration 20553, Testing net (#0)
I0708 02:41:15.519577 24447 solver.cpp:415]     Test net output #0: accuracy = 0.411538
I0708 02:41:15.519661 24447 solver.cpp:415]     Test net output #1: loss = 3.04071 (* 1 = 3.04071 loss)
I0708 02:41:21.023972 24447 solver.cpp:243] Iteration 20574, loss = 1.16196
I0708 02:41:21.023999 24447 solver.cpp:259]     Train net output #0: loss = 1.16196 (* 1 = 1.16196 loss)
I0708 02:41:21.024005 24447 solver.cpp:590] Iteration 20574, lr = 8.44177e-05
I0708 02:41:28.821553 24447 solver.cpp:243] Iteration 20601, loss = 0.923885
I0708 02:41:28.821580 24447 solver.cpp:259]     Train net output #0: loss = 0.923885 (* 1 = 0.923885 loss)
I0708 02:41:28.821586 24447 solver.cpp:590] Iteration 20601, lr = 8.38904e-05
I0708 02:41:36.601835 24447 solver.cpp:243] Iteration 20628, loss = 0.906571
I0708 02:41:36.601862 24447 solver.cpp:259]     Train net output #0: loss = 0.906571 (* 1 = 0.906571 loss)
I0708 02:41:36.601868 24447 solver.cpp:590] Iteration 20628, lr = 8.33664e-05
I0708 02:41:44.399574 24447 solver.cpp:243] Iteration 20655, loss = 1.08107
I0708 02:41:44.399602 24447 solver.cpp:259]     Train net output #0: loss = 1.08107 (* 1 = 1.08107 loss)
I0708 02:41:44.399608 24447 solver.cpp:590] Iteration 20655, lr = 8.28457e-05
I0708 02:41:52.157063 24447 solver.cpp:243] Iteration 20682, loss = 0.88396
I0708 02:41:52.157151 24447 solver.cpp:259]     Train net output #0: loss = 0.88396 (* 1 = 0.88396 loss)
I0708 02:41:52.157158 24447 solver.cpp:590] Iteration 20682, lr = 8.23282e-05
I0708 02:41:59.874045 24447 solver.cpp:243] Iteration 20709, loss = 1.1312
I0708 02:41:59.874079 24447 solver.cpp:259]     Train net output #0: loss = 1.1312 (* 1 = 1.1312 loss)
I0708 02:41:59.874085 24447 solver.cpp:590] Iteration 20709, lr = 8.1814e-05
I0708 02:42:07.538502 24447 solver.cpp:243] Iteration 20736, loss = 1.06913
I0708 02:42:07.538527 24447 solver.cpp:259]     Train net output #0: loss = 1.06913 (* 1 = 1.06913 loss)
I0708 02:42:07.538533 24447 solver.cpp:590] Iteration 20736, lr = 8.13029e-05
I0708 02:42:15.264169 24447 solver.cpp:243] Iteration 20763, loss = 0.949531
I0708 02:42:15.264194 24447 solver.cpp:259]     Train net output #0: loss = 0.949531 (* 1 = 0.949531 loss)
I0708 02:42:15.264201 24447 solver.cpp:590] Iteration 20763, lr = 8.07951e-05
I0708 02:42:18.113204 24447 solver.cpp:347] Iteration 20774, Testing net (#0)
I0708 02:42:37.313513 24447 solver.cpp:415]     Test net output #0: accuracy = 0.412139
I0708 02:42:37.313585 24447 solver.cpp:415]     Test net output #1: loss = 3.04012 (* 1 = 3.04012 loss)
I0708 02:42:41.371839 24447 solver.cpp:243] Iteration 20790, loss = 0.872572
I0708 02:42:41.371863 24447 solver.cpp:259]     Train net output #0: loss = 0.872572 (* 1 = 0.872572 loss)
I0708 02:42:41.371870 24447 solver.cpp:590] Iteration 20790, lr = 8.02904e-05
I0708 02:42:49.155797 24447 solver.cpp:243] Iteration 20817, loss = 0.921022
I0708 02:42:49.155823 24447 solver.cpp:259]     Train net output #0: loss = 0.921022 (* 1 = 0.921022 loss)
I0708 02:42:49.155829 24447 solver.cpp:590] Iteration 20817, lr = 7.97889e-05
I0708 02:42:56.870630 24447 solver.cpp:243] Iteration 20844, loss = 1.13548
I0708 02:42:56.870654 24447 solver.cpp:259]     Train net output #0: loss = 1.13548 (* 1 = 1.13548 loss)
I0708 02:42:56.870661 24447 solver.cpp:590] Iteration 20844, lr = 7.92905e-05
I0708 02:43:04.607903 24447 solver.cpp:243] Iteration 20871, loss = 1.03018
I0708 02:43:04.607930 24447 solver.cpp:259]     Train net output #0: loss = 1.03018 (* 1 = 1.03018 loss)
I0708 02:43:04.607936 24447 solver.cpp:590] Iteration 20871, lr = 7.87953e-05
I0708 02:43:12.363281 24447 solver.cpp:243] Iteration 20898, loss = 0.955656
I0708 02:43:12.363358 24447 solver.cpp:259]     Train net output #0: loss = 0.955656 (* 1 = 0.955656 loss)
I0708 02:43:12.363374 24447 solver.cpp:590] Iteration 20898, lr = 7.83031e-05
I0708 02:43:20.100962 24447 solver.cpp:243] Iteration 20925, loss = 1.00182
I0708 02:43:20.100989 24447 solver.cpp:259]     Train net output #0: loss = 1.00182 (* 1 = 1.00182 loss)
I0708 02:43:20.100996 24447 solver.cpp:590] Iteration 20925, lr = 7.7814e-05
I0708 02:43:27.797240 24447 solver.cpp:243] Iteration 20952, loss = 1.42788
I0708 02:43:27.797266 24447 solver.cpp:259]     Train net output #0: loss = 1.42788 (* 1 = 1.42788 loss)
I0708 02:43:27.797271 24447 solver.cpp:590] Iteration 20952, lr = 7.7328e-05
I0708 02:43:30.913483 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:43:35.498517 24447 solver.cpp:243] Iteration 20979, loss = 1.21331
I0708 02:43:35.498541 24447 solver.cpp:259]     Train net output #0: loss = 1.21331 (* 1 = 1.21331 loss)
I0708 02:43:35.498546 24447 solver.cpp:590] Iteration 20979, lr = 7.6845e-05
I0708 02:43:39.783092 24447 solver.cpp:347] Iteration 20995, Testing net (#0)
I0708 02:43:58.943946 24447 solver.cpp:415]     Test net output #0: accuracy = 0.411899
I0708 02:43:58.944041 24447 solver.cpp:415]     Test net output #1: loss = 3.03974 (* 1 = 3.03974 loss)
I0708 02:44:01.574816 24447 solver.cpp:243] Iteration 21006, loss = 1.08205
I0708 02:44:01.574842 24447 solver.cpp:259]     Train net output #0: loss = 1.08205 (* 1 = 1.08205 loss)
I0708 02:44:01.574848 24447 solver.cpp:590] Iteration 21006, lr = 7.6365e-05
I0708 02:44:09.281839 24447 solver.cpp:243] Iteration 21033, loss = 0.840676
I0708 02:44:09.281868 24447 solver.cpp:259]     Train net output #0: loss = 0.840676 (* 1 = 0.840676 loss)
I0708 02:44:09.281874 24447 solver.cpp:590] Iteration 21033, lr = 7.5888e-05
I0708 02:44:17.026975 24447 solver.cpp:243] Iteration 21060, loss = 0.990713
I0708 02:44:17.026999 24447 solver.cpp:259]     Train net output #0: loss = 0.990713 (* 1 = 0.990713 loss)
I0708 02:44:17.027005 24447 solver.cpp:590] Iteration 21060, lr = 7.5414e-05
I0708 02:44:24.849747 24447 solver.cpp:243] Iteration 21087, loss = 0.957493
I0708 02:44:24.849774 24447 solver.cpp:259]     Train net output #0: loss = 0.957493 (* 1 = 0.957493 loss)
I0708 02:44:24.849781 24447 solver.cpp:590] Iteration 21087, lr = 7.49429e-05
I0708 02:44:32.637001 24447 solver.cpp:243] Iteration 21114, loss = 0.91937
I0708 02:44:32.637069 24447 solver.cpp:259]     Train net output #0: loss = 0.91937 (* 1 = 0.91937 loss)
I0708 02:44:32.637076 24447 solver.cpp:590] Iteration 21114, lr = 7.44748e-05
I0708 02:44:40.423542 24447 solver.cpp:243] Iteration 21141, loss = 0.776805
I0708 02:44:40.423566 24447 solver.cpp:259]     Train net output #0: loss = 0.776805 (* 1 = 0.776805 loss)
I0708 02:44:40.423573 24447 solver.cpp:590] Iteration 21141, lr = 7.40096e-05
I0708 02:44:48.168483 24447 solver.cpp:243] Iteration 21168, loss = 1.02074
I0708 02:44:48.168509 24447 solver.cpp:259]     Train net output #0: loss = 1.02074 (* 1 = 1.02074 loss)
I0708 02:44:48.168514 24447 solver.cpp:590] Iteration 21168, lr = 7.35473e-05
I0708 02:44:55.992009 24447 solver.cpp:243] Iteration 21195, loss = 0.611328
I0708 02:44:55.992036 24447 solver.cpp:259]     Train net output #0: loss = 0.611328 (* 1 = 0.611328 loss)
I0708 02:44:55.992041 24447 solver.cpp:590] Iteration 21195, lr = 7.30879e-05
I0708 02:45:01.749364 24447 solver.cpp:347] Iteration 21216, Testing net (#0)
I0708 02:45:20.956439 24447 solver.cpp:415]     Test net output #0: accuracy = 0.41238
I0708 02:45:20.956513 24447 solver.cpp:415]     Test net output #1: loss = 3.03927 (* 1 = 3.03927 loss)
I0708 02:45:22.169945 24447 solver.cpp:243] Iteration 21222, loss = 1.2798
I0708 02:45:22.169965 24447 solver.cpp:259]     Train net output #0: loss = 1.2798 (* 1 = 1.2798 loss)
I0708 02:45:22.169971 24447 solver.cpp:590] Iteration 21222, lr = 7.26314e-05
I0708 02:45:30.150280 24447 solver.cpp:243] Iteration 21249, loss = 0.673905
I0708 02:45:30.150307 24447 solver.cpp:259]     Train net output #0: loss = 0.673905 (* 1 = 0.673905 loss)
I0708 02:45:30.150313 24447 solver.cpp:590] Iteration 21249, lr = 7.21777e-05
I0708 02:45:38.342427 24447 solver.cpp:243] Iteration 21276, loss = 1.12817
I0708 02:45:38.342452 24447 solver.cpp:259]     Train net output #0: loss = 1.12817 (* 1 = 1.12817 loss)
I0708 02:45:38.342458 24447 solver.cpp:590] Iteration 21276, lr = 7.17269e-05
I0708 02:45:46.105609 24447 solver.cpp:243] Iteration 21303, loss = 0.935402
I0708 02:45:46.105646 24447 solver.cpp:259]     Train net output #0: loss = 0.935402 (* 1 = 0.935402 loss)
I0708 02:45:46.105654 24447 solver.cpp:590] Iteration 21303, lr = 7.12789e-05
I0708 02:45:53.852200 24447 solver.cpp:243] Iteration 21330, loss = 0.847362
I0708 02:45:53.852315 24447 solver.cpp:259]     Train net output #0: loss = 0.847362 (* 1 = 0.847362 loss)
I0708 02:45:53.852324 24447 solver.cpp:590] Iteration 21330, lr = 7.08336e-05
I0708 02:46:01.557471 24447 solver.cpp:243] Iteration 21357, loss = 0.94865
I0708 02:46:01.557497 24447 solver.cpp:259]     Train net output #0: loss = 0.94865 (* 1 = 0.94865 loss)
I0708 02:46:01.557503 24447 solver.cpp:590] Iteration 21357, lr = 7.03912e-05
I0708 02:46:09.229413 24447 solver.cpp:243] Iteration 21384, loss = 1.17471
I0708 02:46:09.229439 24447 solver.cpp:259]     Train net output #0: loss = 1.17471 (* 1 = 1.17471 loss)
I0708 02:46:09.229445 24447 solver.cpp:590] Iteration 21384, lr = 6.99515e-05
I0708 02:46:16.922977 24447 solver.cpp:243] Iteration 21411, loss = 0.990234
I0708 02:46:16.923002 24447 solver.cpp:259]     Train net output #0: loss = 0.990234 (* 1 = 0.990234 loss)
I0708 02:46:16.923008 24447 solver.cpp:590] Iteration 21411, lr = 6.95146e-05
I0708 02:46:24.056958 24447 solver.cpp:347] Iteration 21437, Testing net (#0)
I0708 02:46:25.763108 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:46:43.221946 24447 solver.cpp:415]     Test net output #0: accuracy = 0.412139
I0708 02:46:43.221972 24447 solver.cpp:415]     Test net output #1: loss = 3.03845 (* 1 = 3.03845 loss)
I0708 02:46:43.351279 24447 solver.cpp:243] Iteration 21438, loss = 0.915192
I0708 02:46:43.351317 24447 solver.cpp:259]     Train net output #0: loss = 0.915192 (* 1 = 0.915192 loss)
I0708 02:46:43.351323 24447 solver.cpp:590] Iteration 21438, lr = 6.90804e-05
I0708 02:46:50.735494 24447 solver.cpp:243] Iteration 21465, loss = 1.00234
I0708 02:46:50.735520 24447 solver.cpp:259]     Train net output #0: loss = 1.00234 (* 1 = 1.00234 loss)
I0708 02:46:50.735525 24447 solver.cpp:590] Iteration 21465, lr = 6.86489e-05
I0708 02:46:58.510154 24447 solver.cpp:243] Iteration 21492, loss = 1.01264
I0708 02:46:58.510260 24447 solver.cpp:259]     Train net output #0: loss = 1.01264 (* 1 = 1.01264 loss)
I0708 02:46:58.510277 24447 solver.cpp:590] Iteration 21492, lr = 6.82201e-05
I0708 02:47:06.253463 24447 solver.cpp:243] Iteration 21519, loss = 0.947016
I0708 02:47:06.253489 24447 solver.cpp:259]     Train net output #0: loss = 0.947016 (* 1 = 0.947016 loss)
I0708 02:47:06.253496 24447 solver.cpp:590] Iteration 21519, lr = 6.7794e-05
I0708 02:47:14.017302 24447 solver.cpp:243] Iteration 21546, loss = 1.0704
I0708 02:47:14.017329 24447 solver.cpp:259]     Train net output #0: loss = 1.0704 (* 1 = 1.0704 loss)
I0708 02:47:14.017335 24447 solver.cpp:590] Iteration 21546, lr = 6.73705e-05
I0708 02:47:21.706982 24447 solver.cpp:243] Iteration 21573, loss = 0.91779
I0708 02:47:21.707006 24447 solver.cpp:259]     Train net output #0: loss = 0.91779 (* 1 = 0.91779 loss)
I0708 02:47:21.707012 24447 solver.cpp:590] Iteration 21573, lr = 6.69497e-05
I0708 02:47:29.396008 24447 solver.cpp:243] Iteration 21600, loss = 1.10621
I0708 02:47:29.396077 24447 solver.cpp:259]     Train net output #0: loss = 1.10621 (* 1 = 1.10621 loss)
I0708 02:47:29.396093 24447 solver.cpp:590] Iteration 21600, lr = 6.65315e-05
I0708 02:47:37.075191 24447 solver.cpp:243] Iteration 21627, loss = 0.877463
I0708 02:47:37.075219 24447 solver.cpp:259]     Train net output #0: loss = 0.877463 (* 1 = 0.877463 loss)
I0708 02:47:37.075235 24447 solver.cpp:590] Iteration 21627, lr = 6.61159e-05
I0708 02:47:44.793689 24447 solver.cpp:243] Iteration 21654, loss = 0.995563
I0708 02:47:44.793716 24447 solver.cpp:259]     Train net output #0: loss = 0.995563 (* 1 = 0.995563 loss)
I0708 02:47:44.793722 24447 solver.cpp:590] Iteration 21654, lr = 6.5703e-05
I0708 02:47:45.650441 24447 solver.cpp:347] Iteration 21658, Testing net (#0)
I0708 02:48:04.803200 24447 solver.cpp:415]     Test net output #0: accuracy = 0.412019
I0708 02:48:04.803308 24447 solver.cpp:415]     Test net output #1: loss = 3.03967 (* 1 = 3.03967 loss)
I0708 02:48:10.867316 24447 solver.cpp:243] Iteration 21681, loss = 0.887513
I0708 02:48:10.867342 24447 solver.cpp:259]     Train net output #0: loss = 0.887513 (* 1 = 0.887513 loss)
I0708 02:48:10.867348 24447 solver.cpp:590] Iteration 21681, lr = 6.52926e-05
I0708 02:48:18.593225 24447 solver.cpp:243] Iteration 21708, loss = 1.19601
I0708 02:48:18.593252 24447 solver.cpp:259]     Train net output #0: loss = 1.19601 (* 1 = 1.19601 loss)
I0708 02:48:18.593258 24447 solver.cpp:590] Iteration 21708, lr = 6.48847e-05
I0708 02:48:26.334805 24447 solver.cpp:243] Iteration 21735, loss = 0.770747
I0708 02:48:26.334831 24447 solver.cpp:259]     Train net output #0: loss = 0.770747 (* 1 = 0.770747 loss)
I0708 02:48:26.334837 24447 solver.cpp:590] Iteration 21735, lr = 6.44794e-05
I0708 02:48:34.121098 24447 solver.cpp:243] Iteration 21762, loss = 1.07667
I0708 02:48:34.121124 24447 solver.cpp:259]     Train net output #0: loss = 1.07667 (* 1 = 1.07667 loss)
I0708 02:48:34.121131 24447 solver.cpp:590] Iteration 21762, lr = 6.40767e-05
I0708 02:48:41.836854 24447 solver.cpp:243] Iteration 21789, loss = 0.947761
I0708 02:48:41.836930 24447 solver.cpp:259]     Train net output #0: loss = 0.947761 (* 1 = 0.947761 loss)
I0708 02:48:41.836947 24447 solver.cpp:590] Iteration 21789, lr = 6.36765e-05
I0708 02:48:49.565346 24447 solver.cpp:243] Iteration 21816, loss = 0.854939
I0708 02:48:49.565371 24447 solver.cpp:259]     Train net output #0: loss = 0.854939 (* 1 = 0.854939 loss)
I0708 02:48:49.565377 24447 solver.cpp:590] Iteration 21816, lr = 6.32787e-05
I0708 02:48:57.280099 24447 solver.cpp:243] Iteration 21843, loss = 1.02164
I0708 02:48:57.280125 24447 solver.cpp:259]     Train net output #0: loss = 1.02164 (* 1 = 1.02164 loss)
I0708 02:48:57.280131 24447 solver.cpp:590] Iteration 21843, lr = 6.28835e-05
I0708 02:49:04.998888 24447 solver.cpp:243] Iteration 21870, loss = 1.03173
I0708 02:49:04.998913 24447 solver.cpp:259]     Train net output #0: loss = 1.03173 (* 1 = 1.03173 loss)
I0708 02:49:04.998919 24447 solver.cpp:590] Iteration 21870, lr = 6.24907e-05
I0708 02:49:07.294117 24447 solver.cpp:347] Iteration 21879, Testing net (#0)
I0708 02:49:12.856792 24447 blocking_queue.cpp:50] Data layer prefetch queue empty
I0708 02:49:26.440996 24447 solver.cpp:415]     Test net output #0: accuracy = 0.413462
I0708 02:49:26.441022 24447 solver.cpp:415]     Test net output #1: loss = 3.03878 (* 1 = 3.03878 loss)
I0708 02:49:31.093572 24447 solver.cpp:243] Iteration 21897, loss = 1.02385
I0708 02:49:31.093598 24447 solver.cpp:259]     Train net output #0: loss = 1.02385 (* 1 = 1.02385 loss)
I0708 02:49:31.093605 24447 solver.cpp:590] Iteration 21897, lr = 6.21003e-05
I0708 02:49:38.891844 24447 solver.cpp:243] Iteration 21924, loss = 0.880804
I0708 02:49:38.891871 24447 solver.cpp:259]     Train net output #0: loss = 0.880804 (* 1 = 0.880804 loss)
I0708 02:49:38.891878 24447 solver.cpp:590] Iteration 21924, lr = 6.17125e-05
I0708 02:49:46.619765 24447 solver.cpp:243] Iteration 21951, loss = 1.04364
I0708 02:49:46.619835 24447 solver.cpp:259]     Train net output #0: loss = 1.04364 (* 1 = 1.04364 loss)
I0708 02:49:46.619853 24447 solver.cpp:590] Iteration 21951, lr = 6.1327e-05
I0708 02:49:54.414858 24447 solver.cpp:243] Iteration 21978, loss = 1.18141
I0708 02:49:54.414885 24447 solver.cpp:259]     Train net output #0: loss = 1.18141 (* 1 = 1.18141 loss)
I0708 02:49:54.414892 24447 solver.cpp:590] Iteration 21978, lr = 6.09439e-05
I0708 02:50:02.101989 24447 solver.cpp:243] Iteration 22005, loss = 1.02183
I0708 02:50:02.102015 24447 solver.cpp:259]     Train net output #0: loss = 1.02183 (* 1 = 1.02183 loss)
I0708 02:50:02.102020 24447 solver.cpp:590] Iteration 22005, lr = 6.05632e-05
I0708 02:50:09.812185 24447 solver.cpp:243] Iteration 22032, loss = 0.917669
I0708 02:50:09.812212 24447 solver.cpp:259]     Train net output #0: loss = 0.917669 (* 1 = 0.917669 loss)
I0708 02:50:09.812218 24447 solver.cpp:590] Iteration 22032, lr = 6.0185e-05
I0708 02:50:17.526566 24447 solver.cpp:243] Iteration 22059, loss = 1.03368
I0708 02:50:17.526643 24447 solver.cpp:259]     Train net output #0: loss = 1.03368 (* 1 = 1.03368 loss)
I0708 02:50:17.526651 24447 solver.cpp:590] Iteration 22059, lr = 5.9809e-05
I0708 02:50:25.222795 24447 solver.cpp:243] Iteration 22086, loss = 1.03617
I0708 02:50:25.222820 24447 solver.cpp:259]     Train net output #0: loss = 1.03617 (* 1 = 1.03617 loss)
I0708 02:50:25.222826 24447 solver.cpp:590] Iteration 22086, lr = 5.94354e-05
I0708 02:50:28.942893 24447 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_22100.caffemodel
I0708 02:50:32.878769 24447 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_22100.solverstate
I0708 02:50:33.927127 24447 solver.cpp:347] Iteration 22100, Testing net (#0)
I0708 02:50:53.030654 24447 solver.cpp:415]     Test net output #0: accuracy = 0.411298
I0708 02:50:53.030730 24447 solver.cpp:415]     Test net output #1: loss = 3.04171 (* 1 = 3.04171 loss)
I0708 02:50:53.030743 24447 solver.cpp:332] Optimization Done.
I0708 02:50:53.030745 24447 caffe.cpp:223] Optimization Done.
