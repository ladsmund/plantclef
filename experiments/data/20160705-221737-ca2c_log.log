I0706 05:52:52.612437 22636 caffe.cpp:192] Using GPUs 0
I0706 05:52:52.793853 22636 solver.cpp:54] Initializing solver from parameters:
test_iter: 130
test_interval: 441
base_lr: 0.01
display: 55
max_iter: 35280
lr_policy: "exp"
gamma: 0.99982464
momentum: 0.9
weight_decay: 0.0001
snapshot: 4410
snapshot_prefix: "snapshot"
solver_mode: GPU
device_id: 0
random_seed: 0
net: "train_val.prototxt"
solver_type: SGD
iter_size: 1
I0706 05:52:52.794345 22636 solver.cpp:97] Creating training net from net file: train_val.prototxt
I0706 05:52:52.794880 22636 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0706 05:52:52.794888 22636 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer label
I0706 05:52:52.794898 22636 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0706 05:52:52.794989 22636 net.cpp:52] Initializing net from parameters:
state {
phase: TRAIN
}
layer {
name: "data"
type: "Data"
top: "data"
include {
phase: TRAIN
}
transform_param {
mean_file: "/home/ffw/scratch/plantClef/scatnet_output/train/a4_m2_s1s2_f2/lmdb_mean_coeff.binaryproto"
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/train/a4_m2_s1s2_f2/lmdb_data"
batch_size: 64
backend: LMDB
}
}
layer {
name: "label"
type: "Data"
top: "label"
include {
phase: TRAIN
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/train/a4_m2_s1s2_f2/lmdb_labels"
batch_size: 64
backend: LMDB
}
}
layer {
name: "pool1"
type: "Pooling"
bottom: "data"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 4
stride: 3
}
}
layer {
name: "conv2"
type: "Convolution"
bottom: "pool1"
top: "conv2"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 2
kernel_size: 5
group: 1
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu2"
type: "ReLU"
bottom: "conv2"
top: "conv2"
}
layer {
name: "norm2"
type: "LRN"
bottom: "conv2"
top: "norm2"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool2"
type: "Pooling"
bottom: "norm2"
top: "pool2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool2"
top: "conv3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "conv4"
type: "Convolution"
bottom: "conv3"
top: "conv4"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu4"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "conv5"
type: "Convolution"
bottom: "conv4"
top: "conv5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
group: 1
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "conv5"
top: "conv5"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "conv5"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fc6"
type: "InnerProduct"
bottom: "pool5"
top: "fc6"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "fc6"
top: "fc6"
}
layer {
name: "drop6"
type: "Dropout"
bottom: "fc6"
top: "fc6"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc7"
type: "InnerProduct"
bottom: "fc6"
top: "fc7"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "fc7"
top: "fc7"
}
layer {
name: "drop7"
type: "Dropout"
bottom: "fc7"
top: "fc7"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc8_species"
type: "InnerProduct"
bottom: "fc7"
top: "fc8_species"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 967
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "fc8_species"
bottom: "label"
top: "loss"
}
I0706 05:52:52.795052 22636 layer_factory.hpp:76] Creating layer data
I0706 05:52:52.795125 22636 net.cpp:109] Creating Layer data
I0706 05:52:52.795130 22636 net.cpp:414] data -> data
I0706 05:52:52.795140 22636 data_transformer.cpp:25] Loading mean file from: /home/ffw/scratch/plantClef/scatnet_output/train/a4_m2_s1s2_f2/lmdb_mean_coeff.binaryproto
I0706 05:52:52.798149 22648 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/train/a4_m2_s1s2_f2/lmdb_data
I0706 05:52:52.813454 22636 data_layer.cpp:45] output data size: 64,75,105,105
I0706 05:52:53.037533 22636 net.cpp:153] Setting up data
I0706 05:52:53.037556 22636 net.cpp:160] Top shape: 64 75 105 105 (52920000)
I0706 05:52:53.037559 22636 net.cpp:168] Memory required for data: 211680000
I0706 05:52:53.037564 22636 layer_factory.hpp:76] Creating layer label
I0706 05:52:53.037705 22636 net.cpp:109] Creating Layer label
I0706 05:52:53.037709 22636 net.cpp:414] label -> label
I0706 05:52:53.040904 22650 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/train/a4_m2_s1s2_f2/lmdb_labels
I0706 05:52:53.056452 22636 data_layer.cpp:45] output data size: 64,1,1,1
I0706 05:52:53.056581 22636 net.cpp:153] Setting up label
I0706 05:52:53.056601 22636 net.cpp:160] Top shape: 64 1 1 1 (64)
I0706 05:52:53.056604 22636 net.cpp:168] Memory required for data: 211680256
I0706 05:52:53.056609 22636 layer_factory.hpp:76] Creating layer pool1
I0706 05:52:53.056630 22636 net.cpp:109] Creating Layer pool1
I0706 05:52:53.056634 22636 net.cpp:457] pool1 <- data
I0706 05:52:53.056648 22636 net.cpp:414] pool1 -> pool1
I0706 05:52:53.056695 22636 net.cpp:153] Setting up pool1
I0706 05:52:53.056700 22636 net.cpp:160] Top shape: 64 75 35 35 (5880000)
I0706 05:52:53.056702 22636 net.cpp:168] Memory required for data: 235200256
I0706 05:52:53.056704 22636 layer_factory.hpp:76] Creating layer conv2
I0706 05:52:53.056710 22636 net.cpp:109] Creating Layer conv2
I0706 05:52:53.056712 22636 net.cpp:457] conv2 <- pool1
I0706 05:52:53.056715 22636 net.cpp:414] conv2 -> conv2
I0706 05:52:53.067433 22636 net.cpp:153] Setting up conv2
I0706 05:52:53.067456 22636 net.cpp:160] Top shape: 64 256 35 35 (20070400)
I0706 05:52:53.067459 22636 net.cpp:168] Memory required for data: 315481856
I0706 05:52:53.067479 22636 layer_factory.hpp:76] Creating layer relu2
I0706 05:52:53.067487 22636 net.cpp:109] Creating Layer relu2
I0706 05:52:53.067489 22636 net.cpp:457] relu2 <- conv2
I0706 05:52:53.067493 22636 net.cpp:400] relu2 -> conv2 (in-place)
I0706 05:52:53.067502 22636 net.cpp:153] Setting up relu2
I0706 05:52:53.067504 22636 net.cpp:160] Top shape: 64 256 35 35 (20070400)
I0706 05:52:53.067520 22636 net.cpp:168] Memory required for data: 395763456
I0706 05:52:53.067523 22636 layer_factory.hpp:76] Creating layer norm2
I0706 05:52:53.067528 22636 net.cpp:109] Creating Layer norm2
I0706 05:52:53.067529 22636 net.cpp:457] norm2 <- conv2
I0706 05:52:53.067531 22636 net.cpp:414] norm2 -> norm2
I0706 05:52:53.067558 22636 net.cpp:153] Setting up norm2
I0706 05:52:53.067561 22636 net.cpp:160] Top shape: 64 256 35 35 (20070400)
I0706 05:52:53.067564 22636 net.cpp:168] Memory required for data: 476045056
I0706 05:52:53.067565 22636 layer_factory.hpp:76] Creating layer pool2
I0706 05:52:53.067569 22636 net.cpp:109] Creating Layer pool2
I0706 05:52:53.067570 22636 net.cpp:457] pool2 <- norm2
I0706 05:52:53.067574 22636 net.cpp:414] pool2 -> pool2
I0706 05:52:53.067591 22636 net.cpp:153] Setting up pool2
I0706 05:52:53.067595 22636 net.cpp:160] Top shape: 64 256 17 17 (4734976)
I0706 05:52:53.067596 22636 net.cpp:168] Memory required for data: 494984960
I0706 05:52:53.067597 22636 layer_factory.hpp:76] Creating layer conv3
I0706 05:52:53.067602 22636 net.cpp:109] Creating Layer conv3
I0706 05:52:53.067605 22636 net.cpp:457] conv3 <- pool2
I0706 05:52:53.067607 22636 net.cpp:414] conv3 -> conv3
I0706 05:52:53.086431 22636 net.cpp:153] Setting up conv3
I0706 05:52:53.086447 22636 net.cpp:160] Top shape: 64 384 17 17 (7102464)
I0706 05:52:53.086449 22636 net.cpp:168] Memory required for data: 523394816
I0706 05:52:53.086457 22636 layer_factory.hpp:76] Creating layer relu3
I0706 05:52:53.086464 22636 net.cpp:109] Creating Layer relu3
I0706 05:52:53.086467 22636 net.cpp:457] relu3 <- conv3
I0706 05:52:53.086470 22636 net.cpp:400] relu3 -> conv3 (in-place)
I0706 05:52:53.086477 22636 net.cpp:153] Setting up relu3
I0706 05:52:53.086478 22636 net.cpp:160] Top shape: 64 384 17 17 (7102464)
I0706 05:52:53.086480 22636 net.cpp:168] Memory required for data: 551804672
I0706 05:52:53.086482 22636 layer_factory.hpp:76] Creating layer conv4
I0706 05:52:53.086488 22636 net.cpp:109] Creating Layer conv4
I0706 05:52:53.086488 22636 net.cpp:457] conv4 <- conv3
I0706 05:52:53.086493 22636 net.cpp:414] conv4 -> conv4
I0706 05:52:53.100558 22636 net.cpp:153] Setting up conv4
I0706 05:52:53.100576 22636 net.cpp:160] Top shape: 64 384 17 17 (7102464)
I0706 05:52:53.100579 22636 net.cpp:168] Memory required for data: 580214528
I0706 05:52:53.100586 22636 layer_factory.hpp:76] Creating layer relu4
I0706 05:52:53.100592 22636 net.cpp:109] Creating Layer relu4
I0706 05:52:53.100595 22636 net.cpp:457] relu4 <- conv4
I0706 05:52:53.100600 22636 net.cpp:400] relu4 -> conv4 (in-place)
I0706 05:52:53.100605 22636 net.cpp:153] Setting up relu4
I0706 05:52:53.100607 22636 net.cpp:160] Top shape: 64 384 17 17 (7102464)
I0706 05:52:53.100610 22636 net.cpp:168] Memory required for data: 608624384
I0706 05:52:53.100610 22636 layer_factory.hpp:76] Creating layer conv5
I0706 05:52:53.100616 22636 net.cpp:109] Creating Layer conv5
I0706 05:52:53.100618 22636 net.cpp:457] conv5 <- conv4
I0706 05:52:53.100621 22636 net.cpp:414] conv5 -> conv5
I0706 05:52:53.119657 22636 net.cpp:153] Setting up conv5
I0706 05:52:53.119675 22636 net.cpp:160] Top shape: 64 256 17 17 (4734976)
I0706 05:52:53.119678 22636 net.cpp:168] Memory required for data: 627564288
I0706 05:52:53.119683 22636 layer_factory.hpp:76] Creating layer relu5
I0706 05:52:53.119689 22636 net.cpp:109] Creating Layer relu5
I0706 05:52:53.119691 22636 net.cpp:457] relu5 <- conv5
I0706 05:52:53.119695 22636 net.cpp:400] relu5 -> conv5 (in-place)
I0706 05:52:53.119701 22636 net.cpp:153] Setting up relu5
I0706 05:52:53.119704 22636 net.cpp:160] Top shape: 64 256 17 17 (4734976)
I0706 05:52:53.119705 22636 net.cpp:168] Memory required for data: 646504192
I0706 05:52:53.119707 22636 layer_factory.hpp:76] Creating layer pool5
I0706 05:52:53.119710 22636 net.cpp:109] Creating Layer pool5
I0706 05:52:53.119712 22636 net.cpp:457] pool5 <- conv5
I0706 05:52:53.119715 22636 net.cpp:414] pool5 -> pool5
I0706 05:52:53.119735 22636 net.cpp:153] Setting up pool5
I0706 05:52:53.119738 22636 net.cpp:160] Top shape: 64 256 8 8 (1048576)
I0706 05:52:53.119755 22636 net.cpp:168] Memory required for data: 650698496
I0706 05:52:53.119756 22636 layer_factory.hpp:76] Creating layer fc6
I0706 05:52:53.119761 22636 net.cpp:109] Creating Layer fc6
I0706 05:52:53.119763 22636 net.cpp:457] fc6 <- pool5
I0706 05:52:53.119766 22636 net.cpp:414] fc6 -> fc6
I0706 05:52:54.425999 22636 net.cpp:153] Setting up fc6
I0706 05:52:54.426020 22636 net.cpp:160] Top shape: 64 4096 (262144)
I0706 05:52:54.426023 22636 net.cpp:168] Memory required for data: 651747072
I0706 05:52:54.426031 22636 layer_factory.hpp:76] Creating layer relu6
I0706 05:52:54.426038 22636 net.cpp:109] Creating Layer relu6
I0706 05:52:54.426040 22636 net.cpp:457] relu6 <- fc6
I0706 05:52:54.426044 22636 net.cpp:400] relu6 -> fc6 (in-place)
I0706 05:52:54.426051 22636 net.cpp:153] Setting up relu6
I0706 05:52:54.426054 22636 net.cpp:160] Top shape: 64 4096 (262144)
I0706 05:52:54.426056 22636 net.cpp:168] Memory required for data: 652795648
I0706 05:52:54.426059 22636 layer_factory.hpp:76] Creating layer drop6
I0706 05:52:54.426070 22636 net.cpp:109] Creating Layer drop6
I0706 05:52:54.426072 22636 net.cpp:457] drop6 <- fc6
I0706 05:52:54.426075 22636 net.cpp:400] drop6 -> fc6 (in-place)
I0706 05:52:54.426092 22636 net.cpp:153] Setting up drop6
I0706 05:52:54.426095 22636 net.cpp:160] Top shape: 64 4096 (262144)
I0706 05:52:54.426096 22636 net.cpp:168] Memory required for data: 653844224
I0706 05:52:54.426098 22636 layer_factory.hpp:76] Creating layer fc7
I0706 05:52:54.426102 22636 net.cpp:109] Creating Layer fc7
I0706 05:52:54.426105 22636 net.cpp:457] fc7 <- fc6
I0706 05:52:54.426107 22636 net.cpp:414] fc7 -> fc7
I0706 05:52:54.728427 22636 net.cpp:153] Setting up fc7
I0706 05:52:54.728447 22636 net.cpp:160] Top shape: 64 4096 (262144)
I0706 05:52:54.728451 22636 net.cpp:168] Memory required for data: 654892800
I0706 05:52:54.728456 22636 layer_factory.hpp:76] Creating layer relu7
I0706 05:52:54.728462 22636 net.cpp:109] Creating Layer relu7
I0706 05:52:54.728466 22636 net.cpp:457] relu7 <- fc7
I0706 05:52:54.728468 22636 net.cpp:400] relu7 -> fc7 (in-place)
I0706 05:52:54.728476 22636 net.cpp:153] Setting up relu7
I0706 05:52:54.728477 22636 net.cpp:160] Top shape: 64 4096 (262144)
I0706 05:52:54.728479 22636 net.cpp:168] Memory required for data: 655941376
I0706 05:52:54.728480 22636 layer_factory.hpp:76] Creating layer drop7
I0706 05:52:54.728484 22636 net.cpp:109] Creating Layer drop7
I0706 05:52:54.728487 22636 net.cpp:457] drop7 <- fc7
I0706 05:52:54.728488 22636 net.cpp:400] drop7 -> fc7 (in-place)
I0706 05:52:54.728500 22636 net.cpp:153] Setting up drop7
I0706 05:52:54.728503 22636 net.cpp:160] Top shape: 64 4096 (262144)
I0706 05:52:54.728504 22636 net.cpp:168] Memory required for data: 656989952
I0706 05:52:54.728507 22636 layer_factory.hpp:76] Creating layer fc8_species
I0706 05:52:54.728512 22636 net.cpp:109] Creating Layer fc8_species
I0706 05:52:54.728513 22636 net.cpp:457] fc8_species <- fc7
I0706 05:52:54.728515 22636 net.cpp:414] fc8_species -> fc8_species
I0706 05:52:54.800410 22636 net.cpp:153] Setting up fc8_species
I0706 05:52:54.800426 22636 net.cpp:160] Top shape: 64 967 (61888)
I0706 05:52:54.800428 22636 net.cpp:168] Memory required for data: 657237504
I0706 05:52:54.800433 22636 layer_factory.hpp:76] Creating layer loss
I0706 05:52:54.800446 22636 net.cpp:109] Creating Layer loss
I0706 05:52:54.800448 22636 net.cpp:457] loss <- fc8_species
I0706 05:52:54.800451 22636 net.cpp:457] loss <- label
I0706 05:52:54.800454 22636 net.cpp:414] loss -> loss
I0706 05:52:54.800460 22636 layer_factory.hpp:76] Creating layer loss
I0706 05:52:54.800827 22636 net.cpp:153] Setting up loss
I0706 05:52:54.800833 22636 net.cpp:160] Top shape: (1)
I0706 05:52:54.800835 22636 net.cpp:163]     with loss weight 1
I0706 05:52:54.800848 22636 net.cpp:168] Memory required for data: 657237508
I0706 05:52:54.800849 22636 net.cpp:229] loss needs backward computation.
I0706 05:52:54.800851 22636 net.cpp:229] fc8_species needs backward computation.
I0706 05:52:54.800854 22636 net.cpp:229] drop7 needs backward computation.
I0706 05:52:54.800870 22636 net.cpp:229] relu7 needs backward computation.
I0706 05:52:54.800873 22636 net.cpp:229] fc7 needs backward computation.
I0706 05:52:54.800874 22636 net.cpp:229] drop6 needs backward computation.
I0706 05:52:54.800876 22636 net.cpp:229] relu6 needs backward computation.
I0706 05:52:54.800878 22636 net.cpp:229] fc6 needs backward computation.
I0706 05:52:54.800879 22636 net.cpp:229] pool5 needs backward computation.
I0706 05:52:54.800881 22636 net.cpp:229] relu5 needs backward computation.
I0706 05:52:54.800884 22636 net.cpp:229] conv5 needs backward computation.
I0706 05:52:54.800886 22636 net.cpp:229] relu4 needs backward computation.
I0706 05:52:54.800887 22636 net.cpp:229] conv4 needs backward computation.
I0706 05:52:54.800889 22636 net.cpp:229] relu3 needs backward computation.
I0706 05:52:54.800891 22636 net.cpp:229] conv3 needs backward computation.
I0706 05:52:54.800894 22636 net.cpp:229] pool2 needs backward computation.
I0706 05:52:54.800895 22636 net.cpp:229] norm2 needs backward computation.
I0706 05:52:54.800897 22636 net.cpp:229] relu2 needs backward computation.
I0706 05:52:54.800899 22636 net.cpp:229] conv2 needs backward computation.
I0706 05:52:54.800900 22636 net.cpp:231] pool1 does not need backward computation.
I0706 05:52:54.800904 22636 net.cpp:231] label does not need backward computation.
I0706 05:52:54.800904 22636 net.cpp:231] data does not need backward computation.
I0706 05:52:54.800906 22636 net.cpp:273] This network produces output loss
I0706 05:52:54.800914 22636 net.cpp:286] Network initialization done.
I0706 05:52:54.801313 22636 solver.cpp:187] Creating test net (#0) specified by net file: train_val.prototxt
I0706 05:52:54.801347 22636 net.cpp:325] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0706 05:52:54.801362 22636 net.cpp:325] The NetState phase (1) differed from the phase (0) specified by a rule in layer label
I0706 05:52:54.801455 22636 net.cpp:52] Initializing net from parameters:
state {
phase: TEST
}
layer {
name: "data"
type: "Data"
top: "data"
include {
phase: TEST
}
transform_param {
mean_file: "/home/ffw/scratch/plantClef/scatnet_output/train/a4_m2_s1s2_f2/lmdb_mean_coeff.binaryproto"
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/test/a4_m2_s1s2_f2/lmdb_data"
batch_size: 64
backend: LMDB
}
}
layer {
name: "label"
type: "Data"
top: "label"
include {
phase: TEST
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/test/a4_m2_s1s2_f2/lmdb_labels"
batch_size: 64
backend: LMDB
}
}
layer {
name: "pool1"
type: "Pooling"
bottom: "data"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 4
stride: 3
}
}
layer {
name: "conv2"
type: "Convolution"
bottom: "pool1"
top: "conv2"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 2
kernel_size: 5
group: 1
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu2"
type: "ReLU"
bottom: "conv2"
top: "conv2"
}
layer {
name: "norm2"
type: "LRN"
bottom: "conv2"
top: "norm2"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool2"
type: "Pooling"
bottom: "norm2"
top: "pool2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool2"
top: "conv3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "conv4"
type: "Convolution"
bottom: "conv3"
top: "conv4"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu4"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "conv5"
type: "Convolution"
bottom: "conv4"
top: "conv5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
group: 1
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "conv5"
top: "conv5"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "conv5"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fc6"
type: "InnerProduct"
bottom: "pool5"
top: "fc6"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "fc6"
top: "fc6"
}
layer {
name: "drop6"
type: "Dropout"
bottom: "fc6"
top: "fc6"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc7"
type: "InnerProduct"
bottom: "fc6"
top: "fc7"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "fc7"
top: "fc7"
}
layer {
name: "drop7"
type: "Dropout"
bottom: "fc7"
top: "fc7"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc8_species"
type: "InnerProduct"
bottom: "fc7"
top: "fc8_species"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 967
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "fc8_species"
bottom: "label"
top: "loss"
}
layer {
name: "accuracy"
type: "Accuracy"
bottom: "fc8_species"
bottom: "label"
top: "accuracy"
include {
phase: TEST
}
}
I0706 05:52:54.801512 22636 layer_factory.hpp:76] Creating layer data
I0706 05:52:54.801568 22636 net.cpp:109] Creating Layer data
I0706 05:52:54.801573 22636 net.cpp:414] data -> data
I0706 05:52:54.801578 22636 data_transformer.cpp:25] Loading mean file from: /home/ffw/scratch/plantClef/scatnet_output/train/a4_m2_s1s2_f2/lmdb_mean_coeff.binaryproto
I0706 05:52:54.802314 22653 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/test/a4_m2_s1s2_f2/lmdb_data
I0706 05:52:54.806179 22636 data_layer.cpp:45] output data size: 64,75,105,105
I0706 05:52:55.037149 22636 net.cpp:153] Setting up data
I0706 05:52:55.037166 22636 net.cpp:160] Top shape: 64 75 105 105 (52920000)
I0706 05:52:55.037169 22636 net.cpp:168] Memory required for data: 211680000
I0706 05:52:55.037173 22636 layer_factory.hpp:76] Creating layer label
I0706 05:52:55.037226 22636 net.cpp:109] Creating Layer label
I0706 05:52:55.037241 22636 net.cpp:414] label -> label
I0706 05:52:55.038722 22655 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/test/a4_m2_s1s2_f2/lmdb_labels
I0706 05:52:55.055315 22636 data_layer.cpp:45] output data size: 64,1,1,1
I0706 05:52:55.055408 22636 net.cpp:153] Setting up label
I0706 05:52:55.055423 22636 net.cpp:160] Top shape: 64 1 1 1 (64)
I0706 05:52:55.055424 22636 net.cpp:168] Memory required for data: 211680256
I0706 05:52:55.055428 22636 layer_factory.hpp:76] Creating layer label_label_0_split
I0706 05:52:55.055444 22636 net.cpp:109] Creating Layer label_label_0_split
I0706 05:52:55.055445 22636 net.cpp:457] label_label_0_split <- label
I0706 05:52:55.055449 22636 net.cpp:414] label_label_0_split -> label_label_0_split_0
I0706 05:52:55.055452 22636 net.cpp:414] label_label_0_split -> label_label_0_split_1
I0706 05:52:55.055506 22636 net.cpp:153] Setting up label_label_0_split
I0706 05:52:55.055521 22636 net.cpp:160] Top shape: 64 1 1 1 (64)
I0706 05:52:55.055523 22636 net.cpp:160] Top shape: 64 1 1 1 (64)
I0706 05:52:55.055524 22636 net.cpp:168] Memory required for data: 211680768
I0706 05:52:55.055526 22636 layer_factory.hpp:76] Creating layer pool1
I0706 05:52:55.055531 22636 net.cpp:109] Creating Layer pool1
I0706 05:52:55.055533 22636 net.cpp:457] pool1 <- data
I0706 05:52:55.055536 22636 net.cpp:414] pool1 -> pool1
I0706 05:52:55.055557 22636 net.cpp:153] Setting up pool1
I0706 05:52:55.055560 22636 net.cpp:160] Top shape: 64 75 35 35 (5880000)
I0706 05:52:55.055562 22636 net.cpp:168] Memory required for data: 235200768
I0706 05:52:55.055564 22636 layer_factory.hpp:76] Creating layer conv2
I0706 05:52:55.055569 22636 net.cpp:109] Creating Layer conv2
I0706 05:52:55.055572 22636 net.cpp:457] conv2 <- pool1
I0706 05:52:55.055574 22636 net.cpp:414] conv2 -> conv2
I0706 05:52:55.064795 22636 net.cpp:153] Setting up conv2
I0706 05:52:55.064813 22636 net.cpp:160] Top shape: 64 256 35 35 (20070400)
I0706 05:52:55.064815 22636 net.cpp:168] Memory required for data: 315482368
I0706 05:52:55.064823 22636 layer_factory.hpp:76] Creating layer relu2
I0706 05:52:55.064829 22636 net.cpp:109] Creating Layer relu2
I0706 05:52:55.064832 22636 net.cpp:457] relu2 <- conv2
I0706 05:52:55.064836 22636 net.cpp:400] relu2 -> conv2 (in-place)
I0706 05:52:55.064841 22636 net.cpp:153] Setting up relu2
I0706 05:52:55.064843 22636 net.cpp:160] Top shape: 64 256 35 35 (20070400)
I0706 05:52:55.064844 22636 net.cpp:168] Memory required for data: 395763968
I0706 05:52:55.064846 22636 layer_factory.hpp:76] Creating layer norm2
I0706 05:52:55.064851 22636 net.cpp:109] Creating Layer norm2
I0706 05:52:55.064852 22636 net.cpp:457] norm2 <- conv2
I0706 05:52:55.064856 22636 net.cpp:414] norm2 -> norm2
I0706 05:52:55.064877 22636 net.cpp:153] Setting up norm2
I0706 05:52:55.064879 22636 net.cpp:160] Top shape: 64 256 35 35 (20070400)
I0706 05:52:55.064880 22636 net.cpp:168] Memory required for data: 476045568
I0706 05:52:55.064882 22636 layer_factory.hpp:76] Creating layer pool2
I0706 05:52:55.064887 22636 net.cpp:109] Creating Layer pool2
I0706 05:52:55.064888 22636 net.cpp:457] pool2 <- norm2
I0706 05:52:55.064890 22636 net.cpp:414] pool2 -> pool2
I0706 05:52:55.064908 22636 net.cpp:153] Setting up pool2
I0706 05:52:55.064910 22636 net.cpp:160] Top shape: 64 256 17 17 (4734976)
I0706 05:52:55.064911 22636 net.cpp:168] Memory required for data: 494985472
I0706 05:52:55.064913 22636 layer_factory.hpp:76] Creating layer conv3
I0706 05:52:55.064919 22636 net.cpp:109] Creating Layer conv3
I0706 05:52:55.064921 22636 net.cpp:457] conv3 <- pool2
I0706 05:52:55.064924 22636 net.cpp:414] conv3 -> conv3
I0706 05:52:55.082165 22636 net.cpp:153] Setting up conv3
I0706 05:52:55.082185 22636 net.cpp:160] Top shape: 64 384 17 17 (7102464)
I0706 05:52:55.082187 22636 net.cpp:168] Memory required for data: 523395328
I0706 05:52:55.082195 22636 layer_factory.hpp:76] Creating layer relu3
I0706 05:52:55.082201 22636 net.cpp:109] Creating Layer relu3
I0706 05:52:55.082203 22636 net.cpp:457] relu3 <- conv3
I0706 05:52:55.082207 22636 net.cpp:400] relu3 -> conv3 (in-place)
I0706 05:52:55.082212 22636 net.cpp:153] Setting up relu3
I0706 05:52:55.082216 22636 net.cpp:160] Top shape: 64 384 17 17 (7102464)
I0706 05:52:55.082216 22636 net.cpp:168] Memory required for data: 551805184
I0706 05:52:55.082222 22636 layer_factory.hpp:76] Creating layer conv4
I0706 05:52:55.082228 22636 net.cpp:109] Creating Layer conv4
I0706 05:52:55.082229 22636 net.cpp:457] conv4 <- conv3
I0706 05:52:55.082232 22636 net.cpp:414] conv4 -> conv4
I0706 05:52:55.109937 22636 net.cpp:153] Setting up conv4
I0706 05:52:55.109957 22636 net.cpp:160] Top shape: 64 384 17 17 (7102464)
I0706 05:52:55.109961 22636 net.cpp:168] Memory required for data: 580215040
I0706 05:52:55.109971 22636 layer_factory.hpp:76] Creating layer relu4
I0706 05:52:55.109978 22636 net.cpp:109] Creating Layer relu4
I0706 05:52:55.109982 22636 net.cpp:457] relu4 <- conv4
I0706 05:52:55.109987 22636 net.cpp:400] relu4 -> conv4 (in-place)
I0706 05:52:55.109992 22636 net.cpp:153] Setting up relu4
I0706 05:52:55.109995 22636 net.cpp:160] Top shape: 64 384 17 17 (7102464)
I0706 05:52:55.109998 22636 net.cpp:168] Memory required for data: 608624896
I0706 05:52:55.110000 22636 layer_factory.hpp:76] Creating layer conv5
I0706 05:52:55.110007 22636 net.cpp:109] Creating Layer conv5
I0706 05:52:55.110008 22636 net.cpp:457] conv5 <- conv4
I0706 05:52:55.110013 22636 net.cpp:414] conv5 -> conv5
I0706 05:52:55.127194 22636 net.cpp:153] Setting up conv5
I0706 05:52:55.127214 22636 net.cpp:160] Top shape: 64 256 17 17 (4734976)
I0706 05:52:55.127218 22636 net.cpp:168] Memory required for data: 627564800
I0706 05:52:55.127224 22636 layer_factory.hpp:76] Creating layer relu5
I0706 05:52:55.127230 22636 net.cpp:109] Creating Layer relu5
I0706 05:52:55.127234 22636 net.cpp:457] relu5 <- conv5
I0706 05:52:55.127238 22636 net.cpp:400] relu5 -> conv5 (in-place)
I0706 05:52:55.127244 22636 net.cpp:153] Setting up relu5
I0706 05:52:55.127249 22636 net.cpp:160] Top shape: 64 256 17 17 (4734976)
I0706 05:52:55.127250 22636 net.cpp:168] Memory required for data: 646504704
I0706 05:52:55.127252 22636 layer_factory.hpp:76] Creating layer pool5
I0706 05:52:55.127255 22636 net.cpp:109] Creating Layer pool5
I0706 05:52:55.127257 22636 net.cpp:457] pool5 <- conv5
I0706 05:52:55.127261 22636 net.cpp:414] pool5 -> pool5
I0706 05:52:55.127297 22636 net.cpp:153] Setting up pool5
I0706 05:52:55.127301 22636 net.cpp:160] Top shape: 64 256 8 8 (1048576)
I0706 05:52:55.127303 22636 net.cpp:168] Memory required for data: 650699008
I0706 05:52:55.127305 22636 layer_factory.hpp:76] Creating layer fc6
I0706 05:52:55.127310 22636 net.cpp:109] Creating Layer fc6
I0706 05:52:55.127312 22636 net.cpp:457] fc6 <- pool5
I0706 05:52:55.127315 22636 net.cpp:414] fc6 -> fc6
I0706 05:52:56.394131 22636 net.cpp:153] Setting up fc6
I0706 05:52:56.394150 22636 net.cpp:160] Top shape: 64 4096 (262144)
I0706 05:52:56.394155 22636 net.cpp:168] Memory required for data: 651747584
I0706 05:52:56.394163 22636 layer_factory.hpp:76] Creating layer relu6
I0706 05:52:56.394172 22636 net.cpp:109] Creating Layer relu6
I0706 05:52:56.394176 22636 net.cpp:457] relu6 <- fc6
I0706 05:52:56.394179 22636 net.cpp:400] relu6 -> fc6 (in-place)
I0706 05:52:56.394186 22636 net.cpp:153] Setting up relu6
I0706 05:52:56.394188 22636 net.cpp:160] Top shape: 64 4096 (262144)
I0706 05:52:56.394191 22636 net.cpp:168] Memory required for data: 652796160
I0706 05:52:56.394192 22636 layer_factory.hpp:76] Creating layer drop6
I0706 05:52:56.394196 22636 net.cpp:109] Creating Layer drop6
I0706 05:52:56.394198 22636 net.cpp:457] drop6 <- fc6
I0706 05:52:56.394201 22636 net.cpp:400] drop6 -> fc6 (in-place)
I0706 05:52:56.394217 22636 net.cpp:153] Setting up drop6
I0706 05:52:56.394222 22636 net.cpp:160] Top shape: 64 4096 (262144)
I0706 05:52:56.394222 22636 net.cpp:168] Memory required for data: 653844736
I0706 05:52:56.394224 22636 layer_factory.hpp:76] Creating layer fc7
I0706 05:52:56.394228 22636 net.cpp:109] Creating Layer fc7
I0706 05:52:56.394230 22636 net.cpp:457] fc7 <- fc6
I0706 05:52:56.394233 22636 net.cpp:414] fc7 -> fc7
I0706 05:52:56.699519 22636 net.cpp:153] Setting up fc7
I0706 05:52:56.699538 22636 net.cpp:160] Top shape: 64 4096 (262144)
I0706 05:52:56.699542 22636 net.cpp:168] Memory required for data: 654893312
I0706 05:52:56.699548 22636 layer_factory.hpp:76] Creating layer relu7
I0706 05:52:56.699554 22636 net.cpp:109] Creating Layer relu7
I0706 05:52:56.699558 22636 net.cpp:457] relu7 <- fc7
I0706 05:52:56.699561 22636 net.cpp:400] relu7 -> fc7 (in-place)
I0706 05:52:56.699589 22636 net.cpp:153] Setting up relu7
I0706 05:52:56.699592 22636 net.cpp:160] Top shape: 64 4096 (262144)
I0706 05:52:56.699594 22636 net.cpp:168] Memory required for data: 655941888
I0706 05:52:56.699596 22636 layer_factory.hpp:76] Creating layer drop7
I0706 05:52:56.699600 22636 net.cpp:109] Creating Layer drop7
I0706 05:52:56.699602 22636 net.cpp:457] drop7 <- fc7
I0706 05:52:56.699604 22636 net.cpp:400] drop7 -> fc7 (in-place)
I0706 05:52:56.699622 22636 net.cpp:153] Setting up drop7
I0706 05:52:56.699625 22636 net.cpp:160] Top shape: 64 4096 (262144)
I0706 05:52:56.699627 22636 net.cpp:168] Memory required for data: 656990464
I0706 05:52:56.699628 22636 layer_factory.hpp:76] Creating layer fc8_species
I0706 05:52:56.699633 22636 net.cpp:109] Creating Layer fc8_species
I0706 05:52:56.699635 22636 net.cpp:457] fc8_species <- fc7
I0706 05:52:56.699638 22636 net.cpp:414] fc8_species -> fc8_species
I0706 05:52:56.772506 22636 net.cpp:153] Setting up fc8_species
I0706 05:52:56.772524 22636 net.cpp:160] Top shape: 64 967 (61888)
I0706 05:52:56.772526 22636 net.cpp:168] Memory required for data: 657238016
I0706 05:52:56.772531 22636 layer_factory.hpp:76] Creating layer fc8_species_fc8_species_0_split
I0706 05:52:56.772537 22636 net.cpp:109] Creating Layer fc8_species_fc8_species_0_split
I0706 05:52:56.772541 22636 net.cpp:457] fc8_species_fc8_species_0_split <- fc8_species
I0706 05:52:56.772544 22636 net.cpp:414] fc8_species_fc8_species_0_split -> fc8_species_fc8_species_0_split_0
I0706 05:52:56.772549 22636 net.cpp:414] fc8_species_fc8_species_0_split -> fc8_species_fc8_species_0_split_1
I0706 05:52:56.772570 22636 net.cpp:153] Setting up fc8_species_fc8_species_0_split
I0706 05:52:56.772573 22636 net.cpp:160] Top shape: 64 967 (61888)
I0706 05:52:56.772577 22636 net.cpp:160] Top shape: 64 967 (61888)
I0706 05:52:56.772578 22636 net.cpp:168] Memory required for data: 657733120
I0706 05:52:56.772579 22636 layer_factory.hpp:76] Creating layer loss
I0706 05:52:56.772583 22636 net.cpp:109] Creating Layer loss
I0706 05:52:56.772584 22636 net.cpp:457] loss <- fc8_species_fc8_species_0_split_0
I0706 05:52:56.772588 22636 net.cpp:457] loss <- label_label_0_split_0
I0706 05:52:56.772589 22636 net.cpp:414] loss -> loss
I0706 05:52:56.772593 22636 layer_factory.hpp:76] Creating layer loss
I0706 05:52:56.772680 22636 net.cpp:153] Setting up loss
I0706 05:52:56.772683 22636 net.cpp:160] Top shape: (1)
I0706 05:52:56.772686 22636 net.cpp:163]     with loss weight 1
I0706 05:52:56.772692 22636 net.cpp:168] Memory required for data: 657733124
I0706 05:52:56.772694 22636 layer_factory.hpp:76] Creating layer accuracy
I0706 05:52:56.772698 22636 net.cpp:109] Creating Layer accuracy
I0706 05:52:56.772701 22636 net.cpp:457] accuracy <- fc8_species_fc8_species_0_split_1
I0706 05:52:56.772702 22636 net.cpp:457] accuracy <- label_label_0_split_1
I0706 05:52:56.772704 22636 net.cpp:414] accuracy -> accuracy
I0706 05:52:56.772709 22636 net.cpp:153] Setting up accuracy
I0706 05:52:56.772711 22636 net.cpp:160] Top shape: (1)
I0706 05:52:56.772713 22636 net.cpp:168] Memory required for data: 657733128
I0706 05:52:56.772714 22636 net.cpp:231] accuracy does not need backward computation.
I0706 05:52:56.772716 22636 net.cpp:229] loss needs backward computation.
I0706 05:52:56.772718 22636 net.cpp:229] fc8_species_fc8_species_0_split needs backward computation.
I0706 05:52:56.772721 22636 net.cpp:229] fc8_species needs backward computation.
I0706 05:52:56.772722 22636 net.cpp:229] drop7 needs backward computation.
I0706 05:52:56.772724 22636 net.cpp:229] relu7 needs backward computation.
I0706 05:52:56.772727 22636 net.cpp:229] fc7 needs backward computation.
I0706 05:52:56.772728 22636 net.cpp:229] drop6 needs backward computation.
I0706 05:52:56.772729 22636 net.cpp:229] relu6 needs backward computation.
I0706 05:52:56.772732 22636 net.cpp:229] fc6 needs backward computation.
I0706 05:52:56.772733 22636 net.cpp:229] pool5 needs backward computation.
I0706 05:52:56.772735 22636 net.cpp:229] relu5 needs backward computation.
I0706 05:52:56.772754 22636 net.cpp:229] conv5 needs backward computation.
I0706 05:52:56.772756 22636 net.cpp:229] relu4 needs backward computation.
I0706 05:52:56.772758 22636 net.cpp:229] conv4 needs backward computation.
I0706 05:52:56.772760 22636 net.cpp:229] relu3 needs backward computation.
I0706 05:52:56.772763 22636 net.cpp:229] conv3 needs backward computation.
I0706 05:52:56.772764 22636 net.cpp:229] pool2 needs backward computation.
I0706 05:52:56.772765 22636 net.cpp:229] norm2 needs backward computation.
I0706 05:52:56.772768 22636 net.cpp:229] relu2 needs backward computation.
I0706 05:52:56.772769 22636 net.cpp:229] conv2 needs backward computation.
I0706 05:52:56.772771 22636 net.cpp:231] pool1 does not need backward computation.
I0706 05:52:56.772774 22636 net.cpp:231] label_label_0_split does not need backward computation.
I0706 05:52:56.772776 22636 net.cpp:231] label does not need backward computation.
I0706 05:52:56.772778 22636 net.cpp:231] data does not need backward computation.
I0706 05:52:56.772780 22636 net.cpp:273] This network produces output accuracy
I0706 05:52:56.772783 22636 net.cpp:273] This network produces output loss
I0706 05:52:56.772790 22636 net.cpp:286] Network initialization done.
I0706 05:52:56.772845 22636 solver.cpp:66] Solver scaffolding done.
I0706 05:52:56.773105 22636 caffe.cpp:220] Starting Optimization
I0706 05:52:56.773109 22636 solver.cpp:294] Solving
I0706 05:52:56.773111 22636 solver.cpp:295] Learning Rate Policy: exp
I0706 05:52:56.774071 22636 solver.cpp:347] Iteration 0, Testing net (#0)
I0706 05:52:57.411990 22636 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 05:53:16.628788 22636 solver.cpp:415]     Test net output #0: accuracy = 0
I0706 05:53:16.628823 22636 solver.cpp:415]     Test net output #1: loss = 6.88173 (* 1 = 6.88173 loss)
I0706 05:53:16.892563 22636 solver.cpp:243] Iteration 0, loss = 6.88167
I0706 05:53:16.892592 22636 solver.cpp:259]     Train net output #0: loss = 6.88167 (* 1 = 6.88167 loss)
I0706 05:53:16.892611 22636 solver.cpp:590] Iteration 0, lr = 0.01
I0706 05:53:42.951810 22636 solver.cpp:243] Iteration 55, loss = 6.71065
I0706 05:53:42.952038 22636 solver.cpp:259]     Train net output #0: loss = 6.71065 (* 1 = 6.71065 loss)
I0706 05:53:42.952045 22636 solver.cpp:590] Iteration 55, lr = 0.00990401
I0706 05:54:09.026892 22636 solver.cpp:243] Iteration 110, loss = 6.68976
I0706 05:54:09.026916 22636 solver.cpp:259]     Train net output #0: loss = 6.68976 (* 1 = 6.68976 loss)
I0706 05:54:09.026921 22636 solver.cpp:590] Iteration 110, lr = 0.00980894
I0706 05:54:34.867955 22636 solver.cpp:243] Iteration 165, loss = 6.80007
I0706 05:54:34.869554 22636 solver.cpp:259]     Train net output #0: loss = 6.80007 (* 1 = 6.80007 loss)
I0706 05:54:34.869563 22636 solver.cpp:590] Iteration 165, lr = 0.00971478
I0706 05:55:00.711771 22636 solver.cpp:243] Iteration 220, loss = 6.51914
I0706 05:55:00.711796 22636 solver.cpp:259]     Train net output #0: loss = 6.51914 (* 1 = 6.51914 loss)
I0706 05:55:00.711803 22636 solver.cpp:590] Iteration 220, lr = 0.00962153
I0706 05:55:26.514904 22636 solver.cpp:243] Iteration 275, loss = 6.40208
I0706 05:55:26.515239 22636 solver.cpp:259]     Train net output #0: loss = 6.40208 (* 1 = 6.40208 loss)
I0706 05:55:26.515247 22636 solver.cpp:590] Iteration 275, lr = 0.00952917
I0706 05:55:52.367527 22636 solver.cpp:243] Iteration 330, loss = 6.51519
I0706 05:55:52.367549 22636 solver.cpp:259]     Train net output #0: loss = 6.51519 (* 1 = 6.51519 loss)
I0706 05:55:52.367555 22636 solver.cpp:590] Iteration 330, lr = 0.0094377
I0706 05:56:18.216958 22636 solver.cpp:243] Iteration 385, loss = 6.51639
I0706 05:56:18.217283 22636 solver.cpp:259]     Train net output #0: loss = 6.51639 (* 1 = 6.51639 loss)
I0706 05:56:18.217290 22636 solver.cpp:590] Iteration 385, lr = 0.00934711
I0706 05:56:44.184032 22636 solver.cpp:243] Iteration 440, loss = 6.33348
I0706 05:56:44.184052 22636 solver.cpp:259]     Train net output #0: loss = 6.33348 (* 1 = 6.33348 loss)
I0706 05:56:44.184057 22636 solver.cpp:590] Iteration 440, lr = 0.00925738
I0706 05:56:44.184274 22636 solver.cpp:347] Iteration 441, Testing net (#0)
I0706 05:57:04.406288 22636 solver.cpp:415]     Test net output #0: accuracy = 0.00913462
I0706 05:57:04.406635 22636 solver.cpp:415]     Test net output #1: loss = 6.275 (* 1 = 6.275 loss)
I0706 05:57:30.203940 22636 solver.cpp:243] Iteration 495, loss = 6.39763
I0706 05:57:30.203961 22636 solver.cpp:259]     Train net output #0: loss = 6.39763 (* 1 = 6.39763 loss)
I0706 05:57:30.203966 22636 solver.cpp:590] Iteration 495, lr = 0.00916852
I0706 05:57:56.115882 22636 solver.cpp:243] Iteration 550, loss = 6.27708
I0706 05:57:56.116263 22636 solver.cpp:259]     Train net output #0: loss = 6.27708 (* 1 = 6.27708 loss)
I0706 05:57:56.116272 22636 solver.cpp:590] Iteration 550, lr = 0.00908051
I0706 05:58:22.041734 22636 solver.cpp:243] Iteration 605, loss = 6.22913
I0706 05:58:22.041776 22636 solver.cpp:259]     Train net output #0: loss = 6.22913 (* 1 = 6.22913 loss)
I0706 05:58:22.041790 22636 solver.cpp:590] Iteration 605, lr = 0.00899335
I0706 05:58:47.954030 22636 solver.cpp:243] Iteration 660, loss = 5.99192
I0706 05:58:47.954123 22636 solver.cpp:259]     Train net output #0: loss = 5.99192 (* 1 = 5.99192 loss)
I0706 05:58:47.954129 22636 solver.cpp:590] Iteration 660, lr = 0.00890702
I0706 05:59:13.734966 22636 solver.cpp:243] Iteration 715, loss = 5.87551
I0706 05:59:13.734987 22636 solver.cpp:259]     Train net output #0: loss = 5.87551 (* 1 = 5.87551 loss)
I0706 05:59:13.734993 22636 solver.cpp:590] Iteration 715, lr = 0.00882152
I0706 05:59:39.550299 22636 solver.cpp:243] Iteration 770, loss = 5.80652
I0706 05:59:39.550362 22636 solver.cpp:259]     Train net output #0: loss = 5.80652 (* 1 = 5.80652 loss)
I0706 05:59:39.550379 22636 solver.cpp:590] Iteration 770, lr = 0.00873684
I0706 06:00:05.406363 22636 solver.cpp:243] Iteration 825, loss = 5.83976
I0706 06:00:05.406386 22636 solver.cpp:259]     Train net output #0: loss = 5.83976 (* 1 = 5.83976 loss)
I0706 06:00:05.406393 22636 solver.cpp:590] Iteration 825, lr = 0.00865297
I0706 06:00:31.224839 22636 solver.cpp:243] Iteration 880, loss = 5.81878
I0706 06:00:31.224926 22636 solver.cpp:259]     Train net output #0: loss = 5.81878 (* 1 = 5.81878 loss)
I0706 06:00:31.224932 22636 solver.cpp:590] Iteration 880, lr = 0.00856991
I0706 06:00:31.695385 22636 solver.cpp:347] Iteration 882, Testing net (#0)
I0706 06:00:51.784996 22636 solver.cpp:415]     Test net output #0: accuracy = 0.0262019
I0706 06:00:51.785022 22636 solver.cpp:415]     Test net output #1: loss = 5.76833 (* 1 = 5.76833 loss)
I0706 06:01:17.041467 22636 solver.cpp:243] Iteration 935, loss = 5.99863
I0706 06:01:17.041569 22636 solver.cpp:259]     Train net output #0: loss = 5.99863 (* 1 = 5.99863 loss)
I0706 06:01:17.041586 22636 solver.cpp:590] Iteration 935, lr = 0.00848765
I0706 06:01:42.850749 22636 solver.cpp:243] Iteration 990, loss = 5.74606
I0706 06:01:42.850774 22636 solver.cpp:259]     Train net output #0: loss = 5.74606 (* 1 = 5.74606 loss)
I0706 06:01:42.850780 22636 solver.cpp:590] Iteration 990, lr = 0.00840618
I0706 06:02:08.687098 22636 solver.cpp:243] Iteration 1045, loss = 5.93099
I0706 06:02:08.687186 22636 solver.cpp:259]     Train net output #0: loss = 5.93099 (* 1 = 5.93099 loss)
I0706 06:02:08.687202 22636 solver.cpp:590] Iteration 1045, lr = 0.00832548
I0706 06:02:34.521230 22636 solver.cpp:243] Iteration 1100, loss = 5.8218
I0706 06:02:34.521253 22636 solver.cpp:259]     Train net output #0: loss = 5.8218 (* 1 = 5.8218 loss)
I0706 06:02:34.521260 22636 solver.cpp:590] Iteration 1100, lr = 0.00824557
I0706 06:03:00.317240 22636 solver.cpp:243] Iteration 1155, loss = 5.47234
I0706 06:03:00.317329 22636 solver.cpp:259]     Train net output #0: loss = 5.47234 (* 1 = 5.47234 loss)
I0706 06:03:00.317337 22636 solver.cpp:590] Iteration 1155, lr = 0.00816642
I0706 06:03:26.126112 22636 solver.cpp:243] Iteration 1210, loss = 5.17367
I0706 06:03:26.126135 22636 solver.cpp:259]     Train net output #0: loss = 5.17367 (* 1 = 5.17367 loss)
I0706 06:03:26.126142 22636 solver.cpp:590] Iteration 1210, lr = 0.00808803
I0706 06:03:51.939589 22636 solver.cpp:243] Iteration 1265, loss = 4.97613
I0706 06:03:51.939695 22636 solver.cpp:259]     Train net output #0: loss = 4.97613 (* 1 = 4.97613 loss)
I0706 06:03:51.939702 22636 solver.cpp:590] Iteration 1265, lr = 0.00801039
I0706 06:04:17.723480 22636 solver.cpp:243] Iteration 1320, loss = 5.3083
I0706 06:04:17.723505 22636 solver.cpp:259]     Train net output #0: loss = 5.3083 (* 1 = 5.3083 loss)
I0706 06:04:17.723510 22636 solver.cpp:590] Iteration 1320, lr = 0.0079335
I0706 06:04:18.661835 22636 solver.cpp:347] Iteration 1323, Testing net (#0)
I0706 06:04:39.019421 22636 solver.cpp:415]     Test net output #0: accuracy = 0.050601
I0706 06:04:39.021082 22636 solver.cpp:415]     Test net output #1: loss = 5.41465 (* 1 = 5.41465 loss)
I0706 06:05:03.857385 22636 solver.cpp:243] Iteration 1375, loss = 5.01853
I0706 06:05:03.857408 22636 solver.cpp:259]     Train net output #0: loss = 5.01853 (* 1 = 5.01853 loss)
I0706 06:05:03.857414 22636 solver.cpp:590] Iteration 1375, lr = 0.00785734
I0706 06:05:29.664785 22636 solver.cpp:243] Iteration 1430, loss = 5.30838
I0706 06:05:29.665051 22636 solver.cpp:259]     Train net output #0: loss = 5.30838 (* 1 = 5.30838 loss)
I0706 06:05:29.665060 22636 solver.cpp:590] Iteration 1430, lr = 0.00778192
I0706 06:05:55.553045 22636 solver.cpp:243] Iteration 1485, loss = 5.78548
I0706 06:05:55.553068 22636 solver.cpp:259]     Train net output #0: loss = 5.78548 (* 1 = 5.78548 loss)
I0706 06:05:55.553074 22636 solver.cpp:590] Iteration 1485, lr = 0.00770722
I0706 06:06:21.431715 22636 solver.cpp:243] Iteration 1540, loss = 5.3223
I0706 06:06:21.432126 22636 solver.cpp:259]     Train net output #0: loss = 5.3223 (* 1 = 5.3223 loss)
I0706 06:06:21.432134 22636 solver.cpp:590] Iteration 1540, lr = 0.00763324
I0706 06:06:47.284106 22636 solver.cpp:243] Iteration 1595, loss = 5.0894
I0706 06:06:47.284128 22636 solver.cpp:259]     Train net output #0: loss = 5.0894 (* 1 = 5.0894 loss)
I0706 06:06:47.284134 22636 solver.cpp:590] Iteration 1595, lr = 0.00755996
I0706 06:07:13.135000 22636 solver.cpp:243] Iteration 1650, loss = 5.23112
I0706 06:07:13.135570 22636 solver.cpp:259]     Train net output #0: loss = 5.23112 (* 1 = 5.23112 loss)
I0706 06:07:13.135578 22636 solver.cpp:590] Iteration 1650, lr = 0.00748739
I0706 06:07:38.984048 22636 solver.cpp:243] Iteration 1705, loss = 4.95299
I0706 06:07:38.984071 22636 solver.cpp:259]     Train net output #0: loss = 4.95299 (* 1 = 4.95299 loss)
I0706 06:07:38.984077 22636 solver.cpp:590] Iteration 1705, lr = 0.00741552
I0706 06:08:04.829875 22636 solver.cpp:243] Iteration 1760, loss = 4.8845
I0706 06:08:04.830126 22636 solver.cpp:259]     Train net output #0: loss = 4.8845 (* 1 = 4.8845 loss)
I0706 06:08:04.830133 22636 solver.cpp:590] Iteration 1760, lr = 0.00734434
I0706 06:08:06.240733 22636 solver.cpp:347] Iteration 1764, Testing net (#0)
I0706 06:08:26.607359 22636 solver.cpp:415]     Test net output #0: accuracy = 0.0653846
I0706 06:08:26.607386 22636 solver.cpp:415]     Test net output #1: loss = 5.14397 (* 1 = 5.14397 loss)
I0706 06:08:50.905788 22636 solver.cpp:243] Iteration 1815, loss = 4.90036
I0706 06:08:50.906314 22636 solver.cpp:259]     Train net output #0: loss = 4.90036 (* 1 = 4.90036 loss)
I0706 06:08:50.906323 22636 solver.cpp:590] Iteration 1815, lr = 0.00727384
I0706 06:09:16.825832 22636 solver.cpp:243] Iteration 1870, loss = 5.35018
I0706 06:09:16.825853 22636 solver.cpp:259]     Train net output #0: loss = 5.35018 (* 1 = 5.35018 loss)
I0706 06:09:16.825860 22636 solver.cpp:590] Iteration 1870, lr = 0.00720402
I0706 06:09:42.641360 22636 solver.cpp:243] Iteration 1925, loss = 4.77303
I0706 06:09:42.641551 22636 solver.cpp:259]     Train net output #0: loss = 4.77303 (* 1 = 4.77303 loss)
I0706 06:09:42.641568 22636 solver.cpp:590] Iteration 1925, lr = 0.00713487
I0706 06:10:08.534412 22636 solver.cpp:243] Iteration 1980, loss = 5.01551
I0706 06:10:08.534441 22636 solver.cpp:259]     Train net output #0: loss = 5.01551 (* 1 = 5.01551 loss)
I0706 06:10:08.534451 22636 solver.cpp:590] Iteration 1980, lr = 0.00706638
I0706 06:10:34.397259 22636 solver.cpp:243] Iteration 2035, loss = 5.08805
I0706 06:10:34.397647 22636 solver.cpp:259]     Train net output #0: loss = 5.08805 (* 1 = 5.08805 loss)
I0706 06:10:34.397655 22636 solver.cpp:590] Iteration 2035, lr = 0.00699855
I0706 06:11:00.252903 22636 solver.cpp:243] Iteration 2090, loss = 4.79992
I0706 06:11:00.252926 22636 solver.cpp:259]     Train net output #0: loss = 4.79992 (* 1 = 4.79992 loss)
I0706 06:11:00.252933 22636 solver.cpp:590] Iteration 2090, lr = 0.00693137
I0706 06:11:26.025146 22636 solver.cpp:243] Iteration 2145, loss = 4.43916
I0706 06:11:26.025459 22636 solver.cpp:259]     Train net output #0: loss = 4.43916 (* 1 = 4.43916 loss)
I0706 06:11:26.025466 22636 solver.cpp:590] Iteration 2145, lr = 0.00686483
I0706 06:11:51.844517 22636 solver.cpp:243] Iteration 2200, loss = 4.49895
I0706 06:11:51.844545 22636 solver.cpp:259]     Train net output #0: loss = 4.49895 (* 1 = 4.49895 loss)
I0706 06:11:51.844553 22636 solver.cpp:590] Iteration 2200, lr = 0.00679894
I0706 06:11:53.724026 22636 solver.cpp:347] Iteration 2205, Testing net (#0)
I0706 06:12:00.283929 22654 blocking_queue.cpp:50] Waiting for data
I0706 06:12:13.813248 22636 solver.cpp:415]     Test net output #0: accuracy = 0.0850962
I0706 06:12:13.813276 22636 solver.cpp:415]     Test net output #1: loss = 4.99307 (* 1 = 4.99307 loss)
I0706 06:12:37.666126 22636 solver.cpp:243] Iteration 2255, loss = 4.53766
I0706 06:12:37.666218 22636 solver.cpp:259]     Train net output #0: loss = 4.53766 (* 1 = 4.53766 loss)
I0706 06:12:37.666235 22636 solver.cpp:590] Iteration 2255, lr = 0.00673367
I0706 06:13:03.459653 22636 solver.cpp:243] Iteration 2310, loss = 4.7851
I0706 06:13:03.459676 22636 solver.cpp:259]     Train net output #0: loss = 4.7851 (* 1 = 4.7851 loss)
I0706 06:13:03.459682 22636 solver.cpp:590] Iteration 2310, lr = 0.00666904
I0706 06:13:29.261101 22636 solver.cpp:243] Iteration 2365, loss = 4.46291
I0706 06:13:29.261203 22636 solver.cpp:259]     Train net output #0: loss = 4.46291 (* 1 = 4.46291 loss)
I0706 06:13:29.261220 22636 solver.cpp:590] Iteration 2365, lr = 0.00660502
I0706 06:13:55.072432 22636 solver.cpp:243] Iteration 2420, loss = 4.11697
I0706 06:13:55.072454 22636 solver.cpp:259]     Train net output #0: loss = 4.11697 (* 1 = 4.11697 loss)
I0706 06:13:55.072459 22636 solver.cpp:590] Iteration 2420, lr = 0.00654162
I0706 06:14:20.958675 22636 solver.cpp:243] Iteration 2475, loss = 4.83113
I0706 06:14:20.958793 22636 solver.cpp:259]     Train net output #0: loss = 4.83113 (* 1 = 4.83113 loss)
I0706 06:14:20.958801 22636 solver.cpp:590] Iteration 2475, lr = 0.00647882
I0706 06:14:46.808673 22636 solver.cpp:243] Iteration 2530, loss = 4.31647
I0706 06:14:46.808698 22636 solver.cpp:259]     Train net output #0: loss = 4.31647 (* 1 = 4.31647 loss)
I0706 06:14:46.808704 22636 solver.cpp:590] Iteration 2530, lr = 0.00641663
I0706 06:15:12.634109 22636 solver.cpp:243] Iteration 2585, loss = 3.85978
I0706 06:15:12.634191 22636 solver.cpp:259]     Train net output #0: loss = 3.85978 (* 1 = 3.85978 loss)
I0706 06:15:12.634197 22636 solver.cpp:590] Iteration 2585, lr = 0.00635504
I0706 06:15:38.436210 22636 solver.cpp:243] Iteration 2640, loss = 4.43329
I0706 06:15:38.436235 22636 solver.cpp:259]     Train net output #0: loss = 4.43329 (* 1 = 4.43329 loss)
I0706 06:15:38.436241 22636 solver.cpp:590] Iteration 2640, lr = 0.00629403
I0706 06:15:40.789628 22636 solver.cpp:347] Iteration 2646, Testing net (#0)
I0706 06:16:00.790376 22636 solver.cpp:415]     Test net output #0: accuracy = 0.104928
I0706 06:16:00.790526 22636 solver.cpp:415]     Test net output #1: loss = 4.79586 (* 1 = 4.79586 loss)
I0706 06:16:24.145766 22636 solver.cpp:243] Iteration 2695, loss = 4.04298
I0706 06:16:24.145790 22636 solver.cpp:259]     Train net output #0: loss = 4.04298 (* 1 = 4.04298 loss)
I0706 06:16:24.145797 22636 solver.cpp:590] Iteration 2695, lr = 0.00623362
I0706 06:16:50.017374 22636 solver.cpp:243] Iteration 2750, loss = 4.356
I0706 06:16:50.017505 22636 solver.cpp:259]     Train net output #0: loss = 4.356 (* 1 = 4.356 loss)
I0706 06:16:50.017513 22636 solver.cpp:590] Iteration 2750, lr = 0.00617378
I0706 06:17:15.821818 22636 solver.cpp:243] Iteration 2805, loss = 3.81119
I0706 06:17:15.821842 22636 solver.cpp:259]     Train net output #0: loss = 3.81119 (* 1 = 3.81119 loss)
I0706 06:17:15.821849 22636 solver.cpp:590] Iteration 2805, lr = 0.00611452
I0706 06:17:41.630439 22636 solver.cpp:243] Iteration 2860, loss = 4.12476
I0706 06:17:41.630842 22636 solver.cpp:259]     Train net output #0: loss = 4.12476 (* 1 = 4.12476 loss)
I0706 06:17:41.630851 22636 solver.cpp:590] Iteration 2860, lr = 0.00605582
I0706 06:18:07.463538 22636 solver.cpp:243] Iteration 2915, loss = 4.2353
I0706 06:18:07.463562 22636 solver.cpp:259]     Train net output #0: loss = 4.2353 (* 1 = 4.2353 loss)
I0706 06:18:07.463567 22636 solver.cpp:590] Iteration 2915, lr = 0.00599769
I0706 06:18:33.272649 22636 solver.cpp:243] Iteration 2970, loss = 3.93192
I0706 06:18:33.272979 22636 solver.cpp:259]     Train net output #0: loss = 3.93192 (* 1 = 3.93192 loss)
I0706 06:18:33.272997 22636 solver.cpp:590] Iteration 2970, lr = 0.00594012
I0706 06:18:59.093663 22636 solver.cpp:243] Iteration 3025, loss = 3.55924
I0706 06:18:59.093688 22636 solver.cpp:259]     Train net output #0: loss = 3.55924 (* 1 = 3.55924 loss)
I0706 06:18:59.093694 22636 solver.cpp:590] Iteration 3025, lr = 0.0058831
I0706 06:19:24.911475 22636 solver.cpp:243] Iteration 3080, loss = 4.02906
I0706 06:19:24.913112 22636 solver.cpp:259]     Train net output #0: loss = 4.02906 (* 1 = 4.02906 loss)
I0706 06:19:24.913122 22636 solver.cpp:590] Iteration 3080, lr = 0.00582663
I0706 06:19:27.738386 22636 solver.cpp:347] Iteration 3087, Testing net (#0)
I0706 06:19:49.335768 22636 solver.cpp:415]     Test net output #0: accuracy = 0.1125
I0706 06:19:49.335798 22636 solver.cpp:415]     Test net output #1: loss = 4.82679 (* 1 = 4.82679 loss)
I0706 06:20:12.300549 22636 solver.cpp:243] Iteration 3135, loss = 3.65693
I0706 06:20:12.300992 22636 solver.cpp:259]     Train net output #0: loss = 3.65693 (* 1 = 3.65693 loss)
I0706 06:20:12.301012 22636 solver.cpp:590] Iteration 3135, lr = 0.0057707
I0706 06:20:38.128010 22636 solver.cpp:243] Iteration 3190, loss = 3.68589
I0706 06:20:38.128031 22636 solver.cpp:259]     Train net output #0: loss = 3.68589 (* 1 = 3.68589 loss)
I0706 06:20:38.128038 22636 solver.cpp:590] Iteration 3190, lr = 0.0057153
I0706 06:21:03.920264 22636 solver.cpp:243] Iteration 3245, loss = 3.1449
I0706 06:21:03.920503 22636 solver.cpp:259]     Train net output #0: loss = 3.1449 (* 1 = 3.1449 loss)
I0706 06:21:03.920511 22636 solver.cpp:590] Iteration 3245, lr = 0.00566044
I0706 06:21:29.752610 22636 solver.cpp:243] Iteration 3300, loss = 3.56004
I0706 06:21:29.752634 22636 solver.cpp:259]     Train net output #0: loss = 3.56004 (* 1 = 3.56004 loss)
I0706 06:21:29.752640 22636 solver.cpp:590] Iteration 3300, lr = 0.00560611
I0706 06:21:55.629115 22636 solver.cpp:243] Iteration 3355, loss = 3.37492
I0706 06:21:55.629294 22636 solver.cpp:259]     Train net output #0: loss = 3.37492 (* 1 = 3.37492 loss)
I0706 06:21:55.629303 22636 solver.cpp:590] Iteration 3355, lr = 0.00555229
I0706 06:22:21.508033 22636 solver.cpp:243] Iteration 3410, loss = 3.08098
I0706 06:22:21.508056 22636 solver.cpp:259]     Train net output #0: loss = 3.08098 (* 1 = 3.08098 loss)
I0706 06:22:21.508062 22636 solver.cpp:590] Iteration 3410, lr = 0.005499
I0706 06:22:47.324236 22636 solver.cpp:243] Iteration 3465, loss = 3.00002
I0706 06:22:47.324584 22636 solver.cpp:259]     Train net output #0: loss = 3.00002 (* 1 = 3.00002 loss)
I0706 06:22:47.324592 22636 solver.cpp:590] Iteration 3465, lr = 0.00544621
I0706 06:23:13.115854 22636 solver.cpp:243] Iteration 3520, loss = 3.34387
I0706 06:23:13.115876 22636 solver.cpp:259]     Train net output #0: loss = 3.34387 (* 1 = 3.34387 loss)
I0706 06:23:13.115882 22636 solver.cpp:590] Iteration 3520, lr = 0.00539393
I0706 06:23:16.400264 22636 solver.cpp:347] Iteration 3528, Testing net (#0)
I0706 06:23:17.246536 22636 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 06:23:36.655552 22636 solver.cpp:415]     Test net output #0: accuracy = 0.116587
I0706 06:23:36.655942 22636 solver.cpp:415]     Test net output #1: loss = 4.83738 (* 1 = 4.83738 loss)
I0706 06:23:59.139508 22636 solver.cpp:243] Iteration 3575, loss = 2.85361
I0706 06:23:59.139533 22636 solver.cpp:259]     Train net output #0: loss = 2.85361 (* 1 = 2.85361 loss)
I0706 06:23:59.139539 22636 solver.cpp:590] Iteration 3575, lr = 0.00534216
I0706 06:24:24.970165 22636 solver.cpp:243] Iteration 3630, loss = 3.31152
I0706 06:24:24.970693 22636 solver.cpp:259]     Train net output #0: loss = 3.31152 (* 1 = 3.31152 loss)
I0706 06:24:24.970702 22636 solver.cpp:590] Iteration 3630, lr = 0.00529088
I0706 06:24:50.845762 22636 solver.cpp:243] Iteration 3685, loss = 3.05304
I0706 06:24:50.845787 22636 solver.cpp:259]     Train net output #0: loss = 3.05304 (* 1 = 3.05304 loss)
I0706 06:24:50.845793 22636 solver.cpp:590] Iteration 3685, lr = 0.00524009
I0706 06:25:16.733999 22636 solver.cpp:243] Iteration 3740, loss = 2.97588
I0706 06:25:16.734383 22636 solver.cpp:259]     Train net output #0: loss = 2.97588 (* 1 = 2.97588 loss)
I0706 06:25:16.734392 22636 solver.cpp:590] Iteration 3740, lr = 0.00518979
I0706 06:25:42.596405 22636 solver.cpp:243] Iteration 3795, loss = 2.98603
I0706 06:25:42.596426 22636 solver.cpp:259]     Train net output #0: loss = 2.98603 (* 1 = 2.98603 loss)
I0706 06:25:42.596433 22636 solver.cpp:590] Iteration 3795, lr = 0.00513997
I0706 06:26:08.420462 22636 solver.cpp:243] Iteration 3850, loss = 2.71141
I0706 06:26:08.420748 22636 solver.cpp:259]     Train net output #0: loss = 2.71141 (* 1 = 2.71141 loss)
I0706 06:26:08.420756 22636 solver.cpp:590] Iteration 3850, lr = 0.00509063
I0706 06:26:34.248409 22636 solver.cpp:243] Iteration 3905, loss = 2.4199
I0706 06:26:34.248432 22636 solver.cpp:259]     Train net output #0: loss = 2.4199 (* 1 = 2.4199 loss)
I0706 06:26:34.248438 22636 solver.cpp:590] Iteration 3905, lr = 0.00504177
I0706 06:27:00.162000 22636 solver.cpp:243] Iteration 3960, loss = 2.76944
I0706 06:27:00.162238 22636 solver.cpp:259]     Train net output #0: loss = 2.76944 (* 1 = 2.76944 loss)
I0706 06:27:00.162247 22636 solver.cpp:590] Iteration 3960, lr = 0.00499337
I0706 06:27:03.919574 22636 solver.cpp:347] Iteration 3969, Testing net (#0)
I0706 06:27:25.120815 22636 solver.cpp:415]     Test net output #0: accuracy = 0.113221
I0706 06:27:25.120842 22636 solver.cpp:415]     Test net output #1: loss = 4.93443 (* 1 = 4.93443 loss)
I0706 06:27:47.198781 22636 solver.cpp:243] Iteration 4015, loss = 2.20287
I0706 06:27:47.199031 22636 solver.cpp:259]     Train net output #0: loss = 2.20287 (* 1 = 2.20287 loss)
I0706 06:27:47.199039 22636 solver.cpp:590] Iteration 4015, lr = 0.00494544
I0706 06:28:13.040283 22636 solver.cpp:243] Iteration 4070, loss = 2.56915
I0706 06:28:13.040308 22636 solver.cpp:259]     Train net output #0: loss = 2.56915 (* 1 = 2.56915 loss)
I0706 06:28:13.040315 22636 solver.cpp:590] Iteration 4070, lr = 0.00489797
I0706 06:28:38.855082 22636 solver.cpp:243] Iteration 4125, loss = 2.79524
I0706 06:28:38.856369 22636 solver.cpp:259]     Train net output #0: loss = 2.79524 (* 1 = 2.79524 loss)
I0706 06:28:38.856377 22636 solver.cpp:590] Iteration 4125, lr = 0.00485095
I0706 06:29:04.677543 22636 solver.cpp:243] Iteration 4180, loss = 2.86396
I0706 06:29:04.677568 22636 solver.cpp:259]     Train net output #0: loss = 2.86396 (* 1 = 2.86396 loss)
I0706 06:29:04.677574 22636 solver.cpp:590] Iteration 4180, lr = 0.00480439
I0706 06:29:30.461776 22636 solver.cpp:243] Iteration 4235, loss = 2.76592
I0706 06:29:30.462090 22636 solver.cpp:259]     Train net output #0: loss = 2.76592 (* 1 = 2.76592 loss)
I0706 06:29:30.462097 22636 solver.cpp:590] Iteration 4235, lr = 0.00475827
I0706 06:29:56.351295 22636 solver.cpp:243] Iteration 4290, loss = 2.63458
I0706 06:29:56.351318 22636 solver.cpp:259]     Train net output #0: loss = 2.63458 (* 1 = 2.63458 loss)
I0706 06:29:56.351325 22636 solver.cpp:590] Iteration 4290, lr = 0.00471259
I0706 06:30:22.158294 22636 solver.cpp:243] Iteration 4345, loss = 2.14542
I0706 06:30:22.158529 22636 solver.cpp:259]     Train net output #0: loss = 2.14542 (* 1 = 2.14542 loss)
I0706 06:30:22.158538 22636 solver.cpp:590] Iteration 4345, lr = 0.00466736
I0706 06:30:48.046519 22636 solver.cpp:243] Iteration 4400, loss = 2.31324
I0706 06:30:48.046540 22636 solver.cpp:259]     Train net output #0: loss = 2.31324 (* 1 = 2.31324 loss)
I0706 06:30:48.046545 22636 solver.cpp:590] Iteration 4400, lr = 0.00462255
I0706 06:30:52.272800 22636 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_4410.caffemodel
I0706 06:30:55.272554 22636 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_4410.solverstate
I0706 06:30:56.783762 22636 solver.cpp:347] Iteration 4410, Testing net (#0)
I0706 06:31:18.527886 22636 solver.cpp:415]     Test net output #0: accuracy = 0.122356
I0706 06:31:18.527942 22636 solver.cpp:415]     Test net output #1: loss = 4.9095 (* 1 = 4.9095 loss)
I0706 06:31:40.025074 22636 solver.cpp:243] Iteration 4455, loss = 2.54525
I0706 06:31:40.025166 22636 solver.cpp:259]     Train net output #0: loss = 2.54525 (* 1 = 2.54525 loss)
I0706 06:31:40.025173 22636 solver.cpp:590] Iteration 4455, lr = 0.00457818
I0706 06:32:05.874140 22636 solver.cpp:243] Iteration 4510, loss = 1.95003
I0706 06:32:05.874162 22636 solver.cpp:259]     Train net output #0: loss = 1.95003 (* 1 = 1.95003 loss)
I0706 06:32:05.874168 22636 solver.cpp:590] Iteration 4510, lr = 0.00453423
I0706 06:32:31.714412 22636 solver.cpp:243] Iteration 4565, loss = 2.73169
I0706 06:32:31.714500 22636 solver.cpp:259]     Train net output #0: loss = 2.73169 (* 1 = 2.73169 loss)
I0706 06:32:31.714509 22636 solver.cpp:590] Iteration 4565, lr = 0.00449071
I0706 06:32:57.530889 22636 solver.cpp:243] Iteration 4620, loss = 2.04048
I0706 06:32:57.530915 22636 solver.cpp:259]     Train net output #0: loss = 2.04048 (* 1 = 2.04048 loss)
I0706 06:32:57.530920 22636 solver.cpp:590] Iteration 4620, lr = 0.0044476
I0706 06:33:23.375087 22636 solver.cpp:243] Iteration 4675, loss = 1.96464
I0706 06:33:23.375205 22636 solver.cpp:259]     Train net output #0: loss = 1.96464 (* 1 = 1.96464 loss)
I0706 06:33:23.375212 22636 solver.cpp:590] Iteration 4675, lr = 0.00440491
I0706 06:33:49.230975 22636 solver.cpp:243] Iteration 4730, loss = 1.91888
I0706 06:33:49.231000 22636 solver.cpp:259]     Train net output #0: loss = 1.91888 (* 1 = 1.91888 loss)
I0706 06:33:49.231006 22636 solver.cpp:590] Iteration 4730, lr = 0.00436263
I0706 06:34:15.062830 22636 solver.cpp:243] Iteration 4785, loss = 2.39347
I0706 06:34:15.062917 22636 solver.cpp:259]     Train net output #0: loss = 2.39347 (* 1 = 2.39347 loss)
I0706 06:34:15.062933 22636 solver.cpp:590] Iteration 4785, lr = 0.00432075
I0706 06:34:40.857766 22636 solver.cpp:243] Iteration 4840, loss = 2.44173
I0706 06:34:40.857791 22636 solver.cpp:259]     Train net output #0: loss = 2.44173 (* 1 = 2.44173 loss)
I0706 06:34:40.857797 22636 solver.cpp:590] Iteration 4840, lr = 0.00427927
I0706 06:34:45.546790 22636 solver.cpp:347] Iteration 4851, Testing net (#0)
I0706 06:35:06.766162 22636 solver.cpp:415]     Test net output #0: accuracy = 0.123438
I0706 06:35:06.766190 22636 solver.cpp:415]     Test net output #1: loss = 5.06132 (* 1 = 5.06132 loss)
I0706 06:35:27.836369 22636 solver.cpp:243] Iteration 4895, loss = 1.61841
I0706 06:35:27.836446 22636 solver.cpp:259]     Train net output #0: loss = 1.61841 (* 1 = 1.61841 loss)
I0706 06:35:27.836452 22636 solver.cpp:590] Iteration 4895, lr = 0.0042382
I0706 06:35:53.643209 22636 solver.cpp:243] Iteration 4950, loss = 2.36297
I0706 06:35:53.643240 22636 solver.cpp:259]     Train net output #0: loss = 2.36297 (* 1 = 2.36297 loss)
I0706 06:35:53.643249 22636 solver.cpp:590] Iteration 4950, lr = 0.00419751
I0706 06:36:19.468199 22636 solver.cpp:243] Iteration 5005, loss = 1.89363
I0706 06:36:19.468309 22636 solver.cpp:259]     Train net output #0: loss = 1.89363 (* 1 = 1.89363 loss)
I0706 06:36:19.468317 22636 solver.cpp:590] Iteration 5005, lr = 0.00415722
I0706 06:36:45.397634 22636 solver.cpp:243] Iteration 5060, loss = 1.80549
I0706 06:36:45.397657 22636 solver.cpp:259]     Train net output #0: loss = 1.80549 (* 1 = 1.80549 loss)
I0706 06:36:45.397663 22636 solver.cpp:590] Iteration 5060, lr = 0.00411732
I0706 06:37:11.320400 22636 solver.cpp:243] Iteration 5115, loss = 1.43059
I0706 06:37:11.320508 22636 solver.cpp:259]     Train net output #0: loss = 1.43059 (* 1 = 1.43059 loss)
I0706 06:37:11.320526 22636 solver.cpp:590] Iteration 5115, lr = 0.00407779
I0706 06:37:37.094732 22636 solver.cpp:243] Iteration 5170, loss = 1.84221
I0706 06:37:37.094753 22636 solver.cpp:259]     Train net output #0: loss = 1.84221 (* 1 = 1.84221 loss)
I0706 06:37:37.094758 22636 solver.cpp:590] Iteration 5170, lr = 0.00403865
I0706 06:38:02.876152 22636 solver.cpp:243] Iteration 5225, loss = 2.0169
I0706 06:38:02.876469 22636 solver.cpp:259]     Train net output #0: loss = 2.0169 (* 1 = 2.0169 loss)
I0706 06:38:02.876477 22636 solver.cpp:590] Iteration 5225, lr = 0.00399988
I0706 06:38:28.657524 22636 solver.cpp:243] Iteration 5280, loss = 1.1649
I0706 06:38:28.657548 22636 solver.cpp:259]     Train net output #0: loss = 1.1649 (* 1 = 1.1649 loss)
I0706 06:38:28.657554 22636 solver.cpp:590] Iteration 5280, lr = 0.00396149
I0706 06:38:33.819279 22636 solver.cpp:347] Iteration 5292, Testing net (#0)
I0706 06:38:56.300482 22636 solver.cpp:415]     Test net output #0: accuracy = 0.130769
I0706 06:38:56.300508 22636 solver.cpp:415]     Test net output #1: loss = 5.05188 (* 1 = 5.05188 loss)
I0706 06:39:16.819432 22636 solver.cpp:243] Iteration 5335, loss = 1.54824
I0706 06:39:16.819521 22636 solver.cpp:259]     Train net output #0: loss = 1.54824 (* 1 = 1.54824 loss)
I0706 06:39:16.819528 22636 solver.cpp:590] Iteration 5335, lr = 0.00392346
I0706 06:39:42.626978 22636 solver.cpp:243] Iteration 5390, loss = 1.74126
I0706 06:39:42.627003 22636 solver.cpp:259]     Train net output #0: loss = 1.74126 (* 1 = 1.74126 loss)
I0706 06:39:42.627010 22636 solver.cpp:590] Iteration 5390, lr = 0.0038858
I0706 06:40:08.442518 22636 solver.cpp:243] Iteration 5445, loss = 1.19244
I0706 06:40:08.442610 22636 solver.cpp:259]     Train net output #0: loss = 1.19244 (* 1 = 1.19244 loss)
I0706 06:40:08.442625 22636 solver.cpp:590] Iteration 5445, lr = 0.0038485
I0706 06:40:34.249946 22636 solver.cpp:243] Iteration 5500, loss = 1.46829
I0706 06:40:34.249974 22636 solver.cpp:259]     Train net output #0: loss = 1.46829 (* 1 = 1.46829 loss)
I0706 06:40:34.249979 22636 solver.cpp:590] Iteration 5500, lr = 0.00381156
I0706 06:41:00.034358 22636 solver.cpp:243] Iteration 5555, loss = 1.20436
I0706 06:41:00.034435 22636 solver.cpp:259]     Train net output #0: loss = 1.20436 (* 1 = 1.20436 loss)
I0706 06:41:00.034452 22636 solver.cpp:590] Iteration 5555, lr = 0.00377497
I0706 06:41:25.824089 22636 solver.cpp:243] Iteration 5610, loss = 1.5359
I0706 06:41:25.824112 22636 solver.cpp:259]     Train net output #0: loss = 1.5359 (* 1 = 1.5359 loss)
I0706 06:41:25.824120 22636 solver.cpp:590] Iteration 5610, lr = 0.00373873
I0706 06:41:51.627004 22636 solver.cpp:243] Iteration 5665, loss = 1.54415
I0706 06:41:51.627090 22636 solver.cpp:259]     Train net output #0: loss = 1.54415 (* 1 = 1.54415 loss)
I0706 06:41:51.627096 22636 solver.cpp:590] Iteration 5665, lr = 0.00370284
I0706 06:42:17.414597 22636 solver.cpp:243] Iteration 5720, loss = 1.34746
I0706 06:42:17.414620 22636 solver.cpp:259]     Train net output #0: loss = 1.34746 (* 1 = 1.34746 loss)
I0706 06:42:17.414626 22636 solver.cpp:590] Iteration 5720, lr = 0.0036673
I0706 06:42:23.034317 22636 solver.cpp:347] Iteration 5733, Testing net (#0)
I0706 06:42:46.052662 22636 solver.cpp:415]     Test net output #0: accuracy = 0.120433
I0706 06:42:46.052692 22636 solver.cpp:415]     Test net output #1: loss = 5.28468 (* 1 = 5.28468 loss)
I0706 06:43:06.128756 22636 solver.cpp:243] Iteration 5775, loss = 1.06277
I0706 06:43:06.128844 22636 solver.cpp:259]     Train net output #0: loss = 1.06277 (* 1 = 1.06277 loss)
I0706 06:43:06.128850 22636 solver.cpp:590] Iteration 5775, lr = 0.0036321
I0706 06:43:31.930912 22636 solver.cpp:243] Iteration 5830, loss = 0.838074
I0706 06:43:31.930937 22636 solver.cpp:259]     Train net output #0: loss = 0.838074 (* 1 = 0.838074 loss)
I0706 06:43:31.930943 22636 solver.cpp:590] Iteration 5830, lr = 0.00359723
I0706 06:43:57.737490 22636 solver.cpp:243] Iteration 5885, loss = 0.700014
I0706 06:43:57.737601 22636 solver.cpp:259]     Train net output #0: loss = 0.700014 (* 1 = 0.700014 loss)
I0706 06:43:57.737618 22636 solver.cpp:590] Iteration 5885, lr = 0.0035627
I0706 06:44:23.589005 22636 solver.cpp:243] Iteration 5940, loss = 0.913628
I0706 06:44:23.589030 22636 solver.cpp:259]     Train net output #0: loss = 0.913628 (* 1 = 0.913628 loss)
I0706 06:44:23.589036 22636 solver.cpp:590] Iteration 5940, lr = 0.0035285
I0706 06:44:49.488522 22636 solver.cpp:243] Iteration 5995, loss = 0.890362
I0706 06:44:49.488863 22636 solver.cpp:259]     Train net output #0: loss = 0.890362 (* 1 = 0.890362 loss)
I0706 06:44:49.488872 22636 solver.cpp:590] Iteration 5995, lr = 0.00349463
I0706 06:45:15.377112 22636 solver.cpp:243] Iteration 6050, loss = 1.39373
I0706 06:45:15.377136 22636 solver.cpp:259]     Train net output #0: loss = 1.39373 (* 1 = 1.39373 loss)
I0706 06:45:15.377142 22636 solver.cpp:590] Iteration 6050, lr = 0.00346109
I0706 06:45:41.184552 22636 solver.cpp:243] Iteration 6105, loss = 1.57155
I0706 06:45:41.184921 22636 solver.cpp:259]     Train net output #0: loss = 1.57155 (* 1 = 1.57155 loss)
I0706 06:45:41.184929 22636 solver.cpp:590] Iteration 6105, lr = 0.00342786
I0706 06:46:07.011591 22636 solver.cpp:243] Iteration 6160, loss = 1.09466
I0706 06:46:07.011615 22636 solver.cpp:259]     Train net output #0: loss = 1.09466 (* 1 = 1.09466 loss)
I0706 06:46:07.011622 22636 solver.cpp:590] Iteration 6160, lr = 0.00339496
I0706 06:46:13.105851 22636 solver.cpp:347] Iteration 6174, Testing net (#0)
I0706 06:46:35.741269 22636 solver.cpp:415]     Test net output #0: accuracy = 0.121995
I0706 06:46:35.741297 22636 solver.cpp:415]     Test net output #1: loss = 5.49484 (* 1 = 5.49484 loss)
I0706 06:46:55.390257 22636 solver.cpp:243] Iteration 6215, loss = 0.798517
I0706 06:46:55.390352 22636 solver.cpp:259]     Train net output #0: loss = 0.798517 (* 1 = 0.798517 loss)
I0706 06:46:55.390357 22636 solver.cpp:590] Iteration 6215, lr = 0.00336237
I0706 06:47:21.159859 22636 solver.cpp:243] Iteration 6270, loss = 0.829969
I0706 06:47:21.159883 22636 solver.cpp:259]     Train net output #0: loss = 0.829969 (* 1 = 0.829969 loss)
I0706 06:47:21.159888 22636 solver.cpp:590] Iteration 6270, lr = 0.0033301
I0706 06:47:46.997087 22636 solver.cpp:243] Iteration 6325, loss = 0.950169
I0706 06:47:46.997192 22636 solver.cpp:259]     Train net output #0: loss = 0.950169 (* 1 = 0.950169 loss)
I0706 06:47:46.997200 22636 solver.cpp:590] Iteration 6325, lr = 0.00329813
I0706 06:48:12.808696 22636 solver.cpp:243] Iteration 6380, loss = 0.988263
I0706 06:48:12.808727 22636 solver.cpp:259]     Train net output #0: loss = 0.988263 (* 1 = 0.988263 loss)
I0706 06:48:12.808734 22636 solver.cpp:590] Iteration 6380, lr = 0.00326647
I0706 06:48:38.671391 22636 solver.cpp:243] Iteration 6435, loss = 0.699868
I0706 06:48:38.671507 22636 solver.cpp:259]     Train net output #0: loss = 0.699868 (* 1 = 0.699868 loss)
I0706 06:48:38.671520 22636 solver.cpp:590] Iteration 6435, lr = 0.00323512
I0706 06:49:04.451455 22636 solver.cpp:243] Iteration 6490, loss = 0.643926
I0706 06:49:04.451479 22636 solver.cpp:259]     Train net output #0: loss = 0.643926 (* 1 = 0.643926 loss)
I0706 06:49:04.451485 22636 solver.cpp:590] Iteration 6490, lr = 0.00320406
I0706 06:49:30.262202 22636 solver.cpp:243] Iteration 6545, loss = 0.894334
I0706 06:49:30.262300 22636 solver.cpp:259]     Train net output #0: loss = 0.894334 (* 1 = 0.894334 loss)
I0706 06:49:30.262306 22636 solver.cpp:590] Iteration 6545, lr = 0.00317331
I0706 06:49:56.082943 22636 solver.cpp:243] Iteration 6600, loss = 0.574216
I0706 06:49:56.082973 22636 solver.cpp:259]     Train net output #0: loss = 0.574216 (* 1 = 0.574216 loss)
I0706 06:49:56.082981 22636 solver.cpp:590] Iteration 6600, lr = 0.00314284
I0706 06:50:02.650818 22636 solver.cpp:347] Iteration 6615, Testing net (#0)
I0706 06:50:27.578861 22636 solver.cpp:415]     Test net output #0: accuracy = 0.125962
I0706 06:50:27.578887 22636 solver.cpp:415]     Test net output #1: loss = 5.75637 (* 1 = 5.75637 loss)
I0706 06:50:46.729449 22636 solver.cpp:243] Iteration 6655, loss = 0.560632
I0706 06:50:46.729854 22636 solver.cpp:259]     Train net output #0: loss = 0.560632 (* 1 = 0.560632 loss)
I0706 06:50:46.729863 22636 solver.cpp:590] Iteration 6655, lr = 0.00311268
I0706 06:51:12.613845 22636 solver.cpp:243] Iteration 6710, loss = 0.359725
I0706 06:51:12.613884 22636 solver.cpp:259]     Train net output #0: loss = 0.359725 (* 1 = 0.359725 loss)
I0706 06:51:12.613898 22636 solver.cpp:590] Iteration 6710, lr = 0.0030828
I0706 06:51:38.487534 22636 solver.cpp:243] Iteration 6765, loss = 0.491876
I0706 06:51:38.487632 22636 solver.cpp:259]     Train net output #0: loss = 0.491876 (* 1 = 0.491876 loss)
I0706 06:51:38.487639 22636 solver.cpp:590] Iteration 6765, lr = 0.00305321
I0706 06:52:04.392964 22636 solver.cpp:243] Iteration 6820, loss = 0.463484
I0706 06:52:04.392988 22636 solver.cpp:259]     Train net output #0: loss = 0.463484 (* 1 = 0.463484 loss)
I0706 06:52:04.392994 22636 solver.cpp:590] Iteration 6820, lr = 0.0030239
I0706 06:52:30.290266 22636 solver.cpp:243] Iteration 6875, loss = 0.862879
I0706 06:52:30.290359 22636 solver.cpp:259]     Train net output #0: loss = 0.862879 (* 1 = 0.862879 loss)
I0706 06:52:30.290376 22636 solver.cpp:590] Iteration 6875, lr = 0.00299487
I0706 06:52:56.082937 22636 solver.cpp:243] Iteration 6930, loss = 0.372161
I0706 06:52:56.082960 22636 solver.cpp:259]     Train net output #0: loss = 0.372161 (* 1 = 0.372161 loss)
I0706 06:52:56.082967 22636 solver.cpp:590] Iteration 6930, lr = 0.00296612
I0706 06:53:21.841300 22636 solver.cpp:243] Iteration 6985, loss = 0.373394
I0706 06:53:21.841359 22636 solver.cpp:259]     Train net output #0: loss = 0.373394 (* 1 = 0.373394 loss)
I0706 06:53:21.841367 22636 solver.cpp:590] Iteration 6985, lr = 0.00293765
I0706 06:53:47.624716 22636 solver.cpp:243] Iteration 7040, loss = 0.504829
I0706 06:53:47.624744 22636 solver.cpp:259]     Train net output #0: loss = 0.504829 (* 1 = 0.504829 loss)
I0706 06:53:47.624750 22636 solver.cpp:590] Iteration 7040, lr = 0.00290945
I0706 06:53:54.666471 22636 solver.cpp:347] Iteration 7056, Testing net (#0)
I0706 06:53:55.664489 22636 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 06:54:16.101382 22636 solver.cpp:415]     Test net output #0: accuracy = 0.13774
I0706 06:54:16.101410 22636 solver.cpp:415]     Test net output #1: loss = 5.72367 (* 1 = 5.72367 loss)
I0706 06:54:34.893198 22636 solver.cpp:243] Iteration 7095, loss = 0.684468
I0706 06:54:34.893287 22636 solver.cpp:259]     Train net output #0: loss = 0.684468 (* 1 = 0.684468 loss)
I0706 06:54:34.893303 22636 solver.cpp:590] Iteration 7095, lr = 0.00288152
I0706 06:55:00.778878 22636 solver.cpp:243] Iteration 7150, loss = 0.340668
I0706 06:55:00.778903 22636 solver.cpp:259]     Train net output #0: loss = 0.340668 (* 1 = 0.340668 loss)
I0706 06:55:00.778909 22636 solver.cpp:590] Iteration 7150, lr = 0.00285386
I0706 06:55:26.626830 22636 solver.cpp:243] Iteration 7205, loss = 0.761109
I0706 06:55:26.626924 22636 solver.cpp:259]     Train net output #0: loss = 0.761109 (* 1 = 0.761109 loss)
I0706 06:55:26.626931 22636 solver.cpp:590] Iteration 7205, lr = 0.00282647
I0706 06:55:52.544113 22636 solver.cpp:243] Iteration 7260, loss = 0.287239
I0706 06:55:52.544134 22636 solver.cpp:259]     Train net output #0: loss = 0.287239 (* 1 = 0.287239 loss)
I0706 06:55:52.544140 22636 solver.cpp:590] Iteration 7260, lr = 0.00279934
I0706 06:56:18.415074 22636 solver.cpp:243] Iteration 7315, loss = 0.612465
I0706 06:56:18.415166 22636 solver.cpp:259]     Train net output #0: loss = 0.612465 (* 1 = 0.612465 loss)
I0706 06:56:18.415174 22636 solver.cpp:590] Iteration 7315, lr = 0.00277247
I0706 06:56:44.263334 22636 solver.cpp:243] Iteration 7370, loss = 0.528302
I0706 06:56:44.263358 22636 solver.cpp:259]     Train net output #0: loss = 0.528302 (* 1 = 0.528302 loss)
I0706 06:56:44.263365 22636 solver.cpp:590] Iteration 7370, lr = 0.00274585
I0706 06:57:10.056205 22636 solver.cpp:243] Iteration 7425, loss = 0.257099
I0706 06:57:10.056314 22636 solver.cpp:259]     Train net output #0: loss = 0.257099 (* 1 = 0.257099 loss)
I0706 06:57:10.056330 22636 solver.cpp:590] Iteration 7425, lr = 0.00271949
I0706 06:57:35.878156 22636 solver.cpp:243] Iteration 7480, loss = 0.322022
I0706 06:57:35.878180 22636 solver.cpp:259]     Train net output #0: loss = 0.322022 (* 1 = 0.322022 loss)
I0706 06:57:35.878186 22636 solver.cpp:590] Iteration 7480, lr = 0.00269339
I0706 06:57:43.390782 22636 solver.cpp:347] Iteration 7497, Testing net (#0)
I0706 06:57:49.118855 22654 blocking_queue.cpp:50] Waiting for data
I0706 06:58:09.786535 22636 solver.cpp:415]     Test net output #0: accuracy = 0.133053
I0706 06:58:09.786561 22636 solver.cpp:415]     Test net output #1: loss = 5.57571 (* 1 = 5.57571 loss)
I0706 06:58:28.026823 22636 solver.cpp:243] Iteration 7535, loss = 0.639728
I0706 06:58:28.026912 22636 solver.cpp:259]     Train net output #0: loss = 0.639728 (* 1 = 0.639728 loss)
I0706 06:58:28.026928 22636 solver.cpp:590] Iteration 7535, lr = 0.00266754
I0706 06:58:53.885699 22636 solver.cpp:243] Iteration 7590, loss = 0.399979
I0706 06:58:53.885720 22636 solver.cpp:259]     Train net output #0: loss = 0.399979 (* 1 = 0.399979 loss)
I0706 06:58:53.885727 22636 solver.cpp:590] Iteration 7590, lr = 0.00264193
I0706 06:59:19.752823 22636 solver.cpp:243] Iteration 7645, loss = 0.46372
I0706 06:59:19.752918 22636 solver.cpp:259]     Train net output #0: loss = 0.46372 (* 1 = 0.46372 loss)
I0706 06:59:19.752924 22636 solver.cpp:590] Iteration 7645, lr = 0.00261657
I0706 06:59:45.605124 22636 solver.cpp:243] Iteration 7700, loss = 0.304767
I0706 06:59:45.605147 22636 solver.cpp:259]     Train net output #0: loss = 0.304767 (* 1 = 0.304767 loss)
I0706 06:59:45.605154 22636 solver.cpp:590] Iteration 7700, lr = 0.00259145
I0706 07:00:11.447832 22636 solver.cpp:243] Iteration 7755, loss = 0.617274
I0706 07:00:11.447934 22636 solver.cpp:259]     Train net output #0: loss = 0.617274 (* 1 = 0.617274 loss)
I0706 07:00:11.447943 22636 solver.cpp:590] Iteration 7755, lr = 0.00256658
I0706 07:00:37.274783 22636 solver.cpp:243] Iteration 7810, loss = 0.451783
I0706 07:00:37.274807 22636 solver.cpp:259]     Train net output #0: loss = 0.451783 (* 1 = 0.451783 loss)
I0706 07:00:37.274814 22636 solver.cpp:590] Iteration 7810, lr = 0.00254194
I0706 07:01:03.095849 22636 solver.cpp:243] Iteration 7865, loss = 0.197155
I0706 07:01:03.095942 22636 solver.cpp:259]     Train net output #0: loss = 0.197155 (* 1 = 0.197155 loss)
I0706 07:01:03.095959 22636 solver.cpp:590] Iteration 7865, lr = 0.00251754
I0706 07:01:28.902850 22636 solver.cpp:243] Iteration 7920, loss = 0.273016
I0706 07:01:28.902873 22636 solver.cpp:259]     Train net output #0: loss = 0.273016 (* 1 = 0.273016 loss)
I0706 07:01:28.902879 22636 solver.cpp:590] Iteration 7920, lr = 0.00249337
I0706 07:01:36.880117 22636 solver.cpp:347] Iteration 7938, Testing net (#0)
I0706 07:02:15.128027 22636 solver.cpp:415]     Test net output #0: accuracy = 0.141466
I0706 07:02:15.128130 22636 solver.cpp:415]     Test net output #1: loss = 5.75687 (* 1 = 5.75687 loss)
I0706 07:02:32.854528 22636 solver.cpp:243] Iteration 7975, loss = 0.102861
I0706 07:02:32.854553 22636 solver.cpp:259]     Train net output #0: loss = 0.102861 (* 1 = 0.102861 loss)
I0706 07:02:32.854559 22636 solver.cpp:590] Iteration 7975, lr = 0.00246944
I0706 07:02:58.675406 22636 solver.cpp:243] Iteration 8030, loss = 0.293819
I0706 07:02:58.675496 22636 solver.cpp:259]     Train net output #0: loss = 0.293819 (* 1 = 0.293819 loss)
I0706 07:02:58.675513 22636 solver.cpp:590] Iteration 8030, lr = 0.00244574
I0706 07:03:24.438954 22636 solver.cpp:243] Iteration 8085, loss = 0.945068
I0706 07:03:24.438977 22636 solver.cpp:259]     Train net output #0: loss = 0.945068 (* 1 = 0.945068 loss)
I0706 07:03:24.438982 22636 solver.cpp:590] Iteration 8085, lr = 0.00242226
I0706 07:03:50.232982 22636 solver.cpp:243] Iteration 8140, loss = 0.204743
I0706 07:03:50.233088 22636 solver.cpp:259]     Train net output #0: loss = 0.204743 (* 1 = 0.204743 loss)
I0706 07:03:50.233104 22636 solver.cpp:590] Iteration 8140, lr = 0.00239901
I0706 07:04:16.046974 22636 solver.cpp:243] Iteration 8195, loss = 0.46825
I0706 07:04:16.046998 22636 solver.cpp:259]     Train net output #0: loss = 0.46825 (* 1 = 0.46825 loss)
I0706 07:04:16.047004 22636 solver.cpp:590] Iteration 8195, lr = 0.00237598
I0706 07:04:41.883657 22636 solver.cpp:243] Iteration 8250, loss = 0.105742
I0706 07:04:41.884275 22636 solver.cpp:259]     Train net output #0: loss = 0.105741 (* 1 = 0.105741 loss)
I0706 07:04:41.884282 22636 solver.cpp:590] Iteration 8250, lr = 0.00235317
I0706 07:05:07.711987 22636 solver.cpp:243] Iteration 8305, loss = 0.589024
I0706 07:05:07.712010 22636 solver.cpp:259]     Train net output #0: loss = 0.589024 (* 1 = 0.589024 loss)
I0706 07:05:07.712016 22636 solver.cpp:590] Iteration 8305, lr = 0.00233058
I0706 07:05:33.517225 22636 solver.cpp:243] Iteration 8360, loss = 0.229164
I0706 07:05:33.517495 22636 solver.cpp:259]     Train net output #0: loss = 0.229164 (* 1 = 0.229164 loss)
I0706 07:05:33.517504 22636 solver.cpp:590] Iteration 8360, lr = 0.00230821
I0706 07:05:41.963416 22636 solver.cpp:347] Iteration 8379, Testing net (#0)
I0706 07:05:53.379338 22654 blocking_queue.cpp:50] Waiting for data
I0706 07:06:21.375555 22636 solver.cpp:415]     Test net output #0: accuracy = 0.135697
I0706 07:06:21.375927 22636 solver.cpp:415]     Test net output #1: loss = 5.7036 (* 1 = 5.7036 loss)
I0706 07:06:38.729037 22636 solver.cpp:243] Iteration 8415, loss = 0.141599
I0706 07:06:38.729060 22636 solver.cpp:259]     Train net output #0: loss = 0.141599 (* 1 = 0.141599 loss)
I0706 07:06:38.729066 22636 solver.cpp:590] Iteration 8415, lr = 0.00228606
I0706 07:07:04.619343 22636 solver.cpp:243] Iteration 8470, loss = 0.220684
I0706 07:07:04.619436 22636 solver.cpp:259]     Train net output #0: loss = 0.220684 (* 1 = 0.220684 loss)
I0706 07:07:04.619444 22636 solver.cpp:590] Iteration 8470, lr = 0.00226411
I0706 07:07:30.514662 22636 solver.cpp:243] Iteration 8525, loss = 0.148421
I0706 07:07:30.514685 22636 solver.cpp:259]     Train net output #0: loss = 0.148421 (* 1 = 0.148421 loss)
I0706 07:07:30.514693 22636 solver.cpp:590] Iteration 8525, lr = 0.00224238
I0706 07:07:56.317021 22636 solver.cpp:243] Iteration 8580, loss = 0.223273
I0706 07:07:56.317106 22636 solver.cpp:259]     Train net output #0: loss = 0.223273 (* 1 = 0.223273 loss)
I0706 07:07:56.317113 22636 solver.cpp:590] Iteration 8580, lr = 0.00222085
I0706 07:08:22.121908 22636 solver.cpp:243] Iteration 8635, loss = 0.145328
I0706 07:08:22.121933 22636 solver.cpp:259]     Train net output #0: loss = 0.145327 (* 1 = 0.145327 loss)
I0706 07:08:22.121940 22636 solver.cpp:590] Iteration 8635, lr = 0.00219953
I0706 07:08:47.960373 22636 solver.cpp:243] Iteration 8690, loss = 0.113865
I0706 07:08:47.960511 22636 solver.cpp:259]     Train net output #0: loss = 0.113865 (* 1 = 0.113865 loss)
I0706 07:08:47.960520 22636 solver.cpp:590] Iteration 8690, lr = 0.00217842
I0706 07:09:13.830067 22636 solver.cpp:243] Iteration 8745, loss = 0.263445
I0706 07:09:13.830093 22636 solver.cpp:259]     Train net output #0: loss = 0.263445 (* 1 = 0.263445 loss)
I0706 07:09:13.830101 22636 solver.cpp:590] Iteration 8745, lr = 0.00215751
I0706 07:09:39.653975 22636 solver.cpp:243] Iteration 8800, loss = 0.201459
I0706 07:09:39.654065 22636 solver.cpp:259]     Train net output #0: loss = 0.201459 (* 1 = 0.201459 loss)
I0706 07:09:39.654072 22636 solver.cpp:590] Iteration 8800, lr = 0.0021368
I0706 07:09:48.560248 22636 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_8820.caffemodel
I0706 07:10:01.701845 22636 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_8820.solverstate
I0706 07:10:03.230924 22636 solver.cpp:347] Iteration 8820, Testing net (#0)
I0706 07:10:36.258957 22636 solver.cpp:415]     Test net output #0: accuracy = 0.139904
I0706 07:10:36.259105 22636 solver.cpp:415]     Test net output #1: loss = 5.80855 (* 1 = 5.80855 loss)
I0706 07:10:53.056279 22636 solver.cpp:243] Iteration 8855, loss = 0.0416563
I0706 07:10:53.056306 22636 solver.cpp:259]     Train net output #0: loss = 0.0416563 (* 1 = 0.0416563 loss)
I0706 07:10:53.056313 22636 solver.cpp:590] Iteration 8855, lr = 0.00211629
I0706 07:11:18.817687 22636 solver.cpp:243] Iteration 8910, loss = 0.150337
I0706 07:11:18.860492 22636 solver.cpp:259]     Train net output #0: loss = 0.150337 (* 1 = 0.150337 loss)
I0706 07:11:18.860505 22636 solver.cpp:590] Iteration 8910, lr = 0.00209597
I0706 07:11:44.761620 22636 solver.cpp:243] Iteration 8965, loss = 0.541648
I0706 07:11:44.761642 22636 solver.cpp:259]     Train net output #0: loss = 0.541648 (* 1 = 0.541648 loss)
I0706 07:11:44.761648 22636 solver.cpp:590] Iteration 8965, lr = 0.00207585
I0706 07:12:10.518018 22636 solver.cpp:243] Iteration 9020, loss = 0.153713
I0706 07:12:10.518107 22636 solver.cpp:259]     Train net output #0: loss = 0.153713 (* 1 = 0.153713 loss)
I0706 07:12:10.518115 22636 solver.cpp:590] Iteration 9020, lr = 0.00205593
I0706 07:12:36.315207 22636 solver.cpp:243] Iteration 9075, loss = 0.085557
I0706 07:12:36.315229 22636 solver.cpp:259]     Train net output #0: loss = 0.085557 (* 1 = 0.085557 loss)
I0706 07:12:36.315235 22636 solver.cpp:590] Iteration 9075, lr = 0.00203619
I0706 07:13:02.153975 22636 solver.cpp:243] Iteration 9130, loss = 0.0887812
I0706 07:13:02.154064 22636 solver.cpp:259]     Train net output #0: loss = 0.0887813 (* 1 = 0.0887813 loss)
I0706 07:13:02.154072 22636 solver.cpp:590] Iteration 9130, lr = 0.00201665
I0706 07:13:27.957209 22636 solver.cpp:243] Iteration 9185, loss = 0.11718
I0706 07:13:27.957232 22636 solver.cpp:259]     Train net output #0: loss = 0.11718 (* 1 = 0.11718 loss)
I0706 07:13:27.957239 22636 solver.cpp:590] Iteration 9185, lr = 0.00199729
I0706 07:13:53.814337 22636 solver.cpp:243] Iteration 9240, loss = 0.187088
I0706 07:13:53.814440 22636 solver.cpp:259]     Train net output #0: loss = 0.187088 (* 1 = 0.187088 loss)
I0706 07:13:53.814448 22636 solver.cpp:590] Iteration 9240, lr = 0.00197812
I0706 07:14:03.196867 22636 solver.cpp:347] Iteration 9261, Testing net (#0)
I0706 07:14:06.155896 22654 blocking_queue.cpp:50] Waiting for data
I0706 07:14:27.745579 22636 solver.cpp:415]     Test net output #0: accuracy = 0.14387
I0706 07:14:27.745687 22636 solver.cpp:415]     Test net output #1: loss = 5.94635 (* 1 = 5.94635 loss)
I0706 07:14:44.054347 22636 solver.cpp:243] Iteration 9295, loss = 0.134463
I0706 07:14:44.054370 22636 solver.cpp:259]     Train net output #0: loss = 0.134463 (* 1 = 0.134463 loss)
I0706 07:14:44.054378 22636 solver.cpp:590] Iteration 9295, lr = 0.00195913
I0706 07:15:09.904592 22636 solver.cpp:243] Iteration 9350, loss = 0.0654735
I0706 07:15:09.904682 22636 solver.cpp:259]     Train net output #0: loss = 0.0654735 (* 1 = 0.0654735 loss)
I0706 07:15:09.904690 22636 solver.cpp:590] Iteration 9350, lr = 0.00194032
I0706 07:15:35.653741 22636 solver.cpp:243] Iteration 9405, loss = 0.170165
I0706 07:15:35.653764 22636 solver.cpp:259]     Train net output #0: loss = 0.170165 (* 1 = 0.170165 loss)
I0706 07:15:35.653769 22636 solver.cpp:590] Iteration 9405, lr = 0.0019217
I0706 07:16:01.394897 22636 solver.cpp:243] Iteration 9460, loss = 0.06252
I0706 07:16:01.394986 22636 solver.cpp:259]     Train net output #0: loss = 0.06252 (* 1 = 0.06252 loss)
I0706 07:16:01.395002 22636 solver.cpp:590] Iteration 9460, lr = 0.00190325
I0706 07:16:27.182688 22636 solver.cpp:243] Iteration 9515, loss = 0.133658
I0706 07:16:27.182711 22636 solver.cpp:259]     Train net output #0: loss = 0.133658 (* 1 = 0.133658 loss)
I0706 07:16:27.182718 22636 solver.cpp:590] Iteration 9515, lr = 0.00188498
I0706 07:16:53.067119 22636 solver.cpp:243] Iteration 9570, loss = 0.118564
I0706 07:16:53.067239 22636 solver.cpp:259]     Train net output #0: loss = 0.118564 (* 1 = 0.118564 loss)
I0706 07:16:53.067250 22636 solver.cpp:590] Iteration 9570, lr = 0.00186689
I0706 07:17:18.857309 22636 solver.cpp:243] Iteration 9625, loss = 0.176433
I0706 07:17:18.857334 22636 solver.cpp:259]     Train net output #0: loss = 0.176433 (* 1 = 0.176433 loss)
I0706 07:17:18.857342 22636 solver.cpp:590] Iteration 9625, lr = 0.00184897
I0706 07:17:44.666931 22636 solver.cpp:243] Iteration 9680, loss = 0.0966269
I0706 07:17:44.667208 22636 solver.cpp:259]     Train net output #0: loss = 0.096627 (* 1 = 0.096627 loss)
I0706 07:17:44.667217 22636 solver.cpp:590] Iteration 9680, lr = 0.00183122
I0706 07:17:54.512305 22636 solver.cpp:347] Iteration 9702, Testing net (#0)
I0706 07:18:16.280567 22636 solver.cpp:415]     Test net output #0: accuracy = 0.148678
I0706 07:18:16.280778 22636 solver.cpp:415]     Test net output #1: loss = 5.76207 (* 1 = 5.76207 loss)
I0706 07:18:32.142549 22636 solver.cpp:243] Iteration 9735, loss = 0.0346789
I0706 07:18:32.142573 22636 solver.cpp:259]     Train net output #0: loss = 0.034679 (* 1 = 0.034679 loss)
I0706 07:18:32.142580 22636 solver.cpp:590] Iteration 9735, lr = 0.00181364
I0706 07:18:57.869181 22636 solver.cpp:243] Iteration 9790, loss = 0.221218
I0706 07:18:57.869276 22636 solver.cpp:259]     Train net output #0: loss = 0.221218 (* 1 = 0.221218 loss)
I0706 07:18:57.869292 22636 solver.cpp:590] Iteration 9790, lr = 0.00179623
I0706 07:19:23.778401 22636 solver.cpp:243] Iteration 9845, loss = 0.0330916
I0706 07:19:23.778424 22636 solver.cpp:259]     Train net output #0: loss = 0.0330917 (* 1 = 0.0330917 loss)
I0706 07:19:23.778431 22636 solver.cpp:590] Iteration 9845, lr = 0.00177899
I0706 07:19:49.613124 22636 solver.cpp:243] Iteration 9900, loss = 0.162207
I0706 07:19:49.613216 22636 solver.cpp:259]     Train net output #0: loss = 0.162207 (* 1 = 0.162207 loss)
I0706 07:19:49.613234 22636 solver.cpp:590] Iteration 9900, lr = 0.00176191
I0706 07:20:15.466470 22636 solver.cpp:243] Iteration 9955, loss = 0.0969132
I0706 07:20:15.466495 22636 solver.cpp:259]     Train net output #0: loss = 0.0969133 (* 1 = 0.0969133 loss)
I0706 07:20:15.466500 22636 solver.cpp:590] Iteration 9955, lr = 0.001745
I0706 07:20:41.310741 22636 solver.cpp:243] Iteration 10010, loss = 0.203769
I0706 07:20:41.310830 22636 solver.cpp:259]     Train net output #0: loss = 0.20377 (* 1 = 0.20377 loss)
I0706 07:20:41.310837 22636 solver.cpp:590] Iteration 10010, lr = 0.00172825
I0706 07:21:07.165230 22636 solver.cpp:243] Iteration 10065, loss = 0.387321
I0706 07:21:07.165253 22636 solver.cpp:259]     Train net output #0: loss = 0.387321 (* 1 = 0.387321 loss)
I0706 07:21:07.165261 22636 solver.cpp:590] Iteration 10065, lr = 0.00171166
I0706 07:21:32.944243 22636 solver.cpp:243] Iteration 10120, loss = 0.102919
I0706 07:21:32.944334 22636 solver.cpp:259]     Train net output #0: loss = 0.10292 (* 1 = 0.10292 loss)
I0706 07:21:32.944350 22636 solver.cpp:590] Iteration 10120, lr = 0.00169523
I0706 07:21:43.270087 22636 solver.cpp:347] Iteration 10143, Testing net (#0)
I0706 07:22:03.948712 22636 solver.cpp:415]     Test net output #0: accuracy = 0.151683
I0706 07:22:03.948818 22636 solver.cpp:415]     Test net output #1: loss = 5.9686 (* 1 = 5.9686 loss)
I0706 07:22:19.369277 22636 solver.cpp:243] Iteration 10175, loss = 0.221067
I0706 07:22:19.369302 22636 solver.cpp:259]     Train net output #0: loss = 0.221067 (* 1 = 0.221067 loss)
I0706 07:22:19.369308 22636 solver.cpp:590] Iteration 10175, lr = 0.00167896
I0706 07:22:45.191596 22636 solver.cpp:243] Iteration 10230, loss = 0.20895
I0706 07:22:45.191690 22636 solver.cpp:259]     Train net output #0: loss = 0.20895 (* 1 = 0.20895 loss)
I0706 07:22:45.191697 22636 solver.cpp:590] Iteration 10230, lr = 0.00166284
I0706 07:23:10.943096 22636 solver.cpp:243] Iteration 10285, loss = 0.102768
I0706 07:23:10.943119 22636 solver.cpp:259]     Train net output #0: loss = 0.102768 (* 1 = 0.102768 loss)
I0706 07:23:10.943125 22636 solver.cpp:590] Iteration 10285, lr = 0.00164688
I0706 07:23:36.706642 22636 solver.cpp:243] Iteration 10340, loss = 0.096447
I0706 07:23:36.706751 22636 solver.cpp:259]     Train net output #0: loss = 0.0964471 (* 1 = 0.0964471 loss)
I0706 07:23:36.706768 22636 solver.cpp:590] Iteration 10340, lr = 0.00163107
I0706 07:24:02.485512 22636 solver.cpp:243] Iteration 10395, loss = 0.716391
I0706 07:24:02.485537 22636 solver.cpp:259]     Train net output #0: loss = 0.716391 (* 1 = 0.716391 loss)
I0706 07:24:02.485543 22636 solver.cpp:590] Iteration 10395, lr = 0.00161541
I0706 07:24:28.314236 22636 solver.cpp:243] Iteration 10450, loss = 0.147428
I0706 07:24:28.314716 22636 solver.cpp:259]     Train net output #0: loss = 0.147428 (* 1 = 0.147428 loss)
I0706 07:24:28.314724 22636 solver.cpp:590] Iteration 10450, lr = 0.00159991
I0706 07:24:54.193779 22636 solver.cpp:243] Iteration 10505, loss = 0.134422
I0706 07:24:54.193804 22636 solver.cpp:259]     Train net output #0: loss = 0.134422 (* 1 = 0.134422 loss)
I0706 07:24:54.193810 22636 solver.cpp:590] Iteration 10505, lr = 0.00158455
I0706 07:25:19.955452 22636 solver.cpp:243] Iteration 10560, loss = 0.120438
I0706 07:25:19.955816 22636 solver.cpp:259]     Train net output #0: loss = 0.120439 (* 1 = 0.120439 loss)
I0706 07:25:19.955824 22636 solver.cpp:590] Iteration 10560, lr = 0.00156934
I0706 07:25:30.754745 22636 solver.cpp:347] Iteration 10584, Testing net (#0)
I0706 07:25:32.078770 22636 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 07:25:51.340395 22636 solver.cpp:415]     Test net output #0: accuracy = 0.152885
I0706 07:25:51.340657 22636 solver.cpp:415]     Test net output #1: loss = 5.9265 (* 1 = 5.9265 loss)
I0706 07:26:06.299438 22636 solver.cpp:243] Iteration 10615, loss = 0.0419512
I0706 07:26:06.299463 22636 solver.cpp:259]     Train net output #0: loss = 0.0419513 (* 1 = 0.0419513 loss)
I0706 07:26:06.299470 22636 solver.cpp:590] Iteration 10615, lr = 0.00155427
I0706 07:26:32.092146 22636 solver.cpp:243] Iteration 10670, loss = 0.0610715
I0706 07:26:32.092206 22636 solver.cpp:259]     Train net output #0: loss = 0.0610716 (* 1 = 0.0610716 loss)
I0706 07:26:32.092213 22636 solver.cpp:590] Iteration 10670, lr = 0.00153935
I0706 07:26:57.842027 22636 solver.cpp:243] Iteration 10725, loss = 0.247967
I0706 07:26:57.842052 22636 solver.cpp:259]     Train net output #0: loss = 0.247967 (* 1 = 0.247967 loss)
I0706 07:26:57.842059 22636 solver.cpp:590] Iteration 10725, lr = 0.00152458
I0706 07:27:23.631130 22636 solver.cpp:243] Iteration 10780, loss = 0.0670457
I0706 07:27:23.631260 22636 solver.cpp:259]     Train net output #0: loss = 0.0670457 (* 1 = 0.0670457 loss)
I0706 07:27:23.631268 22636 solver.cpp:590] Iteration 10780, lr = 0.00150994
I0706 07:27:49.446558 22636 solver.cpp:243] Iteration 10835, loss = 0.0920061
I0706 07:27:49.446585 22636 solver.cpp:259]     Train net output #0: loss = 0.0920061 (* 1 = 0.0920061 loss)
I0706 07:27:49.446593 22636 solver.cpp:590] Iteration 10835, lr = 0.00149545
I0706 07:28:15.262079 22636 solver.cpp:243] Iteration 10890, loss = 0.125645
I0706 07:28:15.262166 22636 solver.cpp:259]     Train net output #0: loss = 0.125646 (* 1 = 0.125646 loss)
I0706 07:28:15.262173 22636 solver.cpp:590] Iteration 10890, lr = 0.00148109
I0706 07:28:41.075006 22636 solver.cpp:243] Iteration 10945, loss = 0.165199
I0706 07:28:41.075029 22636 solver.cpp:259]     Train net output #0: loss = 0.165199 (* 1 = 0.165199 loss)
I0706 07:28:41.075036 22636 solver.cpp:590] Iteration 10945, lr = 0.00146688
I0706 07:29:06.837798 22636 solver.cpp:243] Iteration 11000, loss = 0.156104
I0706 07:29:06.837888 22636 solver.cpp:259]     Train net output #0: loss = 0.156104 (* 1 = 0.156104 loss)
I0706 07:29:06.837905 22636 solver.cpp:590] Iteration 11000, lr = 0.0014528
I0706 07:29:18.124517 22636 solver.cpp:347] Iteration 11025, Testing net (#0)
I0706 07:29:40.617138 22636 solver.cpp:415]     Test net output #0: accuracy = 0.150481
I0706 07:29:40.617241 22636 solver.cpp:415]     Test net output #1: loss = 5.90817 (* 1 = 5.90817 loss)
I0706 07:29:55.086302 22636 solver.cpp:243] Iteration 11055, loss = 0.0763092
I0706 07:29:55.086325 22636 solver.cpp:259]     Train net output #0: loss = 0.0763094 (* 1 = 0.0763094 loss)
I0706 07:29:55.086331 22636 solver.cpp:590] Iteration 11055, lr = 0.00143885
I0706 07:30:20.835108 22636 solver.cpp:243] Iteration 11110, loss = 0.104702
I0706 07:30:20.835211 22636 solver.cpp:259]     Train net output #0: loss = 0.104702 (* 1 = 0.104702 loss)
I0706 07:30:20.835218 22636 solver.cpp:590] Iteration 11110, lr = 0.00142504
I0706 07:30:46.639925 22636 solver.cpp:243] Iteration 11165, loss = 0.0642985
I0706 07:30:46.639948 22636 solver.cpp:259]     Train net output #0: loss = 0.0642986 (* 1 = 0.0642986 loss)
I0706 07:30:46.639955 22636 solver.cpp:590] Iteration 11165, lr = 0.00141136
I0706 07:31:12.434753 22636 solver.cpp:243] Iteration 11220, loss = 0.188668
I0706 07:31:12.435190 22636 solver.cpp:259]     Train net output #0: loss = 0.188668 (* 1 = 0.188668 loss)
I0706 07:31:12.435199 22636 solver.cpp:590] Iteration 11220, lr = 0.00139781
I0706 07:31:38.228119 22636 solver.cpp:243] Iteration 11275, loss = 0.130114
I0706 07:31:38.228140 22636 solver.cpp:259]     Train net output #0: loss = 0.130114 (* 1 = 0.130114 loss)
I0706 07:31:38.228147 22636 solver.cpp:590] Iteration 11275, lr = 0.00138439
I0706 07:32:04.038063 22636 solver.cpp:243] Iteration 11330, loss = 0.0291902
I0706 07:32:04.038349 22636 solver.cpp:259]     Train net output #0: loss = 0.0291904 (* 1 = 0.0291904 loss)
I0706 07:32:04.038357 22636 solver.cpp:590] Iteration 11330, lr = 0.00137111
I0706 07:32:29.844660 22636 solver.cpp:243] Iteration 11385, loss = 0.13794
I0706 07:32:29.844684 22636 solver.cpp:259]     Train net output #0: loss = 0.13794 (* 1 = 0.13794 loss)
I0706 07:32:29.844691 22636 solver.cpp:590] Iteration 11385, lr = 0.00135794
I0706 07:32:55.632051 22636 solver.cpp:243] Iteration 11440, loss = 0.118302
I0706 07:32:55.632390 22636 solver.cpp:259]     Train net output #0: loss = 0.118302 (* 1 = 0.118302 loss)
I0706 07:32:55.632400 22636 solver.cpp:590] Iteration 11440, lr = 0.00134491
I0706 07:33:07.388291 22636 solver.cpp:347] Iteration 11466, Testing net (#0)
I0706 07:33:29.654484 22636 solver.cpp:415]     Test net output #0: accuracy = 0.151202
I0706 07:33:29.654898 22636 solver.cpp:415]     Test net output #1: loss = 5.87289 (* 1 = 5.87289 loss)
I0706 07:33:43.674988 22636 solver.cpp:243] Iteration 11495, loss = 0.0522275
I0706 07:33:43.675010 22636 solver.cpp:259]     Train net output #0: loss = 0.0522276 (* 1 = 0.0522276 loss)
I0706 07:33:43.675016 22636 solver.cpp:590] Iteration 11495, lr = 0.001332
I0706 07:34:09.431723 22636 solver.cpp:243] Iteration 11550, loss = 0.0150965
I0706 07:34:09.431813 22636 solver.cpp:259]     Train net output #0: loss = 0.0150966 (* 1 = 0.0150966 loss)
I0706 07:34:09.431818 22636 solver.cpp:590] Iteration 11550, lr = 0.00131921
I0706 07:34:35.259413 22636 solver.cpp:243] Iteration 11605, loss = 0.176601
I0706 07:34:35.259434 22636 solver.cpp:259]     Train net output #0: loss = 0.176601 (* 1 = 0.176601 loss)
I0706 07:34:35.259439 22636 solver.cpp:590] Iteration 11605, lr = 0.00130655
I0706 07:35:01.021546 22636 solver.cpp:243] Iteration 11660, loss = 0.186185
I0706 07:35:01.021632 22636 solver.cpp:259]     Train net output #0: loss = 0.186185 (* 1 = 0.186185 loss)
I0706 07:35:01.021639 22636 solver.cpp:590] Iteration 11660, lr = 0.00129401
I0706 07:35:26.793057 22636 solver.cpp:243] Iteration 11715, loss = 0.0712922
I0706 07:35:26.793082 22636 solver.cpp:259]     Train net output #0: loss = 0.0712925 (* 1 = 0.0712925 loss)
I0706 07:35:26.793087 22636 solver.cpp:590] Iteration 11715, lr = 0.00128159
I0706 07:35:52.595175 22636 solver.cpp:243] Iteration 11770, loss = 0.020491
I0706 07:35:52.595270 22636 solver.cpp:259]     Train net output #0: loss = 0.0204912 (* 1 = 0.0204912 loss)
I0706 07:35:52.595276 22636 solver.cpp:590] Iteration 11770, lr = 0.00126929
I0706 07:36:18.437408 22636 solver.cpp:243] Iteration 11825, loss = 0.0785534
I0706 07:36:18.437435 22636 solver.cpp:259]     Train net output #0: loss = 0.0785536 (* 1 = 0.0785536 loss)
I0706 07:36:18.437443 22636 solver.cpp:590] Iteration 11825, lr = 0.0012571
I0706 07:36:44.292235 22636 solver.cpp:243] Iteration 11880, loss = 0.0810287
I0706 07:36:44.292340 22636 solver.cpp:259]     Train net output #0: loss = 0.081029 (* 1 = 0.081029 loss)
I0706 07:36:44.292346 22636 solver.cpp:590] Iteration 11880, lr = 0.00124503
I0706 07:36:56.555452 22636 solver.cpp:347] Iteration 11907, Testing net (#0)
I0706 07:37:17.230620 22636 solver.cpp:415]     Test net output #0: accuracy = 0.15625
I0706 07:37:17.231004 22636 solver.cpp:415]     Test net output #1: loss = 6.01507 (* 1 = 6.01507 loss)
I0706 07:37:30.794986 22636 solver.cpp:243] Iteration 11935, loss = 0.0929833
I0706 07:37:30.795011 22636 solver.cpp:259]     Train net output #0: loss = 0.0929835 (* 1 = 0.0929835 loss)
I0706 07:37:30.795018 22636 solver.cpp:590] Iteration 11935, lr = 0.00123308
I0706 07:37:56.611134 22636 solver.cpp:243] Iteration 11990, loss = 0.00754368
I0706 07:37:56.611207 22636 solver.cpp:259]     Train net output #0: loss = 0.0075439 (* 1 = 0.0075439 loss)
I0706 07:37:56.611222 22636 solver.cpp:590] Iteration 11990, lr = 0.00122125
I0706 07:38:22.390810 22636 solver.cpp:243] Iteration 12045, loss = 0.0424532
I0706 07:38:22.390833 22636 solver.cpp:259]     Train net output #0: loss = 0.0424534 (* 1 = 0.0424534 loss)
I0706 07:38:22.390839 22636 solver.cpp:590] Iteration 12045, lr = 0.00120952
I0706 07:38:48.193321 22636 solver.cpp:243] Iteration 12100, loss = 0.0114003
I0706 07:38:48.193409 22636 solver.cpp:259]     Train net output #0: loss = 0.0114005 (* 1 = 0.0114005 loss)
I0706 07:38:48.193415 22636 solver.cpp:590] Iteration 12100, lr = 0.00119791
I0706 07:39:14.049659 22636 solver.cpp:243] Iteration 12155, loss = 0.00708605
I0706 07:39:14.049685 22636 solver.cpp:259]     Train net output #0: loss = 0.00708628 (* 1 = 0.00708628 loss)
I0706 07:39:14.049691 22636 solver.cpp:590] Iteration 12155, lr = 0.00118641
I0706 07:39:39.868700 22636 solver.cpp:243] Iteration 12210, loss = 0.170934
I0706 07:39:39.868784 22636 solver.cpp:259]     Train net output #0: loss = 0.170934 (* 1 = 0.170934 loss)
I0706 07:39:39.868800 22636 solver.cpp:590] Iteration 12210, lr = 0.00117503
I0706 07:40:05.703202 22636 solver.cpp:243] Iteration 12265, loss = 0.0183737
I0706 07:40:05.703227 22636 solver.cpp:259]     Train net output #0: loss = 0.0183739 (* 1 = 0.0183739 loss)
I0706 07:40:05.703233 22636 solver.cpp:590] Iteration 12265, lr = 0.00116375
I0706 07:40:31.541015 22636 solver.cpp:243] Iteration 12320, loss = 0.0568431
I0706 07:40:31.541110 22636 solver.cpp:259]     Train net output #0: loss = 0.0568432 (* 1 = 0.0568432 loss)
I0706 07:40:31.541116 22636 solver.cpp:590] Iteration 12320, lr = 0.00115258
I0706 07:40:44.173465 22636 solver.cpp:347] Iteration 12348, Testing net (#0)
I0706 07:41:05.819941 22636 solver.cpp:415]     Test net output #0: accuracy = 0.157212
I0706 07:41:05.820065 22636 solver.cpp:415]     Test net output #1: loss = 5.88047 (* 1 = 5.88047 loss)
I0706 07:41:18.896342 22636 solver.cpp:243] Iteration 12375, loss = 0.0387964
I0706 07:41:18.896366 22636 solver.cpp:259]     Train net output #0: loss = 0.0387966 (* 1 = 0.0387966 loss)
I0706 07:41:18.896373 22636 solver.cpp:590] Iteration 12375, lr = 0.00114151
I0706 07:41:44.666703 22636 solver.cpp:243] Iteration 12430, loss = 0.0136389
I0706 07:41:44.666784 22636 solver.cpp:259]     Train net output #0: loss = 0.0136391 (* 1 = 0.0136391 loss)
I0706 07:41:44.666790 22636 solver.cpp:590] Iteration 12430, lr = 0.00113055
I0706 07:42:10.535409 22636 solver.cpp:243] Iteration 12485, loss = 0.139791
I0706 07:42:10.535434 22636 solver.cpp:259]     Train net output #0: loss = 0.139791 (* 1 = 0.139791 loss)
I0706 07:42:10.535440 22636 solver.cpp:590] Iteration 12485, lr = 0.0011197
I0706 07:42:36.416136 22636 solver.cpp:243] Iteration 12540, loss = 0.0819772
I0706 07:42:36.416268 22636 solver.cpp:259]     Train net output #0: loss = 0.0819774 (* 1 = 0.0819774 loss)
I0706 07:42:36.416276 22636 solver.cpp:590] Iteration 12540, lr = 0.00110895
I0706 07:43:02.168226 22636 solver.cpp:243] Iteration 12595, loss = 0.0191477
I0706 07:43:02.168248 22636 solver.cpp:259]     Train net output #0: loss = 0.0191478 (* 1 = 0.0191478 loss)
I0706 07:43:02.168256 22636 solver.cpp:590] Iteration 12595, lr = 0.00109831
I0706 07:43:27.956533 22636 solver.cpp:243] Iteration 12650, loss = 0.070906
I0706 07:43:27.956640 22636 solver.cpp:259]     Train net output #0: loss = 0.0709062 (* 1 = 0.0709062 loss)
I0706 07:43:27.956657 22636 solver.cpp:590] Iteration 12650, lr = 0.00108777
I0706 07:43:53.774662 22636 solver.cpp:243] Iteration 12705, loss = 0.0647936
I0706 07:43:53.774687 22636 solver.cpp:259]     Train net output #0: loss = 0.0647938 (* 1 = 0.0647938 loss)
I0706 07:43:53.774693 22636 solver.cpp:590] Iteration 12705, lr = 0.00107732
I0706 07:44:19.576630 22636 solver.cpp:243] Iteration 12760, loss = 0.0384915
I0706 07:44:19.577293 22636 solver.cpp:259]     Train net output #0: loss = 0.0384917 (* 1 = 0.0384917 loss)
I0706 07:44:19.577308 22636 solver.cpp:590] Iteration 12760, lr = 0.00106698
I0706 07:44:32.700809 22636 solver.cpp:347] Iteration 12789, Testing net (#0)
I0706 07:44:37.047857 22654 blocking_queue.cpp:50] Waiting for data
I0706 07:44:56.052764 22636 solver.cpp:415]     Test net output #0: accuracy = 0.156731
I0706 07:44:56.053107 22636 solver.cpp:415]     Test net output #1: loss = 5.88486 (* 1 = 5.88486 loss)
I0706 07:45:08.660207 22636 solver.cpp:243] Iteration 12815, loss = 0.152006
I0706 07:45:08.660229 22636 solver.cpp:259]     Train net output #0: loss = 0.152006 (* 1 = 0.152006 loss)
I0706 07:45:08.660235 22636 solver.cpp:590] Iteration 12815, lr = 0.00105674
I0706 07:45:34.424532 22636 solver.cpp:243] Iteration 12870, loss = 0.0647929
I0706 07:45:34.424628 22636 solver.cpp:259]     Train net output #0: loss = 0.0647931 (* 1 = 0.0647931 loss)
I0706 07:45:34.424643 22636 solver.cpp:590] Iteration 12870, lr = 0.0010466
I0706 07:46:00.267693 22636 solver.cpp:243] Iteration 12925, loss = 0.0599565
I0706 07:46:00.267716 22636 solver.cpp:259]     Train net output #0: loss = 0.0599567 (* 1 = 0.0599567 loss)
I0706 07:46:00.267722 22636 solver.cpp:590] Iteration 12925, lr = 0.00103655
I0706 07:46:26.017246 22636 solver.cpp:243] Iteration 12980, loss = 0.0578378
I0706 07:46:26.017326 22636 solver.cpp:259]     Train net output #0: loss = 0.057838 (* 1 = 0.057838 loss)
I0706 07:46:26.017343 22636 solver.cpp:590] Iteration 12980, lr = 0.0010266
I0706 07:46:51.795341 22636 solver.cpp:243] Iteration 13035, loss = 0.0187681
I0706 07:46:51.795366 22636 solver.cpp:259]     Train net output #0: loss = 0.0187684 (* 1 = 0.0187684 loss)
I0706 07:46:51.795372 22636 solver.cpp:590] Iteration 13035, lr = 0.00101675
I0706 07:47:17.593286 22636 solver.cpp:243] Iteration 13090, loss = 0.0474544
I0706 07:47:17.593374 22636 solver.cpp:259]     Train net output #0: loss = 0.0474546 (* 1 = 0.0474546 loss)
I0706 07:47:17.593390 22636 solver.cpp:590] Iteration 13090, lr = 0.00100699
I0706 07:47:43.378599 22636 solver.cpp:243] Iteration 13145, loss = 0.00475608
I0706 07:47:43.378623 22636 solver.cpp:259]     Train net output #0: loss = 0.00475627 (* 1 = 0.00475627 loss)
I0706 07:47:43.378629 22636 solver.cpp:590] Iteration 13145, lr = 0.000997321
I0706 07:48:09.186192 22636 solver.cpp:243] Iteration 13200, loss = 0.11474
I0706 07:48:09.186322 22636 solver.cpp:259]     Train net output #0: loss = 0.11474 (* 1 = 0.11474 loss)
I0706 07:48:09.186339 22636 solver.cpp:590] Iteration 13200, lr = 0.000987747
I0706 07:48:22.787899 22636 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_13230.caffemodel
I0706 07:48:39.812422 22636 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_13230.solverstate
I0706 07:48:41.357971 22636 solver.cpp:347] Iteration 13230, Testing net (#0)
I0706 07:48:53.793228 22654 blocking_queue.cpp:50] Waiting for data
I0706 07:49:03.785434 22636 solver.cpp:415]     Test net output #0: accuracy = 0.153966
I0706 07:49:03.785461 22636 solver.cpp:415]     Test net output #1: loss = 6.01223 (* 1 = 6.01223 loss)
I0706 07:49:15.917426 22636 solver.cpp:243] Iteration 13255, loss = 0.00765696
I0706 07:49:15.917543 22636 solver.cpp:259]     Train net output #0: loss = 0.00765721 (* 1 = 0.00765721 loss)
I0706 07:49:15.917551 22636 solver.cpp:590] Iteration 13255, lr = 0.000978266
I0706 07:49:41.728441 22636 solver.cpp:243] Iteration 13310, loss = 0.0434186
I0706 07:49:41.728471 22636 solver.cpp:259]     Train net output #0: loss = 0.0434189 (* 1 = 0.0434189 loss)
I0706 07:49:41.728479 22636 solver.cpp:590] Iteration 13310, lr = 0.000968875
I0706 07:50:07.521105 22636 solver.cpp:243] Iteration 13365, loss = 0.060083
I0706 07:50:07.521231 22636 solver.cpp:259]     Train net output #0: loss = 0.0600833 (* 1 = 0.0600833 loss)
I0706 07:50:07.521239 22636 solver.cpp:590] Iteration 13365, lr = 0.000959575
I0706 07:50:33.294752 22636 solver.cpp:243] Iteration 13420, loss = 0.158952
I0706 07:50:33.294775 22636 solver.cpp:259]     Train net output #0: loss = 0.158953 (* 1 = 0.158953 loss)
I0706 07:50:33.294781 22636 solver.cpp:590] Iteration 13420, lr = 0.000950364
I0706 07:50:59.054332 22636 solver.cpp:243] Iteration 13475, loss = 0.0242651
I0706 07:50:59.054966 22636 solver.cpp:259]     Train net output #0: loss = 0.0242653 (* 1 = 0.0242653 loss)
I0706 07:50:59.054975 22636 solver.cpp:590] Iteration 13475, lr = 0.000941241
I0706 07:51:24.935726 22636 solver.cpp:243] Iteration 13530, loss = 0.0921527
I0706 07:51:24.935751 22636 solver.cpp:259]     Train net output #0: loss = 0.092153 (* 1 = 0.092153 loss)
I0706 07:51:24.935758 22636 solver.cpp:590] Iteration 13530, lr = 0.000932206
I0706 07:51:50.708250 22636 solver.cpp:243] Iteration 13585, loss = 0.0125347
I0706 07:51:50.714993 22636 solver.cpp:259]     Train net output #0: loss = 0.012535 (* 1 = 0.012535 loss)
I0706 07:51:50.715001 22636 solver.cpp:590] Iteration 13585, lr = 0.000923258
I0706 07:52:16.499768 22636 solver.cpp:243] Iteration 13640, loss = 0.0131815
I0706 07:52:16.499794 22636 solver.cpp:259]     Train net output #0: loss = 0.0131819 (* 1 = 0.0131819 loss)
I0706 07:52:16.499801 22636 solver.cpp:590] Iteration 13640, lr = 0.000914395
I0706 07:52:30.570183 22636 solver.cpp:347] Iteration 13671, Testing net (#0)
I0706 07:52:52.341668 22636 solver.cpp:415]     Test net output #0: accuracy = 0.157212
I0706 07:52:52.341696 22636 solver.cpp:415]     Test net output #1: loss = 6.0214 (* 1 = 6.0214 loss)
I0706 07:53:04.036042 22636 solver.cpp:243] Iteration 13695, loss = 0.0175915
I0706 07:53:04.036103 22636 solver.cpp:259]     Train net output #0: loss = 0.0175918 (* 1 = 0.0175918 loss)
I0706 07:53:04.036109 22636 solver.cpp:590] Iteration 13695, lr = 0.000905618
I0706 07:53:29.871163 22636 solver.cpp:243] Iteration 13750, loss = 0.0475794
I0706 07:53:29.871186 22636 solver.cpp:259]     Train net output #0: loss = 0.0475797 (* 1 = 0.0475797 loss)
I0706 07:53:29.871191 22636 solver.cpp:590] Iteration 13750, lr = 0.000896925
I0706 07:53:55.697228 22636 solver.cpp:243] Iteration 13805, loss = 0.142384
I0706 07:53:55.697312 22636 solver.cpp:259]     Train net output #0: loss = 0.142385 (* 1 = 0.142385 loss)
I0706 07:53:55.697319 22636 solver.cpp:590] Iteration 13805, lr = 0.000888315
I0706 07:54:21.497400 22636 solver.cpp:243] Iteration 13860, loss = 0.0497946
I0706 07:54:21.497457 22636 solver.cpp:259]     Train net output #0: loss = 0.0497949 (* 1 = 0.0497949 loss)
I0706 07:54:21.497473 22636 solver.cpp:590] Iteration 13860, lr = 0.000879788
I0706 07:54:47.313361 22636 solver.cpp:243] Iteration 13915, loss = 0.0201888
I0706 07:54:47.313496 22636 solver.cpp:259]     Train net output #0: loss = 0.0201891 (* 1 = 0.0201891 loss)
I0706 07:54:47.313504 22636 solver.cpp:590] Iteration 13915, lr = 0.000871343
I0706 07:55:13.124686 22636 solver.cpp:243] Iteration 13970, loss = 0.0455377
I0706 07:55:13.124711 22636 solver.cpp:259]     Train net output #0: loss = 0.0455379 (* 1 = 0.0455379 loss)
I0706 07:55:13.124716 22636 solver.cpp:590] Iteration 13970, lr = 0.000862979
I0706 07:55:38.992352 22636 solver.cpp:243] Iteration 14025, loss = 0.0119141
I0706 07:55:38.992454 22636 solver.cpp:259]     Train net output #0: loss = 0.0119144 (* 1 = 0.0119144 loss)
I0706 07:55:38.992460 22636 solver.cpp:590] Iteration 14025, lr = 0.000854695
I0706 07:56:04.860049 22636 solver.cpp:243] Iteration 14080, loss = 0.0257753
I0706 07:56:04.860080 22636 solver.cpp:259]     Train net output #0: loss = 0.0257756 (* 1 = 0.0257756 loss)
I0706 07:56:04.860088 22636 solver.cpp:590] Iteration 14080, lr = 0.000846491
I0706 07:56:19.442709 22636 solver.cpp:347] Iteration 14112, Testing net (#0)
I0706 07:56:21.367518 22636 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 07:56:40.667415 22636 solver.cpp:415]     Test net output #0: accuracy = 0.16262
I0706 07:56:40.667441 22636 solver.cpp:415]     Test net output #1: loss = 5.92453 (* 1 = 5.92453 loss)
I0706 07:56:51.844270 22636 solver.cpp:243] Iteration 14135, loss = 0.0278144
I0706 07:56:51.845819 22636 solver.cpp:259]     Train net output #0: loss = 0.0278148 (* 1 = 0.0278148 loss)
I0706 07:56:51.845829 22636 solver.cpp:590] Iteration 14135, lr = 0.000838365
I0706 07:57:17.775825 22636 solver.cpp:243] Iteration 14190, loss = 0.0645432
I0706 07:57:17.775851 22636 solver.cpp:259]     Train net output #0: loss = 0.0645436 (* 1 = 0.0645436 loss)
I0706 07:57:17.775857 22636 solver.cpp:590] Iteration 14190, lr = 0.000830318
I0706 07:57:43.543016 22636 solver.cpp:243] Iteration 14245, loss = 0.128307
I0706 07:57:43.543157 22636 solver.cpp:259]     Train net output #0: loss = 0.128307 (* 1 = 0.128307 loss)
I0706 07:57:43.543174 22636 solver.cpp:590] Iteration 14245, lr = 0.000822347
I0706 07:58:09.392648 22636 solver.cpp:243] Iteration 14300, loss = 0.0177718
I0706 07:58:09.392673 22636 solver.cpp:259]     Train net output #0: loss = 0.0177722 (* 1 = 0.0177722 loss)
I0706 07:58:09.392678 22636 solver.cpp:590] Iteration 14300, lr = 0.000814453
I0706 07:58:35.184299 22636 solver.cpp:243] Iteration 14355, loss = 0.147348
I0706 07:58:35.184391 22636 solver.cpp:259]     Train net output #0: loss = 0.147348 (* 1 = 0.147348 loss)
I0706 07:58:35.184406 22636 solver.cpp:590] Iteration 14355, lr = 0.000806635
I0706 07:59:01.057690 22636 solver.cpp:243] Iteration 14410, loss = 0.0644089
I0706 07:59:01.057720 22636 solver.cpp:259]     Train net output #0: loss = 0.0644093 (* 1 = 0.0644093 loss)
I0706 07:59:01.057729 22636 solver.cpp:590] Iteration 14410, lr = 0.000798892
I0706 07:59:26.933462 22636 solver.cpp:243] Iteration 14465, loss = 0.0220054
I0706 07:59:26.933553 22636 solver.cpp:259]     Train net output #0: loss = 0.0220058 (* 1 = 0.0220058 loss)
I0706 07:59:26.933559 22636 solver.cpp:590] Iteration 14465, lr = 0.000791224
I0706 07:59:52.722880 22636 solver.cpp:243] Iteration 14520, loss = 0.00686393
I0706 07:59:52.722903 22636 solver.cpp:259]     Train net output #0: loss = 0.00686433 (* 1 = 0.00686433 loss)
I0706 07:59:52.722908 22636 solver.cpp:590] Iteration 14520, lr = 0.000783629
I0706 08:00:07.743093 22636 solver.cpp:347] Iteration 14553, Testing net (#0)
I0706 08:00:29.628522 22636 solver.cpp:415]     Test net output #0: accuracy = 0.161659
I0706 08:00:29.628551 22636 solver.cpp:415]     Test net output #1: loss = 5.97166 (* 1 = 5.97166 loss)
I0706 08:00:40.344163 22636 solver.cpp:243] Iteration 14575, loss = 0.0495512
I0706 08:00:40.344255 22636 solver.cpp:259]     Train net output #0: loss = 0.0495516 (* 1 = 0.0495516 loss)
I0706 08:00:40.344264 22636 solver.cpp:590] Iteration 14575, lr = 0.000776107
I0706 08:01:06.276042 22636 solver.cpp:243] Iteration 14630, loss = 0.00901973
I0706 08:01:06.276067 22636 solver.cpp:259]     Train net output #0: loss = 0.00902015 (* 1 = 0.00902015 loss)
I0706 08:01:06.276074 22636 solver.cpp:590] Iteration 14630, lr = 0.000768657
I0706 08:01:32.176693 22636 solver.cpp:243] Iteration 14685, loss = 0.014841
I0706 08:01:32.176797 22636 solver.cpp:259]     Train net output #0: loss = 0.0148414 (* 1 = 0.0148414 loss)
I0706 08:01:32.176805 22636 solver.cpp:590] Iteration 14685, lr = 0.000761278
I0706 08:01:57.930284 22636 solver.cpp:243] Iteration 14740, loss = 0.0238236
I0706 08:01:57.930306 22636 solver.cpp:259]     Train net output #0: loss = 0.023824 (* 1 = 0.023824 loss)
I0706 08:01:57.930312 22636 solver.cpp:590] Iteration 14740, lr = 0.000753971
I0706 08:02:23.726486 22636 solver.cpp:243] Iteration 14795, loss = 0.00404674
I0706 08:02:23.726575 22636 solver.cpp:259]     Train net output #0: loss = 0.00404718 (* 1 = 0.00404718 loss)
I0706 08:02:23.726589 22636 solver.cpp:590] Iteration 14795, lr = 0.000746733
I0706 08:02:49.563997 22636 solver.cpp:243] Iteration 14850, loss = 0.0775889
I0706 08:02:49.564021 22636 solver.cpp:259]     Train net output #0: loss = 0.0775894 (* 1 = 0.0775894 loss)
I0706 08:02:49.564028 22636 solver.cpp:590] Iteration 14850, lr = 0.000739565
I0706 08:03:15.427057 22636 solver.cpp:243] Iteration 14905, loss = 0.0120966
I0706 08:03:15.427395 22636 solver.cpp:259]     Train net output #0: loss = 0.012097 (* 1 = 0.012097 loss)
I0706 08:03:15.427403 22636 solver.cpp:590] Iteration 14905, lr = 0.000732466
I0706 08:03:41.250773 22636 solver.cpp:243] Iteration 14960, loss = 0.0342549
I0706 08:03:41.250802 22636 solver.cpp:259]     Train net output #0: loss = 0.0342554 (* 1 = 0.0342554 loss)
I0706 08:03:41.250810 22636 solver.cpp:590] Iteration 14960, lr = 0.000725435
I0706 08:03:56.760715 22636 solver.cpp:347] Iteration 14994, Testing net (#0)
I0706 08:04:17.120019 22636 solver.cpp:415]     Test net output #0: accuracy = 0.160817
I0706 08:04:17.120043 22636 solver.cpp:415]     Test net output #1: loss = 6.01024 (* 1 = 6.01024 loss)
I0706 08:04:27.353317 22636 solver.cpp:243] Iteration 15015, loss = 0.0195694
I0706 08:04:27.353409 22636 solver.cpp:259]     Train net output #0: loss = 0.0195698 (* 1 = 0.0195698 loss)
I0706 08:04:27.353415 22636 solver.cpp:590] Iteration 15015, lr = 0.000718472
I0706 08:04:53.201174 22636 solver.cpp:243] Iteration 15070, loss = 0.0278545
I0706 08:04:53.201202 22636 solver.cpp:259]     Train net output #0: loss = 0.0278549 (* 1 = 0.0278549 loss)
I0706 08:04:53.201210 22636 solver.cpp:590] Iteration 15070, lr = 0.000711575
I0706 08:05:19.033294 22636 solver.cpp:243] Iteration 15125, loss = 0.00991435
I0706 08:05:19.033381 22636 solver.cpp:259]     Train net output #0: loss = 0.00991477 (* 1 = 0.00991477 loss)
I0706 08:05:19.033387 22636 solver.cpp:590] Iteration 15125, lr = 0.000704744
I0706 08:05:44.779310 22636 solver.cpp:243] Iteration 15180, loss = 0.00127481
I0706 08:05:44.779336 22636 solver.cpp:259]     Train net output #0: loss = 0.00127522 (* 1 = 0.00127522 loss)
I0706 08:05:44.779342 22636 solver.cpp:590] Iteration 15180, lr = 0.000697979
I0706 08:06:10.577304 22636 solver.cpp:243] Iteration 15235, loss = 0.0135516
I0706 08:06:10.577391 22636 solver.cpp:259]     Train net output #0: loss = 0.013552 (* 1 = 0.013552 loss)
I0706 08:06:10.577409 22636 solver.cpp:590] Iteration 15235, lr = 0.00069128
I0706 08:06:36.420737 22636 solver.cpp:243] Iteration 15290, loss = 0.00941063
I0706 08:06:36.420760 22636 solver.cpp:259]     Train net output #0: loss = 0.00941106 (* 1 = 0.00941106 loss)
I0706 08:06:36.420766 22636 solver.cpp:590] Iteration 15290, lr = 0.000684644
I0706 08:07:02.249275 22636 solver.cpp:243] Iteration 15345, loss = 0.00599313
I0706 08:07:02.249366 22636 solver.cpp:259]     Train net output #0: loss = 0.00599357 (* 1 = 0.00599357 loss)
I0706 08:07:02.249382 22636 solver.cpp:590] Iteration 15345, lr = 0.000678072
I0706 08:07:28.145295 22636 solver.cpp:243] Iteration 15400, loss = 0.0295589
I0706 08:07:28.145319 22636 solver.cpp:259]     Train net output #0: loss = 0.0295593 (* 1 = 0.0295593 loss)
I0706 08:07:28.145325 22636 solver.cpp:590] Iteration 15400, lr = 0.000671563
I0706 08:07:44.058516 22636 solver.cpp:347] Iteration 15435, Testing net (#0)
I0706 08:08:04.285843 22636 solver.cpp:415]     Test net output #0: accuracy = 0.1625
I0706 08:08:04.285871 22636 solver.cpp:415]     Test net output #1: loss = 6.0266 (* 1 = 6.0266 loss)
I0706 08:08:14.068104 22636 solver.cpp:243] Iteration 15455, loss = 0.0218273
I0706 08:08:14.068192 22636 solver.cpp:259]     Train net output #0: loss = 0.0218277 (* 1 = 0.0218277 loss)
I0706 08:08:14.068199 22636 solver.cpp:590] Iteration 15455, lr = 0.000665117
I0706 08:08:39.936944 22636 solver.cpp:243] Iteration 15510, loss = 0.00361905
I0706 08:08:39.936975 22636 solver.cpp:259]     Train net output #0: loss = 0.00361942 (* 1 = 0.00361942 loss)
I0706 08:08:39.936983 22636 solver.cpp:590] Iteration 15510, lr = 0.000658732
I0706 08:09:05.791518 22636 solver.cpp:243] Iteration 15565, loss = 0.0190414
I0706 08:09:05.791596 22636 solver.cpp:259]     Train net output #0: loss = 0.0190417 (* 1 = 0.0190417 loss)
I0706 08:09:05.791604 22636 solver.cpp:590] Iteration 15565, lr = 0.000652409
I0706 08:09:31.641261 22636 solver.cpp:243] Iteration 15620, loss = 0.0217871
I0706 08:09:31.641285 22636 solver.cpp:259]     Train net output #0: loss = 0.0217875 (* 1 = 0.0217875 loss)
I0706 08:09:31.641291 22636 solver.cpp:590] Iteration 15620, lr = 0.000646146
I0706 08:09:57.507709 22636 solver.cpp:243] Iteration 15675, loss = 0.0473926
I0706 08:09:57.507974 22636 solver.cpp:259]     Train net output #0: loss = 0.047393 (* 1 = 0.047393 loss)
I0706 08:09:57.507983 22636 solver.cpp:590] Iteration 15675, lr = 0.000639944
I0706 08:10:23.387442 22636 solver.cpp:243] Iteration 15730, loss = 0.000803716
I0706 08:10:23.387464 22636 solver.cpp:259]     Train net output #0: loss = 0.000804107 (* 1 = 0.000804107 loss)
I0706 08:10:23.387470 22636 solver.cpp:590] Iteration 15730, lr = 0.000633801
I0706 08:10:49.221199 22636 solver.cpp:243] Iteration 15785, loss = 0.0179682
I0706 08:10:49.221740 22636 solver.cpp:259]     Train net output #0: loss = 0.0179686 (* 1 = 0.0179686 loss)
I0706 08:10:49.221748 22636 solver.cpp:590] Iteration 15785, lr = 0.000627717
I0706 08:11:15.063273 22636 solver.cpp:243] Iteration 15840, loss = 0.0716002
I0706 08:11:15.063298 22636 solver.cpp:259]     Train net output #0: loss = 0.0716006 (* 1 = 0.0716006 loss)
I0706 08:11:15.063304 22636 solver.cpp:590] Iteration 15840, lr = 0.000621692
I0706 08:11:31.515652 22636 solver.cpp:347] Iteration 15876, Testing net (#0)
I0706 08:11:51.835897 22636 solver.cpp:415]     Test net output #0: accuracy = 0.159255
I0706 08:11:51.835924 22636 solver.cpp:415]     Test net output #1: loss = 6.0922 (* 1 = 6.0922 loss)
I0706 08:12:01.134316 22636 solver.cpp:243] Iteration 15895, loss = 0.0179669
I0706 08:12:01.134341 22636 solver.cpp:259]     Train net output #0: loss = 0.0179674 (* 1 = 0.0179674 loss)
I0706 08:12:01.134346 22636 solver.cpp:590] Iteration 15895, lr = 0.000615724
I0706 08:12:27.061558 22636 solver.cpp:243] Iteration 15950, loss = 0.0119576
I0706 08:12:27.061688 22636 solver.cpp:259]     Train net output #0: loss = 0.011958 (* 1 = 0.011958 loss)
I0706 08:12:27.061697 22636 solver.cpp:590] Iteration 15950, lr = 0.000609813
I0706 08:12:52.883574 22636 solver.cpp:243] Iteration 16005, loss = 0.00823371
I0706 08:12:52.883594 22636 solver.cpp:259]     Train net output #0: loss = 0.00823413 (* 1 = 0.00823413 loss)
I0706 08:12:52.883600 22636 solver.cpp:590] Iteration 16005, lr = 0.00060396
I0706 08:13:18.761240 22636 solver.cpp:243] Iteration 16060, loss = 0.0225582
I0706 08:13:18.761337 22636 solver.cpp:259]     Train net output #0: loss = 0.0225587 (* 1 = 0.0225587 loss)
I0706 08:13:18.761344 22636 solver.cpp:590] Iteration 16060, lr = 0.000598162
I0706 08:13:44.613908 22636 solver.cpp:243] Iteration 16115, loss = 0.0265891
I0706 08:13:44.613939 22636 solver.cpp:259]     Train net output #0: loss = 0.0265896 (* 1 = 0.0265896 loss)
I0706 08:13:44.613945 22636 solver.cpp:590] Iteration 16115, lr = 0.000592421
I0706 08:14:10.381422 22636 solver.cpp:243] Iteration 16170, loss = 0.043894
I0706 08:14:10.381532 22636 solver.cpp:259]     Train net output #0: loss = 0.0438944 (* 1 = 0.0438944 loss)
I0706 08:14:10.381541 22636 solver.cpp:590] Iteration 16170, lr = 0.000586734
I0706 08:14:36.154602 22636 solver.cpp:243] Iteration 16225, loss = 0.231046
I0706 08:14:36.154624 22636 solver.cpp:259]     Train net output #0: loss = 0.231046 (* 1 = 0.231046 loss)
I0706 08:14:36.154630 22636 solver.cpp:590] Iteration 16225, lr = 0.000581102
I0706 08:15:01.970976 22636 solver.cpp:243] Iteration 16280, loss = 0.0289883
I0706 08:15:01.971060 22636 solver.cpp:259]     Train net output #0: loss = 0.0289887 (* 1 = 0.0289887 loss)
I0706 08:15:01.971068 22636 solver.cpp:590] Iteration 16280, lr = 0.000575524
I0706 08:15:18.874214 22636 solver.cpp:347] Iteration 16317, Testing net (#0)
I0706 08:15:40.475257 22636 solver.cpp:415]     Test net output #0: accuracy = 0.161779
I0706 08:15:40.475389 22636 solver.cpp:415]     Test net output #1: loss = 6.0778 (* 1 = 6.0778 loss)
I0706 08:15:49.307647 22636 solver.cpp:243] Iteration 16335, loss = 0.00577283
I0706 08:15:49.307673 22636 solver.cpp:259]     Train net output #0: loss = 0.00577321 (* 1 = 0.00577321 loss)
I0706 08:15:49.307679 22636 solver.cpp:590] Iteration 16335, lr = 0.000569999
I0706 08:16:15.198914 22636 solver.cpp:243] Iteration 16390, loss = 0.0672036
I0706 08:16:15.199300 22636 solver.cpp:259]     Train net output #0: loss = 0.067204 (* 1 = 0.067204 loss)
I0706 08:16:15.199322 22636 solver.cpp:590] Iteration 16390, lr = 0.000564528
I0706 08:16:41.063918 22636 solver.cpp:243] Iteration 16445, loss = 0.013398
I0706 08:16:41.063943 22636 solver.cpp:259]     Train net output #0: loss = 0.0133984 (* 1 = 0.0133984 loss)
I0706 08:16:41.063949 22636 solver.cpp:590] Iteration 16445, lr = 0.000559109
I0706 08:17:06.805575 22636 solver.cpp:243] Iteration 16500, loss = 0.0326336
I0706 08:17:06.805671 22636 solver.cpp:259]     Train net output #0: loss = 0.032634 (* 1 = 0.032634 loss)
I0706 08:17:06.805680 22636 solver.cpp:590] Iteration 16500, lr = 0.000553742
I0706 08:17:32.607157 22636 solver.cpp:243] Iteration 16555, loss = 0.0468374
I0706 08:17:32.607179 22636 solver.cpp:259]     Train net output #0: loss = 0.0468378 (* 1 = 0.0468378 loss)
I0706 08:17:32.607187 22636 solver.cpp:590] Iteration 16555, lr = 0.000548426
I0706 08:17:58.428514 22636 solver.cpp:243] Iteration 16610, loss = 0.0123345
I0706 08:17:58.428618 22636 solver.cpp:259]     Train net output #0: loss = 0.0123349 (* 1 = 0.0123349 loss)
I0706 08:17:58.428627 22636 solver.cpp:590] Iteration 16610, lr = 0.000543162
I0706 08:18:24.300866 22636 solver.cpp:243] Iteration 16665, loss = 0.00271534
I0706 08:18:24.300891 22636 solver.cpp:259]     Train net output #0: loss = 0.00271576 (* 1 = 0.00271576 loss)
I0706 08:18:24.300899 22636 solver.cpp:590] Iteration 16665, lr = 0.000537948
I0706 08:18:50.109328 22636 solver.cpp:243] Iteration 16720, loss = 0.0140024
I0706 08:18:50.109455 22636 solver.cpp:259]     Train net output #0: loss = 0.0140028 (* 1 = 0.0140028 loss)
I0706 08:18:50.109462 22636 solver.cpp:590] Iteration 16720, lr = 0.000532784
I0706 08:19:07.481411 22636 solver.cpp:347] Iteration 16758, Testing net (#0)
I0706 08:19:28.347447 22636 solver.cpp:415]     Test net output #0: accuracy = 0.163702
I0706 08:19:28.347558 22636 solver.cpp:415]     Test net output #1: loss = 6.13628 (* 1 = 6.13628 loss)
I0706 08:19:36.702735 22636 solver.cpp:243] Iteration 16775, loss = 0.0259162
I0706 08:19:36.702760 22636 solver.cpp:259]     Train net output #0: loss = 0.0259166 (* 1 = 0.0259166 loss)
I0706 08:19:36.702767 22636 solver.cpp:590] Iteration 16775, lr = 0.00052767
I0706 08:20:02.514777 22636 solver.cpp:243] Iteration 16830, loss = 0.00404699
I0706 08:20:02.514868 22636 solver.cpp:259]     Train net output #0: loss = 0.00404744 (* 1 = 0.00404744 loss)
I0706 08:20:02.514876 22636 solver.cpp:590] Iteration 16830, lr = 0.000522605
I0706 08:20:28.342988 22636 solver.cpp:243] Iteration 16885, loss = 0.0314783
I0706 08:20:28.343010 22636 solver.cpp:259]     Train net output #0: loss = 0.0314788 (* 1 = 0.0314788 loss)
I0706 08:20:28.343016 22636 solver.cpp:590] Iteration 16885, lr = 0.000517588
I0706 08:20:54.195189 22636 solver.cpp:243] Iteration 16940, loss = 0.0050892
I0706 08:20:54.195379 22636 solver.cpp:259]     Train net output #0: loss = 0.00508965 (* 1 = 0.00508965 loss)
I0706 08:20:54.195405 22636 solver.cpp:590] Iteration 16940, lr = 0.00051262
I0706 08:21:20.057040 22636 solver.cpp:243] Iteration 16995, loss = 0.0191229
I0706 08:21:20.057065 22636 solver.cpp:259]     Train net output #0: loss = 0.0191233 (* 1 = 0.0191233 loss)
I0706 08:21:20.057071 22636 solver.cpp:590] Iteration 16995, lr = 0.000507699
I0706 08:21:45.817783 22636 solver.cpp:243] Iteration 17050, loss = 0.0125282
I0706 08:21:45.817903 22636 solver.cpp:259]     Train net output #0: loss = 0.0125287 (* 1 = 0.0125287 loss)
I0706 08:21:45.817911 22636 solver.cpp:590] Iteration 17050, lr = 0.000502826
I0706 08:22:11.602655 22636 solver.cpp:243] Iteration 17105, loss = 0.010339
I0706 08:22:11.602680 22636 solver.cpp:259]     Train net output #0: loss = 0.0103394 (* 1 = 0.0103394 loss)
I0706 08:22:11.602687 22636 solver.cpp:590] Iteration 17105, lr = 0.000497999
I0706 08:22:37.398530 22636 solver.cpp:243] Iteration 17160, loss = 0.00172618
I0706 08:22:37.399211 22636 solver.cpp:259]     Train net output #0: loss = 0.00172665 (* 1 = 0.00172665 loss)
I0706 08:22:37.399235 22636 solver.cpp:590] Iteration 17160, lr = 0.000493219
I0706 08:22:55.291484 22636 solver.cpp:347] Iteration 17199, Testing net (#0)
I0706 08:23:15.776981 22636 solver.cpp:415]     Test net output #0: accuracy = 0.16238
I0706 08:23:15.778595 22636 solver.cpp:415]     Test net output #1: loss = 6.1176 (* 1 = 6.1176 loss)
I0706 08:23:23.695334 22636 solver.cpp:243] Iteration 17215, loss = 0.0301187
I0706 08:23:23.695359 22636 solver.cpp:259]     Train net output #0: loss = 0.0301192 (* 1 = 0.0301192 loss)
I0706 08:23:23.695366 22636 solver.cpp:590] Iteration 17215, lr = 0.000488484
I0706 08:23:49.617717 22636 solver.cpp:243] Iteration 17270, loss = 0.050267
I0706 08:23:49.617827 22636 solver.cpp:259]     Train net output #0: loss = 0.0502675 (* 1 = 0.0502675 loss)
I0706 08:23:49.617835 22636 solver.cpp:590] Iteration 17270, lr = 0.000483795
I0706 08:24:15.515152 22636 solver.cpp:243] Iteration 17325, loss = 0.108691
I0706 08:24:15.515172 22636 solver.cpp:259]     Train net output #0: loss = 0.108691 (* 1 = 0.108691 loss)
I0706 08:24:15.515177 22636 solver.cpp:590] Iteration 17325, lr = 0.000479151
I0706 08:24:41.287629 22636 solver.cpp:243] Iteration 17380, loss = 0.00351951
I0706 08:24:41.287749 22636 solver.cpp:259]     Train net output #0: loss = 0.00351997 (* 1 = 0.00351997 loss)
I0706 08:24:41.287756 22636 solver.cpp:590] Iteration 17380, lr = 0.000474552
I0706 08:25:07.087138 22636 solver.cpp:243] Iteration 17435, loss = 0.0368859
I0706 08:25:07.087162 22636 solver.cpp:259]     Train net output #0: loss = 0.0368863 (* 1 = 0.0368863 loss)
I0706 08:25:07.087167 22636 solver.cpp:590] Iteration 17435, lr = 0.000469997
I0706 08:25:32.850039 22636 solver.cpp:243] Iteration 17490, loss = 0.000543451
I0706 08:25:32.850131 22636 solver.cpp:259]     Train net output #0: loss = 0.000543909 (* 1 = 0.000543909 loss)
I0706 08:25:32.850148 22636 solver.cpp:590] Iteration 17490, lr = 0.000465485
I0706 08:25:58.582103 22636 solver.cpp:243] Iteration 17545, loss = 0.095726
I0706 08:25:58.582129 22636 solver.cpp:259]     Train net output #0: loss = 0.0957265 (* 1 = 0.0957265 loss)
I0706 08:25:58.582136 22636 solver.cpp:590] Iteration 17545, lr = 0.000461017
I0706 08:26:24.391654 22636 solver.cpp:243] Iteration 17600, loss = 0.00701033
I0706 08:26:24.391739 22636 solver.cpp:259]     Train net output #0: loss = 0.00701079 (* 1 = 0.00701079 loss)
I0706 08:26:24.391755 22636 solver.cpp:590] Iteration 17600, lr = 0.000456591
I0706 08:26:42.743676 22636 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_17640.caffemodel
I0706 08:27:00.317786 22636 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_17640.solverstate
I0706 08:27:01.884932 22636 solver.cpp:347] Iteration 17640, Testing net (#0)
I0706 08:27:04.957146 22636 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 08:27:23.498729 22636 solver.cpp:415]     Test net output #0: accuracy = 0.162139
I0706 08:27:23.498755 22636 solver.cpp:415]     Test net output #1: loss = 6.09919 (* 1 = 6.09919 loss)
I0706 08:27:30.939208 22636 solver.cpp:243] Iteration 17655, loss = 0.0120162
I0706 08:27:30.939301 22636 solver.cpp:259]     Train net output #0: loss = 0.0120167 (* 1 = 0.0120167 loss)
I0706 08:27:30.939308 22636 solver.cpp:590] Iteration 17655, lr = 0.000452209
I0706 08:27:56.696480 22636 solver.cpp:243] Iteration 17710, loss = 0.0263066
I0706 08:27:56.696503 22636 solver.cpp:259]     Train net output #0: loss = 0.026307 (* 1 = 0.026307 loss)
I0706 08:27:56.696509 22636 solver.cpp:590] Iteration 17710, lr = 0.000447868
I0706 08:28:22.679946 22636 solver.cpp:243] Iteration 17765, loss = 0.0454336
I0706 08:28:22.680059 22636 solver.cpp:259]     Train net output #0: loss = 0.045434 (* 1 = 0.045434 loss)
I0706 08:28:22.680066 22636 solver.cpp:590] Iteration 17765, lr = 0.000443569
I0706 08:28:48.652828 22636 solver.cpp:243] Iteration 17820, loss = 0.0124535
I0706 08:28:48.652853 22636 solver.cpp:259]     Train net output #0: loss = 0.012454 (* 1 = 0.012454 loss)
I0706 08:28:48.652858 22636 solver.cpp:590] Iteration 17820, lr = 0.000439311
I0706 08:29:14.549916 22636 solver.cpp:243] Iteration 17875, loss = 0.00739488
I0706 08:29:14.550238 22636 solver.cpp:259]     Train net output #0: loss = 0.00739532 (* 1 = 0.00739532 loss)
I0706 08:29:14.550247 22636 solver.cpp:590] Iteration 17875, lr = 0.000435094
I0706 08:29:40.327841 22636 solver.cpp:243] Iteration 17930, loss = 0.0204609
I0706 08:29:40.327864 22636 solver.cpp:259]     Train net output #0: loss = 0.0204614 (* 1 = 0.0204614 loss)
I0706 08:29:40.327870 22636 solver.cpp:590] Iteration 17930, lr = 0.000430917
I0706 08:30:06.084259 22636 solver.cpp:243] Iteration 17985, loss = 0.0139475
I0706 08:30:06.084350 22636 solver.cpp:259]     Train net output #0: loss = 0.0139479 (* 1 = 0.0139479 loss)
I0706 08:30:06.084367 22636 solver.cpp:590] Iteration 17985, lr = 0.000426781
I0706 08:30:31.851801 22636 solver.cpp:243] Iteration 18040, loss = 0.0107646
I0706 08:30:31.851824 22636 solver.cpp:259]     Train net output #0: loss = 0.010765 (* 1 = 0.010765 loss)
I0706 08:30:31.851830 22636 solver.cpp:590] Iteration 18040, lr = 0.000422684
I0706 08:30:50.613358 22636 solver.cpp:347] Iteration 18081, Testing net (#0)
I0706 08:31:10.878473 22636 solver.cpp:415]     Test net output #0: accuracy = 0.162019
I0706 08:31:10.878501 22636 solver.cpp:415]     Test net output #1: loss = 6.14068 (* 1 = 6.14068 loss)
I0706 08:31:17.816849 22636 solver.cpp:243] Iteration 18095, loss = 0.0274232
I0706 08:31:17.816870 22636 solver.cpp:259]     Train net output #0: loss = 0.0274237 (* 1 = 0.0274237 loss)
I0706 08:31:17.816877 22636 solver.cpp:590] Iteration 18095, lr = 0.000418627
I0706 08:31:43.580817 22636 solver.cpp:243] Iteration 18150, loss = 0.0190361
I0706 08:31:43.580914 22636 solver.cpp:259]     Train net output #0: loss = 0.0190365 (* 1 = 0.0190365 loss)
I0706 08:31:43.580930 22636 solver.cpp:590] Iteration 18150, lr = 0.000414608
I0706 08:32:09.325907 22636 solver.cpp:243] Iteration 18205, loss = 0.00358153
I0706 08:32:09.325930 22636 solver.cpp:259]     Train net output #0: loss = 0.003582 (* 1 = 0.003582 loss)
I0706 08:32:09.325937 22636 solver.cpp:590] Iteration 18205, lr = 0.000410628
I0706 08:32:35.156710 22636 solver.cpp:243] Iteration 18260, loss = 0.00310657
I0706 08:32:35.156805 22636 solver.cpp:259]     Train net output #0: loss = 0.00310705 (* 1 = 0.00310705 loss)
I0706 08:32:35.156812 22636 solver.cpp:590] Iteration 18260, lr = 0.000406687
I0706 08:33:00.980988 22636 solver.cpp:243] Iteration 18315, loss = 0.00359399
I0706 08:33:00.981011 22636 solver.cpp:259]     Train net output #0: loss = 0.00359448 (* 1 = 0.00359448 loss)
I0706 08:33:00.981016 22636 solver.cpp:590] Iteration 18315, lr = 0.000402783
I0706 08:33:26.861507 22636 solver.cpp:243] Iteration 18370, loss = 0.00104715
I0706 08:33:26.861649 22636 solver.cpp:259]     Train net output #0: loss = 0.00104764 (* 1 = 0.00104764 loss)
I0706 08:33:26.861667 22636 solver.cpp:590] Iteration 18370, lr = 0.000398917
I0706 08:33:52.689015 22636 solver.cpp:243] Iteration 18425, loss = 0.0799277
I0706 08:33:52.689041 22636 solver.cpp:259]     Train net output #0: loss = 0.0799282 (* 1 = 0.0799282 loss)
I0706 08:33:52.689046 22636 solver.cpp:590] Iteration 18425, lr = 0.000395087
I0706 08:34:18.495812 22636 solver.cpp:243] Iteration 18480, loss = 0.00359769
I0706 08:34:18.495903 22636 solver.cpp:259]     Train net output #0: loss = 0.00359817 (* 1 = 0.00359817 loss)
I0706 08:34:18.495919 22636 solver.cpp:590] Iteration 18480, lr = 0.000391295
I0706 08:34:37.797287 22636 solver.cpp:347] Iteration 18522, Testing net (#0)
I0706 08:34:58.444582 22636 solver.cpp:415]     Test net output #0: accuracy = 0.16226
I0706 08:34:58.444730 22636 solver.cpp:415]     Test net output #1: loss = 6.09862 (* 1 = 6.09862 loss)
I0706 08:35:04.942590 22636 solver.cpp:243] Iteration 18535, loss = 0.0150056
I0706 08:35:04.942615 22636 solver.cpp:259]     Train net output #0: loss = 0.0150061 (* 1 = 0.0150061 loss)
I0706 08:35:04.942622 22636 solver.cpp:590] Iteration 18535, lr = 0.000387539
I0706 08:35:30.708593 22636 solver.cpp:243] Iteration 18590, loss = 0.019297
I0706 08:35:30.774580 22636 solver.cpp:259]     Train net output #0: loss = 0.0192975 (* 1 = 0.0192975 loss)
I0706 08:35:30.774592 22636 solver.cpp:590] Iteration 18590, lr = 0.000383819
I0706 08:35:56.611161 22636 solver.cpp:243] Iteration 18645, loss = 0.0238554
I0706 08:35:56.611186 22636 solver.cpp:259]     Train net output #0: loss = 0.0238559 (* 1 = 0.0238559 loss)
I0706 08:35:56.611192 22636 solver.cpp:590] Iteration 18645, lr = 0.000380134
I0706 08:36:22.406955 22636 solver.cpp:243] Iteration 18700, loss = 0.0115415
I0706 08:36:22.407042 22636 solver.cpp:259]     Train net output #0: loss = 0.0115419 (* 1 = 0.0115419 loss)
I0706 08:36:22.407058 22636 solver.cpp:590] Iteration 18700, lr = 0.000376485
I0706 08:36:48.237537 22636 solver.cpp:243] Iteration 18755, loss = 0.00201971
I0706 08:36:48.237561 22636 solver.cpp:259]     Train net output #0: loss = 0.0020202 (* 1 = 0.0020202 loss)
I0706 08:36:48.237567 22636 solver.cpp:590] Iteration 18755, lr = 0.000372872
I0706 08:37:14.100600 22636 solver.cpp:243] Iteration 18810, loss = 0.00106972
I0706 08:37:14.100649 22636 solver.cpp:259]     Train net output #0: loss = 0.00107019 (* 1 = 0.00107019 loss)
I0706 08:37:14.100656 22636 solver.cpp:590] Iteration 18810, lr = 0.000369292
I0706 08:37:39.948621 22636 solver.cpp:243] Iteration 18865, loss = 0.00195051
I0706 08:37:39.948647 22636 solver.cpp:259]     Train net output #0: loss = 0.00195097 (* 1 = 0.00195097 loss)
I0706 08:37:39.948652 22636 solver.cpp:590] Iteration 18865, lr = 0.000365747
I0706 08:38:05.842852 22636 solver.cpp:243] Iteration 18920, loss = 0.137175
I0706 08:38:05.842938 22636 solver.cpp:259]     Train net output #0: loss = 0.137176 (* 1 = 0.137176 loss)
I0706 08:38:05.842944 22636 solver.cpp:590] Iteration 18920, lr = 0.000362237
I0706 08:38:25.606959 22636 solver.cpp:347] Iteration 18963, Testing net (#0)
I0706 08:38:45.889292 22636 solver.cpp:415]     Test net output #0: accuracy = 0.161659
I0706 08:38:45.889371 22636 solver.cpp:415]     Test net output #1: loss = 6.10524 (* 1 = 6.10524 loss)
I0706 08:38:51.913616 22636 solver.cpp:243] Iteration 18975, loss = 0.015276
I0706 08:38:51.913640 22636 solver.cpp:259]     Train net output #0: loss = 0.0152764 (* 1 = 0.0152764 loss)
I0706 08:38:51.913645 22636 solver.cpp:590] Iteration 18975, lr = 0.000358759
I0706 08:39:17.830951 22636 solver.cpp:243] Iteration 19030, loss = 0.00696701
I0706 08:39:17.831039 22636 solver.cpp:259]     Train net output #0: loss = 0.00696747 (* 1 = 0.00696747 loss)
I0706 08:39:17.831056 22636 solver.cpp:590] Iteration 19030, lr = 0.000355316
I0706 08:39:43.623958 22636 solver.cpp:243] Iteration 19085, loss = 0.00173874
I0706 08:39:43.623982 22636 solver.cpp:259]     Train net output #0: loss = 0.00173919 (* 1 = 0.00173919 loss)
I0706 08:39:43.623989 22636 solver.cpp:590] Iteration 19085, lr = 0.000351905
I0706 08:40:09.464375 22636 solver.cpp:243] Iteration 19140, loss = 0.00395826
I0706 08:40:09.464469 22636 solver.cpp:259]     Train net output #0: loss = 0.0039587 (* 1 = 0.0039587 loss)
I0706 08:40:09.464476 22636 solver.cpp:590] Iteration 19140, lr = 0.000348527
I0706 08:40:35.329774 22636 solver.cpp:243] Iteration 19195, loss = 0.0037072
I0706 08:40:35.329799 22636 solver.cpp:259]     Train net output #0: loss = 0.00370764 (* 1 = 0.00370764 loss)
I0706 08:40:35.329807 22636 solver.cpp:590] Iteration 19195, lr = 0.000345181
I0706 08:41:01.217697 22636 solver.cpp:243] Iteration 19250, loss = 0.00650828
I0706 08:41:01.217780 22636 solver.cpp:259]     Train net output #0: loss = 0.00650874 (* 1 = 0.00650874 loss)
I0706 08:41:01.217788 22636 solver.cpp:590] Iteration 19250, lr = 0.000341868
I0706 08:41:27.009327 22636 solver.cpp:243] Iteration 19305, loss = 0.0024462
I0706 08:41:27.009353 22636 solver.cpp:259]     Train net output #0: loss = 0.00244666 (* 1 = 0.00244666 loss)
I0706 08:41:27.009359 22636 solver.cpp:590] Iteration 19305, lr = 0.000338586
I0706 08:41:52.762881 22636 solver.cpp:243] Iteration 19360, loss = 0.00798683
I0706 08:41:52.763439 22636 solver.cpp:259]     Train net output #0: loss = 0.0079873 (* 1 = 0.0079873 loss)
I0706 08:41:52.763447 22636 solver.cpp:590] Iteration 19360, lr = 0.000335336
I0706 08:42:13.009500 22636 solver.cpp:347] Iteration 19404, Testing net (#0)
I0706 08:42:33.140473 22636 solver.cpp:415]     Test net output #0: accuracy = 0.16238
I0706 08:42:33.142138 22636 solver.cpp:415]     Test net output #1: loss = 6.06077 (* 1 = 6.06077 loss)
I0706 08:42:38.687502 22636 solver.cpp:243] Iteration 19415, loss = 0.0253516
I0706 08:42:38.687526 22636 solver.cpp:259]     Train net output #0: loss = 0.0253521 (* 1 = 0.0253521 loss)
I0706 08:42:38.687533 22636 solver.cpp:590] Iteration 19415, lr = 0.000332117
I0706 08:43:04.508297 22636 solver.cpp:243] Iteration 19470, loss = 0.00348431
I0706 08:43:04.508522 22636 solver.cpp:259]     Train net output #0: loss = 0.00348483 (* 1 = 0.00348483 loss)
I0706 08:43:04.508529 22636 solver.cpp:590] Iteration 19470, lr = 0.000328929
I0706 08:43:30.365046 22636 solver.cpp:243] Iteration 19525, loss = 0.00105959
I0706 08:43:30.365069 22636 solver.cpp:259]     Train net output #0: loss = 0.00106011 (* 1 = 0.00106011 loss)
I0706 08:43:30.365075 22636 solver.cpp:590] Iteration 19525, lr = 0.000325772
I0706 08:43:56.237829 22636 solver.cpp:243] Iteration 19580, loss = 0.0138647
I0706 08:43:56.237921 22636 solver.cpp:259]     Train net output #0: loss = 0.0138652 (* 1 = 0.0138652 loss)
I0706 08:43:56.237931 22636 solver.cpp:590] Iteration 19580, lr = 0.000322645
I0706 08:44:22.101485 22636 solver.cpp:243] Iteration 19635, loss = 0.000991113
I0706 08:44:22.101510 22636 solver.cpp:259]     Train net output #0: loss = 0.000991647 (* 1 = 0.000991647 loss)
I0706 08:44:22.101516 22636 solver.cpp:590] Iteration 19635, lr = 0.000319548
I0706 08:44:48.011292 22636 solver.cpp:243] Iteration 19690, loss = 0.00990326
I0706 08:44:48.011371 22636 solver.cpp:259]     Train net output #0: loss = 0.0099038 (* 1 = 0.0099038 loss)
I0706 08:44:48.011387 22636 solver.cpp:590] Iteration 19690, lr = 0.00031648
I0706 08:45:13.918087 22636 solver.cpp:243] Iteration 19745, loss = 0.0190364
I0706 08:45:13.918115 22636 solver.cpp:259]     Train net output #0: loss = 0.0190369 (* 1 = 0.0190369 loss)
I0706 08:45:13.918123 22636 solver.cpp:590] Iteration 19745, lr = 0.000313442
I0706 08:45:39.689908 22636 solver.cpp:243] Iteration 19800, loss = 0.0144719
I0706 08:45:39.689997 22636 solver.cpp:259]     Train net output #0: loss = 0.0144724 (* 1 = 0.0144724 loss)
I0706 08:45:39.690012 22636 solver.cpp:590] Iteration 19800, lr = 0.000310434
I0706 08:46:00.332571 22636 solver.cpp:347] Iteration 19845, Testing net (#0)
I0706 08:46:20.538367 22636 solver.cpp:415]     Test net output #0: accuracy = 0.164663
I0706 08:46:20.538466 22636 solver.cpp:415]     Test net output #1: loss = 6.10052 (* 1 = 6.10052 loss)
I0706 08:46:25.615716 22636 solver.cpp:243] Iteration 19855, loss = 0.00825522
I0706 08:46:25.615739 22636 solver.cpp:259]     Train net output #0: loss = 0.00825576 (* 1 = 0.00825576 loss)
I0706 08:46:25.615746 22636 solver.cpp:590] Iteration 19855, lr = 0.000307454
I0706 08:46:51.446431 22636 solver.cpp:243] Iteration 19910, loss = 0.00253565
I0706 08:46:51.446522 22636 solver.cpp:259]     Train net output #0: loss = 0.00253619 (* 1 = 0.00253619 loss)
I0706 08:46:51.446530 22636 solver.cpp:590] Iteration 19910, lr = 0.000304502
I0706 08:47:17.218387 22636 solver.cpp:243] Iteration 19965, loss = 0.00677202
I0706 08:47:17.218410 22636 solver.cpp:259]     Train net output #0: loss = 0.00677256 (* 1 = 0.00677256 loss)
I0706 08:47:17.218415 22636 solver.cpp:590] Iteration 19965, lr = 0.000301579
I0706 08:47:43.010865 22636 solver.cpp:243] Iteration 20020, loss = 0.00171127
I0706 08:47:43.010978 22636 solver.cpp:259]     Train net output #0: loss = 0.00171181 (* 1 = 0.00171181 loss)
I0706 08:47:43.010995 22636 solver.cpp:590] Iteration 20020, lr = 0.000298685
I0706 08:48:08.827035 22636 solver.cpp:243] Iteration 20075, loss = 0.0236287
I0706 08:48:08.827059 22636 solver.cpp:259]     Train net output #0: loss = 0.0236292 (* 1 = 0.0236292 loss)
I0706 08:48:08.827066 22636 solver.cpp:590] Iteration 20075, lr = 0.000295817
I0706 08:48:34.640370 22636 solver.cpp:243] Iteration 20130, loss = 0.00737083
I0706 08:48:34.640686 22636 solver.cpp:259]     Train net output #0: loss = 0.00737134 (* 1 = 0.00737134 loss)
I0706 08:48:34.640693 22636 solver.cpp:590] Iteration 20130, lr = 0.000292978
I0706 08:49:00.475504 22636 solver.cpp:243] Iteration 20185, loss = 0.0295087
I0706 08:49:00.475531 22636 solver.cpp:259]     Train net output #0: loss = 0.0295092 (* 1 = 0.0295092 loss)
I0706 08:49:00.475538 22636 solver.cpp:590] Iteration 20185, lr = 0.000290166
I0706 08:49:26.238252 22636 solver.cpp:243] Iteration 20240, loss = 0.0342889
I0706 08:49:26.238589 22636 solver.cpp:259]     Train net output #0: loss = 0.0342894 (* 1 = 0.0342894 loss)
I0706 08:49:26.238597 22636 solver.cpp:590] Iteration 20240, lr = 0.00028738
I0706 08:49:47.378504 22636 solver.cpp:347] Iteration 20286, Testing net (#0)
I0706 08:50:07.701246 22636 solver.cpp:415]     Test net output #0: accuracy = 0.161659
I0706 08:50:07.701458 22636 solver.cpp:415]     Test net output #1: loss = 6.11403 (* 1 = 6.11403 loss)
I0706 08:50:12.332590 22636 solver.cpp:243] Iteration 20295, loss = 0.0408962
I0706 08:50:12.332613 22636 solver.cpp:259]     Train net output #0: loss = 0.0408967 (* 1 = 0.0408967 loss)
I0706 08:50:12.332620 22636 solver.cpp:590] Iteration 20295, lr = 0.000284622
I0706 08:50:38.102540 22636 solver.cpp:243] Iteration 20350, loss = 0.0815496
I0706 08:50:38.102860 22636 solver.cpp:259]     Train net output #0: loss = 0.08155 (* 1 = 0.08155 loss)
I0706 08:50:38.102869 22636 solver.cpp:590] Iteration 20350, lr = 0.00028189
I0706 08:51:03.965040 22636 solver.cpp:243] Iteration 20405, loss = 0.00137093
I0706 08:51:03.965065 22636 solver.cpp:259]     Train net output #0: loss = 0.0013714 (* 1 = 0.0013714 loss)
I0706 08:51:03.965071 22636 solver.cpp:590] Iteration 20405, lr = 0.000279184
I0706 08:51:29.795578 22636 solver.cpp:243] Iteration 20460, loss = 0.0396842
I0706 08:51:29.795666 22636 solver.cpp:259]     Train net output #0: loss = 0.0396847 (* 1 = 0.0396847 loss)
I0706 08:51:29.795672 22636 solver.cpp:590] Iteration 20460, lr = 0.000276504
I0706 08:51:55.558233 22636 solver.cpp:243] Iteration 20515, loss = 0.0481715
I0706 08:51:55.558264 22636 solver.cpp:259]     Train net output #0: loss = 0.048172 (* 1 = 0.048172 loss)
I0706 08:51:55.558270 22636 solver.cpp:590] Iteration 20515, lr = 0.00027385
I0706 08:52:21.523459 22636 solver.cpp:243] Iteration 20570, loss = 0.0950359
I0706 08:52:21.523545 22636 solver.cpp:259]     Train net output #0: loss = 0.0950364 (* 1 = 0.0950364 loss)
I0706 08:52:21.523561 22636 solver.cpp:590] Iteration 20570, lr = 0.000271221
I0706 08:52:47.353390 22636 solver.cpp:243] Iteration 20625, loss = 0.00124477
I0706 08:52:47.353415 22636 solver.cpp:259]     Train net output #0: loss = 0.00124527 (* 1 = 0.00124527 loss)
I0706 08:52:47.353421 22636 solver.cpp:590] Iteration 20625, lr = 0.000268617
I0706 08:53:13.183217 22636 solver.cpp:243] Iteration 20680, loss = 0.0303699
I0706 08:53:13.183349 22636 solver.cpp:259]     Train net output #0: loss = 0.0303704 (* 1 = 0.0303704 loss)
I0706 08:53:13.183357 22636 solver.cpp:590] Iteration 20680, lr = 0.000266039
I0706 08:53:34.775300 22636 solver.cpp:347] Iteration 20727, Testing net (#0)
I0706 08:53:55.139000 22636 solver.cpp:415]     Test net output #0: accuracy = 0.163582
I0706 08:53:55.139106 22636 solver.cpp:415]     Test net output #1: loss = 6.06467 (* 1 = 6.06467 loss)
I0706 08:53:59.285046 22636 solver.cpp:243] Iteration 20735, loss = 0.0909261
I0706 08:53:59.285068 22636 solver.cpp:259]     Train net output #0: loss = 0.0909266 (* 1 = 0.0909266 loss)
I0706 08:53:59.285074 22636 solver.cpp:590] Iteration 20735, lr = 0.000263485
I0706 08:54:25.117332 22636 solver.cpp:243] Iteration 20790, loss = 0.0555871
I0706 08:54:25.117357 22636 solver.cpp:259]     Train net output #0: loss = 0.0555876 (* 1 = 0.0555876 loss)
I0706 08:54:25.117362 22636 solver.cpp:590] Iteration 20790, lr = 0.000260956
I0706 08:54:50.947980 22636 solver.cpp:243] Iteration 20845, loss = 0.00778295
I0706 08:54:50.948120 22636 solver.cpp:259]     Train net output #0: loss = 0.00778347 (* 1 = 0.00778347 loss)
I0706 08:54:50.948128 22636 solver.cpp:590] Iteration 20845, lr = 0.000258451
I0706 08:55:16.702745 22636 solver.cpp:243] Iteration 20900, loss = 0.0888538
I0706 08:55:16.702770 22636 solver.cpp:259]     Train net output #0: loss = 0.0888543 (* 1 = 0.0888543 loss)
I0706 08:55:16.702776 22636 solver.cpp:590] Iteration 20900, lr = 0.00025597
I0706 08:55:42.516863 22636 solver.cpp:243] Iteration 20955, loss = 0.0138617
I0706 08:55:42.517216 22636 solver.cpp:259]     Train net output #0: loss = 0.0138623 (* 1 = 0.0138623 loss)
I0706 08:55:42.517235 22636 solver.cpp:590] Iteration 20955, lr = 0.000253513
I0706 08:56:08.504935 22636 solver.cpp:243] Iteration 21010, loss = 0.00684739
I0706 08:56:08.504956 22636 solver.cpp:259]     Train net output #0: loss = 0.00684793 (* 1 = 0.00684793 loss)
I0706 08:56:08.504962 22636 solver.cpp:590] Iteration 21010, lr = 0.000251079
I0706 08:56:34.358151 22636 solver.cpp:243] Iteration 21065, loss = 0.0017611
I0706 08:56:34.358441 22636 solver.cpp:259]     Train net output #0: loss = 0.00176166 (* 1 = 0.00176166 loss)
I0706 08:56:34.358459 22636 solver.cpp:590] Iteration 21065, lr = 0.000248669
I0706 08:57:00.224489 22636 solver.cpp:243] Iteration 21120, loss = 0.00189847
I0706 08:57:00.224519 22636 solver.cpp:259]     Train net output #0: loss = 0.00189902 (* 1 = 0.00189902 loss)
I0706 08:57:00.224526 22636 solver.cpp:590] Iteration 21120, lr = 0.000246282
I0706 08:57:22.295722 22636 solver.cpp:347] Iteration 21168, Testing net (#0)
I0706 08:57:24.933205 22636 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 08:57:42.554229 22636 solver.cpp:415]     Test net output #0: accuracy = 0.161779
I0706 08:57:42.554250 22636 solver.cpp:415]     Test net output #1: loss = 6.08051 (* 1 = 6.08051 loss)
I0706 08:57:46.236394 22636 solver.cpp:243] Iteration 21175, loss = 0.00234528
I0706 08:57:46.236416 22636 solver.cpp:259]     Train net output #0: loss = 0.00234582 (* 1 = 0.00234582 loss)
I0706 08:57:46.236423 22636 solver.cpp:590] Iteration 21175, lr = 0.000243918
I0706 08:58:12.073535 22636 solver.cpp:243] Iteration 21230, loss = 0.00472827
I0706 08:58:12.073858 22636 solver.cpp:259]     Train net output #0: loss = 0.0047288 (* 1 = 0.0047288 loss)
I0706 08:58:12.073866 22636 solver.cpp:590] Iteration 21230, lr = 0.000241577
I0706 08:58:37.968026 22636 solver.cpp:243] Iteration 21285, loss = 0.00477937
I0706 08:58:37.968049 22636 solver.cpp:259]     Train net output #0: loss = 0.00477989 (* 1 = 0.00477989 loss)
I0706 08:58:37.968055 22636 solver.cpp:590] Iteration 21285, lr = 0.000239258
I0706 08:59:03.733340 22636 solver.cpp:243] Iteration 21340, loss = 0.00534176
I0706 08:59:03.733573 22636 solver.cpp:259]     Train net output #0: loss = 0.00534229 (* 1 = 0.00534229 loss)
I0706 08:59:03.733582 22636 solver.cpp:590] Iteration 21340, lr = 0.000236961
I0706 08:59:29.555677 22636 solver.cpp:243] Iteration 21395, loss = 0.106246
I0706 08:59:29.555702 22636 solver.cpp:259]     Train net output #0: loss = 0.106246 (* 1 = 0.106246 loss)
I0706 08:59:29.555709 22636 solver.cpp:590] Iteration 21395, lr = 0.000234687
I0706 08:59:55.384352 22636 solver.cpp:243] Iteration 21450, loss = 0.023223
I0706 08:59:55.384716 22636 solver.cpp:259]     Train net output #0: loss = 0.0232235 (* 1 = 0.0232235 loss)
I0706 08:59:55.384726 22636 solver.cpp:590] Iteration 21450, lr = 0.000232434
I0706 09:00:21.255911 22636 solver.cpp:243] Iteration 21505, loss = 0.0126268
I0706 09:00:21.255935 22636 solver.cpp:259]     Train net output #0: loss = 0.0126273 (* 1 = 0.0126273 loss)
I0706 09:00:21.255942 22636 solver.cpp:590] Iteration 21505, lr = 0.000230203
I0706 09:00:47.084746 22636 solver.cpp:243] Iteration 21560, loss = 0.0565449
I0706 09:00:47.085186 22636 solver.cpp:259]     Train net output #0: loss = 0.0565455 (* 1 = 0.0565455 loss)
I0706 09:00:47.085196 22636 solver.cpp:590] Iteration 21560, lr = 0.000227993
I0706 09:01:09.681715 22636 solver.cpp:347] Iteration 21609, Testing net (#0)
I0706 09:01:29.996778 22636 solver.cpp:415]     Test net output #0: accuracy = 0.161899
I0706 09:01:29.997021 22636 solver.cpp:415]     Test net output #1: loss = 6.08543 (* 1 = 6.08543 loss)
I0706 09:01:33.215236 22636 solver.cpp:243] Iteration 21615, loss = 0.00200827
I0706 09:01:33.215256 22636 solver.cpp:259]     Train net output #0: loss = 0.00200886 (* 1 = 0.00200886 loss)
I0706 09:01:33.215262 22636 solver.cpp:590] Iteration 21615, lr = 0.000225804
I0706 09:01:59.095948 22636 solver.cpp:243] Iteration 21670, loss = 0.00421875
I0706 09:01:59.095974 22636 solver.cpp:259]     Train net output #0: loss = 0.00421935 (* 1 = 0.00421935 loss)
I0706 09:01:59.095981 22636 solver.cpp:590] Iteration 21670, lr = 0.000223637
I0706 09:02:24.891392 22636 solver.cpp:243] Iteration 21725, loss = 0.00337067
I0706 09:02:24.891791 22636 solver.cpp:259]     Train net output #0: loss = 0.00337126 (* 1 = 0.00337126 loss)
I0706 09:02:24.891800 22636 solver.cpp:590] Iteration 21725, lr = 0.00022149
I0706 09:02:50.708063 22636 solver.cpp:243] Iteration 21780, loss = 5.76973e-05
I0706 09:02:50.708089 22636 solver.cpp:259]     Train net output #0: loss = 5.82855e-05 (* 1 = 5.82855e-05 loss)
I0706 09:02:50.708096 22636 solver.cpp:590] Iteration 21780, lr = 0.000219364
I0706 09:03:16.535604 22636 solver.cpp:243] Iteration 21835, loss = 0.00642202
I0706 09:03:16.537253 22636 solver.cpp:259]     Train net output #0: loss = 0.0064226 (* 1 = 0.0064226 loss)
I0706 09:03:16.537263 22636 solver.cpp:590] Iteration 21835, lr = 0.000217258
I0706 09:03:42.474753 22636 solver.cpp:243] Iteration 21890, loss = 0.0122724
I0706 09:03:42.474778 22636 solver.cpp:259]     Train net output #0: loss = 0.012273 (* 1 = 0.012273 loss)
I0706 09:03:42.474786 22636 solver.cpp:590] Iteration 21890, lr = 0.000215173
I0706 09:04:08.433612 22636 solver.cpp:243] Iteration 21945, loss = 0.00072119
I0706 09:04:08.433902 22636 solver.cpp:259]     Train net output #0: loss = 0.000721781 (* 1 = 0.000721781 loss)
I0706 09:04:08.433909 22636 solver.cpp:590] Iteration 21945, lr = 0.000213107
I0706 09:04:34.295269 22636 solver.cpp:243] Iteration 22000, loss = 0.0250276
I0706 09:04:34.295295 22636 solver.cpp:259]     Train net output #0: loss = 0.0250282 (* 1 = 0.0250282 loss)
I0706 09:04:34.295301 22636 solver.cpp:590] Iteration 22000, lr = 0.000211062
I0706 09:04:57.301581 22636 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_22050.caffemodel
I0706 09:05:04.786659 22636 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_22050.solverstate
I0706 09:05:06.320112 22636 solver.cpp:347] Iteration 22050, Testing net (#0)
I0706 09:05:26.721966 22636 solver.cpp:415]     Test net output #0: accuracy = 0.161779
I0706 09:05:26.722005 22636 solver.cpp:415]     Test net output #1: loss = 6.07106 (* 1 = 6.07106 loss)
I0706 09:05:29.447101 22636 solver.cpp:243] Iteration 22055, loss = 0.0047487
I0706 09:05:29.447474 22636 solver.cpp:259]     Train net output #0: loss = 0.00474928 (* 1 = 0.00474928 loss)
I0706 09:05:29.447482 22636 solver.cpp:590] Iteration 22055, lr = 0.000209036
I0706 09:05:55.224027 22636 solver.cpp:243] Iteration 22110, loss = 0.00815891
I0706 09:05:55.224047 22636 solver.cpp:259]     Train net output #0: loss = 0.00815949 (* 1 = 0.00815949 loss)
I0706 09:05:55.224053 22636 solver.cpp:590] Iteration 22110, lr = 0.000207029
I0706 09:06:21.007344 22636 solver.cpp:243] Iteration 22165, loss = 0.00292601
I0706 09:06:21.007437 22636 solver.cpp:259]     Train net output #0: loss = 0.00292659 (* 1 = 0.00292659 loss)
I0706 09:06:21.007453 22636 solver.cpp:590] Iteration 22165, lr = 0.000205042
I0706 09:06:46.845676 22636 solver.cpp:243] Iteration 22220, loss = 0.0145286
I0706 09:06:46.845707 22636 solver.cpp:259]     Train net output #0: loss = 0.0145291 (* 1 = 0.0145291 loss)
I0706 09:06:46.845716 22636 solver.cpp:590] Iteration 22220, lr = 0.000203074
I0706 09:07:12.708259 22636 solver.cpp:243] Iteration 22275, loss = 0.234554
I0706 09:07:12.708369 22636 solver.cpp:259]     Train net output #0: loss = 0.234555 (* 1 = 0.234555 loss)
I0706 09:07:12.708385 22636 solver.cpp:590] Iteration 22275, lr = 0.000201124
I0706 09:07:38.510684 22636 solver.cpp:243] Iteration 22330, loss = 0.0323709
I0706 09:07:38.510707 22636 solver.cpp:259]     Train net output #0: loss = 0.0323714 (* 1 = 0.0323714 loss)
I0706 09:07:38.510715 22636 solver.cpp:590] Iteration 22330, lr = 0.000199194
I0706 09:08:04.256427 22636 solver.cpp:243] Iteration 22385, loss = 0.00392625
I0706 09:08:04.256762 22636 solver.cpp:259]     Train net output #0: loss = 0.00392683 (* 1 = 0.00392683 loss)
I0706 09:08:04.256770 22636 solver.cpp:590] Iteration 22385, lr = 0.000197282
I0706 09:08:30.017885 22636 solver.cpp:243] Iteration 22440, loss = 0.0380471
I0706 09:08:30.017910 22636 solver.cpp:259]     Train net output #0: loss = 0.0380477 (* 1 = 0.0380477 loss)
I0706 09:08:30.017916 22636 solver.cpp:590] Iteration 22440, lr = 0.000195388
I0706 09:08:53.515096 22636 solver.cpp:347] Iteration 22491, Testing net (#0)
I0706 09:09:13.773450 22636 solver.cpp:415]     Test net output #0: accuracy = 0.162981
I0706 09:09:13.773476 22636 solver.cpp:415]     Test net output #1: loss = 6.09148 (* 1 = 6.09148 loss)
I0706 09:09:16.032272 22636 solver.cpp:243] Iteration 22495, loss = 0.000695165
I0706 09:09:16.032296 22636 solver.cpp:259]     Train net output #0: loss = 0.000695764 (* 1 = 0.000695764 loss)
I0706 09:09:16.032302 22636 solver.cpp:590] Iteration 22495, lr = 0.000193512
I0706 09:09:41.747584 22636 solver.cpp:243] Iteration 22550, loss = 0.0193827
I0706 09:09:41.747676 22636 solver.cpp:259]     Train net output #0: loss = 0.0193833 (* 1 = 0.0193833 loss)
I0706 09:09:41.747684 22636 solver.cpp:590] Iteration 22550, lr = 0.000191655
I0706 09:10:07.532045 22636 solver.cpp:243] Iteration 22605, loss = 0.000736056
I0706 09:10:07.532068 22636 solver.cpp:259]     Train net output #0: loss = 0.000736665 (* 1 = 0.000736665 loss)
I0706 09:10:07.532074 22636 solver.cpp:590] Iteration 22605, lr = 0.000189815
I0706 09:10:33.408651 22636 solver.cpp:243] Iteration 22660, loss = 0.00687842
I0706 09:10:33.408735 22636 solver.cpp:259]     Train net output #0: loss = 0.00687903 (* 1 = 0.00687903 loss)
I0706 09:10:33.408752 22636 solver.cpp:590] Iteration 22660, lr = 0.000187993
I0706 09:10:59.185457 22636 solver.cpp:243] Iteration 22715, loss = 0.0240622
I0706 09:10:59.185480 22636 solver.cpp:259]     Train net output #0: loss = 0.0240628 (* 1 = 0.0240628 loss)
I0706 09:10:59.185487 22636 solver.cpp:590] Iteration 22715, lr = 0.000186189
I0706 09:11:25.008534 22636 solver.cpp:243] Iteration 22770, loss = 0.00401017
I0706 09:11:25.008616 22636 solver.cpp:259]     Train net output #0: loss = 0.00401078 (* 1 = 0.00401078 loss)
I0706 09:11:25.008623 22636 solver.cpp:590] Iteration 22770, lr = 0.000184401
I0706 09:11:50.782008 22636 solver.cpp:243] Iteration 22825, loss = 0.00255205
I0706 09:11:50.782033 22636 solver.cpp:259]     Train net output #0: loss = 0.00255265 (* 1 = 0.00255265 loss)
I0706 09:11:50.782040 22636 solver.cpp:590] Iteration 22825, lr = 0.000182631
I0706 09:12:16.601755 22636 solver.cpp:243] Iteration 22880, loss = 0.10292
I0706 09:12:16.601847 22636 solver.cpp:259]     Train net output #0: loss = 0.10292 (* 1 = 0.10292 loss)
I0706 09:12:16.601863 22636 solver.cpp:590] Iteration 22880, lr = 0.000180878
I0706 09:12:40.503159 22636 solver.cpp:347] Iteration 22932, Testing net (#0)
I0706 09:13:00.772260 22636 solver.cpp:415]     Test net output #0: accuracy = 0.163462
I0706 09:13:00.772377 22636 solver.cpp:415]     Test net output #1: loss = 6.08309 (* 1 = 6.08309 loss)
I0706 09:13:02.561969 22636 solver.cpp:243] Iteration 22935, loss = 0.00658926
I0706 09:13:02.561992 22636 solver.cpp:259]     Train net output #0: loss = 0.00658986 (* 1 = 0.00658986 loss)
I0706 09:13:02.561998 22636 solver.cpp:590] Iteration 22935, lr = 0.000179142
I0706 09:13:28.274710 22636 solver.cpp:243] Iteration 22990, loss = 0.0128802
I0706 09:13:28.274735 22636 solver.cpp:259]     Train net output #0: loss = 0.0128808 (* 1 = 0.0128808 loss)
I0706 09:13:28.274741 22636 solver.cpp:590] Iteration 22990, lr = 0.000177422
I0706 09:13:54.040228 22636 solver.cpp:243] Iteration 23045, loss = 0.0166791
I0706 09:13:54.040336 22636 solver.cpp:259]     Train net output #0: loss = 0.0166797 (* 1 = 0.0166797 loss)
I0706 09:13:54.040354 22636 solver.cpp:590] Iteration 23045, lr = 0.000175719
I0706 09:14:19.802608 22636 solver.cpp:243] Iteration 23100, loss = 0.00544322
I0706 09:14:19.802634 22636 solver.cpp:259]     Train net output #0: loss = 0.00544379 (* 1 = 0.00544379 loss)
I0706 09:14:19.802640 22636 solver.cpp:590] Iteration 23100, lr = 0.000174032
I0706 09:14:45.611824 22636 solver.cpp:243] Iteration 23155, loss = 0.0256222
I0706 09:14:45.612164 22636 solver.cpp:259]     Train net output #0: loss = 0.0256227 (* 1 = 0.0256227 loss)
I0706 09:14:45.612172 22636 solver.cpp:590] Iteration 23155, lr = 0.000172362
I0706 09:15:11.401832 22636 solver.cpp:243] Iteration 23210, loss = 0.0114723
I0706 09:15:11.401859 22636 solver.cpp:259]     Train net output #0: loss = 0.0114729 (* 1 = 0.0114729 loss)
I0706 09:15:11.401865 22636 solver.cpp:590] Iteration 23210, lr = 0.000170707
I0706 09:15:37.236913 22636 solver.cpp:243] Iteration 23265, loss = 0.00169568
I0706 09:15:37.237263 22636 solver.cpp:259]     Train net output #0: loss = 0.00169625 (* 1 = 0.00169625 loss)
I0706 09:15:37.237272 22636 solver.cpp:590] Iteration 23265, lr = 0.000169069
I0706 09:16:03.127226 22636 solver.cpp:243] Iteration 23320, loss = 0.00157281
I0706 09:16:03.127248 22636 solver.cpp:259]     Train net output #0: loss = 0.00157339 (* 1 = 0.00157339 loss)
I0706 09:16:03.127254 22636 solver.cpp:590] Iteration 23320, lr = 0.000167446
I0706 09:16:27.508014 22636 solver.cpp:347] Iteration 23373, Testing net (#0)
I0706 09:16:47.604674 22636 solver.cpp:415]     Test net output #0: accuracy = 0.161298
I0706 09:16:47.604703 22636 solver.cpp:415]     Test net output #1: loss = 6.12492 (* 1 = 6.12492 loss)
I0706 09:16:48.930793 22636 solver.cpp:243] Iteration 23375, loss = 0.00805812
I0706 09:16:48.930819 22636 solver.cpp:259]     Train net output #0: loss = 0.00805872 (* 1 = 0.00805872 loss)
I0706 09:16:48.930825 22636 solver.cpp:590] Iteration 23375, lr = 0.000165838
I0706 09:17:14.715183 22636 solver.cpp:243] Iteration 23430, loss = 0.0218283
I0706 09:17:14.715477 22636 solver.cpp:259]     Train net output #0: loss = 0.0218289 (* 1 = 0.0218289 loss)
I0706 09:17:14.715495 22636 solver.cpp:590] Iteration 23430, lr = 0.000164247
I0706 09:17:40.555425 22636 solver.cpp:243] Iteration 23485, loss = 0.0247652
I0706 09:17:40.555447 22636 solver.cpp:259]     Train net output #0: loss = 0.0247658 (* 1 = 0.0247658 loss)
I0706 09:17:40.555454 22636 solver.cpp:590] Iteration 23485, lr = 0.00016267
I0706 09:18:06.384143 22636 solver.cpp:243] Iteration 23540, loss = 0.00260716
I0706 09:18:06.384450 22636 solver.cpp:259]     Train net output #0: loss = 0.00260776 (* 1 = 0.00260776 loss)
I0706 09:18:06.384459 22636 solver.cpp:590] Iteration 23540, lr = 0.000161108
I0706 09:18:32.202777 22636 solver.cpp:243] Iteration 23595, loss = 0.0254469
I0706 09:18:32.202802 22636 solver.cpp:259]     Train net output #0: loss = 0.0254475 (* 1 = 0.0254475 loss)
I0706 09:18:32.202808 22636 solver.cpp:590] Iteration 23595, lr = 0.000159562
I0706 09:18:58.107173 22636 solver.cpp:243] Iteration 23650, loss = 0.00186732
I0706 09:18:58.107399 22636 solver.cpp:259]     Train net output #0: loss = 0.00186794 (* 1 = 0.00186794 loss)
I0706 09:18:58.107409 22636 solver.cpp:590] Iteration 23650, lr = 0.00015803
I0706 09:19:23.949726 22636 solver.cpp:243] Iteration 23705, loss = 0.0246722
I0706 09:19:23.949754 22636 solver.cpp:259]     Train net output #0: loss = 0.0246728 (* 1 = 0.0246728 loss)
I0706 09:19:23.949761 22636 solver.cpp:590] Iteration 23705, lr = 0.000156513
I0706 09:19:49.765987 22636 solver.cpp:243] Iteration 23760, loss = 0.00369897
I0706 09:19:49.766238 22636 solver.cpp:259]     Train net output #0: loss = 0.0036996 (* 1 = 0.0036996 loss)
I0706 09:19:49.766247 22636 solver.cpp:590] Iteration 23760, lr = 0.000155011
I0706 09:20:14.633570 22636 solver.cpp:347] Iteration 23814, Testing net (#0)
I0706 09:20:34.967870 22636 solver.cpp:415]     Test net output #0: accuracy = 0.1625
I0706 09:20:34.969811 22636 solver.cpp:415]     Test net output #1: loss = 6.11935 (* 1 = 6.11935 loss)
I0706 09:20:35.845544 22636 solver.cpp:243] Iteration 23815, loss = 0.0951876
I0706 09:20:35.845571 22636 solver.cpp:259]     Train net output #0: loss = 0.0951882 (* 1 = 0.0951882 loss)
I0706 09:20:35.845577 22636 solver.cpp:590] Iteration 23815, lr = 0.000153523
I0706 09:21:01.680543 22636 solver.cpp:243] Iteration 23870, loss = 0.00723814
I0706 09:21:01.680565 22636 solver.cpp:259]     Train net output #0: loss = 0.00723878 (* 1 = 0.00723878 loss)
I0706 09:21:01.680572 22636 solver.cpp:590] Iteration 23870, lr = 0.000152049
I0706 09:21:27.480945 22636 solver.cpp:243] Iteration 23925, loss = 0.00595424
I0706 09:21:27.481382 22636 solver.cpp:259]     Train net output #0: loss = 0.00595489 (* 1 = 0.00595489 loss)
I0706 09:21:27.481391 22636 solver.cpp:590] Iteration 23925, lr = 0.00015059
I0706 09:21:53.281033 22636 solver.cpp:243] Iteration 23980, loss = 0.0100596
I0706 09:21:53.281060 22636 solver.cpp:259]     Train net output #0: loss = 0.0100602 (* 1 = 0.0100602 loss)
I0706 09:21:53.281067 22636 solver.cpp:590] Iteration 23980, lr = 0.000149144
I0706 09:22:19.105192 22636 solver.cpp:243] Iteration 24035, loss = 0.000488641
I0706 09:22:19.105573 22636 solver.cpp:259]     Train net output #0: loss = 0.000489297 (* 1 = 0.000489297 loss)
I0706 09:22:19.105582 22636 solver.cpp:590] Iteration 24035, lr = 0.000147713
I0706 09:22:44.973526 22636 solver.cpp:243] Iteration 24090, loss = 0.00340186
I0706 09:22:44.973551 22636 solver.cpp:259]     Train net output #0: loss = 0.00340251 (* 1 = 0.00340251 loss)
I0706 09:22:44.973556 22636 solver.cpp:590] Iteration 24090, lr = 0.000146295
I0706 09:23:10.816190 22636 solver.cpp:243] Iteration 24145, loss = 0.0059824
I0706 09:23:10.816642 22636 solver.cpp:259]     Train net output #0: loss = 0.00598305 (* 1 = 0.00598305 loss)
I0706 09:23:10.816650 22636 solver.cpp:590] Iteration 24145, lr = 0.00014489
I0706 09:23:36.587700 22636 solver.cpp:243] Iteration 24200, loss = 0.0328313
I0706 09:23:36.587723 22636 solver.cpp:259]     Train net output #0: loss = 0.032832 (* 1 = 0.032832 loss)
I0706 09:23:36.587728 22636 solver.cpp:590] Iteration 24200, lr = 0.0001435
I0706 09:24:01.907148 22636 solver.cpp:347] Iteration 24255, Testing net (#0)
I0706 09:24:22.153152 22636 solver.cpp:415]     Test net output #0: accuracy = 0.163942
I0706 09:24:22.153179 22636 solver.cpp:415]     Test net output #1: loss = 6.12513 (* 1 = 6.12513 loss)
I0706 09:24:22.540920 22636 solver.cpp:243] Iteration 24255, loss = 0.0334108
I0706 09:24:22.540948 22636 solver.cpp:259]     Train net output #0: loss = 0.0334115 (* 1 = 0.0334115 loss)
I0706 09:24:22.540956 22636 solver.cpp:590] Iteration 24255, lr = 0.000142122
I0706 09:24:48.337795 22636 solver.cpp:243] Iteration 24310, loss = 0.0256088
I0706 09:24:48.338054 22636 solver.cpp:259]     Train net output #0: loss = 0.0256094 (* 1 = 0.0256094 loss)
I0706 09:24:48.338064 22636 solver.cpp:590] Iteration 24310, lr = 0.000140758
I0706 09:25:14.105832 22636 solver.cpp:243] Iteration 24365, loss = 0.00844492
I0706 09:25:14.105872 22636 solver.cpp:259]     Train net output #0: loss = 0.00844556 (* 1 = 0.00844556 loss)
I0706 09:25:14.105880 22636 solver.cpp:590] Iteration 24365, lr = 0.000139407
I0706 09:25:39.913046 22636 solver.cpp:243] Iteration 24420, loss = 0.00885306
I0706 09:25:39.913259 22636 solver.cpp:259]     Train net output #0: loss = 0.0088537 (* 1 = 0.0088537 loss)
I0706 09:25:39.913266 22636 solver.cpp:590] Iteration 24420, lr = 0.000138069
I0706 09:26:05.709686 22636 solver.cpp:243] Iteration 24475, loss = 0.000354116
I0706 09:26:05.709714 22636 solver.cpp:259]     Train net output #0: loss = 0.000354757 (* 1 = 0.000354757 loss)
I0706 09:26:05.709722 22636 solver.cpp:590] Iteration 24475, lr = 0.000136743
I0706 09:26:31.506345 22636 solver.cpp:243] Iteration 24530, loss = 0.000378333
I0706 09:26:31.506633 22636 solver.cpp:259]     Train net output #0: loss = 0.000378966 (* 1 = 0.000378966 loss)
I0706 09:26:31.506641 22636 solver.cpp:590] Iteration 24530, lr = 0.000135431
I0706 09:26:57.288241 22636 solver.cpp:243] Iteration 24585, loss = 0.00725109
I0706 09:26:57.288270 22636 solver.cpp:259]     Train net output #0: loss = 0.00725172 (* 1 = 0.00725172 loss)
I0706 09:26:57.288278 22636 solver.cpp:590] Iteration 24585, lr = 0.000134131
I0706 09:27:23.096029 22636 solver.cpp:243] Iteration 24640, loss = 0.0113029
I0706 09:27:23.096249 22636 solver.cpp:259]     Train net output #0: loss = 0.0113035 (* 1 = 0.0113035 loss)
I0706 09:27:23.096257 22636 solver.cpp:590] Iteration 24640, lr = 0.000132843
I0706 09:27:48.977221 22636 solver.cpp:243] Iteration 24695, loss = 0.000327133
I0706 09:27:48.977243 22636 solver.cpp:259]     Train net output #0: loss = 0.000327752 (* 1 = 0.000327752 loss)
I0706 09:27:48.977250 22636 solver.cpp:590] Iteration 24695, lr = 0.000131568
I0706 09:27:48.977468 22636 solver.cpp:347] Iteration 24696, Testing net (#0)
I0706 09:27:51.817793 22636 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 09:28:09.294611 22636 solver.cpp:415]     Test net output #0: accuracy = 0.163822
I0706 09:28:09.294911 22636 solver.cpp:415]     Test net output #1: loss = 6.1335 (* 1 = 6.1335 loss)
I0706 09:28:35.101397 22636 solver.cpp:243] Iteration 24750, loss = 0.00103862
I0706 09:28:35.101420 22636 solver.cpp:259]     Train net output #0: loss = 0.00103925 (* 1 = 0.00103925 loss)
I0706 09:28:35.101426 22636 solver.cpp:590] Iteration 24750, lr = 0.000130305
I0706 09:29:00.850574 22636 solver.cpp:243] Iteration 24805, loss = 0.0170901
I0706 09:29:00.850903 22636 solver.cpp:259]     Train net output #0: loss = 0.0170907 (* 1 = 0.0170907 loss)
I0706 09:29:00.850910 22636 solver.cpp:590] Iteration 24805, lr = 0.000129054
I0706 09:29:26.642674 22636 solver.cpp:243] Iteration 24860, loss = 0.0353963
I0706 09:29:26.642695 22636 solver.cpp:259]     Train net output #0: loss = 0.0353969 (* 1 = 0.0353969 loss)
I0706 09:29:26.642700 22636 solver.cpp:590] Iteration 24860, lr = 0.000127815
I0706 09:29:52.439606 22636 solver.cpp:243] Iteration 24915, loss = 0.00963706
I0706 09:29:52.439852 22636 solver.cpp:259]     Train net output #0: loss = 0.00963773 (* 1 = 0.00963773 loss)
I0706 09:29:52.439862 22636 solver.cpp:590] Iteration 24915, lr = 0.000126588
I0706 09:30:18.274055 22636 solver.cpp:243] Iteration 24970, loss = 0.00542777
I0706 09:30:18.274080 22636 solver.cpp:259]     Train net output #0: loss = 0.00542844 (* 1 = 0.00542844 loss)
I0706 09:30:18.274085 22636 solver.cpp:590] Iteration 24970, lr = 0.000125373
I0706 09:30:44.109925 22636 solver.cpp:243] Iteration 25025, loss = 0.0531364
I0706 09:30:44.110191 22636 solver.cpp:259]     Train net output #0: loss = 0.053137 (* 1 = 0.053137 loss)
I0706 09:30:44.110199 22636 solver.cpp:590] Iteration 25025, lr = 0.00012417
I0706 09:31:10.005944 22636 solver.cpp:243] Iteration 25080, loss = 0.00641966
I0706 09:31:10.005969 22636 solver.cpp:259]     Train net output #0: loss = 0.00642033 (* 1 = 0.00642033 loss)
I0706 09:31:10.005975 22636 solver.cpp:590] Iteration 25080, lr = 0.000122978
I0706 09:31:35.773694 22636 solver.cpp:243] Iteration 25135, loss = 0.0407149
I0706 09:31:35.774034 22636 solver.cpp:259]     Train net output #0: loss = 0.0407156 (* 1 = 0.0407156 loss)
I0706 09:31:35.774044 22636 solver.cpp:590] Iteration 25135, lr = 0.000121797
I0706 09:31:36.244436 22636 solver.cpp:347] Iteration 25137, Testing net (#0)
I0706 09:31:56.591963 22636 solver.cpp:415]     Test net output #0: accuracy = 0.163822
I0706 09:31:56.591989 22636 solver.cpp:415]     Test net output #1: loss = 6.12167 (* 1 = 6.12167 loss)
I0706 09:32:21.913632 22636 solver.cpp:243] Iteration 25190, loss = 0.0075253
I0706 09:32:21.913975 22636 solver.cpp:259]     Train net output #0: loss = 0.00752597 (* 1 = 0.00752597 loss)
I0706 09:32:21.913985 22636 solver.cpp:590] Iteration 25190, lr = 0.000120628
I0706 09:32:47.686810 22636 solver.cpp:243] Iteration 25245, loss = 0.0179096
I0706 09:32:47.686831 22636 solver.cpp:259]     Train net output #0: loss = 0.0179103 (* 1 = 0.0179103 loss)
I0706 09:32:47.686837 22636 solver.cpp:590] Iteration 25245, lr = 0.00011947
I0706 09:33:13.432139 22636 solver.cpp:243] Iteration 25300, loss = 0.00337548
I0706 09:33:13.432615 22636 solver.cpp:259]     Train net output #0: loss = 0.00337614 (* 1 = 0.00337614 loss)
I0706 09:33:13.432623 22636 solver.cpp:590] Iteration 25300, lr = 0.000118324
I0706 09:33:39.262876 22636 solver.cpp:243] Iteration 25355, loss = 0.000860458
I0706 09:33:39.262900 22636 solver.cpp:259]     Train net output #0: loss = 0.000861122 (* 1 = 0.000861122 loss)
I0706 09:33:39.262907 22636 solver.cpp:590] Iteration 25355, lr = 0.000117188
I0706 09:34:05.075002 22636 solver.cpp:243] Iteration 25410, loss = 0.0858443
I0706 09:34:05.075345 22636 solver.cpp:259]     Train net output #0: loss = 0.085845 (* 1 = 0.085845 loss)
I0706 09:34:05.075352 22636 solver.cpp:590] Iteration 25410, lr = 0.000116063
I0706 09:34:30.923050 22636 solver.cpp:243] Iteration 25465, loss = 0.0225941
I0706 09:34:30.923079 22636 solver.cpp:259]     Train net output #0: loss = 0.0225948 (* 1 = 0.0225948 loss)
I0706 09:34:30.923087 22636 solver.cpp:590] Iteration 25465, lr = 0.000114949
I0706 09:34:56.815608 22636 solver.cpp:243] Iteration 25520, loss = 0.00368685
I0706 09:34:56.816098 22636 solver.cpp:259]     Train net output #0: loss = 0.00368751 (* 1 = 0.00368751 loss)
I0706 09:34:56.816117 22636 solver.cpp:590] Iteration 25520, lr = 0.000113845
I0706 09:35:22.578905 22636 solver.cpp:243] Iteration 25575, loss = 0.144142
I0706 09:35:22.578929 22636 solver.cpp:259]     Train net output #0: loss = 0.144143 (* 1 = 0.144143 loss)
I0706 09:35:22.578936 22636 solver.cpp:590] Iteration 25575, lr = 0.000112753
I0706 09:35:23.515167 22636 solver.cpp:347] Iteration 25578, Testing net (#0)
I0706 09:35:44.077411 22636 solver.cpp:415]     Test net output #0: accuracy = 0.16274
I0706 09:35:44.077684 22636 solver.cpp:415]     Test net output #1: loss = 6.12953 (* 1 = 6.12953 loss)
I0706 09:36:08.896546 22636 solver.cpp:243] Iteration 25630, loss = 0.000430204
I0706 09:36:08.896569 22636 solver.cpp:259]     Train net output #0: loss = 0.000430859 (* 1 = 0.000430859 loss)
I0706 09:36:08.896575 22636 solver.cpp:590] Iteration 25630, lr = 0.00011167
I0706 09:36:34.697870 22636 solver.cpp:243] Iteration 25685, loss = 0.00178686
I0706 09:36:34.698174 22636 solver.cpp:259]     Train net output #0: loss = 0.00178751 (* 1 = 0.00178751 loss)
I0706 09:36:34.698180 22636 solver.cpp:590] Iteration 25685, lr = 0.000110598
I0706 09:37:00.527896 22636 solver.cpp:243] Iteration 25740, loss = 0.00247564
I0706 09:37:00.527921 22636 solver.cpp:259]     Train net output #0: loss = 0.00247629 (* 1 = 0.00247629 loss)
I0706 09:37:00.527927 22636 solver.cpp:590] Iteration 25740, lr = 0.000109537
I0706 09:37:26.276870 22636 solver.cpp:243] Iteration 25795, loss = 0.00137363
I0706 09:37:26.276960 22636 solver.cpp:259]     Train net output #0: loss = 0.00137427 (* 1 = 0.00137427 loss)
I0706 09:37:26.276975 22636 solver.cpp:590] Iteration 25795, lr = 0.000108485
I0706 09:37:52.092288 22636 solver.cpp:243] Iteration 25850, loss = 0.00251994
I0706 09:37:52.092313 22636 solver.cpp:259]     Train net output #0: loss = 0.00252057 (* 1 = 0.00252057 loss)
I0706 09:37:52.092319 22636 solver.cpp:590] Iteration 25850, lr = 0.000107444
I0706 09:38:17.885207 22636 solver.cpp:243] Iteration 25905, loss = 0.00124098
I0706 09:38:17.885298 22636 solver.cpp:259]     Train net output #0: loss = 0.00124162 (* 1 = 0.00124162 loss)
I0706 09:38:17.885305 22636 solver.cpp:590] Iteration 25905, lr = 0.000106412
I0706 09:38:43.631227 22636 solver.cpp:243] Iteration 25960, loss = 0.0136647
I0706 09:38:43.631252 22636 solver.cpp:259]     Train net output #0: loss = 0.0136654 (* 1 = 0.0136654 loss)
I0706 09:38:43.631258 22636 solver.cpp:590] Iteration 25960, lr = 0.000105391
I0706 09:39:09.380266 22636 solver.cpp:243] Iteration 26015, loss = 0.00113324
I0706 09:39:09.380417 22636 solver.cpp:259]     Train net output #0: loss = 0.00113389 (* 1 = 0.00113389 loss)
I0706 09:39:09.380426 22636 solver.cpp:590] Iteration 26015, lr = 0.000104379
I0706 09:39:10.798833 22636 solver.cpp:347] Iteration 26019, Testing net (#0)
I0706 09:39:31.250753 22636 solver.cpp:415]     Test net output #0: accuracy = 0.165986
I0706 09:39:31.250780 22636 solver.cpp:415]     Test net output #1: loss = 6.13161 (* 1 = 6.13161 loss)
I0706 09:39:55.653678 22636 solver.cpp:243] Iteration 26070, loss = 0.00399717
I0706 09:39:55.654319 22636 solver.cpp:259]     Train net output #0: loss = 0.00399781 (* 1 = 0.00399781 loss)
I0706 09:39:55.654327 22636 solver.cpp:590] Iteration 26070, lr = 0.000103377
I0706 09:40:21.464658 22636 solver.cpp:243] Iteration 26125, loss = 0.00894407
I0706 09:40:21.464680 22636 solver.cpp:259]     Train net output #0: loss = 0.00894471 (* 1 = 0.00894471 loss)
I0706 09:40:21.464687 22636 solver.cpp:590] Iteration 26125, lr = 0.000102385
I0706 09:40:47.320672 22636 solver.cpp:243] Iteration 26180, loss = 0.0127381
I0706 09:40:47.321043 22636 solver.cpp:259]     Train net output #0: loss = 0.0127387 (* 1 = 0.0127387 loss)
I0706 09:40:47.321051 22636 solver.cpp:590] Iteration 26180, lr = 0.000101402
I0706 09:41:13.110719 22636 solver.cpp:243] Iteration 26235, loss = 0.0045871
I0706 09:41:13.110748 22636 solver.cpp:259]     Train net output #0: loss = 0.00458773 (* 1 = 0.00458773 loss)
I0706 09:41:13.110755 22636 solver.cpp:590] Iteration 26235, lr = 0.000100429
I0706 09:41:38.880630 22636 solver.cpp:243] Iteration 26290, loss = 0.00859461
I0706 09:41:38.880923 22636 solver.cpp:259]     Train net output #0: loss = 0.00859523 (* 1 = 0.00859523 loss)
I0706 09:41:38.880933 22636 solver.cpp:590] Iteration 26290, lr = 9.94648e-05
I0706 09:42:04.699874 22636 solver.cpp:243] Iteration 26345, loss = 0.00944607
I0706 09:42:04.699898 22636 solver.cpp:259]     Train net output #0: loss = 0.0094467 (* 1 = 0.0094467 loss)
I0706 09:42:04.699903 22636 solver.cpp:590] Iteration 26345, lr = 9.85101e-05
I0706 09:42:30.503888 22636 solver.cpp:243] Iteration 26400, loss = 0.0317459
I0706 09:42:30.504153 22636 solver.cpp:259]     Train net output #0: loss = 0.0317465 (* 1 = 0.0317465 loss)
I0706 09:42:30.504160 22636 solver.cpp:590] Iteration 26400, lr = 9.75645e-05
I0706 09:42:56.359264 22636 solver.cpp:243] Iteration 26455, loss = 0.00339429
I0706 09:42:56.359288 22636 solver.cpp:259]     Train net output #0: loss = 0.00339492 (* 1 = 0.00339492 loss)
I0706 09:42:56.359295 22636 solver.cpp:590] Iteration 26455, lr = 9.66279e-05
I0706 09:42:58.243734 22636 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_26460.caffemodel
I0706 09:43:24.572018 22636 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_26460.solverstate
I0706 09:43:26.130396 22636 solver.cpp:347] Iteration 26460, Testing net (#0)
I0706 09:43:47.382071 22636 solver.cpp:415]     Test net output #0: accuracy = 0.165986
I0706 09:43:47.382098 22636 solver.cpp:415]     Test net output #1: loss = 6.13418 (* 1 = 6.13418 loss)
I0706 09:44:11.234308 22636 solver.cpp:243] Iteration 26510, loss = 0.022627
I0706 09:44:11.234393 22636 solver.cpp:259]     Train net output #0: loss = 0.0226276 (* 1 = 0.0226276 loss)
I0706 09:44:11.234400 22636 solver.cpp:590] Iteration 26510, lr = 9.57004e-05
I0706 09:44:36.966253 22636 solver.cpp:243] Iteration 26565, loss = 0.00867412
I0706 09:44:36.966275 22636 solver.cpp:259]     Train net output #0: loss = 0.00867474 (* 1 = 0.00867474 loss)
I0706 09:44:36.966281 22636 solver.cpp:590] Iteration 26565, lr = 9.47817e-05
I0706 09:45:02.687866 22636 solver.cpp:243] Iteration 26620, loss = 0.0103016
I0706 09:45:02.687952 22636 solver.cpp:259]     Train net output #0: loss = 0.0103023 (* 1 = 0.0103023 loss)
I0706 09:45:02.687958 22636 solver.cpp:590] Iteration 26620, lr = 9.38719e-05
I0706 09:45:28.426906 22636 solver.cpp:243] Iteration 26675, loss = 0.00157211
I0706 09:45:28.426931 22636 solver.cpp:259]     Train net output #0: loss = 0.00157275 (* 1 = 0.00157275 loss)
I0706 09:45:28.426937 22636 solver.cpp:590] Iteration 26675, lr = 9.29708e-05
I0706 09:45:54.190112 22636 solver.cpp:243] Iteration 26730, loss = 0.00106103
I0706 09:45:54.192584 22636 solver.cpp:259]     Train net output #0: loss = 0.00106167 (* 1 = 0.00106167 loss)
I0706 09:45:54.192603 22636 solver.cpp:590] Iteration 26730, lr = 9.20784e-05
I0706 09:46:20.019433 22636 solver.cpp:243] Iteration 26785, loss = 0.0139428
I0706 09:46:20.019459 22636 solver.cpp:259]     Train net output #0: loss = 0.0139435 (* 1 = 0.0139435 loss)
I0706 09:46:20.019464 22636 solver.cpp:590] Iteration 26785, lr = 9.11945e-05
I0706 09:46:45.855324 22636 solver.cpp:243] Iteration 26840, loss = 0.00276827
I0706 09:46:45.855571 22636 solver.cpp:259]     Train net output #0: loss = 0.0027689 (* 1 = 0.0027689 loss)
I0706 09:46:45.855581 22636 solver.cpp:590] Iteration 26840, lr = 9.03191e-05
I0706 09:47:11.573367 22636 solver.cpp:243] Iteration 26895, loss = 0.00151519
I0706 09:47:11.573392 22636 solver.cpp:259]     Train net output #0: loss = 0.00151583 (* 1 = 0.00151583 loss)
I0706 09:47:11.573400 22636 solver.cpp:590] Iteration 26895, lr = 8.94522e-05
I0706 09:47:13.909956 22636 solver.cpp:347] Iteration 26901, Testing net (#0)
I0706 09:47:34.276551 22636 solver.cpp:415]     Test net output #0: accuracy = 0.165505
I0706 09:47:34.276672 22636 solver.cpp:415]     Test net output #1: loss = 6.13132 (* 1 = 6.13132 loss)
I0706 09:47:57.624064 22636 solver.cpp:243] Iteration 26950, loss = 0.000520501
I0706 09:47:57.624090 22636 solver.cpp:259]     Train net output #0: loss = 0.00052115 (* 1 = 0.00052115 loss)
I0706 09:47:57.624097 22636 solver.cpp:590] Iteration 26950, lr = 8.85935e-05
I0706 09:48:23.397409 22636 solver.cpp:243] Iteration 27005, loss = 0.0358579
I0706 09:48:23.397541 22636 solver.cpp:259]     Train net output #0: loss = 0.0358586 (* 1 = 0.0358586 loss)
I0706 09:48:23.397548 22636 solver.cpp:590] Iteration 27005, lr = 8.77431e-05
I0706 09:48:49.162225 22636 solver.cpp:243] Iteration 27060, loss = 0.000276485
I0706 09:48:49.162247 22636 solver.cpp:259]     Train net output #0: loss = 0.000277148 (* 1 = 0.000277148 loss)
I0706 09:48:49.162255 22636 solver.cpp:590] Iteration 27060, lr = 8.69008e-05
I0706 09:49:14.965196 22636 solver.cpp:243] Iteration 27115, loss = 0.0246492
I0706 09:49:14.965293 22636 solver.cpp:259]     Train net output #0: loss = 0.0246499 (* 1 = 0.0246499 loss)
I0706 09:49:14.965309 22636 solver.cpp:590] Iteration 27115, lr = 8.60667e-05
I0706 09:49:40.816671 22636 solver.cpp:243] Iteration 27170, loss = 0.0469551
I0706 09:49:40.816695 22636 solver.cpp:259]     Train net output #0: loss = 0.0469557 (* 1 = 0.0469557 loss)
I0706 09:49:40.816701 22636 solver.cpp:590] Iteration 27170, lr = 8.52405e-05
I0706 09:50:06.651664 22636 solver.cpp:243] Iteration 27225, loss = 0.00394067
I0706 09:50:06.651780 22636 solver.cpp:259]     Train net output #0: loss = 0.00394132 (* 1 = 0.00394132 loss)
I0706 09:50:06.651788 22636 solver.cpp:590] Iteration 27225, lr = 8.44223e-05
I0706 09:50:32.394186 22636 solver.cpp:243] Iteration 27280, loss = 0.00165634
I0706 09:50:32.394210 22636 solver.cpp:259]     Train net output #0: loss = 0.00165698 (* 1 = 0.00165698 loss)
I0706 09:50:32.394217 22636 solver.cpp:590] Iteration 27280, lr = 8.36119e-05
I0706 09:50:58.123155 22636 solver.cpp:243] Iteration 27335, loss = 0.000485728
I0706 09:50:58.123291 22636 solver.cpp:259]     Train net output #0: loss = 0.000486373 (* 1 = 0.000486373 loss)
I0706 09:50:58.123299 22636 solver.cpp:590] Iteration 27335, lr = 8.28093e-05
I0706 09:51:00.939867 22636 solver.cpp:347] Iteration 27342, Testing net (#0)
I0706 09:51:21.427739 22636 solver.cpp:415]     Test net output #0: accuracy = 0.164784
I0706 09:51:21.427767 22636 solver.cpp:415]     Test net output #1: loss = 6.14094 (* 1 = 6.14094 loss)
I0706 09:51:44.299458 22636 solver.cpp:243] Iteration 27390, loss = 0.058505
I0706 09:51:44.299569 22636 solver.cpp:259]     Train net output #0: loss = 0.0585057 (* 1 = 0.0585057 loss)
I0706 09:51:44.299587 22636 solver.cpp:590] Iteration 27390, lr = 8.20144e-05
I0706 09:52:10.069387 22636 solver.cpp:243] Iteration 27445, loss = 0.00572744
I0706 09:52:10.069409 22636 solver.cpp:259]     Train net output #0: loss = 0.00572808 (* 1 = 0.00572808 loss)
I0706 09:52:10.069416 22636 solver.cpp:590] Iteration 27445, lr = 8.12271e-05
I0706 09:52:35.898959 22636 solver.cpp:243] Iteration 27500, loss = 0.000422973
I0706 09:52:35.899296 22636 solver.cpp:259]     Train net output #0: loss = 0.000423606 (* 1 = 0.000423606 loss)
I0706 09:52:35.899327 22636 solver.cpp:590] Iteration 27500, lr = 8.04474e-05
I0706 09:53:01.776839 22636 solver.cpp:243] Iteration 27555, loss = 0.00177258
I0706 09:53:01.776865 22636 solver.cpp:259]     Train net output #0: loss = 0.00177321 (* 1 = 0.00177321 loss)
I0706 09:53:01.776872 22636 solver.cpp:590] Iteration 27555, lr = 7.96752e-05
I0706 09:53:27.667556 22636 solver.cpp:243] Iteration 27610, loss = 0.000362819
I0706 09:53:27.668002 22636 solver.cpp:259]     Train net output #0: loss = 0.000363448 (* 1 = 0.000363448 loss)
I0706 09:53:27.668011 22636 solver.cpp:590] Iteration 27610, lr = 7.89104e-05
I0706 09:53:53.508826 22636 solver.cpp:243] Iteration 27665, loss = 0.00438976
I0706 09:53:53.508852 22636 solver.cpp:259]     Train net output #0: loss = 0.00439038 (* 1 = 0.00439038 loss)
I0706 09:53:53.508857 22636 solver.cpp:590] Iteration 27665, lr = 7.81529e-05
I0706 09:54:19.341300 22636 solver.cpp:243] Iteration 27720, loss = 0.00254388
I0706 09:54:19.341559 22636 solver.cpp:259]     Train net output #0: loss = 0.0025445 (* 1 = 0.0025445 loss)
I0706 09:54:19.341567 22636 solver.cpp:590] Iteration 27720, lr = 7.74027e-05
I0706 09:54:45.183632 22636 solver.cpp:243] Iteration 27775, loss = 0.0577295
I0706 09:54:45.183656 22636 solver.cpp:259]     Train net output #0: loss = 0.0577301 (* 1 = 0.0577301 loss)
I0706 09:54:45.183662 22636 solver.cpp:590] Iteration 27775, lr = 7.66597e-05
I0706 09:54:48.475780 22636 solver.cpp:347] Iteration 27783, Testing net (#0)
I0706 09:55:08.548712 22636 solver.cpp:415]     Test net output #0: accuracy = 0.164183
I0706 09:55:08.548923 22636 solver.cpp:415]     Test net output #1: loss = 6.12234 (* 1 = 6.12234 loss)
I0706 09:55:31.075431 22636 solver.cpp:243] Iteration 27830, loss = 0.00127912
I0706 09:55:31.075453 22636 solver.cpp:259]     Train net output #0: loss = 0.00127973 (* 1 = 0.00127973 loss)
I0706 09:55:31.075460 22636 solver.cpp:590] Iteration 27830, lr = 7.59238e-05
I0706 09:55:56.929167 22636 solver.cpp:243] Iteration 27885, loss = 0.0227526
I0706 09:55:56.929603 22636 solver.cpp:259]     Train net output #0: loss = 0.0227532 (* 1 = 0.0227532 loss)
I0706 09:55:56.929611 22636 solver.cpp:590] Iteration 27885, lr = 7.51951e-05
I0706 09:56:22.716975 22636 solver.cpp:243] Iteration 27940, loss = 0.00147966
I0706 09:56:22.717000 22636 solver.cpp:259]     Train net output #0: loss = 0.00148029 (* 1 = 0.00148029 loss)
I0706 09:56:22.717006 22636 solver.cpp:590] Iteration 27940, lr = 7.44732e-05
I0706 09:56:48.505939 22636 solver.cpp:243] Iteration 27995, loss = 0.000518005
I0706 09:56:48.506435 22636 solver.cpp:259]     Train net output #0: loss = 0.000518636 (* 1 = 0.000518636 loss)
I0706 09:56:48.506444 22636 solver.cpp:590] Iteration 27995, lr = 7.37584e-05
I0706 09:57:14.379386 22636 solver.cpp:243] Iteration 28050, loss = 0.0309267
I0706 09:57:14.379411 22636 solver.cpp:259]     Train net output #0: loss = 0.0309273 (* 1 = 0.0309273 loss)
I0706 09:57:14.379418 22636 solver.cpp:590] Iteration 28050, lr = 7.30504e-05
I0706 09:57:40.299824 22636 solver.cpp:243] Iteration 28105, loss = 0.013529
I0706 09:57:40.300216 22636 solver.cpp:259]     Train net output #0: loss = 0.0135297 (* 1 = 0.0135297 loss)
I0706 09:57:40.300225 22636 solver.cpp:590] Iteration 28105, lr = 7.23491e-05
I0706 09:58:06.132498 22636 solver.cpp:243] Iteration 28160, loss = 0.0271282
I0706 09:58:06.132520 22636 solver.cpp:259]     Train net output #0: loss = 0.0271289 (* 1 = 0.0271289 loss)
I0706 09:58:06.132526 22636 solver.cpp:590] Iteration 28160, lr = 7.16546e-05
I0706 09:58:31.906898 22636 solver.cpp:243] Iteration 28215, loss = 0.195752
I0706 09:58:31.907202 22636 solver.cpp:259]     Train net output #0: loss = 0.195753 (* 1 = 0.195753 loss)
I0706 09:58:31.907209 22636 solver.cpp:590] Iteration 28215, lr = 7.09668e-05
I0706 09:58:35.659785 22636 solver.cpp:347] Iteration 28224, Testing net (#0)
I0706 09:58:38.643100 22636 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 09:58:56.001204 22636 solver.cpp:415]     Test net output #0: accuracy = 0.164303
I0706 09:58:56.001229 22636 solver.cpp:415]     Test net output #1: loss = 6.12846 (* 1 = 6.12846 loss)
I0706 09:59:18.013432 22636 solver.cpp:243] Iteration 28270, loss = 0.00992058
I0706 09:59:18.013759 22636 solver.cpp:259]     Train net output #0: loss = 0.00992124 (* 1 = 0.00992124 loss)
I0706 09:59:18.013768 22636 solver.cpp:590] Iteration 28270, lr = 7.02856e-05
I0706 09:59:43.823884 22636 solver.cpp:243] Iteration 28325, loss = 0.00735781
I0706 09:59:43.823930 22636 solver.cpp:259]     Train net output #0: loss = 0.00735847 (* 1 = 0.00735847 loss)
I0706 09:59:43.823948 22636 solver.cpp:590] Iteration 28325, lr = 6.96109e-05
I0706 10:00:09.692463 22636 solver.cpp:243] Iteration 28380, loss = 0.0522141
I0706 10:00:09.692689 22636 solver.cpp:259]     Train net output #0: loss = 0.0522147 (* 1 = 0.0522147 loss)
I0706 10:00:09.692698 22636 solver.cpp:590] Iteration 28380, lr = 6.89427e-05
I0706 10:00:35.482733 22636 solver.cpp:243] Iteration 28435, loss = 0.00180486
I0706 10:00:35.482755 22636 solver.cpp:259]     Train net output #0: loss = 0.00180553 (* 1 = 0.00180553 loss)
I0706 10:00:35.482761 22636 solver.cpp:590] Iteration 28435, lr = 6.82809e-05
I0706 10:01:01.244513 22636 solver.cpp:243] Iteration 28490, loss = 0.00114479
I0706 10:01:01.244885 22636 solver.cpp:259]     Train net output #0: loss = 0.00114546 (* 1 = 0.00114546 loss)
I0706 10:01:01.244894 22636 solver.cpp:590] Iteration 28490, lr = 6.76255e-05
I0706 10:01:27.150002 22636 solver.cpp:243] Iteration 28545, loss = 0.00174942
I0706 10:01:27.150027 22636 solver.cpp:259]     Train net output #0: loss = 0.00175009 (* 1 = 0.00175009 loss)
I0706 10:01:27.150032 22636 solver.cpp:590] Iteration 28545, lr = 6.69764e-05
I0706 10:01:53.034041 22636 solver.cpp:243] Iteration 28600, loss = 0.000403219
I0706 10:01:53.034137 22636 solver.cpp:259]     Train net output #0: loss = 0.000403888 (* 1 = 0.000403888 loss)
I0706 10:01:53.034152 22636 solver.cpp:590] Iteration 28600, lr = 6.63334e-05
I0706 10:02:18.844203 22636 solver.cpp:243] Iteration 28655, loss = 0.00530481
I0706 10:02:18.844228 22636 solver.cpp:259]     Train net output #0: loss = 0.00530546 (* 1 = 0.00530546 loss)
I0706 10:02:18.844235 22636 solver.cpp:590] Iteration 28655, lr = 6.56967e-05
I0706 10:02:23.067502 22636 solver.cpp:347] Iteration 28665, Testing net (#0)
I0706 10:02:43.464295 22636 solver.cpp:415]     Test net output #0: accuracy = 0.164784
I0706 10:02:43.464323 22636 solver.cpp:415]     Test net output #1: loss = 6.13288 (* 1 = 6.13288 loss)
I0706 10:03:05.076437 22636 solver.cpp:243] Iteration 28710, loss = 0.122508
I0706 10:03:05.076557 22636 solver.cpp:259]     Train net output #0: loss = 0.122509 (* 1 = 0.122509 loss)
I0706 10:03:05.076567 22636 solver.cpp:590] Iteration 28710, lr = 6.50661e-05
I0706 10:03:30.901227 22636 solver.cpp:243] Iteration 28765, loss = 0.0351586
I0706 10:03:30.901253 22636 solver.cpp:259]     Train net output #0: loss = 0.0351593 (* 1 = 0.0351593 loss)
I0706 10:03:30.901259 22636 solver.cpp:590] Iteration 28765, lr = 6.44415e-05
I0706 10:03:56.718044 22636 solver.cpp:243] Iteration 28820, loss = 0.00839062
I0706 10:03:56.718133 22636 solver.cpp:259]     Train net output #0: loss = 0.00839128 (* 1 = 0.00839128 loss)
I0706 10:03:56.718139 22636 solver.cpp:590] Iteration 28820, lr = 6.38229e-05
I0706 10:04:22.622191 22636 solver.cpp:243] Iteration 28875, loss = 0.0565154
I0706 10:04:22.622217 22636 solver.cpp:259]     Train net output #0: loss = 0.0565161 (* 1 = 0.0565161 loss)
I0706 10:04:22.622223 22636 solver.cpp:590] Iteration 28875, lr = 6.32103e-05
I0706 10:04:48.409255 22636 solver.cpp:243] Iteration 28930, loss = 0.0161626
I0706 10:04:48.409366 22636 solver.cpp:259]     Train net output #0: loss = 0.0161633 (* 1 = 0.0161633 loss)
I0706 10:04:48.409384 22636 solver.cpp:590] Iteration 28930, lr = 6.26035e-05
I0706 10:05:14.202064 22636 solver.cpp:243] Iteration 28985, loss = 0.00089477
I0706 10:05:14.202088 22636 solver.cpp:259]     Train net output #0: loss = 0.000895394 (* 1 = 0.000895394 loss)
I0706 10:05:14.202095 22636 solver.cpp:590] Iteration 28985, lr = 6.20026e-05
I0706 10:05:40.018311 22636 solver.cpp:243] Iteration 29040, loss = 0.0130696
I0706 10:05:40.018903 22636 solver.cpp:259]     Train net output #0: loss = 0.0130702 (* 1 = 0.0130702 loss)
I0706 10:05:40.018913 22636 solver.cpp:590] Iteration 29040, lr = 6.14074e-05
I0706 10:06:05.811635 22636 solver.cpp:243] Iteration 29095, loss = 0.0559408
I0706 10:06:05.811656 22636 solver.cpp:259]     Train net output #0: loss = 0.0559414 (* 1 = 0.0559414 loss)
I0706 10:06:05.811663 22636 solver.cpp:590] Iteration 29095, lr = 6.0818e-05
I0706 10:06:10.505782 22636 solver.cpp:347] Iteration 29106, Testing net (#0)
I0706 10:06:30.772773 22636 solver.cpp:415]     Test net output #0: accuracy = 0.164784
I0706 10:06:30.772799 22636 solver.cpp:415]     Test net output #1: loss = 6.13402 (* 1 = 6.13402 loss)
I0706 10:06:51.779247 22636 solver.cpp:243] Iteration 29150, loss = 0.0114022
I0706 10:06:51.779338 22636 solver.cpp:259]     Train net output #0: loss = 0.0114028 (* 1 = 0.0114028 loss)
I0706 10:06:51.779346 22636 solver.cpp:590] Iteration 29150, lr = 6.02342e-05
I0706 10:07:17.588703 22636 solver.cpp:243] Iteration 29205, loss = 0.0119189
I0706 10:07:17.588727 22636 solver.cpp:259]     Train net output #0: loss = 0.0119196 (* 1 = 0.0119196 loss)
I0706 10:07:17.588734 22636 solver.cpp:590] Iteration 29205, lr = 5.9656e-05
I0706 10:07:43.329063 22636 solver.cpp:243] Iteration 29260, loss = 0.00362319
I0706 10:07:43.329172 22636 solver.cpp:259]     Train net output #0: loss = 0.00362383 (* 1 = 0.00362383 loss)
I0706 10:07:43.329180 22636 solver.cpp:590] Iteration 29260, lr = 5.90833e-05
I0706 10:08:09.062258 22636 solver.cpp:243] Iteration 29315, loss = 0.062743
I0706 10:08:09.062283 22636 solver.cpp:259]     Train net output #0: loss = 0.0627436 (* 1 = 0.0627436 loss)
I0706 10:08:09.062289 22636 solver.cpp:590] Iteration 29315, lr = 5.85162e-05
I0706 10:08:34.849992 22636 solver.cpp:243] Iteration 29370, loss = 0.00900039
I0706 10:08:34.850085 22636 solver.cpp:259]     Train net output #0: loss = 0.00900101 (* 1 = 0.00900101 loss)
I0706 10:08:34.850101 22636 solver.cpp:590] Iteration 29370, lr = 5.79545e-05
I0706 10:09:00.628423 22636 solver.cpp:243] Iteration 29425, loss = 0.0569175
I0706 10:09:00.628448 22636 solver.cpp:259]     Train net output #0: loss = 0.0569181 (* 1 = 0.0569181 loss)
I0706 10:09:00.628454 22636 solver.cpp:590] Iteration 29425, lr = 5.73982e-05
I0706 10:09:26.413158 22636 solver.cpp:243] Iteration 29480, loss = 0.0541278
I0706 10:09:26.413234 22636 solver.cpp:259]     Train net output #0: loss = 0.0541284 (* 1 = 0.0541284 loss)
I0706 10:09:26.413251 22636 solver.cpp:590] Iteration 29480, lr = 5.68472e-05
I0706 10:09:52.268764 22636 solver.cpp:243] Iteration 29535, loss = 0.00240595
I0706 10:09:52.268790 22636 solver.cpp:259]     Train net output #0: loss = 0.00240656 (* 1 = 0.00240656 loss)
I0706 10:09:52.268795 22636 solver.cpp:590] Iteration 29535, lr = 5.63015e-05
I0706 10:09:57.412837 22636 solver.cpp:347] Iteration 29547, Testing net (#0)
I0706 10:10:17.721349 22636 solver.cpp:415]     Test net output #0: accuracy = 0.164784
I0706 10:10:17.721384 22636 solver.cpp:415]     Test net output #1: loss = 6.1347 (* 1 = 6.1347 loss)
I0706 10:10:38.297497 22636 solver.cpp:243] Iteration 29590, loss = 0.00070506
I0706 10:10:38.297600 22636 solver.cpp:259]     Train net output #0: loss = 0.00070565 (* 1 = 0.00070565 loss)
I0706 10:10:38.297608 22636 solver.cpp:590] Iteration 29590, lr = 5.57611e-05
I0706 10:11:04.101383 22636 solver.cpp:243] Iteration 29645, loss = 0.0396296
I0706 10:11:04.101405 22636 solver.cpp:259]     Train net output #0: loss = 0.0396302 (* 1 = 0.0396302 loss)
I0706 10:11:04.101411 22636 solver.cpp:590] Iteration 29645, lr = 5.52258e-05
I0706 10:11:29.894417 22636 solver.cpp:243] Iteration 29700, loss = 0.00231863
I0706 10:11:29.894546 22636 solver.cpp:259]     Train net output #0: loss = 0.00231922 (* 1 = 0.00231922 loss)
I0706 10:11:29.894552 22636 solver.cpp:590] Iteration 29700, lr = 5.46957e-05
I0706 10:11:55.836730 22636 solver.cpp:243] Iteration 29755, loss = 0.0150919
I0706 10:11:55.836755 22636 solver.cpp:259]     Train net output #0: loss = 0.0150925 (* 1 = 0.0150925 loss)
I0706 10:11:55.836760 22636 solver.cpp:590] Iteration 29755, lr = 5.41707e-05
I0706 10:12:21.632408 22636 solver.cpp:243] Iteration 29810, loss = 0.012281
I0706 10:12:21.632727 22636 solver.cpp:259]     Train net output #0: loss = 0.0122816 (* 1 = 0.0122816 loss)
I0706 10:12:21.632736 22636 solver.cpp:590] Iteration 29810, lr = 5.36507e-05
I0706 10:12:47.477427 22636 solver.cpp:243] Iteration 29865, loss = 0.00290866
I0706 10:12:47.477448 22636 solver.cpp:259]     Train net output #0: loss = 0.00290925 (* 1 = 0.00290925 loss)
I0706 10:12:47.477454 22636 solver.cpp:590] Iteration 29865, lr = 5.31357e-05
I0706 10:13:13.241204 22636 solver.cpp:243] Iteration 29920, loss = 0.000371497
I0706 10:13:13.241607 22636 solver.cpp:259]     Train net output #0: loss = 0.000372094 (* 1 = 0.000372094 loss)
I0706 10:13:13.241616 22636 solver.cpp:590] Iteration 29920, lr = 5.26256e-05
I0706 10:13:39.088922 22636 solver.cpp:243] Iteration 29975, loss = 0.0137807
I0706 10:13:39.088948 22636 solver.cpp:259]     Train net output #0: loss = 0.0137813 (* 1 = 0.0137813 loss)
I0706 10:13:39.088953 22636 solver.cpp:590] Iteration 29975, lr = 5.21204e-05
I0706 10:13:44.713493 22636 solver.cpp:347] Iteration 29988, Testing net (#0)
I0706 10:14:05.037461 22636 solver.cpp:415]     Test net output #0: accuracy = 0.164663
I0706 10:14:05.037497 22636 solver.cpp:415]     Test net output #1: loss = 6.13861 (* 1 = 6.13861 loss)
I0706 10:14:25.141458 22636 solver.cpp:243] Iteration 30030, loss = 0.0126112
I0706 10:14:25.141548 22636 solver.cpp:259]     Train net output #0: loss = 0.0126118 (* 1 = 0.0126118 loss)
I0706 10:14:25.141566 22636 solver.cpp:590] Iteration 30030, lr = 5.16201e-05
I0706 10:14:50.957240 22636 solver.cpp:243] Iteration 30085, loss = 0.00528432
I0706 10:14:50.957265 22636 solver.cpp:259]     Train net output #0: loss = 0.0052849 (* 1 = 0.0052849 loss)
I0706 10:14:50.957272 22636 solver.cpp:590] Iteration 30085, lr = 5.11246e-05
I0706 10:15:16.719303 22636 solver.cpp:243] Iteration 30140, loss = 0.00474443
I0706 10:15:16.719401 22636 solver.cpp:259]     Train net output #0: loss = 0.00474502 (* 1 = 0.00474502 loss)
I0706 10:15:16.719419 22636 solver.cpp:590] Iteration 30140, lr = 5.06339e-05
I0706 10:15:42.529433 22636 solver.cpp:243] Iteration 30195, loss = 0.036197
I0706 10:15:42.529456 22636 solver.cpp:259]     Train net output #0: loss = 0.0361975 (* 1 = 0.0361975 loss)
I0706 10:15:42.529464 22636 solver.cpp:590] Iteration 30195, lr = 5.01478e-05
I0706 10:16:08.287353 22636 solver.cpp:243] Iteration 30250, loss = 0.0184179
I0706 10:16:08.287487 22636 solver.cpp:259]     Train net output #0: loss = 0.0184185 (* 1 = 0.0184185 loss)
I0706 10:16:08.287493 22636 solver.cpp:590] Iteration 30250, lr = 4.96665e-05
I0706 10:16:34.123872 22636 solver.cpp:243] Iteration 30305, loss = 0.00185122
I0706 10:16:34.123895 22636 solver.cpp:259]     Train net output #0: loss = 0.00185182 (* 1 = 0.00185182 loss)
I0706 10:16:34.123901 22636 solver.cpp:590] Iteration 30305, lr = 4.91897e-05
I0706 10:16:59.944869 22636 solver.cpp:243] Iteration 30360, loss = 0.00482384
I0706 10:16:59.944986 22636 solver.cpp:259]     Train net output #0: loss = 0.00482443 (* 1 = 0.00482443 loss)
I0706 10:16:59.944994 22636 solver.cpp:590] Iteration 30360, lr = 4.87175e-05
I0706 10:17:25.733609 22636 solver.cpp:243] Iteration 30415, loss = 0.0038515
I0706 10:17:25.733644 22636 solver.cpp:259]     Train net output #0: loss = 0.0038521 (* 1 = 0.0038521 loss)
I0706 10:17:25.733650 22636 solver.cpp:590] Iteration 30415, lr = 4.82499e-05
I0706 10:17:31.838063 22636 solver.cpp:347] Iteration 30429, Testing net (#0)
I0706 10:17:52.122164 22636 solver.cpp:415]     Test net output #0: accuracy = 0.164303
I0706 10:17:52.122189 22636 solver.cpp:415]     Test net output #1: loss = 6.14354 (* 1 = 6.14354 loss)
I0706 10:18:11.764613 22636 solver.cpp:243] Iteration 30470, loss = 0.00869716
I0706 10:18:11.764966 22636 solver.cpp:259]     Train net output #0: loss = 0.00869774 (* 1 = 0.00869774 loss)
I0706 10:18:11.764974 22636 solver.cpp:590] Iteration 30470, lr = 4.77867e-05
I0706 10:18:37.648025 22636 solver.cpp:243] Iteration 30525, loss = 0.000540025
I0706 10:18:37.648047 22636 solver.cpp:259]     Train net output #0: loss = 0.00054062 (* 1 = 0.00054062 loss)
I0706 10:18:37.648053 22636 solver.cpp:590] Iteration 30525, lr = 4.7328e-05
I0706 10:19:03.453299 22636 solver.cpp:243] Iteration 30580, loss = 0.0707063
I0706 10:19:03.453387 22636 solver.cpp:259]     Train net output #0: loss = 0.0707069 (* 1 = 0.0707069 loss)
I0706 10:19:03.453403 22636 solver.cpp:590] Iteration 30580, lr = 4.68737e-05
I0706 10:19:29.310581 22636 solver.cpp:243] Iteration 30635, loss = 0.00936712
I0706 10:19:29.310606 22636 solver.cpp:259]     Train net output #0: loss = 0.00936772 (* 1 = 0.00936772 loss)
I0706 10:19:29.310611 22636 solver.cpp:590] Iteration 30635, lr = 4.64238e-05
I0706 10:19:55.112917 22636 solver.cpp:243] Iteration 30690, loss = 0.0102467
I0706 10:19:55.113009 22636 solver.cpp:259]     Train net output #0: loss = 0.0102473 (* 1 = 0.0102473 loss)
I0706 10:19:55.113015 22636 solver.cpp:590] Iteration 30690, lr = 4.59781e-05
I0706 10:20:20.911562 22636 solver.cpp:243] Iteration 30745, loss = 0.0992577
I0706 10:20:20.911586 22636 solver.cpp:259]     Train net output #0: loss = 0.0992583 (* 1 = 0.0992583 loss)
I0706 10:20:20.911593 22636 solver.cpp:590] Iteration 30745, lr = 4.55368e-05
I0706 10:20:46.814604 22636 solver.cpp:243] Iteration 30800, loss = 0.00665583
I0706 10:20:46.814692 22636 solver.cpp:259]     Train net output #0: loss = 0.00665644 (* 1 = 0.00665644 loss)
I0706 10:20:46.814708 22636 solver.cpp:590] Iteration 30800, lr = 4.50997e-05
I0706 10:21:12.677512 22636 solver.cpp:243] Iteration 30855, loss = 0.00103574
I0706 10:21:12.677538 22636 solver.cpp:259]     Train net output #0: loss = 0.00103634 (* 1 = 0.00103634 loss)
I0706 10:21:12.677544 22636 solver.cpp:590] Iteration 30855, lr = 4.46668e-05
I0706 10:21:19.261682 22636 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_30870.caffemodel
I0706 10:21:32.719089 22636 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_30870.solverstate
I0706 10:21:34.270318 22636 solver.cpp:347] Iteration 30870, Testing net (#0)
I0706 10:21:55.449620 22636 solver.cpp:415]     Test net output #0: accuracy = 0.163942
I0706 10:21:55.449743 22636 solver.cpp:415]     Test net output #1: loss = 6.14435 (* 1 = 6.14435 loss)
I0706 10:22:14.614665 22636 solver.cpp:243] Iteration 30910, loss = 0.00125218
I0706 10:22:14.614689 22636 solver.cpp:259]     Train net output #0: loss = 0.00125278 (* 1 = 0.00125278 loss)
I0706 10:22:14.614696 22636 solver.cpp:590] Iteration 30910, lr = 4.4238e-05
I0706 10:22:40.361690 22636 solver.cpp:243] Iteration 30965, loss = 0.0182825
I0706 10:22:40.361780 22636 solver.cpp:259]     Train net output #0: loss = 0.0182831 (* 1 = 0.0182831 loss)
I0706 10:22:40.361793 22636 solver.cpp:590] Iteration 30965, lr = 4.38134e-05
I0706 10:23:06.122514 22636 solver.cpp:243] Iteration 31020, loss = 0.0181056
I0706 10:23:06.122539 22636 solver.cpp:259]     Train net output #0: loss = 0.0181062 (* 1 = 0.0181062 loss)
I0706 10:23:06.122545 22636 solver.cpp:590] Iteration 31020, lr = 4.33928e-05
I0706 10:23:31.907740 22636 solver.cpp:243] Iteration 31075, loss = 0.000273678
I0706 10:23:31.907831 22636 solver.cpp:259]     Train net output #0: loss = 0.000274272 (* 1 = 0.000274272 loss)
I0706 10:23:31.907838 22636 solver.cpp:590] Iteration 31075, lr = 4.29763e-05
I0706 10:23:57.661981 22636 solver.cpp:243] Iteration 31130, loss = 0.0026433
I0706 10:23:57.662003 22636 solver.cpp:259]     Train net output #0: loss = 0.0026439 (* 1 = 0.0026439 loss)
I0706 10:23:57.662009 22636 solver.cpp:590] Iteration 31130, lr = 4.25637e-05
I0706 10:24:23.430788 22636 solver.cpp:243] Iteration 31185, loss = 0.136548
I0706 10:24:23.442572 22636 solver.cpp:259]     Train net output #0: loss = 0.136548 (* 1 = 0.136548 loss)
I0706 10:24:23.442581 22636 solver.cpp:590] Iteration 31185, lr = 4.21552e-05
I0706 10:24:49.229756 22636 solver.cpp:243] Iteration 31240, loss = 0.00400879
I0706 10:24:49.229779 22636 solver.cpp:259]     Train net output #0: loss = 0.00400939 (* 1 = 0.00400939 loss)
I0706 10:24:49.229785 22636 solver.cpp:590] Iteration 31240, lr = 4.17505e-05
I0706 10:25:15.047901 22636 solver.cpp:243] Iteration 31295, loss = 0.00440508
I0706 10:25:15.048439 22636 solver.cpp:259]     Train net output #0: loss = 0.00440568 (* 1 = 0.00440568 loss)
I0706 10:25:15.048447 22636 solver.cpp:590] Iteration 31295, lr = 4.13497e-05
I0706 10:25:22.086076 22636 solver.cpp:347] Iteration 31311, Testing net (#0)
I0706 10:25:42.305528 22636 solver.cpp:415]     Test net output #0: accuracy = 0.164663
I0706 10:25:42.305582 22636 solver.cpp:415]     Test net output #1: loss = 6.13574 (* 1 = 6.13574 loss)
I0706 10:26:00.950332 22636 solver.cpp:243] Iteration 31350, loss = 0.0513368
I0706 10:26:00.950618 22636 solver.cpp:259]     Train net output #0: loss = 0.0513374 (* 1 = 0.0513374 loss)
I0706 10:26:00.950626 22636 solver.cpp:590] Iteration 31350, lr = 4.09528e-05
I0706 10:26:26.755252 22636 solver.cpp:243] Iteration 31405, loss = 0.00250487
I0706 10:26:26.755275 22636 solver.cpp:259]     Train net output #0: loss = 0.00250547 (* 1 = 0.00250547 loss)
I0706 10:26:26.755281 22636 solver.cpp:590] Iteration 31405, lr = 4.05597e-05
I0706 10:26:52.493525 22636 solver.cpp:243] Iteration 31460, loss = 0.00450352
I0706 10:26:52.493706 22636 solver.cpp:259]     Train net output #0: loss = 0.00450414 (* 1 = 0.00450414 loss)
I0706 10:26:52.493715 22636 solver.cpp:590] Iteration 31460, lr = 4.01704e-05
I0706 10:27:18.375490 22636 solver.cpp:243] Iteration 31515, loss = 0.00142186
I0706 10:27:18.375515 22636 solver.cpp:259]     Train net output #0: loss = 0.00142247 (* 1 = 0.00142247 loss)
I0706 10:27:18.375521 22636 solver.cpp:590] Iteration 31515, lr = 3.97848e-05
I0706 10:27:44.158448 22636 solver.cpp:243] Iteration 31570, loss = 0.0118555
I0706 10:27:44.158823 22636 solver.cpp:259]     Train net output #0: loss = 0.0118561 (* 1 = 0.0118561 loss)
I0706 10:27:44.158831 22636 solver.cpp:590] Iteration 31570, lr = 3.94029e-05
I0706 10:28:10.118546 22636 solver.cpp:243] Iteration 31625, loss = 0.00136792
I0706 10:28:10.118569 22636 solver.cpp:259]     Train net output #0: loss = 0.00136854 (* 1 = 0.00136854 loss)
I0706 10:28:10.118576 22636 solver.cpp:590] Iteration 31625, lr = 3.90246e-05
I0706 10:28:35.924952 22636 solver.cpp:243] Iteration 31680, loss = 0.00272185
I0706 10:28:35.925252 22636 solver.cpp:259]     Train net output #0: loss = 0.00272247 (* 1 = 0.00272247 loss)
I0706 10:28:35.925261 22636 solver.cpp:590] Iteration 31680, lr = 3.865e-05
I0706 10:29:01.806572 22636 solver.cpp:243] Iteration 31735, loss = 0.00399543
I0706 10:29:01.806596 22636 solver.cpp:259]     Train net output #0: loss = 0.00399605 (* 1 = 0.00399605 loss)
I0706 10:29:01.806603 22636 solver.cpp:590] Iteration 31735, lr = 3.8279e-05
I0706 10:29:09.314553 22636 solver.cpp:347] Iteration 31752, Testing net (#0)
I0706 10:29:12.666959 22636 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 10:29:29.689559 22636 solver.cpp:415]     Test net output #0: accuracy = 0.165024
I0706 10:29:29.689586 22636 solver.cpp:415]     Test net output #1: loss = 6.13818 (* 1 = 6.13818 loss)
I0706 10:29:47.881656 22636 solver.cpp:243] Iteration 31790, loss = 9.75619e-05
I0706 10:29:47.881760 22636 solver.cpp:259]     Train net output #0: loss = 9.81869e-05 (* 1 = 9.81869e-05 loss)
I0706 10:29:47.881768 22636 solver.cpp:590] Iteration 31790, lr = 3.79116e-05
I0706 10:30:13.674995 22636 solver.cpp:243] Iteration 31845, loss = 0.0496654
I0706 10:30:13.675020 22636 solver.cpp:259]     Train net output #0: loss = 0.0496661 (* 1 = 0.0496661 loss)
I0706 10:30:13.675026 22636 solver.cpp:590] Iteration 31845, lr = 3.75477e-05
I0706 10:30:39.439462 22636 solver.cpp:243] Iteration 31900, loss = 0.00771722
I0706 10:30:39.439862 22636 solver.cpp:259]     Train net output #0: loss = 0.00771787 (* 1 = 0.00771787 loss)
I0706 10:30:39.439882 22636 solver.cpp:590] Iteration 31900, lr = 3.71872e-05
I0706 10:31:05.339323 22636 solver.cpp:243] Iteration 31955, loss = 0.00365429
I0706 10:31:05.339347 22636 solver.cpp:259]     Train net output #0: loss = 0.00365493 (* 1 = 0.00365493 loss)
I0706 10:31:05.339354 22636 solver.cpp:590] Iteration 31955, lr = 3.68303e-05
I0706 10:31:31.201103 22636 solver.cpp:243] Iteration 32010, loss = 0.00620413
I0706 10:31:31.201380 22636 solver.cpp:259]     Train net output #0: loss = 0.00620477 (* 1 = 0.00620477 loss)
I0706 10:31:31.201390 22636 solver.cpp:590] Iteration 32010, lr = 3.64767e-05
I0706 10:31:57.003669 22636 solver.cpp:243] Iteration 32065, loss = 0.000351146
I0706 10:31:57.003691 22636 solver.cpp:259]     Train net output #0: loss = 0.000351773 (* 1 = 0.000351773 loss)
I0706 10:31:57.003697 22636 solver.cpp:590] Iteration 32065, lr = 3.61266e-05
I0706 10:32:22.840833 22636 solver.cpp:243] Iteration 32120, loss = 0.00134914
I0706 10:32:22.841075 22636 solver.cpp:259]     Train net output #0: loss = 0.00134976 (* 1 = 0.00134976 loss)
I0706 10:32:22.841084 22636 solver.cpp:590] Iteration 32120, lr = 3.57798e-05
I0706 10:32:48.669883 22636 solver.cpp:243] Iteration 32175, loss = 0.00292968
I0706 10:32:48.669908 22636 solver.cpp:259]     Train net output #0: loss = 0.0029303 (* 1 = 0.0029303 loss)
I0706 10:32:48.669915 22636 solver.cpp:590] Iteration 32175, lr = 3.54364e-05
I0706 10:32:56.684237 22636 solver.cpp:347] Iteration 32193, Testing net (#0)
I0706 10:33:17.756674 22636 solver.cpp:415]     Test net output #0: accuracy = 0.165264
I0706 10:33:17.756700 22636 solver.cpp:415]     Test net output #1: loss = 6.14242 (* 1 = 6.14242 loss)
I0706 10:33:35.507531 22636 solver.cpp:243] Iteration 32230, loss = 0.00297196
I0706 10:33:35.507678 22636 solver.cpp:259]     Train net output #0: loss = 0.0029726 (* 1 = 0.0029726 loss)
I0706 10:33:35.507697 22636 solver.cpp:590] Iteration 32230, lr = 3.50962e-05
I0706 10:34:01.343658 22636 solver.cpp:243] Iteration 32285, loss = 0.00243014
I0706 10:34:01.343682 22636 solver.cpp:259]     Train net output #0: loss = 0.00243078 (* 1 = 0.00243078 loss)
I0706 10:34:01.343688 22636 solver.cpp:590] Iteration 32285, lr = 3.47593e-05
I0706 10:34:27.153051 22636 solver.cpp:243] Iteration 32340, loss = 0.00166963
I0706 10:34:27.153141 22636 solver.cpp:259]     Train net output #0: loss = 0.00167027 (* 1 = 0.00167027 loss)
I0706 10:34:27.153148 22636 solver.cpp:590] Iteration 32340, lr = 3.44257e-05
I0706 10:34:53.021561 22636 solver.cpp:243] Iteration 32395, loss = 0.0158554
I0706 10:34:53.021586 22636 solver.cpp:259]     Train net output #0: loss = 0.015856 (* 1 = 0.015856 loss)
I0706 10:34:53.021594 22636 solver.cpp:590] Iteration 32395, lr = 3.40952e-05
I0706 10:35:18.852072 22636 solver.cpp:243] Iteration 32450, loss = 0.00357267
I0706 10:35:18.852157 22636 solver.cpp:259]     Train net output #0: loss = 0.0035733 (* 1 = 0.0035733 loss)
I0706 10:35:18.852174 22636 solver.cpp:590] Iteration 32450, lr = 3.37679e-05
I0706 10:35:44.617311 22636 solver.cpp:243] Iteration 32505, loss = 0.00119323
I0706 10:35:44.617334 22636 solver.cpp:259]     Train net output #0: loss = 0.00119386 (* 1 = 0.00119386 loss)
I0706 10:35:44.617341 22636 solver.cpp:590] Iteration 32505, lr = 3.34438e-05
I0706 10:36:10.452348 22636 solver.cpp:243] Iteration 32560, loss = 0.00520981
I0706 10:36:10.452442 22636 solver.cpp:259]     Train net output #0: loss = 0.00521045 (* 1 = 0.00521045 loss)
I0706 10:36:10.452460 22636 solver.cpp:590] Iteration 32560, lr = 3.31227e-05
I0706 10:36:36.190170 22636 solver.cpp:243] Iteration 32615, loss = 0.0175873
I0706 10:36:36.190191 22636 solver.cpp:259]     Train net output #0: loss = 0.017588 (* 1 = 0.017588 loss)
I0706 10:36:36.190198 22636 solver.cpp:590] Iteration 32615, lr = 3.28048e-05
I0706 10:36:44.619648 22636 solver.cpp:347] Iteration 32634, Testing net (#0)
I0706 10:37:09.817186 22636 solver.cpp:415]     Test net output #0: accuracy = 0.165024
I0706 10:37:09.817211 22636 solver.cpp:415]     Test net output #1: loss = 6.1461 (* 1 = 6.1461 loss)
I0706 10:37:27.091859 22636 solver.cpp:243] Iteration 32670, loss = 0.0264718
I0706 10:37:27.092196 22636 solver.cpp:259]     Train net output #0: loss = 0.0264724 (* 1 = 0.0264724 loss)
I0706 10:37:27.092205 22636 solver.cpp:590] Iteration 32670, lr = 3.24899e-05
I0706 10:37:52.928263 22636 solver.cpp:243] Iteration 32725, loss = 0.00078842
I0706 10:37:52.928289 22636 solver.cpp:259]     Train net output #0: loss = 0.000789051 (* 1 = 0.000789051 loss)
I0706 10:37:52.928295 22636 solver.cpp:590] Iteration 32725, lr = 3.2178e-05
I0706 10:38:18.709517 22636 solver.cpp:243] Iteration 32780, loss = 0.0183812
I0706 10:38:18.709570 22636 solver.cpp:259]     Train net output #0: loss = 0.0183819 (* 1 = 0.0183819 loss)
I0706 10:38:18.709578 22636 solver.cpp:590] Iteration 32780, lr = 3.18691e-05
I0706 10:38:44.488909 22636 solver.cpp:243] Iteration 32835, loss = 0.0019135
I0706 10:38:44.488934 22636 solver.cpp:259]     Train net output #0: loss = 0.00191412 (* 1 = 0.00191412 loss)
I0706 10:38:44.488940 22636 solver.cpp:590] Iteration 32835, lr = 3.15632e-05
I0706 10:39:10.267560 22636 solver.cpp:243] Iteration 32890, loss = 0.00553229
I0706 10:39:10.267648 22636 solver.cpp:259]     Train net output #0: loss = 0.0055329 (* 1 = 0.0055329 loss)
I0706 10:39:10.267654 22636 solver.cpp:590] Iteration 32890, lr = 3.12602e-05
I0706 10:39:36.003626 22636 solver.cpp:243] Iteration 32945, loss = 0.0145354
I0706 10:39:36.003649 22636 solver.cpp:259]     Train net output #0: loss = 0.014536 (* 1 = 0.014536 loss)
I0706 10:39:36.003655 22636 solver.cpp:590] Iteration 32945, lr = 3.09602e-05
I0706 10:40:01.770948 22636 solver.cpp:243] Iteration 33000, loss = 0.00802096
I0706 10:40:01.771082 22636 solver.cpp:259]     Train net output #0: loss = 0.00802157 (* 1 = 0.00802157 loss)
I0706 10:40:01.771090 22636 solver.cpp:590] Iteration 33000, lr = 3.0663e-05
I0706 10:40:27.556979 22636 solver.cpp:243] Iteration 33055, loss = 0.00656071
I0706 10:40:27.557010 22636 solver.cpp:259]     Train net output #0: loss = 0.0065613 (* 1 = 0.0065613 loss)
I0706 10:40:27.557018 22636 solver.cpp:590] Iteration 33055, lr = 3.03687e-05
I0706 10:40:36.518133 22636 solver.cpp:347] Iteration 33075, Testing net (#0)
I0706 10:40:39.575664 22654 blocking_queue.cpp:50] Waiting for data
I0706 10:41:04.446365 22636 solver.cpp:415]     Test net output #0: accuracy = 0.164904
I0706 10:41:04.446398 22636 solver.cpp:415]     Test net output #1: loss = 6.14635 (* 1 = 6.14635 loss)
I0706 10:41:21.299262 22636 solver.cpp:243] Iteration 33110, loss = 0.000908981
I0706 10:41:21.299394 22636 solver.cpp:259]     Train net output #0: loss = 0.000909584 (* 1 = 0.000909584 loss)
I0706 10:41:21.299402 22636 solver.cpp:590] Iteration 33110, lr = 3.00771e-05
I0706 10:41:47.152463 22636 solver.cpp:243] Iteration 33165, loss = 0.0742771
I0706 10:41:47.152485 22636 solver.cpp:259]     Train net output #0: loss = 0.0742777 (* 1 = 0.0742777 loss)
I0706 10:41:47.152492 22636 solver.cpp:590] Iteration 33165, lr = 2.97884e-05
I0706 10:42:13.016803 22636 solver.cpp:243] Iteration 33220, loss = 0.0293603
I0706 10:42:13.016891 22636 solver.cpp:259]     Train net output #0: loss = 0.0293609 (* 1 = 0.0293609 loss)
I0706 10:42:13.016898 22636 solver.cpp:590] Iteration 33220, lr = 2.95025e-05
I0706 10:42:38.807649 22636 solver.cpp:243] Iteration 33275, loss = 0.000838285
I0706 10:42:38.807673 22636 solver.cpp:259]     Train net output #0: loss = 0.00083889 (* 1 = 0.00083889 loss)
I0706 10:42:38.807679 22636 solver.cpp:590] Iteration 33275, lr = 2.92193e-05
I0706 10:43:04.521805 22636 solver.cpp:243] Iteration 33330, loss = 0.00092141
I0706 10:43:04.521913 22636 solver.cpp:259]     Train net output #0: loss = 0.000922006 (* 1 = 0.000922006 loss)
I0706 10:43:04.521919 22636 solver.cpp:590] Iteration 33330, lr = 2.89388e-05
I0706 10:43:30.316862 22636 solver.cpp:243] Iteration 33385, loss = 0.00928598
I0706 10:43:30.316886 22636 solver.cpp:259]     Train net output #0: loss = 0.00928659 (* 1 = 0.00928659 loss)
I0706 10:43:30.316892 22636 solver.cpp:590] Iteration 33385, lr = 2.8661e-05
I0706 10:43:56.257948 22636 solver.cpp:243] Iteration 33440, loss = 0.0124499
I0706 10:43:56.258313 22636 solver.cpp:259]     Train net output #0: loss = 0.0124505 (* 1 = 0.0124505 loss)
I0706 10:43:56.258322 22636 solver.cpp:590] Iteration 33440, lr = 2.83859e-05
I0706 10:44:22.105070 22636 solver.cpp:243] Iteration 33495, loss = 0.0199098
I0706 10:44:22.105094 22636 solver.cpp:259]     Train net output #0: loss = 0.0199105 (* 1 = 0.0199105 loss)
I0706 10:44:22.105100 22636 solver.cpp:590] Iteration 33495, lr = 2.81134e-05
I0706 10:44:31.483808 22636 solver.cpp:347] Iteration 33516, Testing net (#0)
I0706 10:45:04.237287 22636 solver.cpp:415]     Test net output #0: accuracy = 0.165144
I0706 10:45:04.237390 22636 solver.cpp:415]     Test net output #1: loss = 6.15167 (* 1 = 6.15167 loss)
I0706 10:45:20.547148 22636 solver.cpp:243] Iteration 33550, loss = 0.00159852
I0706 10:45:20.547174 22636 solver.cpp:259]     Train net output #0: loss = 0.00159915 (* 1 = 0.00159915 loss)
I0706 10:45:20.547181 22636 solver.cpp:590] Iteration 33550, lr = 2.78436e-05
I0706 10:45:46.295519 22636 solver.cpp:243] Iteration 33605, loss = 0.00440287
I0706 10:45:46.295652 22636 solver.cpp:259]     Train net output #0: loss = 0.00440351 (* 1 = 0.00440351 loss)
I0706 10:45:46.295660 22636 solver.cpp:590] Iteration 33605, lr = 2.75763e-05
I0706 10:46:12.148923 22636 solver.cpp:243] Iteration 33660, loss = 0.00204892
I0706 10:46:12.148948 22636 solver.cpp:259]     Train net output #0: loss = 0.00204956 (* 1 = 0.00204956 loss)
I0706 10:46:12.148954 22636 solver.cpp:590] Iteration 33660, lr = 2.73116e-05
I0706 10:46:38.056203 22636 solver.cpp:243] Iteration 33715, loss = 0.0171568
I0706 10:46:38.056334 22636 solver.cpp:259]     Train net output #0: loss = 0.0171574 (* 1 = 0.0171574 loss)
I0706 10:46:38.056342 22636 solver.cpp:590] Iteration 33715, lr = 2.70494e-05
I0706 10:47:03.870048 22636 solver.cpp:243] Iteration 33770, loss = 0.000519604
I0706 10:47:03.870071 22636 solver.cpp:259]     Train net output #0: loss = 0.00052023 (* 1 = 0.00052023 loss)
I0706 10:47:03.870077 22636 solver.cpp:590] Iteration 33770, lr = 2.67898e-05
I0706 10:47:29.673722 22636 solver.cpp:243] Iteration 33825, loss = 0.00939568
I0706 10:47:29.673776 22636 solver.cpp:259]     Train net output #0: loss = 0.00939629 (* 1 = 0.00939629 loss)
I0706 10:47:29.673782 22636 solver.cpp:590] Iteration 33825, lr = 2.65326e-05
I0706 10:47:55.458554 22636 solver.cpp:243] Iteration 33880, loss = 0.00165163
I0706 10:47:55.458575 22636 solver.cpp:259]     Train net output #0: loss = 0.00165225 (* 1 = 0.00165225 loss)
I0706 10:47:55.458581 22636 solver.cpp:590] Iteration 33880, lr = 2.62779e-05
I0706 10:48:21.270859 22636 solver.cpp:243] Iteration 33935, loss = 0.00337571
I0706 10:48:21.270951 22636 solver.cpp:259]     Train net output #0: loss = 0.00337634 (* 1 = 0.00337634 loss)
I0706 10:48:21.270957 22636 solver.cpp:590] Iteration 33935, lr = 2.60257e-05
I0706 10:48:31.140707 22636 solver.cpp:347] Iteration 33957, Testing net (#0)
I0706 10:48:36.859578 22654 blocking_queue.cpp:50] Waiting for data
I0706 10:48:58.938017 22636 solver.cpp:415]     Test net output #0: accuracy = 0.165264
I0706 10:48:58.938124 22636 solver.cpp:415]     Test net output #1: loss = 6.14509 (* 1 = 6.14509 loss)
I0706 10:49:14.825557 22636 solver.cpp:243] Iteration 33990, loss = 0.089837
I0706 10:49:14.825582 22636 solver.cpp:259]     Train net output #0: loss = 0.0898377 (* 1 = 0.0898377 loss)
I0706 10:49:14.825588 22636 solver.cpp:590] Iteration 33990, lr = 2.57758e-05
I0706 10:49:40.671474 22636 solver.cpp:243] Iteration 34045, loss = 0.000177067
I0706 10:49:40.671587 22636 solver.cpp:259]     Train net output #0: loss = 0.0001777 (* 1 = 0.0001777 loss)
I0706 10:49:40.671604 22636 solver.cpp:590] Iteration 34045, lr = 2.55284e-05
I0706 10:50:06.499424 22636 solver.cpp:243] Iteration 34100, loss = 0.0368549
I0706 10:50:06.499462 22636 solver.cpp:259]     Train net output #0: loss = 0.0368555 (* 1 = 0.0368555 loss)
I0706 10:50:06.499469 22636 solver.cpp:590] Iteration 34100, lr = 2.52834e-05
I0706 10:50:32.344390 22636 solver.cpp:243] Iteration 34155, loss = 0.000143583
I0706 10:50:32.344694 22636 solver.cpp:259]     Train net output #0: loss = 0.000144211 (* 1 = 0.000144211 loss)
I0706 10:50:32.344702 22636 solver.cpp:590] Iteration 34155, lr = 2.50407e-05
I0706 10:50:58.129252 22636 solver.cpp:243] Iteration 34210, loss = 0.0167265
I0706 10:50:58.129277 22636 solver.cpp:259]     Train net output #0: loss = 0.0167271 (* 1 = 0.0167271 loss)
I0706 10:50:58.129283 22636 solver.cpp:590] Iteration 34210, lr = 2.48003e-05
I0706 10:51:23.973556 22636 solver.cpp:243] Iteration 34265, loss = 0.0247807
I0706 10:51:23.973820 22636 solver.cpp:259]     Train net output #0: loss = 0.0247814 (* 1 = 0.0247814 loss)
I0706 10:51:23.973829 22636 solver.cpp:590] Iteration 34265, lr = 2.45622e-05
I0706 10:51:49.811372 22636 solver.cpp:243] Iteration 34320, loss = 0.0152818
I0706 10:51:49.811394 22636 solver.cpp:259]     Train net output #0: loss = 0.0152824 (* 1 = 0.0152824 loss)
I0706 10:51:49.811399 22636 solver.cpp:590] Iteration 34320, lr = 2.43265e-05
I0706 10:52:15.586200 22636 solver.cpp:243] Iteration 34375, loss = 0.0595116
I0706 10:52:15.586460 22636 solver.cpp:259]     Train net output #0: loss = 0.0595123 (* 1 = 0.0595123 loss)
I0706 10:52:15.586469 22636 solver.cpp:590] Iteration 34375, lr = 2.4093e-05
I0706 10:52:25.960970 22636 solver.cpp:347] Iteration 34398, Testing net (#0)
I0706 10:52:48.800472 22636 solver.cpp:415]     Test net output #0: accuracy = 0.165024
I0706 10:52:48.800752 22636 solver.cpp:415]     Test net output #1: loss = 6.1466 (* 1 = 6.1466 loss)
I0706 10:53:04.187747 22636 solver.cpp:243] Iteration 34430, loss = 0.0634412
I0706 10:53:04.187770 22636 solver.cpp:259]     Train net output #0: loss = 0.0634418 (* 1 = 0.0634418 loss)
I0706 10:53:04.187777 22636 solver.cpp:590] Iteration 34430, lr = 2.38617e-05
I0706 10:53:29.989320 22636 solver.cpp:243] Iteration 34485, loss = 0.00785323
I0706 10:53:29.989406 22636 solver.cpp:259]     Train net output #0: loss = 0.00785384 (* 1 = 0.00785384 loss)
I0706 10:53:29.989423 22636 solver.cpp:590] Iteration 34485, lr = 2.36326e-05
I0706 10:53:55.861353 22636 solver.cpp:243] Iteration 34540, loss = 0.0339993
I0706 10:53:55.861376 22636 solver.cpp:259]     Train net output #0: loss = 0.0339999 (* 1 = 0.0339999 loss)
I0706 10:53:55.861382 22636 solver.cpp:590] Iteration 34540, lr = 2.34058e-05
I0706 10:54:21.692509 22636 solver.cpp:243] Iteration 34595, loss = 0.0992374
I0706 10:54:21.692603 22636 solver.cpp:259]     Train net output #0: loss = 0.099238 (* 1 = 0.099238 loss)
I0706 10:54:21.692610 22636 solver.cpp:590] Iteration 34595, lr = 2.31811e-05
I0706 10:54:47.454392 22636 solver.cpp:243] Iteration 34650, loss = 0.00291446
I0706 10:54:47.454416 22636 solver.cpp:259]     Train net output #0: loss = 0.00291505 (* 1 = 0.00291505 loss)
I0706 10:54:47.454421 22636 solver.cpp:590] Iteration 34650, lr = 2.29586e-05
I0706 10:55:13.306819 22636 solver.cpp:243] Iteration 34705, loss = 0.0657681
I0706 10:55:13.306912 22636 solver.cpp:259]     Train net output #0: loss = 0.0657687 (* 1 = 0.0657687 loss)
I0706 10:55:13.306928 22636 solver.cpp:590] Iteration 34705, lr = 2.27382e-05
I0706 10:55:39.135313 22636 solver.cpp:243] Iteration 34760, loss = 0.0037737
I0706 10:55:39.135336 22636 solver.cpp:259]     Train net output #0: loss = 0.0037743 (* 1 = 0.0037743 loss)
I0706 10:55:39.135344 22636 solver.cpp:590] Iteration 34760, lr = 2.25199e-05
I0706 10:56:04.978431 22636 solver.cpp:243] Iteration 34815, loss = 0.00190835
I0706 10:56:04.978539 22636 solver.cpp:259]     Train net output #0: loss = 0.00190896 (* 1 = 0.00190896 loss)
I0706 10:56:04.978556 22636 solver.cpp:590] Iteration 34815, lr = 2.23038e-05
I0706 10:56:15.752151 22636 solver.cpp:347] Iteration 34839, Testing net (#0)
I0706 10:56:37.181241 22636 solver.cpp:415]     Test net output #0: accuracy = 0.165144
I0706 10:56:37.181515 22636 solver.cpp:415]     Test net output #1: loss = 6.14437 (* 1 = 6.14437 loss)
I0706 10:56:52.080320 22636 solver.cpp:243] Iteration 34870, loss = 0.035057
I0706 10:56:52.080344 22636 solver.cpp:259]     Train net output #0: loss = 0.0350576 (* 1 = 0.0350576 loss)
I0706 10:56:52.080349 22636 solver.cpp:590] Iteration 34870, lr = 2.20897e-05
I0706 10:57:17.871140 22636 solver.cpp:243] Iteration 34925, loss = 0.0185354
I0706 10:57:17.871269 22636 solver.cpp:259]     Train net output #0: loss = 0.018536 (* 1 = 0.018536 loss)
I0706 10:57:17.871278 22636 solver.cpp:590] Iteration 34925, lr = 2.18776e-05
I0706 10:57:43.630264 22636 solver.cpp:243] Iteration 34980, loss = 0.0166077
I0706 10:57:43.630285 22636 solver.cpp:259]     Train net output #0: loss = 0.0166082 (* 1 = 0.0166082 loss)
I0706 10:57:43.630290 22636 solver.cpp:590] Iteration 34980, lr = 2.16676e-05
I0706 10:58:09.374846 22636 solver.cpp:243] Iteration 35035, loss = 0.0211143
I0706 10:58:09.374938 22636 solver.cpp:259]     Train net output #0: loss = 0.0211148 (* 1 = 0.0211148 loss)
I0706 10:58:09.374954 22636 solver.cpp:590] Iteration 35035, lr = 2.14596e-05
I0706 10:58:35.191311 22636 solver.cpp:243] Iteration 35090, loss = 0.00689636
I0706 10:58:35.191332 22636 solver.cpp:259]     Train net output #0: loss = 0.00689694 (* 1 = 0.00689694 loss)
I0706 10:58:35.191339 22636 solver.cpp:590] Iteration 35090, lr = 2.12536e-05
I0706 10:59:00.965757 22636 solver.cpp:243] Iteration 35145, loss = 0.000583013
I0706 10:59:00.965847 22636 solver.cpp:259]     Train net output #0: loss = 0.000583588 (* 1 = 0.000583588 loss)
I0706 10:59:00.965853 22636 solver.cpp:590] Iteration 35145, lr = 2.10496e-05
I0706 10:59:26.731087 22636 solver.cpp:243] Iteration 35200, loss = 0.000714542
I0706 10:59:26.731109 22636 solver.cpp:259]     Train net output #0: loss = 0.000715119 (* 1 = 0.000715119 loss)
I0706 10:59:26.731117 22636 solver.cpp:590] Iteration 35200, lr = 2.08476e-05
I0706 10:59:52.522320 22636 solver.cpp:243] Iteration 35255, loss = 0.00125584
I0706 10:59:52.522405 22636 solver.cpp:259]     Train net output #0: loss = 0.00125641 (* 1 = 0.00125641 loss)
I0706 10:59:52.522423 22636 solver.cpp:590] Iteration 35255, lr = 2.06475e-05
I0706 11:00:03.742717 22636 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_35280.caffemodel
I0706 11:00:20.041431 22636 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_35280.solverstate
I0706 11:00:21.599401 22636 solver.cpp:347] Iteration 35280, Testing net (#0)
I0706 11:00:26.207870 22636 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 11:00:45.209974 22636 solver.cpp:415]     Test net output #0: accuracy = 0.165264
I0706 11:00:45.210000 22636 solver.cpp:415]     Test net output #1: loss = 6.14472 (* 1 = 6.14472 loss)
I0706 11:00:45.210003 22636 solver.cpp:332] Optimization Done.
I0706 11:00:45.210005 22636 caffe.cpp:223] Optimization Done.
