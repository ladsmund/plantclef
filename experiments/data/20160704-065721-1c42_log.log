I0704 10:26:43.539194 20391 caffe.cpp:192] Using GPUs 0
I0704 10:26:43.914134 20391 solver.cpp:54] Initializing solver from parameters:
test_iter: 260
test_interval: 221
base_lr: 0.01
display: 27
max_iter: 22100
lr_policy: "exp"
gamma: 0.99976796
momentum: 0.9
weight_decay: 0.0001
snapshot: 2210
snapshot_prefix: "snapshot"
solver_mode: GPU
device_id: 0
random_seed: 0
net: "train_val.prototxt"
solver_type: SGD
I0704 10:26:43.914769 20391 solver.cpp:97] Creating training net from net file: train_val.prototxt
I0704 10:26:43.915899 20391 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer val-data
I0704 10:26:43.915916 20391 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0704 10:26:43.916015 20391 net.cpp:52] Initializing net from parameters:
state {
phase: TRAIN
}
layer {
name: "train-data"
type: "Data"
top: "data"
top: "label"
include {
phase: TRAIN
}
transform_param {
mirror: true
crop_size: 227
mean_file: "/home/ffw/scratch/digits/jobs/20160624-120053-bb9a/mean.binaryproto"
}
data_param {
source: "/home/ffw/scratch/digits/jobs/20160624-120053-bb9a/train_db"
batch_size: 128
backend: LMDB
}
}
layer {
name: "conv1"
type: "Convolution"
bottom: "data"
top: "conv1"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 11
stride: 4
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu1"
type: "ReLU"
bottom: "conv1"
top: "conv1"
}
layer {
name: "norm1"
type: "LRN"
bottom: "conv1"
top: "norm1"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool1"
type: "Pooling"
bottom: "norm1"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv2"
type: "Convolution"
bottom: "pool1"
top: "conv2"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 2
kernel_size: 5
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu2"
type: "ReLU"
bottom: "conv2"
top: "conv2"
}
layer {
name: "norm2"
type: "LRN"
bottom: "conv2"
top: "norm2"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool2"
type: "Pooling"
bottom: "norm2"
top: "pool2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool2"
top: "conv3"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "conv4"
type: "Convolution"
bottom: "conv3"
top: "conv4"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu4"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "conv5"
type: "Convolution"
bottom: "conv4"
top: "conv5"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "conv5"
top: "conv5"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "conv5"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fc6_clean"
type: "InnerProduct"
bottom: "pool5"
top: "fc6_clean"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "fc6_clean"
top: "fc6_clean"
}
layer {
name: "drop6"
type: "Dropout"
bottom: "fc6_clean"
top: "fc6_clean"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc7_clean"
type: "InnerProduct"
bottom: "fc6_clean"
top: "fc7_clean"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "fc7_clean"
top: "fc7_clean"
}
layer {
name: "drop7"
type: "Dropout"
bottom: "fc7_clean"
top: "fc7_clean"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc8_clean"
type: "InnerProduct"
bottom: "fc7_clean"
top: "fc8_clean"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 967
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "fc8_clean"
bottom: "label"
top: "loss"
}
I0704 10:26:43.916079 20391 layer_factory.hpp:76] Creating layer train-data
I0704 10:26:43.916762 20391 net.cpp:109] Creating Layer train-data
I0704 10:26:43.916769 20391 net.cpp:414] train-data -> data
I0704 10:26:43.917098 20391 net.cpp:414] train-data -> label
I0704 10:26:43.917104 20391 data_transformer.cpp:25] Loading mean file from: /home/ffw/scratch/digits/jobs/20160624-120053-bb9a/mean.binaryproto
I0704 10:26:43.920429 20403 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/digits/jobs/20160624-120053-bb9a/train_db
I0704 10:26:43.926558 20391 data_layer.cpp:45] output data size: 128,3,227,227
I0704 10:26:44.013020 20391 net.cpp:153] Setting up train-data
I0704 10:26:44.013048 20391 net.cpp:160] Top shape: 128 3 227 227 (19787136)
I0704 10:26:44.013053 20391 net.cpp:160] Top shape: 128 (128)
I0704 10:26:44.013056 20391 net.cpp:168] Memory required for data: 79149056
I0704 10:26:44.013063 20391 layer_factory.hpp:76] Creating layer conv1
I0704 10:26:44.013494 20391 net.cpp:109] Creating Layer conv1
I0704 10:26:44.013504 20391 net.cpp:457] conv1 <- data
I0704 10:26:44.013514 20391 net.cpp:414] conv1 -> conv1
I0704 10:26:44.015947 20391 net.cpp:153] Setting up conv1
I0704 10:26:44.015959 20391 net.cpp:160] Top shape: 128 96 55 55 (37171200)
I0704 10:26:44.015960 20391 net.cpp:168] Memory required for data: 227833856
I0704 10:26:44.015969 20391 layer_factory.hpp:76] Creating layer relu1
I0704 10:26:44.015974 20391 net.cpp:109] Creating Layer relu1
I0704 10:26:44.015975 20391 net.cpp:457] relu1 <- conv1
I0704 10:26:44.015980 20391 net.cpp:400] relu1 -> conv1 (in-place)
I0704 10:26:44.015985 20391 net.cpp:153] Setting up relu1
I0704 10:26:44.015988 20391 net.cpp:160] Top shape: 128 96 55 55 (37171200)
I0704 10:26:44.015990 20391 net.cpp:168] Memory required for data: 376518656
I0704 10:26:44.015991 20391 layer_factory.hpp:76] Creating layer norm1
I0704 10:26:44.016571 20391 net.cpp:109] Creating Layer norm1
I0704 10:26:44.016579 20391 net.cpp:457] norm1 <- conv1
I0704 10:26:44.016582 20391 net.cpp:414] norm1 -> norm1
I0704 10:26:44.022959 20391 net.cpp:153] Setting up norm1
I0704 10:26:44.022969 20391 net.cpp:160] Top shape: 128 96 55 55 (37171200)
I0704 10:26:44.022972 20391 net.cpp:168] Memory required for data: 525203456
I0704 10:26:44.022976 20391 layer_factory.hpp:76] Creating layer pool1
I0704 10:26:44.022985 20391 net.cpp:109] Creating Layer pool1
I0704 10:26:44.023005 20391 net.cpp:457] pool1 <- norm1
I0704 10:26:44.023010 20391 net.cpp:414] pool1 -> pool1
I0704 10:26:44.023035 20391 net.cpp:153] Setting up pool1
I0704 10:26:44.023038 20391 net.cpp:160] Top shape: 128 96 27 27 (8957952)
I0704 10:26:44.023041 20391 net.cpp:168] Memory required for data: 561035264
I0704 10:26:44.023041 20391 layer_factory.hpp:76] Creating layer conv2
I0704 10:26:44.023046 20391 net.cpp:109] Creating Layer conv2
I0704 10:26:44.023048 20391 net.cpp:457] conv2 <- pool1
I0704 10:26:44.023051 20391 net.cpp:414] conv2 -> conv2
I0704 10:26:44.029948 20391 net.cpp:153] Setting up conv2
I0704 10:26:44.029963 20391 net.cpp:160] Top shape: 128 256 27 27 (23887872)
I0704 10:26:44.029966 20391 net.cpp:168] Memory required for data: 656586752
I0704 10:26:44.029973 20391 layer_factory.hpp:76] Creating layer relu2
I0704 10:26:44.029979 20391 net.cpp:109] Creating Layer relu2
I0704 10:26:44.029981 20391 net.cpp:457] relu2 <- conv2
I0704 10:26:44.029984 20391 net.cpp:400] relu2 -> conv2 (in-place)
I0704 10:26:44.029989 20391 net.cpp:153] Setting up relu2
I0704 10:26:44.029992 20391 net.cpp:160] Top shape: 128 256 27 27 (23887872)
I0704 10:26:44.029994 20391 net.cpp:168] Memory required for data: 752138240
I0704 10:26:44.029995 20391 layer_factory.hpp:76] Creating layer norm2
I0704 10:26:44.030000 20391 net.cpp:109] Creating Layer norm2
I0704 10:26:44.030001 20391 net.cpp:457] norm2 <- conv2
I0704 10:26:44.030004 20391 net.cpp:414] norm2 -> norm2
I0704 10:26:44.030025 20391 net.cpp:153] Setting up norm2
I0704 10:26:44.030028 20391 net.cpp:160] Top shape: 128 256 27 27 (23887872)
I0704 10:26:44.030030 20391 net.cpp:168] Memory required for data: 847689728
I0704 10:26:44.030031 20391 layer_factory.hpp:76] Creating layer pool2
I0704 10:26:44.030035 20391 net.cpp:109] Creating Layer pool2
I0704 10:26:44.030037 20391 net.cpp:457] pool2 <- norm2
I0704 10:26:44.030040 20391 net.cpp:414] pool2 -> pool2
I0704 10:26:44.030055 20391 net.cpp:153] Setting up pool2
I0704 10:26:44.030058 20391 net.cpp:160] Top shape: 128 256 13 13 (5537792)
I0704 10:26:44.030061 20391 net.cpp:168] Memory required for data: 869840896
I0704 10:26:44.030061 20391 layer_factory.hpp:76] Creating layer conv3
I0704 10:26:44.030066 20391 net.cpp:109] Creating Layer conv3
I0704 10:26:44.030068 20391 net.cpp:457] conv3 <- pool2
I0704 10:26:44.030071 20391 net.cpp:414] conv3 -> conv3
I0704 10:26:44.047962 20391 net.cpp:153] Setting up conv3
I0704 10:26:44.047984 20391 net.cpp:160] Top shape: 128 384 13 13 (8306688)
I0704 10:26:44.047986 20391 net.cpp:168] Memory required for data: 903067648
I0704 10:26:44.047994 20391 layer_factory.hpp:76] Creating layer relu3
I0704 10:26:44.048001 20391 net.cpp:109] Creating Layer relu3
I0704 10:26:44.048002 20391 net.cpp:457] relu3 <- conv3
I0704 10:26:44.048005 20391 net.cpp:400] relu3 -> conv3 (in-place)
I0704 10:26:44.048010 20391 net.cpp:153] Setting up relu3
I0704 10:26:44.048013 20391 net.cpp:160] Top shape: 128 384 13 13 (8306688)
I0704 10:26:44.048015 20391 net.cpp:168] Memory required for data: 936294400
I0704 10:26:44.048017 20391 layer_factory.hpp:76] Creating layer conv4
I0704 10:26:44.048022 20391 net.cpp:109] Creating Layer conv4
I0704 10:26:44.048023 20391 net.cpp:457] conv4 <- conv3
I0704 10:26:44.048027 20391 net.cpp:414] conv4 -> conv4
I0704 10:26:44.062052 20391 net.cpp:153] Setting up conv4
I0704 10:26:44.062067 20391 net.cpp:160] Top shape: 128 384 13 13 (8306688)
I0704 10:26:44.062070 20391 net.cpp:168] Memory required for data: 969521152
I0704 10:26:44.062075 20391 layer_factory.hpp:76] Creating layer relu4
I0704 10:26:44.062080 20391 net.cpp:109] Creating Layer relu4
I0704 10:26:44.062083 20391 net.cpp:457] relu4 <- conv4
I0704 10:26:44.062086 20391 net.cpp:400] relu4 -> conv4 (in-place)
I0704 10:26:44.062093 20391 net.cpp:153] Setting up relu4
I0704 10:26:44.062094 20391 net.cpp:160] Top shape: 128 384 13 13 (8306688)
I0704 10:26:44.062096 20391 net.cpp:168] Memory required for data: 1002747904
I0704 10:26:44.062098 20391 layer_factory.hpp:76] Creating layer conv5
I0704 10:26:44.062116 20391 net.cpp:109] Creating Layer conv5
I0704 10:26:44.062119 20391 net.cpp:457] conv5 <- conv4
I0704 10:26:44.062121 20391 net.cpp:414] conv5 -> conv5
I0704 10:26:44.072484 20391 net.cpp:153] Setting up conv5
I0704 10:26:44.072499 20391 net.cpp:160] Top shape: 128 256 13 13 (5537792)
I0704 10:26:44.072501 20391 net.cpp:168] Memory required for data: 1024899072
I0704 10:26:44.072509 20391 layer_factory.hpp:76] Creating layer relu5
I0704 10:26:44.072515 20391 net.cpp:109] Creating Layer relu5
I0704 10:26:44.072517 20391 net.cpp:457] relu5 <- conv5
I0704 10:26:44.072520 20391 net.cpp:400] relu5 -> conv5 (in-place)
I0704 10:26:44.072525 20391 net.cpp:153] Setting up relu5
I0704 10:26:44.072528 20391 net.cpp:160] Top shape: 128 256 13 13 (5537792)
I0704 10:26:44.072530 20391 net.cpp:168] Memory required for data: 1047050240
I0704 10:26:44.072531 20391 layer_factory.hpp:76] Creating layer pool5
I0704 10:26:44.072535 20391 net.cpp:109] Creating Layer pool5
I0704 10:26:44.072536 20391 net.cpp:457] pool5 <- conv5
I0704 10:26:44.072540 20391 net.cpp:414] pool5 -> pool5
I0704 10:26:44.072561 20391 net.cpp:153] Setting up pool5
I0704 10:26:44.072563 20391 net.cpp:160] Top shape: 128 256 6 6 (1179648)
I0704 10:26:44.072564 20391 net.cpp:168] Memory required for data: 1051768832
I0704 10:26:44.072566 20391 layer_factory.hpp:76] Creating layer fc6_clean
I0704 10:26:44.072572 20391 net.cpp:109] Creating Layer fc6_clean
I0704 10:26:44.072573 20391 net.cpp:457] fc6_clean <- pool5
I0704 10:26:44.072576 20391 net.cpp:414] fc6_clean -> fc6_clean
I0704 10:26:44.764777 20391 net.cpp:153] Setting up fc6_clean
I0704 10:26:44.764796 20391 net.cpp:160] Top shape: 128 4096 (524288)
I0704 10:26:44.764798 20391 net.cpp:168] Memory required for data: 1053865984
I0704 10:26:44.764804 20391 layer_factory.hpp:76] Creating layer relu6
I0704 10:26:44.764811 20391 net.cpp:109] Creating Layer relu6
I0704 10:26:44.764814 20391 net.cpp:457] relu6 <- fc6_clean
I0704 10:26:44.764818 20391 net.cpp:400] relu6 -> fc6_clean (in-place)
I0704 10:26:44.764825 20391 net.cpp:153] Setting up relu6
I0704 10:26:44.764828 20391 net.cpp:160] Top shape: 128 4096 (524288)
I0704 10:26:44.764830 20391 net.cpp:168] Memory required for data: 1055963136
I0704 10:26:44.764832 20391 layer_factory.hpp:76] Creating layer drop6
I0704 10:26:44.765260 20391 net.cpp:109] Creating Layer drop6
I0704 10:26:44.765269 20391 net.cpp:457] drop6 <- fc6_clean
I0704 10:26:44.765272 20391 net.cpp:400] drop6 -> fc6_clean (in-place)
I0704 10:26:44.765296 20391 net.cpp:153] Setting up drop6
I0704 10:26:44.765300 20391 net.cpp:160] Top shape: 128 4096 (524288)
I0704 10:26:44.765301 20391 net.cpp:168] Memory required for data: 1058060288
I0704 10:26:44.765303 20391 layer_factory.hpp:76] Creating layer fc7_clean
I0704 10:26:44.765310 20391 net.cpp:109] Creating Layer fc7_clean
I0704 10:26:44.765311 20391 net.cpp:457] fc7_clean <- fc6_clean
I0704 10:26:44.765313 20391 net.cpp:414] fc7_clean -> fc7_clean
I0704 10:26:45.074092 20391 net.cpp:153] Setting up fc7_clean
I0704 10:26:45.074111 20391 net.cpp:160] Top shape: 128 4096 (524288)
I0704 10:26:45.074115 20391 net.cpp:168] Memory required for data: 1060157440
I0704 10:26:45.074120 20391 layer_factory.hpp:76] Creating layer relu7
I0704 10:26:45.074127 20391 net.cpp:109] Creating Layer relu7
I0704 10:26:45.074129 20391 net.cpp:457] relu7 <- fc7_clean
I0704 10:26:45.074134 20391 net.cpp:400] relu7 -> fc7_clean (in-place)
I0704 10:26:45.074141 20391 net.cpp:153] Setting up relu7
I0704 10:26:45.074143 20391 net.cpp:160] Top shape: 128 4096 (524288)
I0704 10:26:45.074144 20391 net.cpp:168] Memory required for data: 1062254592
I0704 10:26:45.074146 20391 layer_factory.hpp:76] Creating layer drop7
I0704 10:26:45.074151 20391 net.cpp:109] Creating Layer drop7
I0704 10:26:45.074152 20391 net.cpp:457] drop7 <- fc7_clean
I0704 10:26:45.074154 20391 net.cpp:400] drop7 -> fc7_clean (in-place)
I0704 10:26:45.074165 20391 net.cpp:153] Setting up drop7
I0704 10:26:45.074168 20391 net.cpp:160] Top shape: 128 4096 (524288)
I0704 10:26:45.074187 20391 net.cpp:168] Memory required for data: 1064351744
I0704 10:26:45.074188 20391 layer_factory.hpp:76] Creating layer fc8_clean
I0704 10:26:45.074193 20391 net.cpp:109] Creating Layer fc8_clean
I0704 10:26:45.074195 20391 net.cpp:457] fc8_clean <- fc7_clean
I0704 10:26:45.074198 20391 net.cpp:414] fc8_clean -> fc8_clean
I0704 10:26:45.145769 20391 net.cpp:153] Setting up fc8_clean
I0704 10:26:45.145787 20391 net.cpp:160] Top shape: 128 967 (123776)
I0704 10:26:45.145790 20391 net.cpp:168] Memory required for data: 1064846848
I0704 10:26:45.145797 20391 layer_factory.hpp:76] Creating layer loss
I0704 10:26:45.145807 20391 net.cpp:109] Creating Layer loss
I0704 10:26:45.145812 20391 net.cpp:457] loss <- fc8_clean
I0704 10:26:45.145814 20391 net.cpp:457] loss <- label
I0704 10:26:45.145818 20391 net.cpp:414] loss -> loss
I0704 10:26:45.145824 20391 layer_factory.hpp:76] Creating layer loss
I0704 10:26:45.146284 20391 net.cpp:153] Setting up loss
I0704 10:26:45.146292 20391 net.cpp:160] Top shape: (1)
I0704 10:26:45.146294 20391 net.cpp:163]     with loss weight 1
I0704 10:26:45.146308 20391 net.cpp:168] Memory required for data: 1064846852
I0704 10:26:45.146311 20391 net.cpp:229] loss needs backward computation.
I0704 10:26:45.146313 20391 net.cpp:229] fc8_clean needs backward computation.
I0704 10:26:45.146316 20391 net.cpp:229] drop7 needs backward computation.
I0704 10:26:45.146317 20391 net.cpp:229] relu7 needs backward computation.
I0704 10:26:45.146318 20391 net.cpp:229] fc7_clean needs backward computation.
I0704 10:26:45.146320 20391 net.cpp:229] drop6 needs backward computation.
I0704 10:26:45.146322 20391 net.cpp:229] relu6 needs backward computation.
I0704 10:26:45.146324 20391 net.cpp:229] fc6_clean needs backward computation.
I0704 10:26:45.146327 20391 net.cpp:231] pool5 does not need backward computation.
I0704 10:26:45.146328 20391 net.cpp:231] relu5 does not need backward computation.
I0704 10:26:45.146330 20391 net.cpp:231] conv5 does not need backward computation.
I0704 10:26:45.146333 20391 net.cpp:231] relu4 does not need backward computation.
I0704 10:26:45.146334 20391 net.cpp:231] conv4 does not need backward computation.
I0704 10:26:45.146337 20391 net.cpp:231] relu3 does not need backward computation.
I0704 10:26:45.146338 20391 net.cpp:231] conv3 does not need backward computation.
I0704 10:26:45.146342 20391 net.cpp:231] pool2 does not need backward computation.
I0704 10:26:45.146343 20391 net.cpp:231] norm2 does not need backward computation.
I0704 10:26:45.146345 20391 net.cpp:231] relu2 does not need backward computation.
I0704 10:26:45.146347 20391 net.cpp:231] conv2 does not need backward computation.
I0704 10:26:45.146349 20391 net.cpp:231] pool1 does not need backward computation.
I0704 10:26:45.146352 20391 net.cpp:231] norm1 does not need backward computation.
I0704 10:26:45.146353 20391 net.cpp:231] relu1 does not need backward computation.
I0704 10:26:45.146355 20391 net.cpp:231] conv1 does not need backward computation.
I0704 10:26:45.146358 20391 net.cpp:231] train-data does not need backward computation.
I0704 10:26:45.146359 20391 net.cpp:273] This network produces output loss
I0704 10:26:45.146368 20391 net.cpp:286] Network initialization done.
I0704 10:26:45.147322 20391 solver.cpp:187] Creating test net (#0) specified by net file: train_val.prototxt
I0704 10:26:45.147368 20391 net.cpp:325] The NetState phase (1) differed from the phase (0) specified by a rule in layer train-data
I0704 10:26:45.147475 20391 net.cpp:52] Initializing net from parameters:
state {
phase: TEST
}
layer {
name: "val-data"
type: "Data"
top: "data"
top: "label"
include {
phase: TEST
}
transform_param {
crop_size: 227
mean_file: "/home/ffw/scratch/digits/jobs/20160624-120053-bb9a/mean.binaryproto"
}
data_param {
source: "/home/ffw/scratch/digits/jobs/20160624-120053-bb9a/val_db"
batch_size: 32
backend: LMDB
}
}
layer {
name: "conv1"
type: "Convolution"
bottom: "data"
top: "conv1"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 11
stride: 4
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu1"
type: "ReLU"
bottom: "conv1"
top: "conv1"
}
layer {
name: "norm1"
type: "LRN"
bottom: "conv1"
top: "norm1"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool1"
type: "Pooling"
bottom: "norm1"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv2"
type: "Convolution"
bottom: "pool1"
top: "conv2"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 2
kernel_size: 5
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu2"
type: "ReLU"
bottom: "conv2"
top: "conv2"
}
layer {
name: "norm2"
type: "LRN"
bottom: "conv2"
top: "norm2"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool2"
type: "Pooling"
bottom: "norm2"
top: "pool2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool2"
top: "conv3"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "conv4"
type: "Convolution"
bottom: "conv3"
top: "conv4"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu4"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "conv5"
type: "Convolution"
bottom: "conv4"
top: "conv5"
param {
lr_mult: 0
decay_mult: 0
}
param {
lr_mult: 0
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "conv5"
top: "conv5"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "conv5"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fc6_clean"
type: "InnerProduct"
bottom: "pool5"
top: "fc6_clean"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "fc6_clean"
top: "fc6_clean"
}
layer {
name: "drop6"
type: "Dropout"
bottom: "fc6_clean"
top: "fc6_clean"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc7_clean"
type: "InnerProduct"
bottom: "fc6_clean"
top: "fc7_clean"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "fc7_clean"
top: "fc7_clean"
}
layer {
name: "drop7"
type: "Dropout"
bottom: "fc7_clean"
top: "fc7_clean"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc8_clean"
type: "InnerProduct"
bottom: "fc7_clean"
top: "fc8_clean"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 967
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "accuracy"
type: "Accuracy"
bottom: "fc8_clean"
bottom: "label"
top: "accuracy"
include {
phase: TEST
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "fc8_clean"
bottom: "label"
top: "loss"
}
I0704 10:26:45.147545 20391 layer_factory.hpp:76] Creating layer val-data
I0704 10:26:45.147596 20391 net.cpp:109] Creating Layer val-data
I0704 10:26:45.147610 20391 net.cpp:414] val-data -> data
I0704 10:26:45.147615 20391 net.cpp:414] val-data -> label
I0704 10:26:45.147619 20391 data_transformer.cpp:25] Loading mean file from: /home/ffw/scratch/digits/jobs/20160624-120053-bb9a/mean.binaryproto
I0704 10:26:45.148793 20405 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/digits/jobs/20160624-120053-bb9a/val_db
I0704 10:26:45.152885 20391 data_layer.cpp:45] output data size: 32,3,227,227
I0704 10:26:45.175771 20391 net.cpp:153] Setting up val-data
I0704 10:26:45.175789 20391 net.cpp:160] Top shape: 32 3 227 227 (4946784)
I0704 10:26:45.175792 20391 net.cpp:160] Top shape: 32 (32)
I0704 10:26:45.175794 20391 net.cpp:168] Memory required for data: 19787264
I0704 10:26:45.175798 20391 layer_factory.hpp:76] Creating layer label_val-data_1_split
I0704 10:26:45.176862 20391 net.cpp:109] Creating Layer label_val-data_1_split
I0704 10:26:45.176867 20391 net.cpp:457] label_val-data_1_split <- label
I0704 10:26:45.176872 20391 net.cpp:414] label_val-data_1_split -> label_val-data_1_split_0
I0704 10:26:45.176877 20391 net.cpp:414] label_val-data_1_split -> label_val-data_1_split_1
I0704 10:26:45.176916 20391 net.cpp:153] Setting up label_val-data_1_split
I0704 10:26:45.176919 20391 net.cpp:160] Top shape: 32 (32)
I0704 10:26:45.176923 20391 net.cpp:160] Top shape: 32 (32)
I0704 10:26:45.176923 20391 net.cpp:168] Memory required for data: 19787520
I0704 10:26:45.176925 20391 layer_factory.hpp:76] Creating layer conv1
I0704 10:26:45.176931 20391 net.cpp:109] Creating Layer conv1
I0704 10:26:45.176934 20391 net.cpp:457] conv1 <- data
I0704 10:26:45.176936 20391 net.cpp:414] conv1 -> conv1
I0704 10:26:45.177901 20391 net.cpp:153] Setting up conv1
I0704 10:26:45.177911 20391 net.cpp:160] Top shape: 32 96 55 55 (9292800)
I0704 10:26:45.177914 20391 net.cpp:168] Memory required for data: 56958720
I0704 10:26:45.177924 20391 layer_factory.hpp:76] Creating layer relu1
I0704 10:26:45.177930 20391 net.cpp:109] Creating Layer relu1
I0704 10:26:45.177933 20391 net.cpp:457] relu1 <- conv1
I0704 10:26:45.177937 20391 net.cpp:400] relu1 -> conv1 (in-place)
I0704 10:26:45.177952 20391 net.cpp:153] Setting up relu1
I0704 10:26:45.177954 20391 net.cpp:160] Top shape: 32 96 55 55 (9292800)
I0704 10:26:45.177956 20391 net.cpp:168] Memory required for data: 94129920
I0704 10:26:45.177958 20391 layer_factory.hpp:76] Creating layer norm1
I0704 10:26:45.177963 20391 net.cpp:109] Creating Layer norm1
I0704 10:26:45.177964 20391 net.cpp:457] norm1 <- conv1
I0704 10:26:45.177966 20391 net.cpp:414] norm1 -> norm1
I0704 10:26:45.177989 20391 net.cpp:153] Setting up norm1
I0704 10:26:45.177992 20391 net.cpp:160] Top shape: 32 96 55 55 (9292800)
I0704 10:26:45.177994 20391 net.cpp:168] Memory required for data: 131301120
I0704 10:26:45.177995 20391 layer_factory.hpp:76] Creating layer pool1
I0704 10:26:45.177999 20391 net.cpp:109] Creating Layer pool1
I0704 10:26:45.178000 20391 net.cpp:457] pool1 <- norm1
I0704 10:26:45.178004 20391 net.cpp:414] pool1 -> pool1
I0704 10:26:45.178020 20391 net.cpp:153] Setting up pool1
I0704 10:26:45.178022 20391 net.cpp:160] Top shape: 32 96 27 27 (2239488)
I0704 10:26:45.178025 20391 net.cpp:168] Memory required for data: 140259072
I0704 10:26:45.178025 20391 layer_factory.hpp:76] Creating layer conv2
I0704 10:26:45.178030 20391 net.cpp:109] Creating Layer conv2
I0704 10:26:45.178031 20391 net.cpp:457] conv2 <- pool1
I0704 10:26:45.178047 20391 net.cpp:414] conv2 -> conv2
I0704 10:26:45.184962 20391 net.cpp:153] Setting up conv2
I0704 10:26:45.184975 20391 net.cpp:160] Top shape: 32 256 27 27 (5971968)
I0704 10:26:45.184978 20391 net.cpp:168] Memory required for data: 164146944
I0704 10:26:45.184985 20391 layer_factory.hpp:76] Creating layer relu2
I0704 10:26:45.184991 20391 net.cpp:109] Creating Layer relu2
I0704 10:26:45.184994 20391 net.cpp:457] relu2 <- conv2
I0704 10:26:45.184998 20391 net.cpp:400] relu2 -> conv2 (in-place)
I0704 10:26:45.185003 20391 net.cpp:153] Setting up relu2
I0704 10:26:45.185006 20391 net.cpp:160] Top shape: 32 256 27 27 (5971968)
I0704 10:26:45.185009 20391 net.cpp:168] Memory required for data: 188034816
I0704 10:26:45.185009 20391 layer_factory.hpp:76] Creating layer norm2
I0704 10:26:45.185015 20391 net.cpp:109] Creating Layer norm2
I0704 10:26:45.185017 20391 net.cpp:457] norm2 <- conv2
I0704 10:26:45.185019 20391 net.cpp:414] norm2 -> norm2
I0704 10:26:45.185060 20391 net.cpp:153] Setting up norm2
I0704 10:26:45.185066 20391 net.cpp:160] Top shape: 32 256 27 27 (5971968)
I0704 10:26:45.185068 20391 net.cpp:168] Memory required for data: 211922688
I0704 10:26:45.185071 20391 layer_factory.hpp:76] Creating layer pool2
I0704 10:26:45.185075 20391 net.cpp:109] Creating Layer pool2
I0704 10:26:45.185080 20391 net.cpp:457] pool2 <- norm2
I0704 10:26:45.185083 20391 net.cpp:414] pool2 -> pool2
I0704 10:26:45.185117 20391 net.cpp:153] Setting up pool2
I0704 10:26:45.185122 20391 net.cpp:160] Top shape: 32 256 13 13 (1384448)
I0704 10:26:45.185124 20391 net.cpp:168] Memory required for data: 217460480
I0704 10:26:45.185127 20391 layer_factory.hpp:76] Creating layer conv3
I0704 10:26:45.185132 20391 net.cpp:109] Creating Layer conv3
I0704 10:26:45.185133 20391 net.cpp:457] conv3 <- pool2
I0704 10:26:45.185137 20391 net.cpp:414] conv3 -> conv3
I0704 10:26:45.202915 20391 net.cpp:153] Setting up conv3
I0704 10:26:45.202930 20391 net.cpp:160] Top shape: 32 384 13 13 (2076672)
I0704 10:26:45.202932 20391 net.cpp:168] Memory required for data: 225767168
I0704 10:26:45.202939 20391 layer_factory.hpp:76] Creating layer relu3
I0704 10:26:45.202945 20391 net.cpp:109] Creating Layer relu3
I0704 10:26:45.202949 20391 net.cpp:457] relu3 <- conv3
I0704 10:26:45.202951 20391 net.cpp:400] relu3 -> conv3 (in-place)
I0704 10:26:45.202956 20391 net.cpp:153] Setting up relu3
I0704 10:26:45.202960 20391 net.cpp:160] Top shape: 32 384 13 13 (2076672)
I0704 10:26:45.202960 20391 net.cpp:168] Memory required for data: 234073856
I0704 10:26:45.202962 20391 layer_factory.hpp:76] Creating layer conv4
I0704 10:26:45.202967 20391 net.cpp:109] Creating Layer conv4
I0704 10:26:45.202970 20391 net.cpp:457] conv4 <- conv3
I0704 10:26:45.202972 20391 net.cpp:414] conv4 -> conv4
I0704 10:26:45.215770 20391 net.cpp:153] Setting up conv4
I0704 10:26:45.215785 20391 net.cpp:160] Top shape: 32 384 13 13 (2076672)
I0704 10:26:45.215786 20391 net.cpp:168] Memory required for data: 242380544
I0704 10:26:45.215791 20391 layer_factory.hpp:76] Creating layer relu4
I0704 10:26:45.215796 20391 net.cpp:109] Creating Layer relu4
I0704 10:26:45.215800 20391 net.cpp:457] relu4 <- conv4
I0704 10:26:45.215803 20391 net.cpp:400] relu4 -> conv4 (in-place)
I0704 10:26:45.215808 20391 net.cpp:153] Setting up relu4
I0704 10:26:45.215811 20391 net.cpp:160] Top shape: 32 384 13 13 (2076672)
I0704 10:26:45.215812 20391 net.cpp:168] Memory required for data: 250687232
I0704 10:26:45.215814 20391 layer_factory.hpp:76] Creating layer conv5
I0704 10:26:45.215819 20391 net.cpp:109] Creating Layer conv5
I0704 10:26:45.215821 20391 net.cpp:457] conv5 <- conv4
I0704 10:26:45.215824 20391 net.cpp:414] conv5 -> conv5
I0704 10:26:45.225457 20391 net.cpp:153] Setting up conv5
I0704 10:26:45.225468 20391 net.cpp:160] Top shape: 32 256 13 13 (1384448)
I0704 10:26:45.225471 20391 net.cpp:168] Memory required for data: 256225024
I0704 10:26:45.225478 20391 layer_factory.hpp:76] Creating layer relu5
I0704 10:26:45.225483 20391 net.cpp:109] Creating Layer relu5
I0704 10:26:45.225498 20391 net.cpp:457] relu5 <- conv5
I0704 10:26:45.225502 20391 net.cpp:400] relu5 -> conv5 (in-place)
I0704 10:26:45.225507 20391 net.cpp:153] Setting up relu5
I0704 10:26:45.225510 20391 net.cpp:160] Top shape: 32 256 13 13 (1384448)
I0704 10:26:45.225512 20391 net.cpp:168] Memory required for data: 261762816
I0704 10:26:45.225513 20391 layer_factory.hpp:76] Creating layer pool5
I0704 10:26:45.225518 20391 net.cpp:109] Creating Layer pool5
I0704 10:26:45.225520 20391 net.cpp:457] pool5 <- conv5
I0704 10:26:45.225523 20391 net.cpp:414] pool5 -> pool5
I0704 10:26:45.225545 20391 net.cpp:153] Setting up pool5
I0704 10:26:45.225548 20391 net.cpp:160] Top shape: 32 256 6 6 (294912)
I0704 10:26:45.225550 20391 net.cpp:168] Memory required for data: 262942464
I0704 10:26:45.225553 20391 layer_factory.hpp:76] Creating layer fc6_clean
I0704 10:26:45.225558 20391 net.cpp:109] Creating Layer fc6_clean
I0704 10:26:45.225558 20391 net.cpp:457] fc6_clean <- pool5
I0704 10:26:45.225561 20391 net.cpp:414] fc6_clean -> fc6_clean
I0704 10:26:45.911588 20391 net.cpp:153] Setting up fc6_clean
I0704 10:26:45.911607 20391 net.cpp:160] Top shape: 32 4096 (131072)
I0704 10:26:45.911610 20391 net.cpp:168] Memory required for data: 263466752
I0704 10:26:45.911617 20391 layer_factory.hpp:76] Creating layer relu6
I0704 10:26:45.911623 20391 net.cpp:109] Creating Layer relu6
I0704 10:26:45.911626 20391 net.cpp:457] relu6 <- fc6_clean
I0704 10:26:45.911630 20391 net.cpp:400] relu6 -> fc6_clean (in-place)
I0704 10:26:45.911638 20391 net.cpp:153] Setting up relu6
I0704 10:26:45.911640 20391 net.cpp:160] Top shape: 32 4096 (131072)
I0704 10:26:45.911641 20391 net.cpp:168] Memory required for data: 263991040
I0704 10:26:45.911644 20391 layer_factory.hpp:76] Creating layer drop6
I0704 10:26:45.911648 20391 net.cpp:109] Creating Layer drop6
I0704 10:26:45.911650 20391 net.cpp:457] drop6 <- fc6_clean
I0704 10:26:45.911653 20391 net.cpp:400] drop6 -> fc6_clean (in-place)
I0704 10:26:45.911671 20391 net.cpp:153] Setting up drop6
I0704 10:26:45.911674 20391 net.cpp:160] Top shape: 32 4096 (131072)
I0704 10:26:45.911676 20391 net.cpp:168] Memory required for data: 264515328
I0704 10:26:45.911677 20391 layer_factory.hpp:76] Creating layer fc7_clean
I0704 10:26:45.911682 20391 net.cpp:109] Creating Layer fc7_clean
I0704 10:26:45.911684 20391 net.cpp:457] fc7_clean <- fc6_clean
I0704 10:26:45.911687 20391 net.cpp:414] fc7_clean -> fc7_clean
I0704 10:26:46.213592 20391 net.cpp:153] Setting up fc7_clean
I0704 10:26:46.213610 20391 net.cpp:160] Top shape: 32 4096 (131072)
I0704 10:26:46.213614 20391 net.cpp:168] Memory required for data: 265039616
I0704 10:26:46.213619 20391 layer_factory.hpp:76] Creating layer relu7
I0704 10:26:46.213626 20391 net.cpp:109] Creating Layer relu7
I0704 10:26:46.213629 20391 net.cpp:457] relu7 <- fc7_clean
I0704 10:26:46.213634 20391 net.cpp:400] relu7 -> fc7_clean (in-place)
I0704 10:26:46.213640 20391 net.cpp:153] Setting up relu7
I0704 10:26:46.213642 20391 net.cpp:160] Top shape: 32 4096 (131072)
I0704 10:26:46.213644 20391 net.cpp:168] Memory required for data: 265563904
I0704 10:26:46.213646 20391 layer_factory.hpp:76] Creating layer drop7
I0704 10:26:46.213650 20391 net.cpp:109] Creating Layer drop7
I0704 10:26:46.213652 20391 net.cpp:457] drop7 <- fc7_clean
I0704 10:26:46.213654 20391 net.cpp:400] drop7 -> fc7_clean (in-place)
I0704 10:26:46.213672 20391 net.cpp:153] Setting up drop7
I0704 10:26:46.213675 20391 net.cpp:160] Top shape: 32 4096 (131072)
I0704 10:26:46.213677 20391 net.cpp:168] Memory required for data: 266088192
I0704 10:26:46.213678 20391 layer_factory.hpp:76] Creating layer fc8_clean
I0704 10:26:46.213683 20391 net.cpp:109] Creating Layer fc8_clean
I0704 10:26:46.213685 20391 net.cpp:457] fc8_clean <- fc7_clean
I0704 10:26:46.213688 20391 net.cpp:414] fc8_clean -> fc8_clean
I0704 10:26:46.285547 20391 net.cpp:153] Setting up fc8_clean
I0704 10:26:46.285563 20391 net.cpp:160] Top shape: 32 967 (30944)
I0704 10:26:46.285567 20391 net.cpp:168] Memory required for data: 266211968
I0704 10:26:46.285589 20391 layer_factory.hpp:76] Creating layer fc8_clean_fc8_clean_0_split
I0704 10:26:46.285596 20391 net.cpp:109] Creating Layer fc8_clean_fc8_clean_0_split
I0704 10:26:46.285599 20391 net.cpp:457] fc8_clean_fc8_clean_0_split <- fc8_clean
I0704 10:26:46.285604 20391 net.cpp:414] fc8_clean_fc8_clean_0_split -> fc8_clean_fc8_clean_0_split_0
I0704 10:26:46.285609 20391 net.cpp:414] fc8_clean_fc8_clean_0_split -> fc8_clean_fc8_clean_0_split_1
I0704 10:26:46.285637 20391 net.cpp:153] Setting up fc8_clean_fc8_clean_0_split
I0704 10:26:46.285640 20391 net.cpp:160] Top shape: 32 967 (30944)
I0704 10:26:46.285642 20391 net.cpp:160] Top shape: 32 967 (30944)
I0704 10:26:46.285645 20391 net.cpp:168] Memory required for data: 266459520
I0704 10:26:46.285646 20391 layer_factory.hpp:76] Creating layer accuracy
I0704 10:26:46.285657 20391 net.cpp:109] Creating Layer accuracy
I0704 10:26:46.285660 20391 net.cpp:457] accuracy <- fc8_clean_fc8_clean_0_split_0
I0704 10:26:46.285661 20391 net.cpp:457] accuracy <- label_val-data_1_split_0
I0704 10:26:46.285665 20391 net.cpp:414] accuracy -> accuracy
I0704 10:26:46.285668 20391 net.cpp:153] Setting up accuracy
I0704 10:26:46.285671 20391 net.cpp:160] Top shape: (1)
I0704 10:26:46.285672 20391 net.cpp:168] Memory required for data: 266459524
I0704 10:26:46.285675 20391 layer_factory.hpp:76] Creating layer loss
I0704 10:26:46.285678 20391 net.cpp:109] Creating Layer loss
I0704 10:26:46.285679 20391 net.cpp:457] loss <- fc8_clean_fc8_clean_0_split_1
I0704 10:26:46.285682 20391 net.cpp:457] loss <- label_val-data_1_split_1
I0704 10:26:46.285684 20391 net.cpp:414] loss -> loss
I0704 10:26:46.285688 20391 layer_factory.hpp:76] Creating layer loss
I0704 10:26:46.285768 20391 net.cpp:153] Setting up loss
I0704 10:26:46.285773 20391 net.cpp:160] Top shape: (1)
I0704 10:26:46.285773 20391 net.cpp:163]     with loss weight 1
I0704 10:26:46.285780 20391 net.cpp:168] Memory required for data: 266459528
I0704 10:26:46.285783 20391 net.cpp:229] loss needs backward computation.
I0704 10:26:46.285784 20391 net.cpp:231] accuracy does not need backward computation.
I0704 10:26:46.285786 20391 net.cpp:229] fc8_clean_fc8_clean_0_split needs backward computation.
I0704 10:26:46.285789 20391 net.cpp:229] fc8_clean needs backward computation.
I0704 10:26:46.285790 20391 net.cpp:229] drop7 needs backward computation.
I0704 10:26:46.285792 20391 net.cpp:229] relu7 needs backward computation.
I0704 10:26:46.285794 20391 net.cpp:229] fc7_clean needs backward computation.
I0704 10:26:46.285796 20391 net.cpp:229] drop6 needs backward computation.
I0704 10:26:46.285799 20391 net.cpp:229] relu6 needs backward computation.
I0704 10:26:46.285800 20391 net.cpp:229] fc6_clean needs backward computation.
I0704 10:26:46.285802 20391 net.cpp:231] pool5 does not need backward computation.
I0704 10:26:46.285804 20391 net.cpp:231] relu5 does not need backward computation.
I0704 10:26:46.285806 20391 net.cpp:231] conv5 does not need backward computation.
I0704 10:26:46.285809 20391 net.cpp:231] relu4 does not need backward computation.
I0704 10:26:46.285810 20391 net.cpp:231] conv4 does not need backward computation.
I0704 10:26:46.285812 20391 net.cpp:231] relu3 does not need backward computation.
I0704 10:26:46.285815 20391 net.cpp:231] conv3 does not need backward computation.
I0704 10:26:46.285816 20391 net.cpp:231] pool2 does not need backward computation.
I0704 10:26:46.285818 20391 net.cpp:231] norm2 does not need backward computation.
I0704 10:26:46.285820 20391 net.cpp:231] relu2 does not need backward computation.
I0704 10:26:46.285822 20391 net.cpp:231] conv2 does not need backward computation.
I0704 10:26:46.285825 20391 net.cpp:231] pool1 does not need backward computation.
I0704 10:26:46.285826 20391 net.cpp:231] norm1 does not need backward computation.
I0704 10:26:46.285828 20391 net.cpp:231] relu1 does not need backward computation.
I0704 10:26:46.285830 20391 net.cpp:231] conv1 does not need backward computation.
I0704 10:26:46.285833 20391 net.cpp:231] label_val-data_1_split does not need backward computation.
I0704 10:26:46.285840 20391 net.cpp:231] val-data does not need backward computation.
I0704 10:26:46.285842 20391 net.cpp:273] This network produces output accuracy
I0704 10:26:46.285845 20391 net.cpp:273] This network produces output loss
I0704 10:26:46.285853 20391 net.cpp:286] Network initialization done.
I0704 10:26:46.285919 20391 solver.cpp:66] Solver scaffolding done.
I0704 10:26:46.286229 20391 caffe.cpp:135] Finetuning from /home/ffw/workspace/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0704 10:26:48.704300 20391 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: /home/ffw/workspace/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0704 10:26:48.704322 20391 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W0704 10:26:48.704327 20391 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0704 10:26:48.704509 20391 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ffw/workspace/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0704 10:26:49.049046 20391 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
I0704 10:26:49.564626 20391 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: /home/ffw/workspace/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0704 10:26:49.564651 20391 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W0704 10:26:49.564652 20391 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0704 10:26:49.564661 20391 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ffw/workspace/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0704 10:26:49.897601 20391 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
I0704 10:26:49.919734 20391 caffe.cpp:220] Starting Optimization
I0704 10:26:49.919752 20391 solver.cpp:294] Solving
I0704 10:26:49.919755 20391 solver.cpp:295] Learning Rate Policy: exp
I0704 10:26:49.920830 20391 solver.cpp:347] Iteration 0, Testing net (#0)
I0704 10:26:50.149230 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 10:27:09.155308 20391 solver.cpp:415]     Test net output #0: accuracy = 0.00120192
I0704 10:27:09.155331 20391 solver.cpp:415]     Test net output #1: loss = 7.07288 (* 1 = 7.07288 loss)
I0704 10:27:09.279695 20391 solver.cpp:243] Iteration 0, loss = 7.58855
I0704 10:27:09.279716 20391 solver.cpp:259]     Train net output #0: loss = 7.58855 (* 1 = 7.58855 loss)
I0704 10:27:09.279726 20391 solver.cpp:590] Iteration 0, lr = 0.01
I0704 10:27:16.361132 20391 solver.cpp:243] Iteration 27, loss = 6.98205
I0704 10:27:16.361358 20391 solver.cpp:259]     Train net output #0: loss = 6.98205 (* 1 = 6.98205 loss)
I0704 10:27:16.361366 20391 solver.cpp:590] Iteration 27, lr = 0.00993754
I0704 10:27:24.093147 20391 solver.cpp:243] Iteration 54, loss = 6.27431
I0704 10:27:24.093170 20391 solver.cpp:259]     Train net output #0: loss = 6.27431 (* 1 = 6.27431 loss)
I0704 10:27:24.093176 20391 solver.cpp:590] Iteration 54, lr = 0.00987547
I0704 10:27:31.835119 20391 solver.cpp:243] Iteration 81, loss = 6.33105
I0704 10:27:31.835144 20391 solver.cpp:259]     Train net output #0: loss = 6.33105 (* 1 = 6.33105 loss)
I0704 10:27:31.835150 20391 solver.cpp:590] Iteration 81, lr = 0.00981378
I0704 10:27:39.589879 20391 solver.cpp:243] Iteration 108, loss = 6.05728
I0704 10:27:39.589905 20391 solver.cpp:259]     Train net output #0: loss = 6.05728 (* 1 = 6.05728 loss)
I0704 10:27:39.589912 20391 solver.cpp:590] Iteration 108, lr = 0.00975248
I0704 10:27:47.299151 20391 solver.cpp:243] Iteration 135, loss = 5.48127
I0704 10:27:47.299263 20391 solver.cpp:259]     Train net output #0: loss = 5.48127 (* 1 = 5.48127 loss)
I0704 10:27:47.299270 20391 solver.cpp:590] Iteration 135, lr = 0.00969157
I0704 10:27:55.044780 20391 solver.cpp:243] Iteration 162, loss = 5.93487
I0704 10:27:55.044803 20391 solver.cpp:259]     Train net output #0: loss = 5.93487 (* 1 = 5.93487 loss)
I0704 10:27:55.044809 20391 solver.cpp:590] Iteration 162, lr = 0.00963103
I0704 10:28:02.749714 20391 solver.cpp:243] Iteration 189, loss = 6.00608
I0704 10:28:02.749738 20391 solver.cpp:259]     Train net output #0: loss = 6.00608 (* 1 = 6.00608 loss)
I0704 10:28:02.749744 20391 solver.cpp:590] Iteration 189, lr = 0.00957087
I0704 10:28:10.468361 20391 solver.cpp:243] Iteration 216, loss = 5.88512
I0704 10:28:10.468384 20391 solver.cpp:259]     Train net output #0: loss = 5.88512 (* 1 = 5.88512 loss)
I0704 10:28:10.468389 20391 solver.cpp:590] Iteration 216, lr = 0.00951109
I0704 10:28:11.607596 20391 solver.cpp:347] Iteration 221, Testing net (#0)
I0704 10:28:30.777953 20391 solver.cpp:415]     Test net output #0: accuracy = 0.096875
I0704 10:28:30.778038 20391 solver.cpp:415]     Test net output #1: loss = 5.1883 (* 1 = 5.1883 loss)
I0704 10:28:36.496064 20391 solver.cpp:243] Iteration 243, loss = 5.57526
I0704 10:28:36.496091 20391 solver.cpp:259]     Train net output #0: loss = 5.57526 (* 1 = 5.57526 loss)
I0704 10:28:36.496096 20391 solver.cpp:590] Iteration 243, lr = 0.00945168
I0704 10:28:44.164156 20391 solver.cpp:243] Iteration 270, loss = 5.50489
I0704 10:28:44.164180 20391 solver.cpp:259]     Train net output #0: loss = 5.50489 (* 1 = 5.50489 loss)
I0704 10:28:44.164186 20391 solver.cpp:590] Iteration 270, lr = 0.00939264
I0704 10:28:51.835613 20391 solver.cpp:243] Iteration 297, loss = 5.56916
I0704 10:28:51.835638 20391 solver.cpp:259]     Train net output #0: loss = 5.56916 (* 1 = 5.56916 loss)
I0704 10:28:51.835644 20391 solver.cpp:590] Iteration 297, lr = 0.00933397
I0704 10:28:59.545869 20391 solver.cpp:243] Iteration 324, loss = 5.75689
I0704 10:28:59.545894 20391 solver.cpp:259]     Train net output #0: loss = 5.75689 (* 1 = 5.75689 loss)
I0704 10:28:59.545900 20391 solver.cpp:590] Iteration 324, lr = 0.00927567
I0704 10:29:07.202364 20391 solver.cpp:243] Iteration 351, loss = 5.49213
I0704 10:29:07.202432 20391 solver.cpp:259]     Train net output #0: loss = 5.49213 (* 1 = 5.49213 loss)
I0704 10:29:07.202448 20391 solver.cpp:590] Iteration 351, lr = 0.00921773
I0704 10:29:14.894824 20391 solver.cpp:243] Iteration 378, loss = 5.29952
I0704 10:29:14.894850 20391 solver.cpp:259]     Train net output #0: loss = 5.29952 (* 1 = 5.29952 loss)
I0704 10:29:14.894855 20391 solver.cpp:590] Iteration 378, lr = 0.00916016
I0704 10:29:22.575266 20391 solver.cpp:243] Iteration 405, loss = 5.33697
I0704 10:29:22.575295 20391 solver.cpp:259]     Train net output #0: loss = 5.33697 (* 1 = 5.33697 loss)
I0704 10:29:22.575302 20391 solver.cpp:590] Iteration 405, lr = 0.00910294
I0704 10:29:30.237623 20391 solver.cpp:243] Iteration 432, loss = 5.57583
I0704 10:29:30.237648 20391 solver.cpp:259]     Train net output #0: loss = 5.57583 (* 1 = 5.57583 loss)
I0704 10:29:30.237654 20391 solver.cpp:590] Iteration 432, lr = 0.00904608
I0704 10:29:32.818230 20391 solver.cpp:347] Iteration 442, Testing net (#0)
I0704 10:29:36.991101 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 10:29:52.018041 20391 solver.cpp:415]     Test net output #0: accuracy = 0.104207
I0704 10:29:52.018112 20391 solver.cpp:415]     Test net output #1: loss = 4.9829 (* 1 = 4.9829 loss)
I0704 10:29:56.335638 20391 solver.cpp:243] Iteration 459, loss = 5.63688
I0704 10:29:56.335662 20391 solver.cpp:259]     Train net output #0: loss = 5.63688 (* 1 = 5.63688 loss)
I0704 10:29:56.335669 20391 solver.cpp:590] Iteration 459, lr = 0.00898958
I0704 10:30:04.031684 20391 solver.cpp:243] Iteration 486, loss = 5.64343
I0704 10:30:04.031711 20391 solver.cpp:259]     Train net output #0: loss = 5.64343 (* 1 = 5.64343 loss)
I0704 10:30:04.031718 20391 solver.cpp:590] Iteration 486, lr = 0.00893343
I0704 10:30:11.722059 20391 solver.cpp:243] Iteration 513, loss = 5.45111
I0704 10:30:11.722084 20391 solver.cpp:259]     Train net output #0: loss = 5.45111 (* 1 = 5.45111 loss)
I0704 10:30:11.722090 20391 solver.cpp:590] Iteration 513, lr = 0.00887763
I0704 10:30:19.421727 20391 solver.cpp:243] Iteration 540, loss = 5.57646
I0704 10:30:19.421751 20391 solver.cpp:259]     Train net output #0: loss = 5.57646 (* 1 = 5.57646 loss)
I0704 10:30:19.421756 20391 solver.cpp:590] Iteration 540, lr = 0.00882217
I0704 10:30:27.123157 20391 solver.cpp:243] Iteration 567, loss = 5.60512
I0704 10:30:27.123255 20391 solver.cpp:259]     Train net output #0: loss = 5.60512 (* 1 = 5.60512 loss)
I0704 10:30:27.123270 20391 solver.cpp:590] Iteration 567, lr = 0.00876707
I0704 10:30:34.831248 20391 solver.cpp:243] Iteration 594, loss = 5.6082
I0704 10:30:34.831275 20391 solver.cpp:259]     Train net output #0: loss = 5.6082 (* 1 = 5.6082 loss)
I0704 10:30:34.831281 20391 solver.cpp:590] Iteration 594, lr = 0.00871231
I0704 10:30:42.547322 20391 solver.cpp:243] Iteration 621, loss = 5.70551
I0704 10:30:42.547348 20391 solver.cpp:259]     Train net output #0: loss = 5.70551 (* 1 = 5.70551 loss)
I0704 10:30:42.547354 20391 solver.cpp:590] Iteration 621, lr = 0.00865789
I0704 10:30:50.224933 20391 solver.cpp:243] Iteration 648, loss = 5.8104
I0704 10:30:50.224957 20391 solver.cpp:259]     Train net output #0: loss = 5.8104 (* 1 = 5.8104 loss)
I0704 10:30:50.224962 20391 solver.cpp:590] Iteration 648, lr = 0.00860381
I0704 10:30:54.216882 20391 solver.cpp:347] Iteration 663, Testing net (#0)
I0704 10:31:13.731410 20391 solver.cpp:415]     Test net output #0: accuracy = 0.117668
I0704 10:31:13.731487 20391 solver.cpp:415]     Test net output #1: loss = 4.98357 (* 1 = 4.98357 loss)
I0704 10:31:16.626051 20391 solver.cpp:243] Iteration 675, loss = 5.55828
I0704 10:31:16.626097 20391 solver.cpp:259]     Train net output #0: loss = 5.55828 (* 1 = 5.55828 loss)
I0704 10:31:16.626104 20391 solver.cpp:590] Iteration 675, lr = 0.00855007
I0704 10:31:24.308609 20391 solver.cpp:243] Iteration 702, loss = 5.32804
I0704 10:31:24.308634 20391 solver.cpp:259]     Train net output #0: loss = 5.32804 (* 1 = 5.32804 loss)
I0704 10:31:24.308641 20391 solver.cpp:590] Iteration 702, lr = 0.00849666
I0704 10:31:32.009438 20391 solver.cpp:243] Iteration 729, loss = 5.35486
I0704 10:31:32.009461 20391 solver.cpp:259]     Train net output #0: loss = 5.35486 (* 1 = 5.35486 loss)
I0704 10:31:32.009466 20391 solver.cpp:590] Iteration 729, lr = 0.00844359
I0704 10:31:39.708461 20391 solver.cpp:243] Iteration 756, loss = 5.38975
I0704 10:31:39.708487 20391 solver.cpp:259]     Train net output #0: loss = 5.38975 (* 1 = 5.38975 loss)
I0704 10:31:39.708492 20391 solver.cpp:590] Iteration 756, lr = 0.00839085
I0704 10:31:47.407018 20391 solver.cpp:243] Iteration 783, loss = 5.1833
I0704 10:31:47.407090 20391 solver.cpp:259]     Train net output #0: loss = 5.1833 (* 1 = 5.1833 loss)
I0704 10:31:47.407107 20391 solver.cpp:590] Iteration 783, lr = 0.00833844
I0704 10:31:55.096678 20391 solver.cpp:243] Iteration 810, loss = 5.02522
I0704 10:31:55.096704 20391 solver.cpp:259]     Train net output #0: loss = 5.02522 (* 1 = 5.02522 loss)
I0704 10:31:55.096710 20391 solver.cpp:590] Iteration 810, lr = 0.00828636
I0704 10:32:02.797651 20391 solver.cpp:243] Iteration 837, loss = 5.66589
I0704 10:32:02.797677 20391 solver.cpp:259]     Train net output #0: loss = 5.66589 (* 1 = 5.66589 loss)
I0704 10:32:02.797683 20391 solver.cpp:590] Iteration 837, lr = 0.0082346
I0704 10:32:10.445014 20391 solver.cpp:243] Iteration 864, loss = 5.37551
I0704 10:32:10.445039 20391 solver.cpp:259]     Train net output #0: loss = 5.37551 (* 1 = 5.37551 loss)
I0704 10:32:10.445044 20391 solver.cpp:590] Iteration 864, lr = 0.00818316
I0704 10:32:15.841713 20391 solver.cpp:347] Iteration 884, Testing net (#0)
I0704 10:32:24.196044 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 10:32:35.568874 20391 solver.cpp:415]     Test net output #0: accuracy = 0.124159
I0704 10:32:35.568898 20391 solver.cpp:415]     Test net output #1: loss = 5.01196 (* 1 = 5.01196 loss)
I0704 10:32:37.071691 20391 solver.cpp:243] Iteration 891, loss = 5.45471
I0704 10:32:37.071715 20391 solver.cpp:259]     Train net output #0: loss = 5.45471 (* 1 = 5.45471 loss)
I0704 10:32:37.071722 20391 solver.cpp:590] Iteration 891, lr = 0.00813205
I0704 10:32:44.793236 20391 solver.cpp:243] Iteration 918, loss = 5.49012
I0704 10:32:44.793261 20391 solver.cpp:259]     Train net output #0: loss = 5.49012 (* 1 = 5.49012 loss)
I0704 10:32:44.793267 20391 solver.cpp:590] Iteration 918, lr = 0.00808125
I0704 10:32:52.600165 20391 solver.cpp:243] Iteration 945, loss = 5.23331
I0704 10:32:52.600191 20391 solver.cpp:259]     Train net output #0: loss = 5.23331 (* 1 = 5.23331 loss)
I0704 10:32:52.600198 20391 solver.cpp:590] Iteration 945, lr = 0.00803078
I0704 10:33:00.443774 20391 solver.cpp:243] Iteration 972, loss = 5.32395
I0704 10:33:00.443846 20391 solver.cpp:259]     Train net output #0: loss = 5.32395 (* 1 = 5.32395 loss)
I0704 10:33:00.443862 20391 solver.cpp:590] Iteration 972, lr = 0.00798061
I0704 10:33:08.345453 20391 solver.cpp:243] Iteration 999, loss = 5.11604
I0704 10:33:08.345477 20391 solver.cpp:259]     Train net output #0: loss = 5.11604 (* 1 = 5.11604 loss)
I0704 10:33:08.345484 20391 solver.cpp:590] Iteration 999, lr = 0.00793076
I0704 10:33:16.018121 20391 solver.cpp:243] Iteration 1026, loss = 5.35271
I0704 10:33:16.018146 20391 solver.cpp:259]     Train net output #0: loss = 5.35271 (* 1 = 5.35271 loss)
I0704 10:33:16.018151 20391 solver.cpp:590] Iteration 1026, lr = 0.00788123
I0704 10:33:23.706794 20391 solver.cpp:243] Iteration 1053, loss = 5.28292
I0704 10:33:23.706820 20391 solver.cpp:259]     Train net output #0: loss = 5.28292 (* 1 = 5.28292 loss)
I0704 10:33:23.706825 20391 solver.cpp:590] Iteration 1053, lr = 0.007832
I0704 10:33:31.366027 20391 solver.cpp:243] Iteration 1080, loss = 5.29628
I0704 10:33:31.366092 20391 solver.cpp:259]     Train net output #0: loss = 5.29628 (* 1 = 5.29628 loss)
I0704 10:33:31.366099 20391 solver.cpp:590] Iteration 1080, lr = 0.00778308
I0704 10:33:38.172291 20391 solver.cpp:347] Iteration 1105, Testing net (#0)
I0704 10:33:57.302402 20391 solver.cpp:415]     Test net output #0: accuracy = 0.136418
I0704 10:33:57.302426 20391 solver.cpp:415]     Test net output #1: loss = 4.92298 (* 1 = 4.92298 loss)
I0704 10:33:57.532001 20391 solver.cpp:243] Iteration 1107, loss = 5.46914
I0704 10:33:57.532026 20391 solver.cpp:259]     Train net output #0: loss = 5.46914 (* 1 = 5.46914 loss)
I0704 10:33:57.532032 20391 solver.cpp:590] Iteration 1107, lr = 0.00773446
I0704 10:34:05.019634 20391 solver.cpp:243] Iteration 1134, loss = 5.15128
I0704 10:34:05.019716 20391 solver.cpp:259]     Train net output #0: loss = 5.15128 (* 1 = 5.15128 loss)
I0704 10:34:05.019723 20391 solver.cpp:590] Iteration 1134, lr = 0.00768615
I0704 10:34:12.693440 20391 solver.cpp:243] Iteration 1161, loss = 5.36363
I0704 10:34:12.693464 20391 solver.cpp:259]     Train net output #0: loss = 5.36363 (* 1 = 5.36363 loss)
I0704 10:34:12.693470 20391 solver.cpp:590] Iteration 1161, lr = 0.00763814
I0704 10:34:20.363692 20391 solver.cpp:243] Iteration 1188, loss = 5.16996
I0704 10:34:20.363718 20391 solver.cpp:259]     Train net output #0: loss = 5.16996 (* 1 = 5.16996 loss)
I0704 10:34:20.363724 20391 solver.cpp:590] Iteration 1188, lr = 0.00759043
I0704 10:34:28.051077 20391 solver.cpp:243] Iteration 1215, loss = 5.39929
I0704 10:34:28.051101 20391 solver.cpp:259]     Train net output #0: loss = 5.39929 (* 1 = 5.39929 loss)
I0704 10:34:28.051107 20391 solver.cpp:590] Iteration 1215, lr = 0.00754302
I0704 10:34:35.724548 20391 solver.cpp:243] Iteration 1242, loss = 4.90543
I0704 10:34:35.724618 20391 solver.cpp:259]     Train net output #0: loss = 4.90543 (* 1 = 4.90543 loss)
I0704 10:34:35.724635 20391 solver.cpp:590] Iteration 1242, lr = 0.0074959
I0704 10:34:43.417953 20391 solver.cpp:243] Iteration 1269, loss = 5.04777
I0704 10:34:43.417979 20391 solver.cpp:259]     Train net output #0: loss = 5.04777 (* 1 = 5.04777 loss)
I0704 10:34:43.417984 20391 solver.cpp:590] Iteration 1269, lr = 0.00744908
I0704 10:34:51.089658 20391 solver.cpp:243] Iteration 1296, loss = 4.95618
I0704 10:34:51.089682 20391 solver.cpp:259]     Train net output #0: loss = 4.95618 (* 1 = 4.95618 loss)
I0704 10:34:51.089690 20391 solver.cpp:590] Iteration 1296, lr = 0.00740256
I0704 10:34:58.747200 20391 solver.cpp:243] Iteration 1323, loss = 5.12945
I0704 10:34:58.747225 20391 solver.cpp:259]     Train net output #0: loss = 5.12945 (* 1 = 5.12945 loss)
I0704 10:34:58.747231 20391 solver.cpp:590] Iteration 1323, lr = 0.00735632
I0704 10:34:59.312995 20391 solver.cpp:347] Iteration 1326, Testing net (#0)
I0704 10:35:11.364876 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 10:35:18.674597 20391 solver.cpp:415]     Test net output #0: accuracy = 0.147236
I0704 10:35:18.674621 20391 solver.cpp:415]     Test net output #1: loss = 4.96264 (* 1 = 4.96264 loss)
I0704 10:35:24.973368 20391 solver.cpp:243] Iteration 1350, loss = 5.28577
I0704 10:35:24.973394 20391 solver.cpp:259]     Train net output #0: loss = 5.28577 (* 1 = 5.28577 loss)
I0704 10:35:24.973400 20391 solver.cpp:590] Iteration 1350, lr = 0.00731037
I0704 10:35:32.637929 20391 solver.cpp:243] Iteration 1377, loss = 5.21139
I0704 10:35:32.637953 20391 solver.cpp:259]     Train net output #0: loss = 5.21139 (* 1 = 5.21139 loss)
I0704 10:35:32.637960 20391 solver.cpp:590] Iteration 1377, lr = 0.0072647
I0704 10:35:40.305513 20391 solver.cpp:243] Iteration 1404, loss = 5.4511
I0704 10:35:40.305538 20391 solver.cpp:259]     Train net output #0: loss = 5.4511 (* 1 = 5.4511 loss)
I0704 10:35:40.305543 20391 solver.cpp:590] Iteration 1404, lr = 0.00721933
I0704 10:35:47.983645 20391 solver.cpp:243] Iteration 1431, loss = 5.12097
I0704 10:35:47.983762 20391 solver.cpp:259]     Train net output #0: loss = 5.12097 (* 1 = 5.12097 loss)
I0704 10:35:47.983768 20391 solver.cpp:590] Iteration 1431, lr = 0.00717423
I0704 10:35:55.637593 20391 solver.cpp:243] Iteration 1458, loss = 5.3075
I0704 10:35:55.637619 20391 solver.cpp:259]     Train net output #0: loss = 5.3075 (* 1 = 5.3075 loss)
I0704 10:35:55.637625 20391 solver.cpp:590] Iteration 1458, lr = 0.00712942
I0704 10:36:03.329020 20391 solver.cpp:243] Iteration 1485, loss = 5.2883
I0704 10:36:03.329044 20391 solver.cpp:259]     Train net output #0: loss = 5.2883 (* 1 = 5.2883 loss)
I0704 10:36:03.329049 20391 solver.cpp:590] Iteration 1485, lr = 0.00708489
I0704 10:36:10.994354 20391 solver.cpp:243] Iteration 1512, loss = 4.97688
I0704 10:36:10.994381 20391 solver.cpp:259]     Train net output #0: loss = 4.97688 (* 1 = 4.97688 loss)
I0704 10:36:10.994387 20391 solver.cpp:590] Iteration 1512, lr = 0.00704064
I0704 10:36:18.645290 20391 solver.cpp:243] Iteration 1539, loss = 5.09726
I0704 10:36:18.645407 20391 solver.cpp:259]     Train net output #0: loss = 5.09726 (* 1 = 5.09726 loss)
I0704 10:36:18.645416 20391 solver.cpp:590] Iteration 1539, lr = 0.00699666
I0704 10:36:20.630694 20391 solver.cpp:347] Iteration 1547, Testing net (#0)
I0704 10:36:39.911005 20391 solver.cpp:415]     Test net output #0: accuracy = 0.158293
I0704 10:36:39.911029 20391 solver.cpp:415]     Test net output #1: loss = 4.94501 (* 1 = 4.94501 loss)
I0704 10:36:44.787824 20391 solver.cpp:243] Iteration 1566, loss = 4.99401
I0704 10:36:44.787849 20391 solver.cpp:259]     Train net output #0: loss = 4.99401 (* 1 = 4.99401 loss)
I0704 10:36:44.787855 20391 solver.cpp:590] Iteration 1566, lr = 0.00695296
I0704 10:36:52.458019 20391 solver.cpp:243] Iteration 1593, loss = 5.05491
I0704 10:36:52.458099 20391 solver.cpp:259]     Train net output #0: loss = 5.05491 (* 1 = 5.05491 loss)
I0704 10:36:52.458106 20391 solver.cpp:590] Iteration 1593, lr = 0.00690953
I0704 10:37:00.138865 20391 solver.cpp:243] Iteration 1620, loss = 5.00309
I0704 10:37:00.138890 20391 solver.cpp:259]     Train net output #0: loss = 5.00309 (* 1 = 5.00309 loss)
I0704 10:37:00.138896 20391 solver.cpp:590] Iteration 1620, lr = 0.00686637
I0704 10:37:07.826737 20391 solver.cpp:243] Iteration 1647, loss = 4.75939
I0704 10:37:07.826761 20391 solver.cpp:259]     Train net output #0: loss = 4.75939 (* 1 = 4.75939 loss)
I0704 10:37:07.826766 20391 solver.cpp:590] Iteration 1647, lr = 0.00682348
I0704 10:37:15.498904 20391 solver.cpp:243] Iteration 1674, loss = 4.49053
I0704 10:37:15.498930 20391 solver.cpp:259]     Train net output #0: loss = 4.49053 (* 1 = 4.49053 loss)
I0704 10:37:15.498937 20391 solver.cpp:590] Iteration 1674, lr = 0.00678086
I0704 10:37:23.196576 20391 solver.cpp:243] Iteration 1701, loss = 5.08698
I0704 10:37:23.196712 20391 solver.cpp:259]     Train net output #0: loss = 5.08698 (* 1 = 5.08698 loss)
I0704 10:37:23.196719 20391 solver.cpp:590] Iteration 1701, lr = 0.0067385
I0704 10:37:30.896234 20391 solver.cpp:243] Iteration 1728, loss = 5.14505
I0704 10:37:30.896260 20391 solver.cpp:259]     Train net output #0: loss = 5.14505 (* 1 = 5.14505 loss)
I0704 10:37:30.896265 20391 solver.cpp:590] Iteration 1728, lr = 0.00669641
I0704 10:37:38.555475 20391 solver.cpp:243] Iteration 1755, loss = 4.8052
I0704 10:37:38.555500 20391 solver.cpp:259]     Train net output #0: loss = 4.8052 (* 1 = 4.8052 loss)
I0704 10:37:38.555507 20391 solver.cpp:590] Iteration 1755, lr = 0.00665458
I0704 10:37:41.968406 20391 solver.cpp:347] Iteration 1768, Testing net (#0)
I0704 10:37:57.657974 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 10:38:01.071594 20391 solver.cpp:415]     Test net output #0: accuracy = 0.175481
I0704 10:38:01.071619 20391 solver.cpp:415]     Test net output #1: loss = 4.71319 (* 1 = 4.71319 loss)
I0704 10:38:04.532017 20391 solver.cpp:243] Iteration 1782, loss = 4.70031
I0704 10:38:04.532042 20391 solver.cpp:259]     Train net output #0: loss = 4.70031 (* 1 = 4.70031 loss)
I0704 10:38:04.532047 20391 solver.cpp:590] Iteration 1782, lr = 0.00661302
I0704 10:38:12.204144 20391 solver.cpp:243] Iteration 1809, loss = 4.56965
I0704 10:38:12.204169 20391 solver.cpp:259]     Train net output #0: loss = 4.56965 (* 1 = 4.56965 loss)
I0704 10:38:12.204175 20391 solver.cpp:590] Iteration 1809, lr = 0.00657171
I0704 10:38:19.887567 20391 solver.cpp:243] Iteration 1836, loss = 4.63278
I0704 10:38:19.887593 20391 solver.cpp:259]     Train net output #0: loss = 4.63278 (* 1 = 4.63278 loss)
I0704 10:38:19.887599 20391 solver.cpp:590] Iteration 1836, lr = 0.00653066
I0704 10:38:27.575325 20391 solver.cpp:243] Iteration 1863, loss = 4.99897
I0704 10:38:27.575350 20391 solver.cpp:259]     Train net output #0: loss = 4.99897 (* 1 = 4.99897 loss)
I0704 10:38:27.575356 20391 solver.cpp:590] Iteration 1863, lr = 0.00648987
I0704 10:38:35.249438 20391 solver.cpp:243] Iteration 1890, loss = 4.82458
I0704 10:38:35.249508 20391 solver.cpp:259]     Train net output #0: loss = 4.82458 (* 1 = 4.82458 loss)
I0704 10:38:35.249524 20391 solver.cpp:590] Iteration 1890, lr = 0.00644933
I0704 10:38:42.932006 20391 solver.cpp:243] Iteration 1917, loss = 4.84589
I0704 10:38:42.932032 20391 solver.cpp:259]     Train net output #0: loss = 4.84589 (* 1 = 4.84589 loss)
I0704 10:38:42.932039 20391 solver.cpp:590] Iteration 1917, lr = 0.00640905
I0704 10:38:50.657893 20391 solver.cpp:243] Iteration 1944, loss = 4.81717
I0704 10:38:50.657918 20391 solver.cpp:259]     Train net output #0: loss = 4.81717 (* 1 = 4.81717 loss)
I0704 10:38:50.657924 20391 solver.cpp:590] Iteration 1944, lr = 0.00636902
I0704 10:38:58.317903 20391 solver.cpp:243] Iteration 1971, loss = 4.60641
I0704 10:38:58.317936 20391 solver.cpp:259]     Train net output #0: loss = 4.60641 (* 1 = 4.60641 loss)
I0704 10:38:58.317942 20391 solver.cpp:590] Iteration 1971, lr = 0.00632924
I0704 10:39:03.134814 20391 solver.cpp:347] Iteration 1989, Testing net (#0)
I0704 10:39:22.365942 20391 solver.cpp:415]     Test net output #0: accuracy = 0.197596
I0704 10:39:22.366013 20391 solver.cpp:415]     Test net output #1: loss = 4.49978 (* 1 = 4.49978 loss)
I0704 10:39:24.422142 20391 solver.cpp:243] Iteration 1998, loss = 4.91662
I0704 10:39:24.422168 20391 solver.cpp:259]     Train net output #0: loss = 4.91662 (* 1 = 4.91662 loss)
I0704 10:39:24.422173 20391 solver.cpp:590] Iteration 1998, lr = 0.0062897
I0704 10:39:32.104079 20391 solver.cpp:243] Iteration 2025, loss = 4.78607
I0704 10:39:32.104104 20391 solver.cpp:259]     Train net output #0: loss = 4.78607 (* 1 = 4.78607 loss)
I0704 10:39:32.104110 20391 solver.cpp:590] Iteration 2025, lr = 0.00625041
I0704 10:39:40.508884 20391 solver.cpp:243] Iteration 2052, loss = 4.49879
I0704 10:39:40.508911 20391 solver.cpp:259]     Train net output #0: loss = 4.49879 (* 1 = 4.49879 loss)
I0704 10:39:40.508918 20391 solver.cpp:590] Iteration 2052, lr = 0.00621137
I0704 10:39:49.898028 20391 solver.cpp:243] Iteration 2079, loss = 4.70002
I0704 10:39:49.898054 20391 solver.cpp:259]     Train net output #0: loss = 4.70002 (* 1 = 4.70002 loss)
I0704 10:39:49.898061 20391 solver.cpp:590] Iteration 2079, lr = 0.00617258
I0704 10:39:59.306188 20391 solver.cpp:243] Iteration 2106, loss = 4.6126
I0704 10:39:59.306291 20391 solver.cpp:259]     Train net output #0: loss = 4.6126 (* 1 = 4.6126 loss)
I0704 10:39:59.306298 20391 solver.cpp:590] Iteration 2106, lr = 0.00613402
I0704 10:40:08.085666 20391 solver.cpp:243] Iteration 2133, loss = 4.66342
I0704 10:40:08.085695 20391 solver.cpp:259]     Train net output #0: loss = 4.66342 (* 1 = 4.66342 loss)
I0704 10:40:08.085710 20391 solver.cpp:590] Iteration 2133, lr = 0.00609571
I0704 10:40:17.152109 20391 solver.cpp:243] Iteration 2160, loss = 5.0977
I0704 10:40:17.152134 20391 solver.cpp:259]     Train net output #0: loss = 5.0977 (* 1 = 5.0977 loss)
I0704 10:40:17.152140 20391 solver.cpp:590] Iteration 2160, lr = 0.00605763
I0704 10:40:25.733294 20391 solver.cpp:243] Iteration 2187, loss = 4.9836
I0704 10:40:25.733319 20391 solver.cpp:259]     Train net output #0: loss = 4.9836 (* 1 = 4.9836 loss)
I0704 10:40:25.733326 20391 solver.cpp:590] Iteration 2187, lr = 0.00601979
I0704 10:40:32.716444 20391 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_2210.caffemodel
I0704 10:40:39.864702 20391 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_2210.solverstate
I0704 10:40:40.931813 20391 solver.cpp:347] Iteration 2210, Testing net (#0)
I0704 10:41:00.062439 20391 solver.cpp:415]     Test net output #0: accuracy = 0.190986
I0704 10:41:00.062463 20391 solver.cpp:415]     Test net output #1: loss = 4.63771 (* 1 = 4.63771 loss)
I0704 10:41:00.694547 20391 solver.cpp:243] Iteration 2214, loss = 4.78064
I0704 10:41:00.694572 20391 solver.cpp:259]     Train net output #0: loss = 4.78064 (* 1 = 4.78064 loss)
I0704 10:41:00.694578 20391 solver.cpp:590] Iteration 2214, lr = 0.00598219
I0704 10:41:02.106119 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 10:41:08.399461 20391 solver.cpp:243] Iteration 2241, loss = 4.359
I0704 10:41:08.399518 20391 solver.cpp:259]     Train net output #0: loss = 4.359 (* 1 = 4.359 loss)
I0704 10:41:08.399525 20391 solver.cpp:590] Iteration 2241, lr = 0.00594483
I0704 10:41:16.094944 20391 solver.cpp:243] Iteration 2268, loss = 4.54705
I0704 10:41:16.094966 20391 solver.cpp:259]     Train net output #0: loss = 4.54705 (* 1 = 4.54705 loss)
I0704 10:41:16.094972 20391 solver.cpp:590] Iteration 2268, lr = 0.00590769
I0704 10:41:23.933969 20391 solver.cpp:243] Iteration 2295, loss = 4.42914
I0704 10:41:23.934015 20391 solver.cpp:259]     Train net output #0: loss = 4.42914 (* 1 = 4.42914 loss)
I0704 10:41:23.934022 20391 solver.cpp:590] Iteration 2295, lr = 0.00587079
I0704 10:41:31.625887 20391 solver.cpp:243] Iteration 2322, loss = 4.65195
I0704 10:41:31.625915 20391 solver.cpp:259]     Train net output #0: loss = 4.65195 (* 1 = 4.65195 loss)
I0704 10:41:31.625919 20391 solver.cpp:590] Iteration 2322, lr = 0.00583412
I0704 10:41:39.356245 20391 solver.cpp:243] Iteration 2349, loss = 4.53891
I0704 10:41:39.356314 20391 solver.cpp:259]     Train net output #0: loss = 4.53891 (* 1 = 4.53891 loss)
I0704 10:41:39.356331 20391 solver.cpp:590] Iteration 2349, lr = 0.00579768
I0704 10:41:47.065860 20391 solver.cpp:243] Iteration 2376, loss = 4.37148
I0704 10:41:47.065884 20391 solver.cpp:259]     Train net output #0: loss = 4.37148 (* 1 = 4.37148 loss)
I0704 10:41:47.065889 20391 solver.cpp:590] Iteration 2376, lr = 0.00576147
I0704 10:41:54.730814 20391 solver.cpp:243] Iteration 2403, loss = 4.22217
I0704 10:41:54.730839 20391 solver.cpp:259]     Train net output #0: loss = 4.22217 (* 1 = 4.22217 loss)
I0704 10:41:54.730845 20391 solver.cpp:590] Iteration 2403, lr = 0.00572548
I0704 10:42:02.452141 20391 solver.cpp:243] Iteration 2430, loss = 4.34663
I0704 10:42:02.452167 20391 solver.cpp:259]     Train net output #0: loss = 4.34663 (* 1 = 4.34663 loss)
I0704 10:42:02.452173 20391 solver.cpp:590] Iteration 2430, lr = 0.00568972
I0704 10:42:02.452385 20391 solver.cpp:347] Iteration 2431, Testing net (#0)
I0704 10:42:21.568132 20391 solver.cpp:415]     Test net output #0: accuracy = 0.195673
I0704 10:42:21.568238 20391 solver.cpp:415]     Test net output #1: loss = 4.48841 (* 1 = 4.48841 loss)
I0704 10:42:28.441751 20391 solver.cpp:243] Iteration 2457, loss = 4.01721
I0704 10:42:28.441777 20391 solver.cpp:259]     Train net output #0: loss = 4.01721 (* 1 = 4.01721 loss)
I0704 10:42:28.441783 20391 solver.cpp:590] Iteration 2457, lr = 0.00565418
I0704 10:42:36.109702 20391 solver.cpp:243] Iteration 2484, loss = 4.22594
I0704 10:42:36.109729 20391 solver.cpp:259]     Train net output #0: loss = 4.22594 (* 1 = 4.22594 loss)
I0704 10:42:36.109733 20391 solver.cpp:590] Iteration 2484, lr = 0.00561886
I0704 10:42:43.774246 20391 solver.cpp:243] Iteration 2511, loss = 4.08526
I0704 10:42:43.774272 20391 solver.cpp:259]     Train net output #0: loss = 4.08526 (* 1 = 4.08526 loss)
I0704 10:42:43.774278 20391 solver.cpp:590] Iteration 2511, lr = 0.00558376
I0704 10:42:51.465847 20391 solver.cpp:243] Iteration 2538, loss = 4.3203
I0704 10:42:51.465874 20391 solver.cpp:259]     Train net output #0: loss = 4.3203 (* 1 = 4.3203 loss)
I0704 10:42:51.465883 20391 solver.cpp:590] Iteration 2538, lr = 0.00554888
I0704 10:42:59.130897 20391 solver.cpp:243] Iteration 2565, loss = 4.39523
I0704 10:42:59.131016 20391 solver.cpp:259]     Train net output #0: loss = 4.39523 (* 1 = 4.39523 loss)
I0704 10:42:59.131021 20391 solver.cpp:590] Iteration 2565, lr = 0.00551422
I0704 10:43:06.823436 20391 solver.cpp:243] Iteration 2592, loss = 4.10894
I0704 10:43:06.823462 20391 solver.cpp:259]     Train net output #0: loss = 4.10894 (* 1 = 4.10894 loss)
I0704 10:43:06.823467 20391 solver.cpp:590] Iteration 2592, lr = 0.00547978
I0704 10:43:14.492938 20391 solver.cpp:243] Iteration 2619, loss = 4.42199
I0704 10:43:14.492965 20391 solver.cpp:259]     Train net output #0: loss = 4.42199 (* 1 = 4.42199 loss)
I0704 10:43:14.492971 20391 solver.cpp:590] Iteration 2619, lr = 0.00544555
I0704 10:43:22.148406 20391 solver.cpp:243] Iteration 2646, loss = 4.42598
I0704 10:43:22.148432 20391 solver.cpp:259]     Train net output #0: loss = 4.42598 (* 1 = 4.42598 loss)
I0704 10:43:22.148437 20391 solver.cpp:590] Iteration 2646, lr = 0.00541154
I0704 10:43:23.555266 20391 solver.cpp:347] Iteration 2652, Testing net (#0)
I0704 10:43:42.783869 20391 solver.cpp:415]     Test net output #0: accuracy = 0.219591
I0704 10:43:42.783946 20391 solver.cpp:415]     Test net output #1: loss = 4.36971 (* 1 = 4.36971 loss)
I0704 10:43:48.239676 20391 solver.cpp:243] Iteration 2673, loss = 3.89024
I0704 10:43:48.239701 20391 solver.cpp:259]     Train net output #0: loss = 3.89024 (* 1 = 3.89024 loss)
I0704 10:43:48.239706 20391 solver.cpp:590] Iteration 2673, lr = 0.00537774
I0704 10:43:55.923329 20391 solver.cpp:243] Iteration 2700, loss = 4.32055
I0704 10:43:55.923354 20391 solver.cpp:259]     Train net output #0: loss = 4.32055 (* 1 = 4.32055 loss)
I0704 10:43:55.923360 20391 solver.cpp:590] Iteration 2700, lr = 0.00534415
I0704 10:43:59.623309 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 10:44:03.601794 20391 solver.cpp:243] Iteration 2727, loss = 4.00116
I0704 10:44:03.601819 20391 solver.cpp:259]     Train net output #0: loss = 4.00116 (* 1 = 4.00116 loss)
I0704 10:44:03.601825 20391 solver.cpp:590] Iteration 2727, lr = 0.00531077
I0704 10:44:11.300678 20391 solver.cpp:243] Iteration 2754, loss = 4.21502
I0704 10:44:11.300703 20391 solver.cpp:259]     Train net output #0: loss = 4.21502 (* 1 = 4.21502 loss)
I0704 10:44:11.300707 20391 solver.cpp:590] Iteration 2754, lr = 0.00527759
I0704 10:44:18.969027 20391 solver.cpp:243] Iteration 2781, loss = 3.90716
I0704 10:44:18.969111 20391 solver.cpp:259]     Train net output #0: loss = 3.90716 (* 1 = 3.90716 loss)
I0704 10:44:18.969118 20391 solver.cpp:590] Iteration 2781, lr = 0.00524463
I0704 10:44:26.688906 20391 solver.cpp:243] Iteration 2808, loss = 4.32213
I0704 10:44:26.688931 20391 solver.cpp:259]     Train net output #0: loss = 4.32213 (* 1 = 4.32213 loss)
I0704 10:44:26.688937 20391 solver.cpp:590] Iteration 2808, lr = 0.00521187
I0704 10:44:34.372660 20391 solver.cpp:243] Iteration 2835, loss = 4.29669
I0704 10:44:34.372687 20391 solver.cpp:259]     Train net output #0: loss = 4.29669 (* 1 = 4.29669 loss)
I0704 10:44:34.372704 20391 solver.cpp:590] Iteration 2835, lr = 0.00517932
I0704 10:44:42.086442 20391 solver.cpp:243] Iteration 2862, loss = 3.84364
I0704 10:44:42.086467 20391 solver.cpp:259]     Train net output #0: loss = 3.84364 (* 1 = 3.84364 loss)
I0704 10:44:42.086472 20391 solver.cpp:590] Iteration 2862, lr = 0.00514696
I0704 10:44:44.969866 20391 solver.cpp:347] Iteration 2873, Testing net (#0)
I0704 10:45:04.267782 20391 solver.cpp:415]     Test net output #0: accuracy = 0.228966
I0704 10:45:04.267871 20391 solver.cpp:415]     Test net output #1: loss = 4.22976 (* 1 = 4.22976 loss)
I0704 10:45:08.306406 20391 solver.cpp:243] Iteration 2889, loss = 4.09958
I0704 10:45:08.306429 20391 solver.cpp:259]     Train net output #0: loss = 4.09958 (* 1 = 4.09958 loss)
I0704 10:45:08.306435 20391 solver.cpp:590] Iteration 2889, lr = 0.00511481
I0704 10:45:15.981454 20391 solver.cpp:243] Iteration 2916, loss = 3.9218
I0704 10:45:15.981477 20391 solver.cpp:259]     Train net output #0: loss = 3.9218 (* 1 = 3.9218 loss)
I0704 10:45:15.981483 20391 solver.cpp:590] Iteration 2916, lr = 0.00508287
I0704 10:45:23.652283 20391 solver.cpp:243] Iteration 2943, loss = 3.87689
I0704 10:45:23.652309 20391 solver.cpp:259]     Train net output #0: loss = 3.87689 (* 1 = 3.87689 loss)
I0704 10:45:23.652315 20391 solver.cpp:590] Iteration 2943, lr = 0.00505112
I0704 10:45:31.351541 20391 solver.cpp:243] Iteration 2970, loss = 3.66883
I0704 10:45:31.351567 20391 solver.cpp:259]     Train net output #0: loss = 3.66883 (* 1 = 3.66883 loss)
I0704 10:45:31.351573 20391 solver.cpp:590] Iteration 2970, lr = 0.00501957
I0704 10:45:39.010166 20391 solver.cpp:243] Iteration 2997, loss = 4.05549
I0704 10:45:39.010231 20391 solver.cpp:259]     Train net output #0: loss = 4.05549 (* 1 = 4.05549 loss)
I0704 10:45:39.010247 20391 solver.cpp:590] Iteration 2997, lr = 0.00498821
I0704 10:45:46.691421 20391 solver.cpp:243] Iteration 3024, loss = 3.92988
I0704 10:45:46.691447 20391 solver.cpp:259]     Train net output #0: loss = 3.92988 (* 1 = 3.92988 loss)
I0704 10:45:46.691452 20391 solver.cpp:590] Iteration 3024, lr = 0.00495706
I0704 10:45:54.361107 20391 solver.cpp:243] Iteration 3051, loss = 3.60896
I0704 10:45:54.361130 20391 solver.cpp:259]     Train net output #0: loss = 3.60896 (* 1 = 3.60896 loss)
I0704 10:45:54.361136 20391 solver.cpp:590] Iteration 3051, lr = 0.00492609
I0704 10:46:02.014535 20391 solver.cpp:243] Iteration 3078, loss = 3.7468
I0704 10:46:02.014559 20391 solver.cpp:259]     Train net output #0: loss = 3.7468 (* 1 = 3.7468 loss)
I0704 10:46:02.014565 20391 solver.cpp:590] Iteration 3078, lr = 0.00489532
I0704 10:46:06.256278 20391 solver.cpp:347] Iteration 3094, Testing net (#0)
I0704 10:46:25.382905 20391 solver.cpp:415]     Test net output #0: accuracy = 0.24976
I0704 10:46:25.383003 20391 solver.cpp:415]     Test net output #1: loss = 4.04894 (* 1 = 4.04894 loss)
I0704 10:46:27.991730 20391 solver.cpp:243] Iteration 3105, loss = 3.89386
I0704 10:46:27.991755 20391 solver.cpp:259]     Train net output #0: loss = 3.89386 (* 1 = 3.89386 loss)
I0704 10:46:27.991761 20391 solver.cpp:590] Iteration 3105, lr = 0.00486475
I0704 10:46:35.662585 20391 solver.cpp:243] Iteration 3132, loss = 3.74544
I0704 10:46:35.662611 20391 solver.cpp:259]     Train net output #0: loss = 3.74544 (* 1 = 3.74544 loss)
I0704 10:46:35.662616 20391 solver.cpp:590] Iteration 3132, lr = 0.00483436
I0704 10:46:43.333040 20391 solver.cpp:243] Iteration 3159, loss = 3.77332
I0704 10:46:43.333066 20391 solver.cpp:259]     Train net output #0: loss = 3.77332 (* 1 = 3.77332 loss)
I0704 10:46:43.333072 20391 solver.cpp:590] Iteration 3159, lr = 0.00480416
I0704 10:46:51.009552 20391 solver.cpp:243] Iteration 3186, loss = 3.78055
I0704 10:46:51.009577 20391 solver.cpp:259]     Train net output #0: loss = 3.78055 (* 1 = 3.78055 loss)
I0704 10:46:51.009582 20391 solver.cpp:590] Iteration 3186, lr = 0.00477416
I0704 10:46:56.972906 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 10:46:58.668124 20391 solver.cpp:243] Iteration 3213, loss = 3.84171
I0704 10:46:58.668149 20391 solver.cpp:259]     Train net output #0: loss = 3.84171 (* 1 = 3.84171 loss)
I0704 10:46:58.668155 20391 solver.cpp:590] Iteration 3213, lr = 0.00474433
I0704 10:47:06.357602 20391 solver.cpp:243] Iteration 3240, loss = 3.74573
I0704 10:47:06.357627 20391 solver.cpp:259]     Train net output #0: loss = 3.74573 (* 1 = 3.74573 loss)
I0704 10:47:06.357633 20391 solver.cpp:590] Iteration 3240, lr = 0.0047147
I0704 10:47:14.036582 20391 solver.cpp:243] Iteration 3267, loss = 3.72272
I0704 10:47:14.036605 20391 solver.cpp:259]     Train net output #0: loss = 3.72272 (* 1 = 3.72272 loss)
I0704 10:47:14.036612 20391 solver.cpp:590] Iteration 3267, lr = 0.00468525
I0704 10:47:21.693451 20391 solver.cpp:243] Iteration 3294, loss = 3.49561
I0704 10:47:21.693475 20391 solver.cpp:259]     Train net output #0: loss = 3.49561 (* 1 = 3.49561 loss)
I0704 10:47:21.693481 20391 solver.cpp:590] Iteration 3294, lr = 0.00465599
I0704 10:47:27.357834 20391 solver.cpp:347] Iteration 3315, Testing net (#0)
I0704 10:47:46.647181 20391 solver.cpp:415]     Test net output #0: accuracy = 0.26274
I0704 10:47:46.647203 20391 solver.cpp:415]     Test net output #1: loss = 3.9902 (* 1 = 3.9902 loss)
I0704 10:47:47.845336 20391 solver.cpp:243] Iteration 3321, loss = 3.54683
I0704 10:47:47.845361 20391 solver.cpp:259]     Train net output #0: loss = 3.54683 (* 1 = 3.54683 loss)
I0704 10:47:47.845367 20391 solver.cpp:590] Iteration 3321, lr = 0.0046269
I0704 10:47:55.517686 20391 solver.cpp:243] Iteration 3348, loss = 3.76003
I0704 10:47:55.517711 20391 solver.cpp:259]     Train net output #0: loss = 3.76003 (* 1 = 3.76003 loss)
I0704 10:47:55.517719 20391 solver.cpp:590] Iteration 3348, lr = 0.004598
I0704 10:48:03.781815 20391 solver.cpp:243] Iteration 3375, loss = 4.15171
I0704 10:48:03.781908 20391 solver.cpp:259]     Train net output #0: loss = 4.15171 (* 1 = 4.15171 loss)
I0704 10:48:03.781916 20391 solver.cpp:590] Iteration 3375, lr = 0.00456928
I0704 10:48:11.697963 20391 solver.cpp:243] Iteration 3402, loss = 3.32349
I0704 10:48:11.697988 20391 solver.cpp:259]     Train net output #0: loss = 3.32349 (* 1 = 3.32349 loss)
I0704 10:48:11.697993 20391 solver.cpp:590] Iteration 3402, lr = 0.00454074
I0704 10:48:19.372761 20391 solver.cpp:243] Iteration 3429, loss = 3.76351
I0704 10:48:19.372786 20391 solver.cpp:259]     Train net output #0: loss = 3.76351 (* 1 = 3.76351 loss)
I0704 10:48:19.372792 20391 solver.cpp:590] Iteration 3429, lr = 0.00451238
I0704 10:48:27.345687 20391 solver.cpp:243] Iteration 3456, loss = 3.58621
I0704 10:48:27.345711 20391 solver.cpp:259]     Train net output #0: loss = 3.58621 (* 1 = 3.58621 loss)
I0704 10:48:27.345717 20391 solver.cpp:590] Iteration 3456, lr = 0.00448419
I0704 10:48:35.422735 20391 solver.cpp:243] Iteration 3483, loss = 3.75574
I0704 10:48:35.422806 20391 solver.cpp:259]     Train net output #0: loss = 3.75574 (* 1 = 3.75574 loss)
I0704 10:48:35.422822 20391 solver.cpp:590] Iteration 3483, lr = 0.00445618
I0704 10:48:43.068718 20391 solver.cpp:243] Iteration 3510, loss = 3.66548
I0704 10:48:43.068744 20391 solver.cpp:259]     Train net output #0: loss = 3.66548 (* 1 = 3.66548 loss)
I0704 10:48:43.068750 20391 solver.cpp:590] Iteration 3510, lr = 0.00442835
I0704 10:48:50.588328 20391 solver.cpp:347] Iteration 3536, Testing net (#0)
I0704 10:49:09.674839 20391 solver.cpp:415]     Test net output #0: accuracy = 0.271875
I0704 10:49:09.674938 20391 solver.cpp:415]     Test net output #1: loss = 3.89717 (* 1 = 3.89717 loss)
I0704 10:49:09.817970 20391 solver.cpp:243] Iteration 3537, loss = 3.9714
I0704 10:49:09.817994 20391 solver.cpp:259]     Train net output #0: loss = 3.9714 (* 1 = 3.9714 loss)
I0704 10:49:09.818002 20391 solver.cpp:590] Iteration 3537, lr = 0.00440069
I0704 10:49:17.108173 20391 solver.cpp:243] Iteration 3564, loss = 3.51425
I0704 10:49:17.108208 20391 solver.cpp:259]     Train net output #0: loss = 3.51425 (* 1 = 3.51425 loss)
I0704 10:49:17.108213 20391 solver.cpp:590] Iteration 3564, lr = 0.0043732
I0704 10:49:24.778026 20391 solver.cpp:243] Iteration 3591, loss = 3.44218
I0704 10:49:24.778050 20391 solver.cpp:259]     Train net output #0: loss = 3.44218 (* 1 = 3.44218 loss)
I0704 10:49:24.778055 20391 solver.cpp:590] Iteration 3591, lr = 0.00434589
I0704 10:49:32.463485 20391 solver.cpp:243] Iteration 3618, loss = 3.44752
I0704 10:49:32.463510 20391 solver.cpp:259]     Train net output #0: loss = 3.44752 (* 1 = 3.44752 loss)
I0704 10:49:32.463515 20391 solver.cpp:590] Iteration 3618, lr = 0.00431874
I0704 10:49:40.165977 20391 solver.cpp:243] Iteration 3645, loss = 3.39863
I0704 10:49:40.166116 20391 solver.cpp:259]     Train net output #0: loss = 3.39863 (* 1 = 3.39863 loss)
I0704 10:49:40.166124 20391 solver.cpp:590] Iteration 3645, lr = 0.00429176
I0704 10:49:47.871964 20391 solver.cpp:243] Iteration 3672, loss = 3.45429
I0704 10:49:47.871989 20391 solver.cpp:259]     Train net output #0: loss = 3.45429 (* 1 = 3.45429 loss)
I0704 10:49:47.871995 20391 solver.cpp:590] Iteration 3672, lr = 0.00426496
I0704 10:49:55.563352 20391 solver.cpp:243] Iteration 3699, loss = 3.70367
I0704 10:49:55.563380 20391 solver.cpp:259]     Train net output #0: loss = 3.70367 (* 1 = 3.70367 loss)
I0704 10:49:55.563385 20391 solver.cpp:590] Iteration 3699, lr = 0.00423832
I0704 10:49:56.135367 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 10:50:03.208019 20391 solver.cpp:243] Iteration 3726, loss = 3.34986
I0704 10:50:03.208044 20391 solver.cpp:259]     Train net output #0: loss = 3.34986 (* 1 = 3.34986 loss)
I0704 10:50:03.208048 20391 solver.cpp:590] Iteration 3726, lr = 0.00421184
I0704 10:50:10.917563 20391 solver.cpp:243] Iteration 3753, loss = 3.85182
I0704 10:50:10.917634 20391 solver.cpp:259]     Train net output #0: loss = 3.85182 (* 1 = 3.85182 loss)
I0704 10:50:10.917650 20391 solver.cpp:590] Iteration 3753, lr = 0.00418554
I0704 10:50:11.837610 20391 solver.cpp:347] Iteration 3757, Testing net (#0)
I0704 10:50:30.992558 20391 solver.cpp:415]     Test net output #0: accuracy = 0.280649
I0704 10:50:30.992583 20391 solver.cpp:415]     Test net output #1: loss = 3.90585 (* 1 = 3.90585 loss)
I0704 10:50:37.018590 20391 solver.cpp:243] Iteration 3780, loss = 3.83204
I0704 10:50:37.018615 20391 solver.cpp:259]     Train net output #0: loss = 3.83204 (* 1 = 3.83204 loss)
I0704 10:50:37.018620 20391 solver.cpp:590] Iteration 3780, lr = 0.00415939
I0704 10:50:44.679488 20391 solver.cpp:243] Iteration 3807, loss = 3.45557
I0704 10:50:44.679558 20391 solver.cpp:259]     Train net output #0: loss = 3.45557 (* 1 = 3.45557 loss)
I0704 10:50:44.679575 20391 solver.cpp:590] Iteration 3807, lr = 0.00413341
I0704 10:50:52.348018 20391 solver.cpp:243] Iteration 3834, loss = 3.44705
I0704 10:50:52.348045 20391 solver.cpp:259]     Train net output #0: loss = 3.44705 (* 1 = 3.44705 loss)
I0704 10:50:52.348050 20391 solver.cpp:590] Iteration 3834, lr = 0.00410759
I0704 10:51:00.057704 20391 solver.cpp:243] Iteration 3861, loss = 3.33366
I0704 10:51:00.057730 20391 solver.cpp:259]     Train net output #0: loss = 3.33366 (* 1 = 3.33366 loss)
I0704 10:51:00.057736 20391 solver.cpp:590] Iteration 3861, lr = 0.00408194
I0704 10:51:07.802110 20391 solver.cpp:243] Iteration 3888, loss = 3.53277
I0704 10:51:07.802142 20391 solver.cpp:259]     Train net output #0: loss = 3.53277 (* 1 = 3.53277 loss)
I0704 10:51:07.802148 20391 solver.cpp:590] Iteration 3888, lr = 0.00405644
I0704 10:51:15.515913 20391 solver.cpp:243] Iteration 3915, loss = 3.68701
I0704 10:51:15.516005 20391 solver.cpp:259]     Train net output #0: loss = 3.68701 (* 1 = 3.68701 loss)
I0704 10:51:15.516022 20391 solver.cpp:590] Iteration 3915, lr = 0.0040311
I0704 10:51:23.172539 20391 solver.cpp:243] Iteration 3942, loss = 3.33832
I0704 10:51:23.172564 20391 solver.cpp:259]     Train net output #0: loss = 3.33832 (* 1 = 3.33832 loss)
I0704 10:51:23.172570 20391 solver.cpp:590] Iteration 3942, lr = 0.00400592
I0704 10:51:30.829718 20391 solver.cpp:243] Iteration 3969, loss = 3.13653
I0704 10:51:30.829744 20391 solver.cpp:259]     Train net output #0: loss = 3.13653 (* 1 = 3.13653 loss)
I0704 10:51:30.829751 20391 solver.cpp:590] Iteration 3969, lr = 0.0039809
I0704 10:51:33.086576 20391 solver.cpp:347] Iteration 3978, Testing net (#0)
I0704 10:51:52.297152 20391 solver.cpp:415]     Test net output #0: accuracy = 0.286178
I0704 10:51:52.297225 20391 solver.cpp:415]     Test net output #1: loss = 3.72742 (* 1 = 3.72742 loss)
I0704 10:51:56.941007 20391 solver.cpp:243] Iteration 3996, loss = 3.41699
I0704 10:51:56.941032 20391 solver.cpp:259]     Train net output #0: loss = 3.41699 (* 1 = 3.41699 loss)
I0704 10:51:56.941038 20391 solver.cpp:590] Iteration 3996, lr = 0.00395603
I0704 10:52:04.688133 20391 solver.cpp:243] Iteration 4023, loss = 3.60413
I0704 10:52:04.688155 20391 solver.cpp:259]     Train net output #0: loss = 3.60413 (* 1 = 3.60413 loss)
I0704 10:52:04.688161 20391 solver.cpp:590] Iteration 4023, lr = 0.00393132
I0704 10:52:12.537240 20391 solver.cpp:243] Iteration 4050, loss = 3.21719
I0704 10:52:12.537266 20391 solver.cpp:259]     Train net output #0: loss = 3.21719 (* 1 = 3.21719 loss)
I0704 10:52:12.537271 20391 solver.cpp:590] Iteration 4050, lr = 0.00390677
I0704 10:52:20.257606 20391 solver.cpp:243] Iteration 4077, loss = 2.89895
I0704 10:52:20.257632 20391 solver.cpp:259]     Train net output #0: loss = 2.89895 (* 1 = 2.89895 loss)
I0704 10:52:20.257637 20391 solver.cpp:590] Iteration 4077, lr = 0.00388237
I0704 10:52:27.955204 20391 solver.cpp:243] Iteration 4104, loss = 3.33949
I0704 10:52:27.955278 20391 solver.cpp:259]     Train net output #0: loss = 3.33949 (* 1 = 3.33949 loss)
I0704 10:52:27.955298 20391 solver.cpp:590] Iteration 4104, lr = 0.00385812
I0704 10:52:35.624377 20391 solver.cpp:243] Iteration 4131, loss = 2.74695
I0704 10:52:35.624400 20391 solver.cpp:259]     Train net output #0: loss = 2.74695 (* 1 = 2.74695 loss)
I0704 10:52:35.624406 20391 solver.cpp:590] Iteration 4131, lr = 0.00383402
I0704 10:52:43.278647 20391 solver.cpp:243] Iteration 4158, loss = 2.97433
I0704 10:52:43.278673 20391 solver.cpp:259]     Train net output #0: loss = 2.97433 (* 1 = 2.97433 loss)
I0704 10:52:43.278679 20391 solver.cpp:590] Iteration 4158, lr = 0.00381007
I0704 10:52:50.919220 20391 solver.cpp:243] Iteration 4185, loss = 3.04292
I0704 10:52:50.919245 20391 solver.cpp:259]     Train net output #0: loss = 3.04292 (* 1 = 3.04292 loss)
I0704 10:52:50.919250 20391 solver.cpp:590] Iteration 4185, lr = 0.00378627
I0704 10:52:53.883638 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 10:52:54.730741 20391 solver.cpp:347] Iteration 4199, Testing net (#0)
I0704 10:53:13.941087 20391 solver.cpp:415]     Test net output #0: accuracy = 0.298798
I0704 10:53:13.941159 20391 solver.cpp:415]     Test net output #1: loss = 3.63398 (* 1 = 3.63398 loss)
I0704 10:53:17.139359 20391 solver.cpp:243] Iteration 4212, loss = 2.83415
I0704 10:53:17.139384 20391 solver.cpp:259]     Train net output #0: loss = 2.83415 (* 1 = 2.83415 loss)
I0704 10:53:17.139389 20391 solver.cpp:590] Iteration 4212, lr = 0.00376262
I0704 10:53:24.808478 20391 solver.cpp:243] Iteration 4239, loss = 2.82223
I0704 10:53:24.808504 20391 solver.cpp:259]     Train net output #0: loss = 2.82223 (* 1 = 2.82223 loss)
I0704 10:53:24.808511 20391 solver.cpp:590] Iteration 4239, lr = 0.00373912
I0704 10:53:32.476935 20391 solver.cpp:243] Iteration 4266, loss = 3.35028
I0704 10:53:32.476960 20391 solver.cpp:259]     Train net output #0: loss = 3.35028 (* 1 = 3.35028 loss)
I0704 10:53:32.476966 20391 solver.cpp:590] Iteration 4266, lr = 0.00371576
I0704 10:53:40.153234 20391 solver.cpp:243] Iteration 4293, loss = 2.70617
I0704 10:53:40.153260 20391 solver.cpp:259]     Train net output #0: loss = 2.70617 (* 1 = 2.70617 loss)
I0704 10:53:40.153266 20391 solver.cpp:590] Iteration 4293, lr = 0.00369255
I0704 10:53:47.985977 20391 solver.cpp:243] Iteration 4320, loss = 2.87301
I0704 10:53:47.986081 20391 solver.cpp:259]     Train net output #0: loss = 2.87301 (* 1 = 2.87301 loss)
I0704 10:53:47.986088 20391 solver.cpp:590] Iteration 4320, lr = 0.00366949
I0704 10:53:55.795557 20391 solver.cpp:243] Iteration 4347, loss = 3.34781
I0704 10:53:55.795583 20391 solver.cpp:259]     Train net output #0: loss = 3.34781 (* 1 = 3.34781 loss)
I0704 10:53:55.795588 20391 solver.cpp:590] Iteration 4347, lr = 0.00364657
I0704 10:54:03.462317 20391 solver.cpp:243] Iteration 4374, loss = 3.06258
I0704 10:54:03.462342 20391 solver.cpp:259]     Train net output #0: loss = 3.06258 (* 1 = 3.06258 loss)
I0704 10:54:03.462347 20391 solver.cpp:590] Iteration 4374, lr = 0.00362379
I0704 10:54:11.254791 20391 solver.cpp:243] Iteration 4401, loss = 2.84002
I0704 10:54:11.254815 20391 solver.cpp:259]     Train net output #0: loss = 2.84002 (* 1 = 2.84002 loss)
I0704 10:54:11.254822 20391 solver.cpp:590] Iteration 4401, lr = 0.00360116
I0704 10:54:16.624950 20391 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_4420.caffemodel
I0704 10:54:32.575847 20391 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_4420.solverstate
I0704 10:54:33.596827 20391 solver.cpp:347] Iteration 4420, Testing net (#0)
I0704 10:54:52.790474 20391 solver.cpp:415]     Test net output #0: accuracy = 0.307452
I0704 10:54:52.790499 20391 solver.cpp:415]     Test net output #1: loss = 3.58848 (* 1 = 3.58848 loss)
I0704 10:54:54.579483 20391 solver.cpp:243] Iteration 4428, loss = 2.86453
I0704 10:54:54.579509 20391 solver.cpp:259]     Train net output #0: loss = 2.86453 (* 1 = 2.86453 loss)
I0704 10:54:54.579515 20391 solver.cpp:590] Iteration 4428, lr = 0.00357866
I0704 10:55:02.348867 20391 solver.cpp:243] Iteration 4455, loss = 3.26559
I0704 10:55:02.348892 20391 solver.cpp:259]     Train net output #0: loss = 3.26559 (* 1 = 3.26559 loss)
I0704 10:55:02.348898 20391 solver.cpp:590] Iteration 4455, lr = 0.00355631
I0704 10:55:10.083616 20391 solver.cpp:243] Iteration 4482, loss = 3.00744
I0704 10:55:10.083684 20391 solver.cpp:259]     Train net output #0: loss = 3.00744 (* 1 = 3.00744 loss)
I0704 10:55:10.083701 20391 solver.cpp:590] Iteration 4482, lr = 0.00353409
I0704 10:55:17.922637 20391 solver.cpp:243] Iteration 4509, loss = 2.99588
I0704 10:55:17.922662 20391 solver.cpp:259]     Train net output #0: loss = 2.99588 (* 1 = 2.99588 loss)
I0704 10:55:17.922667 20391 solver.cpp:590] Iteration 4509, lr = 0.00351202
I0704 10:55:25.669080 20391 solver.cpp:243] Iteration 4536, loss = 2.89189
I0704 10:55:25.669103 20391 solver.cpp:259]     Train net output #0: loss = 2.89189 (* 1 = 2.89189 loss)
I0704 10:55:25.669108 20391 solver.cpp:590] Iteration 4536, lr = 0.00349008
I0704 10:55:33.412982 20391 solver.cpp:243] Iteration 4563, loss = 2.59534
I0704 10:55:33.413009 20391 solver.cpp:259]     Train net output #0: loss = 2.59534 (* 1 = 2.59534 loss)
I0704 10:55:33.413015 20391 solver.cpp:590] Iteration 4563, lr = 0.00346828
I0704 10:55:41.189972 20391 solver.cpp:243] Iteration 4590, loss = 2.79322
I0704 10:55:41.190052 20391 solver.cpp:259]     Train net output #0: loss = 2.79322 (* 1 = 2.79322 loss)
I0704 10:55:41.190059 20391 solver.cpp:590] Iteration 4590, lr = 0.00344662
I0704 10:55:48.920106 20391 solver.cpp:243] Iteration 4617, loss = 2.81611
I0704 10:55:48.920130 20391 solver.cpp:259]     Train net output #0: loss = 2.81611 (* 1 = 2.81611 loss)
I0704 10:55:48.920136 20391 solver.cpp:590] Iteration 4617, lr = 0.00342509
I0704 10:55:55.441426 20391 solver.cpp:347] Iteration 4641, Testing net (#0)
I0704 10:55:59.256680 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 10:56:14.662968 20391 solver.cpp:415]     Test net output #0: accuracy = 0.317428
I0704 10:56:14.663061 20391 solver.cpp:415]     Test net output #1: loss = 3.50643 (* 1 = 3.50643 loss)
I0704 10:56:15.013245 20391 solver.cpp:243] Iteration 4644, loss = 2.9462
I0704 10:56:15.013270 20391 solver.cpp:259]     Train net output #0: loss = 2.9462 (* 1 = 2.9462 loss)
I0704 10:56:15.013276 20391 solver.cpp:590] Iteration 4644, lr = 0.0034037
I0704 10:56:22.720425 20391 solver.cpp:243] Iteration 4671, loss = 2.92196
I0704 10:56:22.720450 20391 solver.cpp:259]     Train net output #0: loss = 2.92196 (* 1 = 2.92196 loss)
I0704 10:56:22.720456 20391 solver.cpp:590] Iteration 4671, lr = 0.00338244
I0704 10:56:30.426071 20391 solver.cpp:243] Iteration 4698, loss = 2.71142
I0704 10:56:30.426097 20391 solver.cpp:259]     Train net output #0: loss = 2.71142 (* 1 = 2.71142 loss)
I0704 10:56:30.426103 20391 solver.cpp:590] Iteration 4698, lr = 0.00336131
I0704 10:56:38.158520 20391 solver.cpp:243] Iteration 4725, loss = 2.46935
I0704 10:56:38.158546 20391 solver.cpp:259]     Train net output #0: loss = 2.46935 (* 1 = 2.46935 loss)
I0704 10:56:38.158552 20391 solver.cpp:590] Iteration 4725, lr = 0.00334031
I0704 10:56:45.874058 20391 solver.cpp:243] Iteration 4752, loss = 2.69486
I0704 10:56:45.874168 20391 solver.cpp:259]     Train net output #0: loss = 2.69486 (* 1 = 2.69486 loss)
I0704 10:56:45.874176 20391 solver.cpp:590] Iteration 4752, lr = 0.00331945
I0704 10:56:53.630182 20391 solver.cpp:243] Iteration 4779, loss = 2.58066
I0704 10:56:53.630208 20391 solver.cpp:259]     Train net output #0: loss = 2.58066 (* 1 = 2.58066 loss)
I0704 10:56:53.630214 20391 solver.cpp:590] Iteration 4779, lr = 0.00329871
I0704 10:57:01.394830 20391 solver.cpp:243] Iteration 4806, loss = 2.75555
I0704 10:57:01.394855 20391 solver.cpp:259]     Train net output #0: loss = 2.75555 (* 1 = 2.75555 loss)
I0704 10:57:01.394860 20391 solver.cpp:590] Iteration 4806, lr = 0.00327811
I0704 10:57:09.097535 20391 solver.cpp:243] Iteration 4833, loss = 3.19352
I0704 10:57:09.097561 20391 solver.cpp:259]     Train net output #0: loss = 3.19352 (* 1 = 3.19352 loss)
I0704 10:57:09.097568 20391 solver.cpp:590] Iteration 4833, lr = 0.00325763
I0704 10:57:16.752866 20391 solver.cpp:243] Iteration 4860, loss = 3.03356
I0704 10:57:16.752923 20391 solver.cpp:259]     Train net output #0: loss = 3.03356 (* 1 = 3.03356 loss)
I0704 10:57:16.752928 20391 solver.cpp:590] Iteration 4860, lr = 0.00323729
I0704 10:57:17.037509 20391 solver.cpp:347] Iteration 4862, Testing net (#0)
I0704 10:57:36.208256 20391 solver.cpp:415]     Test net output #0: accuracy = 0.321274
I0704 10:57:36.208281 20391 solver.cpp:415]     Test net output #1: loss = 3.43181 (* 1 = 3.43181 loss)
I0704 10:57:42.834450 20391 solver.cpp:243] Iteration 4887, loss = 2.48313
I0704 10:57:42.834473 20391 solver.cpp:259]     Train net output #0: loss = 2.48313 (* 1 = 2.48313 loss)
I0704 10:57:42.834480 20391 solver.cpp:590] Iteration 4887, lr = 0.00321707
I0704 10:57:50.523926 20391 solver.cpp:243] Iteration 4914, loss = 2.6398
I0704 10:57:50.524083 20391 solver.cpp:259]     Train net output #0: loss = 2.6398 (* 1 = 2.6398 loss)
I0704 10:57:50.524091 20391 solver.cpp:590] Iteration 4914, lr = 0.00319697
I0704 10:57:58.225219 20391 solver.cpp:243] Iteration 4941, loss = 2.70605
I0704 10:57:58.225244 20391 solver.cpp:259]     Train net output #0: loss = 2.70605 (* 1 = 2.70605 loss)
I0704 10:57:58.225250 20391 solver.cpp:590] Iteration 4941, lr = 0.003177
I0704 10:58:06.231480 20391 solver.cpp:243] Iteration 4968, loss = 2.72881
I0704 10:58:06.231505 20391 solver.cpp:259]     Train net output #0: loss = 2.72881 (* 1 = 2.72881 loss)
I0704 10:58:06.231511 20391 solver.cpp:590] Iteration 4968, lr = 0.00315716
I0704 10:58:14.384542 20391 solver.cpp:243] Iteration 4995, loss = 2.51022
I0704 10:58:14.384568 20391 solver.cpp:259]     Train net output #0: loss = 2.51022 (* 1 = 2.51022 loss)
I0704 10:58:14.384573 20391 solver.cpp:590] Iteration 4995, lr = 0.00313744
I0704 10:58:22.165518 20391 solver.cpp:243] Iteration 5022, loss = 2.65597
I0704 10:58:22.165616 20391 solver.cpp:259]     Train net output #0: loss = 2.65597 (* 1 = 2.65597 loss)
I0704 10:58:22.165622 20391 solver.cpp:590] Iteration 5022, lr = 0.00311784
I0704 10:58:29.890319 20391 solver.cpp:243] Iteration 5049, loss = 2.55127
I0704 10:58:29.890346 20391 solver.cpp:259]     Train net output #0: loss = 2.55127 (* 1 = 2.55127 loss)
I0704 10:58:29.890352 20391 solver.cpp:590] Iteration 5049, lr = 0.00309837
I0704 10:58:37.621525 20391 solver.cpp:243] Iteration 5076, loss = 2.45019
I0704 10:58:37.621551 20391 solver.cpp:259]     Train net output #0: loss = 2.45019 (* 1 = 2.45019 loss)
I0704 10:58:37.621556 20391 solver.cpp:590] Iteration 5076, lr = 0.00307901
I0704 10:58:39.324826 20391 solver.cpp:347] Iteration 5083, Testing net (#0)
I0704 10:58:46.950125 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 10:58:58.417934 20391 solver.cpp:415]     Test net output #0: accuracy = 0.328365
I0704 10:58:58.418056 20391 solver.cpp:415]     Test net output #1: loss = 3.3442 (* 1 = 3.3442 loss)
I0704 10:59:03.604529 20391 solver.cpp:243] Iteration 5103, loss = 2.70723
I0704 10:59:03.604554 20391 solver.cpp:259]     Train net output #0: loss = 2.70723 (* 1 = 2.70723 loss)
I0704 10:59:03.604559 20391 solver.cpp:590] Iteration 5103, lr = 0.00305978
I0704 10:59:11.307590 20391 solver.cpp:243] Iteration 5130, loss = 2.78332
I0704 10:59:11.307615 20391 solver.cpp:259]     Train net output #0: loss = 2.78332 (* 1 = 2.78332 loss)
I0704 10:59:11.307621 20391 solver.cpp:590] Iteration 5130, lr = 0.00304067
I0704 10:59:19.011791 20391 solver.cpp:243] Iteration 5157, loss = 2.74724
I0704 10:59:19.011816 20391 solver.cpp:259]     Train net output #0: loss = 2.74724 (* 1 = 2.74724 loss)
I0704 10:59:19.011822 20391 solver.cpp:590] Iteration 5157, lr = 0.00302168
I0704 10:59:26.700075 20391 solver.cpp:243] Iteration 5184, loss = 2.41799
I0704 10:59:26.700101 20391 solver.cpp:259]     Train net output #0: loss = 2.41799 (* 1 = 2.41799 loss)
I0704 10:59:26.700108 20391 solver.cpp:590] Iteration 5184, lr = 0.0030028
I0704 10:59:34.457671 20391 solver.cpp:243] Iteration 5211, loss = 2.4839
I0704 10:59:34.457754 20391 solver.cpp:259]     Train net output #0: loss = 2.4839 (* 1 = 2.4839 loss)
I0704 10:59:34.457762 20391 solver.cpp:590] Iteration 5211, lr = 0.00298404
I0704 10:59:42.218389 20391 solver.cpp:243] Iteration 5238, loss = 2.66649
I0704 10:59:42.218415 20391 solver.cpp:259]     Train net output #0: loss = 2.66649 (* 1 = 2.66649 loss)
I0704 10:59:42.218421 20391 solver.cpp:590] Iteration 5238, lr = 0.00296541
I0704 10:59:49.934219 20391 solver.cpp:243] Iteration 5265, loss = 2.86659
I0704 10:59:49.934243 20391 solver.cpp:259]     Train net output #0: loss = 2.86659 (* 1 = 2.86659 loss)
I0704 10:59:49.934249 20391 solver.cpp:590] Iteration 5265, lr = 0.00294688
I0704 10:59:57.658962 20391 solver.cpp:243] Iteration 5292, loss = 2.45465
I0704 10:59:57.658987 20391 solver.cpp:259]     Train net output #0: loss = 2.45465 (* 1 = 2.45465 loss)
I0704 10:59:57.658993 20391 solver.cpp:590] Iteration 5292, lr = 0.00292848
I0704 11:00:00.799690 20391 solver.cpp:347] Iteration 5304, Testing net (#0)
I0704 11:00:19.911764 20391 solver.cpp:415]     Test net output #0: accuracy = 0.340144
I0704 11:00:19.911875 20391 solver.cpp:415]     Test net output #1: loss = 3.29918 (* 1 = 3.29918 loss)
I0704 11:00:23.700242 20391 solver.cpp:243] Iteration 5319, loss = 2.4932
I0704 11:00:23.700269 20391 solver.cpp:259]     Train net output #0: loss = 2.4932 (* 1 = 2.4932 loss)
I0704 11:00:23.700275 20391 solver.cpp:590] Iteration 5319, lr = 0.00291018
I0704 11:00:31.498188 20391 solver.cpp:243] Iteration 5346, loss = 2.50599
I0704 11:00:31.498216 20391 solver.cpp:259]     Train net output #0: loss = 2.50599 (* 1 = 2.50599 loss)
I0704 11:00:31.498222 20391 solver.cpp:590] Iteration 5346, lr = 0.00289201
I0704 11:00:39.204330 20391 solver.cpp:243] Iteration 5373, loss = 2.3895
I0704 11:00:39.204357 20391 solver.cpp:259]     Train net output #0: loss = 2.3895 (* 1 = 2.3895 loss)
I0704 11:00:39.204363 20391 solver.cpp:590] Iteration 5373, lr = 0.00287394
I0704 11:00:46.969776 20391 solver.cpp:243] Iteration 5400, loss = 2.2871
I0704 11:00:46.969800 20391 solver.cpp:259]     Train net output #0: loss = 2.2871 (* 1 = 2.2871 loss)
I0704 11:00:46.969806 20391 solver.cpp:590] Iteration 5400, lr = 0.00285599
I0704 11:00:54.654232 20391 solver.cpp:243] Iteration 5427, loss = 2.17714
I0704 11:00:54.654371 20391 solver.cpp:259]     Train net output #0: loss = 2.17714 (* 1 = 2.17714 loss)
I0704 11:00:54.654378 20391 solver.cpp:590] Iteration 5427, lr = 0.00283815
I0704 11:01:02.351701 20391 solver.cpp:243] Iteration 5454, loss = 2.68997
I0704 11:01:02.351724 20391 solver.cpp:259]     Train net output #0: loss = 2.68997 (* 1 = 2.68997 loss)
I0704 11:01:02.351730 20391 solver.cpp:590] Iteration 5454, lr = 0.00282042
I0704 11:01:10.014412 20391 solver.cpp:243] Iteration 5481, loss = 2.42944
I0704 11:01:10.014437 20391 solver.cpp:259]     Train net output #0: loss = 2.42944 (* 1 = 2.42944 loss)
I0704 11:01:10.014443 20391 solver.cpp:590] Iteration 5481, lr = 0.00280281
I0704 11:01:17.674829 20391 solver.cpp:243] Iteration 5508, loss = 2.52513
I0704 11:01:17.674856 20391 solver.cpp:259]     Train net output #0: loss = 2.52513 (* 1 = 2.52513 loss)
I0704 11:01:17.674861 20391 solver.cpp:590] Iteration 5508, lr = 0.0027853
I0704 11:01:22.197458 20391 solver.cpp:347] Iteration 5525, Testing net (#0)
I0704 11:01:33.668401 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:01:41.294718 20391 solver.cpp:415]     Test net output #0: accuracy = 0.344351
I0704 11:01:41.294742 20391 solver.cpp:415]     Test net output #1: loss = 3.22448 (* 1 = 3.22448 loss)
I0704 11:01:43.640771 20391 solver.cpp:243] Iteration 5535, loss = 2.15371
I0704 11:01:43.640795 20391 solver.cpp:259]     Train net output #0: loss = 2.15371 (* 1 = 2.15371 loss)
I0704 11:01:43.640801 20391 solver.cpp:590] Iteration 5535, lr = 0.0027679
I0704 11:01:51.318074 20391 solver.cpp:243] Iteration 5562, loss = 2.23251
I0704 11:01:51.318101 20391 solver.cpp:259]     Train net output #0: loss = 2.23251 (* 1 = 2.23251 loss)
I0704 11:01:51.318107 20391 solver.cpp:590] Iteration 5562, lr = 0.00275061
I0704 11:01:59.061012 20391 solver.cpp:243] Iteration 5589, loss = 2.9771
I0704 11:01:59.061039 20391 solver.cpp:259]     Train net output #0: loss = 2.9771 (* 1 = 2.9771 loss)
I0704 11:01:59.061045 20391 solver.cpp:590] Iteration 5589, lr = 0.00273343
I0704 11:02:06.801903 20391 solver.cpp:243] Iteration 5616, loss = 2.27971
I0704 11:02:06.802019 20391 solver.cpp:259]     Train net output #0: loss = 2.27971 (* 1 = 2.27971 loss)
I0704 11:02:06.802026 20391 solver.cpp:590] Iteration 5616, lr = 0.00271636
I0704 11:02:14.515141 20391 solver.cpp:243] Iteration 5643, loss = 2.64426
I0704 11:02:14.515168 20391 solver.cpp:259]     Train net output #0: loss = 2.64426 (* 1 = 2.64426 loss)
I0704 11:02:14.515174 20391 solver.cpp:590] Iteration 5643, lr = 0.00269939
I0704 11:02:22.214438 20391 solver.cpp:243] Iteration 5670, loss = 2.23681
I0704 11:02:22.214460 20391 solver.cpp:259]     Train net output #0: loss = 2.23681 (* 1 = 2.23681 loss)
I0704 11:02:22.214467 20391 solver.cpp:590] Iteration 5670, lr = 0.00268253
I0704 11:02:29.884394 20391 solver.cpp:243] Iteration 5697, loss = 2.6223
I0704 11:02:29.884420 20391 solver.cpp:259]     Train net output #0: loss = 2.6223 (* 1 = 2.6223 loss)
I0704 11:02:29.884426 20391 solver.cpp:590] Iteration 5697, lr = 0.00266577
I0704 11:02:37.599176 20391 solver.cpp:243] Iteration 5724, loss = 2.58545
I0704 11:02:37.599262 20391 solver.cpp:259]     Train net output #0: loss = 2.58545 (* 1 = 2.58545 loss)
I0704 11:02:37.599269 20391 solver.cpp:590] Iteration 5724, lr = 0.00264912
I0704 11:02:43.542469 20391 solver.cpp:347] Iteration 5746, Testing net (#0)
I0704 11:03:02.641930 20391 solver.cpp:415]     Test net output #0: accuracy = 0.347356
I0704 11:03:02.641957 20391 solver.cpp:415]     Test net output #1: loss = 3.19261 (* 1 = 3.19261 loss)
I0704 11:03:03.562228 20391 solver.cpp:243] Iteration 5751, loss = 2.1668
I0704 11:03:03.562254 20391 solver.cpp:259]     Train net output #0: loss = 2.1668 (* 1 = 2.1668 loss)
I0704 11:03:03.562260 20391 solver.cpp:590] Iteration 5751, lr = 0.00263258
I0704 11:03:11.246119 20391 solver.cpp:243] Iteration 5778, loss = 2.38853
I0704 11:03:11.246213 20391 solver.cpp:259]     Train net output #0: loss = 2.38853 (* 1 = 2.38853 loss)
I0704 11:03:11.246230 20391 solver.cpp:590] Iteration 5778, lr = 0.00261613
I0704 11:03:18.924726 20391 solver.cpp:243] Iteration 5805, loss = 2.14042
I0704 11:03:18.924751 20391 solver.cpp:259]     Train net output #0: loss = 2.14042 (* 1 = 2.14042 loss)
I0704 11:03:18.924757 20391 solver.cpp:590] Iteration 5805, lr = 0.00259979
I0704 11:03:26.622176 20391 solver.cpp:243] Iteration 5832, loss = 1.88367
I0704 11:03:26.622202 20391 solver.cpp:259]     Train net output #0: loss = 1.88367 (* 1 = 1.88367 loss)
I0704 11:03:26.622207 20391 solver.cpp:590] Iteration 5832, lr = 0.00258355
I0704 11:03:34.282379 20391 solver.cpp:243] Iteration 5859, loss = 2.40211
I0704 11:03:34.282404 20391 solver.cpp:259]     Train net output #0: loss = 2.40211 (* 1 = 2.40211 loss)
I0704 11:03:34.282410 20391 solver.cpp:590] Iteration 5859, lr = 0.00256742
I0704 11:03:41.982211 20391 solver.cpp:243] Iteration 5886, loss = 2.58113
I0704 11:03:41.982306 20391 solver.cpp:259]     Train net output #0: loss = 2.58113 (* 1 = 2.58113 loss)
I0704 11:03:41.982313 20391 solver.cpp:590] Iteration 5886, lr = 0.00255138
I0704 11:03:49.660959 20391 solver.cpp:243] Iteration 5913, loss = 2.17717
I0704 11:03:49.660985 20391 solver.cpp:259]     Train net output #0: loss = 2.17717 (* 1 = 2.17717 loss)
I0704 11:03:49.660991 20391 solver.cpp:590] Iteration 5913, lr = 0.00253544
I0704 11:03:57.374912 20391 solver.cpp:243] Iteration 5940, loss = 2.37396
I0704 11:03:57.374938 20391 solver.cpp:259]     Train net output #0: loss = 2.37396 (* 1 = 2.37396 loss)
I0704 11:03:57.374943 20391 solver.cpp:590] Iteration 5940, lr = 0.00251961
I0704 11:04:04.796303 20391 solver.cpp:347] Iteration 5967, Testing net (#0)
I0704 11:04:20.260907 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:04:24.078089 20391 solver.cpp:415]     Test net output #0: accuracy = 0.350481
I0704 11:04:24.078116 20391 solver.cpp:415]     Test net output #1: loss = 3.16955 (* 1 = 3.16955 loss)
I0704 11:04:24.134945 20391 solver.cpp:243] Iteration 5967, loss = 1.82474
I0704 11:04:24.134970 20391 solver.cpp:259]     Train net output #0: loss = 1.82474 (* 1 = 1.82474 loss)
I0704 11:04:24.134976 20391 solver.cpp:590] Iteration 5967, lr = 0.00250387
I0704 11:04:31.292107 20391 solver.cpp:243] Iteration 5994, loss = 2.21274
I0704 11:04:31.292132 20391 solver.cpp:259]     Train net output #0: loss = 2.21274 (* 1 = 2.21274 loss)
I0704 11:04:31.292138 20391 solver.cpp:590] Iteration 5994, lr = 0.00248823
I0704 11:04:38.991791 20391 solver.cpp:243] Iteration 6021, loss = 2.15453
I0704 11:04:38.991817 20391 solver.cpp:259]     Train net output #0: loss = 2.15453 (* 1 = 2.15453 loss)
I0704 11:04:38.991823 20391 solver.cpp:590] Iteration 6021, lr = 0.00247269
I0704 11:04:46.687779 20391 solver.cpp:243] Iteration 6048, loss = 2.67696
I0704 11:04:46.687805 20391 solver.cpp:259]     Train net output #0: loss = 2.67696 (* 1 = 2.67696 loss)
I0704 11:04:46.687810 20391 solver.cpp:590] Iteration 6048, lr = 0.00245724
I0704 11:04:54.405977 20391 solver.cpp:243] Iteration 6075, loss = 2.11186
I0704 11:04:54.406105 20391 solver.cpp:259]     Train net output #0: loss = 2.11186 (* 1 = 2.11186 loss)
I0704 11:04:54.406111 20391 solver.cpp:590] Iteration 6075, lr = 0.00244189
I0704 11:05:02.108567 20391 solver.cpp:243] Iteration 6102, loss = 2.0008
I0704 11:05:02.108593 20391 solver.cpp:259]     Train net output #0: loss = 2.0008 (* 1 = 2.0008 loss)
I0704 11:05:02.108599 20391 solver.cpp:590] Iteration 6102, lr = 0.00242664
I0704 11:05:09.829535 20391 solver.cpp:243] Iteration 6129, loss = 2.05376
I0704 11:05:09.829561 20391 solver.cpp:259]     Train net output #0: loss = 2.05376 (* 1 = 2.05376 loss)
I0704 11:05:09.829567 20391 solver.cpp:590] Iteration 6129, lr = 0.00241148
I0704 11:05:17.499271 20391 solver.cpp:243] Iteration 6156, loss = 2.04633
I0704 11:05:17.499300 20391 solver.cpp:259]     Train net output #0: loss = 2.04633 (* 1 = 2.04633 loss)
I0704 11:05:17.499306 20391 solver.cpp:590] Iteration 6156, lr = 0.00239642
I0704 11:05:25.209281 20391 solver.cpp:243] Iteration 6183, loss = 2.3681
I0704 11:05:25.209403 20391 solver.cpp:259]     Train net output #0: loss = 2.3681 (* 1 = 2.3681 loss)
I0704 11:05:25.209410 20391 solver.cpp:590] Iteration 6183, lr = 0.00238145
I0704 11:05:26.354673 20391 solver.cpp:347] Iteration 6188, Testing net (#0)
I0704 11:05:45.540433 20391 solver.cpp:415]     Test net output #0: accuracy = 0.360337
I0704 11:05:45.540458 20391 solver.cpp:415]     Test net output #1: loss = 3.12164 (* 1 = 3.12164 loss)
I0704 11:05:51.383409 20391 solver.cpp:243] Iteration 6210, loss = 2.19392
I0704 11:05:51.383432 20391 solver.cpp:259]     Train net output #0: loss = 2.19392 (* 1 = 2.19392 loss)
I0704 11:05:51.383438 20391 solver.cpp:590] Iteration 6210, lr = 0.00236658
I0704 11:05:59.088009 20391 solver.cpp:243] Iteration 6237, loss = 1.67824
I0704 11:05:59.088080 20391 solver.cpp:259]     Train net output #0: loss = 1.67824 (* 1 = 1.67824 loss)
I0704 11:05:59.088098 20391 solver.cpp:590] Iteration 6237, lr = 0.00235179
I0704 11:06:07.234235 20391 solver.cpp:243] Iteration 6264, loss = 2.43629
I0704 11:06:07.234261 20391 solver.cpp:259]     Train net output #0: loss = 2.43629 (* 1 = 2.43629 loss)
I0704 11:06:07.234266 20391 solver.cpp:590] Iteration 6264, lr = 0.0023371
I0704 11:06:15.186920 20391 solver.cpp:243] Iteration 6291, loss = 1.91663
I0704 11:06:15.186946 20391 solver.cpp:259]     Train net output #0: loss = 1.91663 (* 1 = 1.91663 loss)
I0704 11:06:15.186952 20391 solver.cpp:590] Iteration 6291, lr = 0.00232251
I0704 11:06:22.937122 20391 solver.cpp:243] Iteration 6318, loss = 2.30973
I0704 11:06:22.937146 20391 solver.cpp:259]     Train net output #0: loss = 2.30973 (* 1 = 2.30973 loss)
I0704 11:06:22.937151 20391 solver.cpp:590] Iteration 6318, lr = 0.002308
I0704 11:06:30.657357 20391 solver.cpp:243] Iteration 6345, loss = 2.03847
I0704 11:06:30.657429 20391 solver.cpp:259]     Train net output #0: loss = 2.03847 (* 1 = 2.03847 loss)
I0704 11:06:30.657436 20391 solver.cpp:590] Iteration 6345, lr = 0.00229358
I0704 11:06:38.376415 20391 solver.cpp:243] Iteration 6372, loss = 2.00246
I0704 11:06:38.376440 20391 solver.cpp:259]     Train net output #0: loss = 2.00246 (* 1 = 2.00246 loss)
I0704 11:06:38.376446 20391 solver.cpp:590] Iteration 6372, lr = 0.00227926
I0704 11:06:46.082417 20391 solver.cpp:243] Iteration 6399, loss = 2.26881
I0704 11:06:46.082442 20391 solver.cpp:259]     Train net output #0: loss = 2.26881 (* 1 = 2.26881 loss)
I0704 11:06:46.082449 20391 solver.cpp:590] Iteration 6399, lr = 0.00226502
I0704 11:06:48.628705 20391 solver.cpp:347] Iteration 6409, Testing net (#0)
I0704 11:07:07.835467 20391 solver.cpp:415]     Test net output #0: accuracy = 0.359856
I0704 11:07:07.835551 20391 solver.cpp:415]     Test net output #1: loss = 3.08206 (* 1 = 3.08206 loss)
I0704 11:07:08.185784 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:07:12.244352 20391 solver.cpp:243] Iteration 6426, loss = 1.92016
I0704 11:07:12.244376 20391 solver.cpp:259]     Train net output #0: loss = 1.92016 (* 1 = 1.92016 loss)
I0704 11:07:12.244382 20391 solver.cpp:590] Iteration 6426, lr = 0.00225087
I0704 11:07:20.079071 20391 solver.cpp:243] Iteration 6453, loss = 2.32242
I0704 11:07:20.079095 20391 solver.cpp:259]     Train net output #0: loss = 2.32242 (* 1 = 2.32242 loss)
I0704 11:07:20.079102 20391 solver.cpp:590] Iteration 6453, lr = 0.00223681
I0704 11:07:27.832945 20391 solver.cpp:243] Iteration 6480, loss = 1.62187
I0704 11:07:27.832970 20391 solver.cpp:259]     Train net output #0: loss = 1.62187 (* 1 = 1.62187 loss)
I0704 11:07:27.832976 20391 solver.cpp:590] Iteration 6480, lr = 0.00222284
I0704 11:07:35.524166 20391 solver.cpp:243] Iteration 6507, loss = 2.06175
I0704 11:07:35.524190 20391 solver.cpp:259]     Train net output #0: loss = 2.06175 (* 1 = 2.06175 loss)
I0704 11:07:35.524196 20391 solver.cpp:590] Iteration 6507, lr = 0.00220896
I0704 11:07:43.210602 20391 solver.cpp:243] Iteration 6534, loss = 2.24195
I0704 11:07:43.210739 20391 solver.cpp:259]     Train net output #0: loss = 2.24195 (* 1 = 2.24195 loss)
I0704 11:07:43.210747 20391 solver.cpp:590] Iteration 6534, lr = 0.00219516
I0704 11:07:50.909718 20391 solver.cpp:243] Iteration 6561, loss = 1.79669
I0704 11:07:50.909741 20391 solver.cpp:259]     Train net output #0: loss = 1.79669 (* 1 = 1.79669 loss)
I0704 11:07:50.909749 20391 solver.cpp:590] Iteration 6561, lr = 0.00218145
I0704 11:07:58.560048 20391 solver.cpp:243] Iteration 6588, loss = 1.9316
I0704 11:07:58.560072 20391 solver.cpp:259]     Train net output #0: loss = 1.9316 (* 1 = 1.9316 loss)
I0704 11:07:58.560078 20391 solver.cpp:590] Iteration 6588, lr = 0.00216782
I0704 11:08:06.347793 20391 solver.cpp:243] Iteration 6615, loss = 1.81061
I0704 11:08:06.347839 20391 solver.cpp:259]     Train net output #0: loss = 1.81061 (* 1 = 1.81061 loss)
I0704 11:08:06.347848 20391 solver.cpp:590] Iteration 6615, lr = 0.00215428
I0704 11:08:10.331439 20391 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_6630.caffemodel
I0704 11:08:25.921586 20391 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_6630.solverstate
I0704 11:08:26.945013 20391 solver.cpp:347] Iteration 6630, Testing net (#0)
I0704 11:08:46.142462 20391 solver.cpp:415]     Test net output #0: accuracy = 0.366827
I0704 11:08:46.142487 20391 solver.cpp:415]     Test net output #1: loss = 3.03112 (* 1 = 3.03112 loss)
I0704 11:08:49.052312 20391 solver.cpp:243] Iteration 6642, loss = 1.80366
I0704 11:08:49.052345 20391 solver.cpp:259]     Train net output #0: loss = 1.80366 (* 1 = 1.80366 loss)
I0704 11:08:49.052351 20391 solver.cpp:590] Iteration 6642, lr = 0.00214082
I0704 11:08:56.723057 20391 solver.cpp:243] Iteration 6669, loss = 1.94312
I0704 11:08:56.723137 20391 solver.cpp:259]     Train net output #0: loss = 1.94312 (* 1 = 1.94312 loss)
I0704 11:08:56.723145 20391 solver.cpp:590] Iteration 6669, lr = 0.00212745
I0704 11:09:04.405781 20391 solver.cpp:243] Iteration 6696, loss = 1.60735
I0704 11:09:04.405807 20391 solver.cpp:259]     Train net output #0: loss = 1.60735 (* 1 = 1.60735 loss)
I0704 11:09:04.405812 20391 solver.cpp:590] Iteration 6696, lr = 0.00211416
I0704 11:09:12.130040 20391 solver.cpp:243] Iteration 6723, loss = 1.72084
I0704 11:09:12.130066 20391 solver.cpp:259]     Train net output #0: loss = 1.72084 (* 1 = 1.72084 loss)
I0704 11:09:12.130072 20391 solver.cpp:590] Iteration 6723, lr = 0.00210096
I0704 11:09:19.963686 20391 solver.cpp:243] Iteration 6750, loss = 1.89829
I0704 11:09:19.963711 20391 solver.cpp:259]     Train net output #0: loss = 1.89829 (* 1 = 1.89829 loss)
I0704 11:09:19.963717 20391 solver.cpp:590] Iteration 6750, lr = 0.00208783
I0704 11:09:27.666211 20391 solver.cpp:243] Iteration 6777, loss = 1.64106
I0704 11:09:27.666282 20391 solver.cpp:259]     Train net output #0: loss = 1.64106 (* 1 = 1.64106 loss)
I0704 11:09:27.666298 20391 solver.cpp:590] Iteration 6777, lr = 0.00207479
I0704 11:09:35.395334 20391 solver.cpp:243] Iteration 6804, loss = 1.80103
I0704 11:09:35.395360 20391 solver.cpp:259]     Train net output #0: loss = 1.80103 (* 1 = 1.80103 loss)
I0704 11:09:35.395366 20391 solver.cpp:590] Iteration 6804, lr = 0.00206183
I0704 11:09:43.062510 20391 solver.cpp:243] Iteration 6831, loss = 1.70713
I0704 11:09:43.062535 20391 solver.cpp:259]     Train net output #0: loss = 1.70713 (* 1 = 1.70713 loss)
I0704 11:09:43.062541 20391 solver.cpp:590] Iteration 6831, lr = 0.00204895
I0704 11:09:48.435545 20391 solver.cpp:347] Iteration 6851, Testing net (#0)
I0704 11:10:07.544770 20391 solver.cpp:415]     Test net output #0: accuracy = 0.371995
I0704 11:10:07.544859 20391 solver.cpp:415]     Test net output #1: loss = 3.00562 (* 1 = 3.00562 loss)
I0704 11:10:09.030563 20391 solver.cpp:243] Iteration 6858, loss = 1.79677
I0704 11:10:09.030591 20391 solver.cpp:259]     Train net output #0: loss = 1.79677 (* 1 = 1.79677 loss)
I0704 11:10:09.030598 20391 solver.cpp:590] Iteration 6858, lr = 0.00203616
I0704 11:10:16.715426 20391 solver.cpp:243] Iteration 6885, loss = 1.73479
I0704 11:10:16.715451 20391 solver.cpp:259]     Train net output #0: loss = 1.73479 (* 1 = 1.73479 loss)
I0704 11:10:16.715457 20391 solver.cpp:590] Iteration 6885, lr = 0.00202344
I0704 11:10:22.689558 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:10:24.396265 20391 solver.cpp:243] Iteration 6912, loss = 1.62903
I0704 11:10:24.396291 20391 solver.cpp:259]     Train net output #0: loss = 1.62903 (* 1 = 1.62903 loss)
I0704 11:10:24.396297 20391 solver.cpp:590] Iteration 6912, lr = 0.0020108
I0704 11:10:32.087502 20391 solver.cpp:243] Iteration 6939, loss = 1.60306
I0704 11:10:32.087543 20391 solver.cpp:259]     Train net output #0: loss = 1.60306 (* 1 = 1.60306 loss)
I0704 11:10:32.087551 20391 solver.cpp:590] Iteration 6939, lr = 0.00199824
I0704 11:10:39.757414 20391 solver.cpp:243] Iteration 6966, loss = 1.82575
I0704 11:10:39.757501 20391 solver.cpp:259]     Train net output #0: loss = 1.82575 (* 1 = 1.82575 loss)
I0704 11:10:39.757517 20391 solver.cpp:590] Iteration 6966, lr = 0.00198576
I0704 11:10:47.461100 20391 solver.cpp:243] Iteration 6993, loss = 1.78516
I0704 11:10:47.461127 20391 solver.cpp:259]     Train net output #0: loss = 1.78516 (* 1 = 1.78516 loss)
I0704 11:10:47.461132 20391 solver.cpp:590] Iteration 6993, lr = 0.00197335
I0704 11:10:55.143095 20391 solver.cpp:243] Iteration 7020, loss = 2.012
I0704 11:10:55.143121 20391 solver.cpp:259]     Train net output #0: loss = 2.012 (* 1 = 2.012 loss)
I0704 11:10:55.143126 20391 solver.cpp:590] Iteration 7020, lr = 0.00196103
I0704 11:11:02.808962 20391 solver.cpp:243] Iteration 7047, loss = 1.66414
I0704 11:11:02.808989 20391 solver.cpp:259]     Train net output #0: loss = 1.66414 (* 1 = 1.66414 loss)
I0704 11:11:02.808995 20391 solver.cpp:590] Iteration 7047, lr = 0.00194878
I0704 11:11:09.602728 20391 solver.cpp:347] Iteration 7072, Testing net (#0)
I0704 11:11:28.720559 20391 solver.cpp:415]     Test net output #0: accuracy = 0.374639
I0704 11:11:28.720660 20391 solver.cpp:415]     Test net output #1: loss = 2.97059 (* 1 = 2.97059 loss)
I0704 11:11:28.949894 20391 solver.cpp:243] Iteration 7074, loss = 1.79352
I0704 11:11:28.949920 20391 solver.cpp:259]     Train net output #0: loss = 1.79352 (* 1 = 1.79352 loss)
I0704 11:11:28.949926 20391 solver.cpp:590] Iteration 7074, lr = 0.00193661
I0704 11:11:36.472749 20391 solver.cpp:243] Iteration 7101, loss = 1.67106
I0704 11:11:36.472772 20391 solver.cpp:259]     Train net output #0: loss = 1.67106 (* 1 = 1.67106 loss)
I0704 11:11:36.472779 20391 solver.cpp:590] Iteration 7101, lr = 0.00192451
I0704 11:11:44.154531 20391 solver.cpp:243] Iteration 7128, loss = 1.78123
I0704 11:11:44.154562 20391 solver.cpp:259]     Train net output #0: loss = 1.78123 (* 1 = 1.78123 loss)
I0704 11:11:44.154570 20391 solver.cpp:590] Iteration 7128, lr = 0.00191249
I0704 11:11:51.864410 20391 solver.cpp:243] Iteration 7155, loss = 1.50337
I0704 11:11:51.864435 20391 solver.cpp:259]     Train net output #0: loss = 1.50337 (* 1 = 1.50337 loss)
I0704 11:11:51.864440 20391 solver.cpp:590] Iteration 7155, lr = 0.00190054
I0704 11:11:59.554570 20391 solver.cpp:243] Iteration 7182, loss = 1.80091
I0704 11:11:59.554672 20391 solver.cpp:259]     Train net output #0: loss = 1.80091 (* 1 = 1.80091 loss)
I0704 11:11:59.554687 20391 solver.cpp:590] Iteration 7182, lr = 0.00188867
I0704 11:12:07.296167 20391 solver.cpp:243] Iteration 7209, loss = 1.52522
I0704 11:12:07.296205 20391 solver.cpp:259]     Train net output #0: loss = 1.52522 (* 1 = 1.52522 loss)
I0704 11:12:07.296214 20391 solver.cpp:590] Iteration 7209, lr = 0.00187688
I0704 11:12:14.986186 20391 solver.cpp:243] Iteration 7236, loss = 1.67759
I0704 11:12:14.986210 20391 solver.cpp:259]     Train net output #0: loss = 1.67759 (* 1 = 1.67759 loss)
I0704 11:12:14.986217 20391 solver.cpp:590] Iteration 7236, lr = 0.00186515
I0704 11:12:22.667726 20391 solver.cpp:243] Iteration 7263, loss = 1.82607
I0704 11:12:22.667752 20391 solver.cpp:259]     Train net output #0: loss = 1.82607 (* 1 = 1.82607 loss)
I0704 11:12:22.667757 20391 solver.cpp:590] Iteration 7263, lr = 0.0018535
I0704 11:12:30.320230 20391 solver.cpp:243] Iteration 7290, loss = 1.75862
I0704 11:12:30.320333 20391 solver.cpp:259]     Train net output #0: loss = 1.75862 (* 1 = 1.75862 loss)
I0704 11:12:30.320339 20391 solver.cpp:590] Iteration 7290, lr = 0.00184192
I0704 11:12:30.891798 20391 solver.cpp:347] Iteration 7293, Testing net (#0)
I0704 11:12:50.000934 20391 solver.cpp:415]     Test net output #0: accuracy = 0.377043
I0704 11:12:50.000959 20391 solver.cpp:415]     Test net output #1: loss = 2.95583 (* 1 = 2.95583 loss)
I0704 11:12:56.324594 20391 solver.cpp:243] Iteration 7317, loss = 1.54613
I0704 11:12:56.324620 20391 solver.cpp:259]     Train net output #0: loss = 1.54613 (* 1 = 1.54613 loss)
I0704 11:12:56.324626 20391 solver.cpp:590] Iteration 7317, lr = 0.00183042
I0704 11:13:04.012326 20391 solver.cpp:243] Iteration 7344, loss = 1.55284
I0704 11:13:04.012445 20391 solver.cpp:259]     Train net output #0: loss = 1.55284 (* 1 = 1.55284 loss)
I0704 11:13:04.012452 20391 solver.cpp:590] Iteration 7344, lr = 0.00181899
I0704 11:13:11.703143 20391 solver.cpp:243] Iteration 7371, loss = 1.87424
I0704 11:13:11.703171 20391 solver.cpp:259]     Train net output #0: loss = 1.87424 (* 1 = 1.87424 loss)
I0704 11:13:11.703176 20391 solver.cpp:590] Iteration 7371, lr = 0.00180762
I0704 11:13:20.029088 20391 solver.cpp:243] Iteration 7398, loss = 1.80177
I0704 11:13:20.029114 20391 solver.cpp:259]     Train net output #0: loss = 1.80177 (* 1 = 1.80177 loss)
I0704 11:13:20.029119 20391 solver.cpp:590] Iteration 7398, lr = 0.00179633
I0704 11:13:20.594851 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:13:28.491850 20391 solver.cpp:243] Iteration 7425, loss = 1.54972
I0704 11:13:28.491878 20391 solver.cpp:259]     Train net output #0: loss = 1.54972 (* 1 = 1.54972 loss)
I0704 11:13:28.491883 20391 solver.cpp:590] Iteration 7425, lr = 0.00178511
I0704 11:13:36.894039 20391 solver.cpp:243] Iteration 7452, loss = 1.82143
I0704 11:13:36.894124 20391 solver.cpp:259]     Train net output #0: loss = 1.82143 (* 1 = 1.82143 loss)
I0704 11:13:36.894131 20391 solver.cpp:590] Iteration 7452, lr = 0.00177396
I0704 11:13:44.741458 20391 solver.cpp:243] Iteration 7479, loss = 1.39414
I0704 11:13:44.741484 20391 solver.cpp:259]     Train net output #0: loss = 1.39414 (* 1 = 1.39414 loss)
I0704 11:13:44.741490 20391 solver.cpp:590] Iteration 7479, lr = 0.00176288
I0704 11:13:52.566751 20391 solver.cpp:243] Iteration 7506, loss = 1.37474
I0704 11:13:52.566777 20391 solver.cpp:259]     Train net output #0: loss = 1.37474 (* 1 = 1.37474 loss)
I0704 11:13:52.566782 20391 solver.cpp:590] Iteration 7506, lr = 0.00175187
I0704 11:13:54.549906 20391 solver.cpp:347] Iteration 7514, Testing net (#0)
I0704 11:14:13.847879 20391 solver.cpp:415]     Test net output #0: accuracy = 0.376322
I0704 11:14:13.847941 20391 solver.cpp:415]     Test net output #1: loss = 2.93591 (* 1 = 2.93591 loss)
I0704 11:14:18.734388 20391 solver.cpp:243] Iteration 7533, loss = 1.4219
I0704 11:14:18.734413 20391 solver.cpp:259]     Train net output #0: loss = 1.4219 (* 1 = 1.4219 loss)
I0704 11:14:18.734418 20391 solver.cpp:590] Iteration 7533, lr = 0.00174093
I0704 11:14:26.416895 20391 solver.cpp:243] Iteration 7560, loss = 1.78014
I0704 11:14:26.416923 20391 solver.cpp:259]     Train net output #0: loss = 1.78014 (* 1 = 1.78014 loss)
I0704 11:14:26.416927 20391 solver.cpp:590] Iteration 7560, lr = 0.00173005
I0704 11:14:34.391194 20391 solver.cpp:243] Iteration 7587, loss = 1.57661
I0704 11:14:34.391218 20391 solver.cpp:259]     Train net output #0: loss = 1.57661 (* 1 = 1.57661 loss)
I0704 11:14:34.391223 20391 solver.cpp:590] Iteration 7587, lr = 0.00171925
I0704 11:14:43.206751 20391 solver.cpp:243] Iteration 7614, loss = 1.41445
I0704 11:14:43.206775 20391 solver.cpp:259]     Train net output #0: loss = 1.41445 (* 1 = 1.41445 loss)
I0704 11:14:43.206781 20391 solver.cpp:590] Iteration 7614, lr = 0.00170851
I0704 11:14:51.778744 20391 solver.cpp:243] Iteration 7641, loss = 1.74375
I0704 11:14:51.778842 20391 solver.cpp:259]     Train net output #0: loss = 1.74375 (* 1 = 1.74375 loss)
I0704 11:14:51.778848 20391 solver.cpp:590] Iteration 7641, lr = 0.00169784
I0704 11:14:59.659786 20391 solver.cpp:243] Iteration 7668, loss = 1.66915
I0704 11:14:59.659813 20391 solver.cpp:259]     Train net output #0: loss = 1.66915 (* 1 = 1.66915 loss)
I0704 11:14:59.659821 20391 solver.cpp:590] Iteration 7668, lr = 0.00168723
I0704 11:15:07.899355 20391 solver.cpp:243] Iteration 7695, loss = 1.66709
I0704 11:15:07.899381 20391 solver.cpp:259]     Train net output #0: loss = 1.66709 (* 1 = 1.66709 loss)
I0704 11:15:07.899387 20391 solver.cpp:590] Iteration 7695, lr = 0.00167669
I0704 11:15:16.051599 20391 solver.cpp:243] Iteration 7722, loss = 1.609
I0704 11:15:16.051625 20391 solver.cpp:259]     Train net output #0: loss = 1.609 (* 1 = 1.609 loss)
I0704 11:15:16.051630 20391 solver.cpp:590] Iteration 7722, lr = 0.00166622
I0704 11:15:19.477578 20391 solver.cpp:347] Iteration 7735, Testing net (#0)
I0704 11:15:38.580240 20391 solver.cpp:415]     Test net output #0: accuracy = 0.378365
I0704 11:15:38.580325 20391 solver.cpp:415]     Test net output #1: loss = 2.90166 (* 1 = 2.90166 loss)
I0704 11:15:42.123657 20391 solver.cpp:243] Iteration 7749, loss = 1.56186
I0704 11:15:42.123683 20391 solver.cpp:259]     Train net output #0: loss = 1.56186 (* 1 = 1.56186 loss)
I0704 11:15:42.123689 20391 solver.cpp:590] Iteration 7749, lr = 0.00165581
I0704 11:15:49.876893 20391 solver.cpp:243] Iteration 7776, loss = 1.48456
I0704 11:15:49.876919 20391 solver.cpp:259]     Train net output #0: loss = 1.48456 (* 1 = 1.48456 loss)
I0704 11:15:49.876924 20391 solver.cpp:590] Iteration 7776, lr = 0.00164547
I0704 11:15:57.630784 20391 solver.cpp:243] Iteration 7803, loss = 1.47556
I0704 11:15:57.630808 20391 solver.cpp:259]     Train net output #0: loss = 1.47556 (* 1 = 1.47556 loss)
I0704 11:15:57.630815 20391 solver.cpp:590] Iteration 7803, lr = 0.00163519
I0704 11:16:05.358124 20391 solver.cpp:243] Iteration 7830, loss = 1.29068
I0704 11:16:05.358150 20391 solver.cpp:259]     Train net output #0: loss = 1.29068 (* 1 = 1.29068 loss)
I0704 11:16:05.358156 20391 solver.cpp:590] Iteration 7830, lr = 0.00162498
I0704 11:16:13.060451 20391 solver.cpp:243] Iteration 7857, loss = 1.40937
I0704 11:16:13.060518 20391 solver.cpp:259]     Train net output #0: loss = 1.40937 (* 1 = 1.40937 loss)
I0704 11:16:13.060534 20391 solver.cpp:590] Iteration 7857, lr = 0.00161483
I0704 11:16:20.950969 20391 solver.cpp:243] Iteration 7884, loss = 1.57443
I0704 11:16:20.950994 20391 solver.cpp:259]     Train net output #0: loss = 1.57443 (* 1 = 1.57443 loss)
I0704 11:16:20.951000 20391 solver.cpp:590] Iteration 7884, lr = 0.00160474
I0704 11:16:23.890192 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:16:28.809624 20391 solver.cpp:243] Iteration 7911, loss = 1.54001
I0704 11:16:28.809648 20391 solver.cpp:259]     Train net output #0: loss = 1.54001 (* 1 = 1.54001 loss)
I0704 11:16:28.809654 20391 solver.cpp:590] Iteration 7911, lr = 0.00159472
I0704 11:16:36.686280 20391 solver.cpp:243] Iteration 7938, loss = 1.80541
I0704 11:16:36.686306 20391 solver.cpp:259]     Train net output #0: loss = 1.80541 (* 1 = 1.80541 loss)
I0704 11:16:36.686312 20391 solver.cpp:590] Iteration 7938, lr = 0.00158476
I0704 11:16:41.744928 20391 solver.cpp:347] Iteration 7956, Testing net (#0)
I0704 11:17:01.165272 20391 solver.cpp:415]     Test net output #0: accuracy = 0.379808
I0704 11:17:01.165344 20391 solver.cpp:415]     Test net output #1: loss = 2.90035 (* 1 = 2.90035 loss)
I0704 11:17:03.220540 20391 solver.cpp:243] Iteration 7965, loss = 1.74078
I0704 11:17:03.220564 20391 solver.cpp:259]     Train net output #0: loss = 1.74078 (* 1 = 1.74078 loss)
I0704 11:17:03.220569 20391 solver.cpp:590] Iteration 7965, lr = 0.00157486
I0704 11:17:10.933979 20391 solver.cpp:243] Iteration 7992, loss = 1.37659
I0704 11:17:10.934006 20391 solver.cpp:259]     Train net output #0: loss = 1.37659 (* 1 = 1.37659 loss)
I0704 11:17:10.934012 20391 solver.cpp:590] Iteration 7992, lr = 0.00156502
I0704 11:17:18.619187 20391 solver.cpp:243] Iteration 8019, loss = 1.68632
I0704 11:17:18.619213 20391 solver.cpp:259]     Train net output #0: loss = 1.68632 (* 1 = 1.68632 loss)
I0704 11:17:18.619220 20391 solver.cpp:590] Iteration 8019, lr = 0.00155525
I0704 11:17:26.315996 20391 solver.cpp:243] Iteration 8046, loss = 1.70501
I0704 11:17:26.316021 20391 solver.cpp:259]     Train net output #0: loss = 1.70501 (* 1 = 1.70501 loss)
I0704 11:17:26.316027 20391 solver.cpp:590] Iteration 8046, lr = 0.00154553
I0704 11:17:34.175442 20391 solver.cpp:243] Iteration 8073, loss = 1.19135
I0704 11:17:34.175582 20391 solver.cpp:259]     Train net output #0: loss = 1.19135 (* 1 = 1.19135 loss)
I0704 11:17:34.175590 20391 solver.cpp:590] Iteration 8073, lr = 0.00153588
I0704 11:17:41.871402 20391 solver.cpp:243] Iteration 8100, loss = 1.58699
I0704 11:17:41.871429 20391 solver.cpp:259]     Train net output #0: loss = 1.58699 (* 1 = 1.58699 loss)
I0704 11:17:41.871438 20391 solver.cpp:590] Iteration 8100, lr = 0.00152628
I0704 11:17:49.570649 20391 solver.cpp:243] Iteration 8127, loss = 1.28974
I0704 11:17:49.570674 20391 solver.cpp:259]     Train net output #0: loss = 1.28974 (* 1 = 1.28974 loss)
I0704 11:17:49.570682 20391 solver.cpp:590] Iteration 8127, lr = 0.00151675
I0704 11:17:57.417057 20391 solver.cpp:243] Iteration 8154, loss = 1.35432
I0704 11:17:57.417083 20391 solver.cpp:259]     Train net output #0: loss = 1.35432 (* 1 = 1.35432 loss)
I0704 11:17:57.417089 20391 solver.cpp:590] Iteration 8154, lr = 0.00150728
I0704 11:18:03.648015 20391 solver.cpp:347] Iteration 8177, Testing net (#0)
I0704 11:18:22.843662 20391 solver.cpp:415]     Test net output #0: accuracy = 0.383774
I0704 11:18:22.843727 20391 solver.cpp:415]     Test net output #1: loss = 2.88757 (* 1 = 2.88757 loss)
I0704 11:18:23.474648 20391 solver.cpp:243] Iteration 8181, loss = 1.76853
I0704 11:18:23.474674 20391 solver.cpp:259]     Train net output #0: loss = 1.76853 (* 1 = 1.76853 loss)
I0704 11:18:23.474681 20391 solver.cpp:590] Iteration 8181, lr = 0.00149786
I0704 11:18:31.165316 20391 solver.cpp:243] Iteration 8208, loss = 1.39556
I0704 11:18:31.165341 20391 solver.cpp:259]     Train net output #0: loss = 1.39556 (* 1 = 1.39556 loss)
I0704 11:18:31.165346 20391 solver.cpp:590] Iteration 8208, lr = 0.00148851
I0704 11:18:38.848373 20391 solver.cpp:243] Iteration 8235, loss = 1.18271
I0704 11:18:38.848398 20391 solver.cpp:259]     Train net output #0: loss = 1.18271 (* 1 = 1.18271 loss)
I0704 11:18:38.848404 20391 solver.cpp:590] Iteration 8235, lr = 0.00147921
I0704 11:18:46.568125 20391 solver.cpp:243] Iteration 8262, loss = 1.43753
I0704 11:18:46.568151 20391 solver.cpp:259]     Train net output #0: loss = 1.43753 (* 1 = 1.43753 loss)
I0704 11:18:46.568157 20391 solver.cpp:590] Iteration 8262, lr = 0.00146997
I0704 11:18:54.312917 20391 solver.cpp:243] Iteration 8289, loss = 1.36622
I0704 11:18:54.312964 20391 solver.cpp:259]     Train net output #0: loss = 1.36622 (* 1 = 1.36622 loss)
I0704 11:18:54.312971 20391 solver.cpp:590] Iteration 8289, lr = 0.00146079
I0704 11:19:02.045435 20391 solver.cpp:243] Iteration 8316, loss = 1.60904
I0704 11:19:02.045461 20391 solver.cpp:259]     Train net output #0: loss = 1.60904 (* 1 = 1.60904 loss)
I0704 11:19:02.045467 20391 solver.cpp:590] Iteration 8316, lr = 0.00145166
I0704 11:19:09.783763 20391 solver.cpp:243] Iteration 8343, loss = 1.41002
I0704 11:19:09.783788 20391 solver.cpp:259]     Train net output #0: loss = 1.41002 (* 1 = 1.41002 loss)
I0704 11:19:09.783794 20391 solver.cpp:590] Iteration 8343, lr = 0.00144259
I0704 11:19:17.511595 20391 solver.cpp:243] Iteration 8370, loss = 1.38124
I0704 11:19:17.511618 20391 solver.cpp:259]     Train net output #0: loss = 1.38124 (* 1 = 1.38124 loss)
I0704 11:19:17.511625 20391 solver.cpp:590] Iteration 8370, lr = 0.00143358
I0704 11:19:22.612100 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:19:25.172873 20391 solver.cpp:243] Iteration 8397, loss = 1.61775
I0704 11:19:25.172963 20391 solver.cpp:259]     Train net output #0: loss = 1.61775 (* 1 = 1.61775 loss)
I0704 11:19:25.172979 20391 solver.cpp:590] Iteration 8397, lr = 0.00142463
I0704 11:19:25.173193 20391 solver.cpp:347] Iteration 8398, Testing net (#0)
I0704 11:19:44.589118 20391 solver.cpp:415]     Test net output #0: accuracy = 0.388341
I0704 11:19:44.589143 20391 solver.cpp:415]     Test net output #1: loss = 2.87594 (* 1 = 2.87594 loss)
I0704 11:19:51.559270 20391 solver.cpp:243] Iteration 8424, loss = 1.90355
I0704 11:19:51.559298 20391 solver.cpp:259]     Train net output #0: loss = 1.90355 (* 1 = 1.90355 loss)
I0704 11:19:51.559304 20391 solver.cpp:590] Iteration 8424, lr = 0.00141573
I0704 11:19:59.321478 20391 solver.cpp:243] Iteration 8451, loss = 1.28087
I0704 11:19:59.321537 20391 solver.cpp:259]     Train net output #0: loss = 1.28087 (* 1 = 1.28087 loss)
I0704 11:19:59.321542 20391 solver.cpp:590] Iteration 8451, lr = 0.00140689
I0704 11:20:07.094102 20391 solver.cpp:243] Iteration 8478, loss = 1.10947
I0704 11:20:07.094127 20391 solver.cpp:259]     Train net output #0: loss = 1.10947 (* 1 = 1.10947 loss)
I0704 11:20:07.094132 20391 solver.cpp:590] Iteration 8478, lr = 0.0013981
I0704 11:20:14.827587 20391 solver.cpp:243] Iteration 8505, loss = 1.17365
I0704 11:20:14.827612 20391 solver.cpp:259]     Train net output #0: loss = 1.17365 (* 1 = 1.17365 loss)
I0704 11:20:14.827618 20391 solver.cpp:590] Iteration 8505, lr = 0.00138937
I0704 11:20:22.657762 20391 solver.cpp:243] Iteration 8532, loss = 1.75424
I0704 11:20:22.657788 20391 solver.cpp:259]     Train net output #0: loss = 1.75424 (* 1 = 1.75424 loss)
I0704 11:20:22.657794 20391 solver.cpp:590] Iteration 8532, lr = 0.00138069
I0704 11:20:30.511020 20391 solver.cpp:243] Iteration 8559, loss = 1.38297
I0704 11:20:30.511080 20391 solver.cpp:259]     Train net output #0: loss = 1.38297 (* 1 = 1.38297 loss)
I0704 11:20:30.511086 20391 solver.cpp:590] Iteration 8559, lr = 0.00137206
I0704 11:20:38.249615 20391 solver.cpp:243] Iteration 8586, loss = 1.37306
I0704 11:20:38.249640 20391 solver.cpp:259]     Train net output #0: loss = 1.37306 (* 1 = 1.37306 loss)
I0704 11:20:38.249645 20391 solver.cpp:590] Iteration 8586, lr = 0.00136349
I0704 11:20:45.943035 20391 solver.cpp:243] Iteration 8613, loss = 1.06441
I0704 11:20:45.943060 20391 solver.cpp:259]     Train net output #0: loss = 1.06441 (* 1 = 1.06441 loss)
I0704 11:20:45.943068 20391 solver.cpp:590] Iteration 8613, lr = 0.00135498
I0704 11:20:47.382222 20391 solver.cpp:347] Iteration 8619, Testing net (#0)
I0704 11:21:06.732653 20391 solver.cpp:415]     Test net output #0: accuracy = 0.389543
I0704 11:21:06.732708 20391 solver.cpp:415]     Test net output #1: loss = 2.85483 (* 1 = 2.85483 loss)
I0704 11:21:12.202401 20391 solver.cpp:243] Iteration 8640, loss = 1.47167
I0704 11:21:12.202428 20391 solver.cpp:259]     Train net output #0: loss = 1.47167 (* 1 = 1.47167 loss)
I0704 11:21:12.202435 20391 solver.cpp:590] Iteration 8640, lr = 0.00134651
I0704 11:21:19.900143 20391 solver.cpp:243] Iteration 8667, loss = 1.08613
I0704 11:21:19.900169 20391 solver.cpp:259]     Train net output #0: loss = 1.08613 (* 1 = 1.08613 loss)
I0704 11:21:19.900176 20391 solver.cpp:590] Iteration 8667, lr = 0.0013381
I0704 11:21:27.590036 20391 solver.cpp:243] Iteration 8694, loss = 1.23479
I0704 11:21:27.590062 20391 solver.cpp:259]     Train net output #0: loss = 1.23479 (* 1 = 1.23479 loss)
I0704 11:21:27.590067 20391 solver.cpp:590] Iteration 8694, lr = 0.00132975
I0704 11:21:35.264829 20391 solver.cpp:243] Iteration 8721, loss = 1.29928
I0704 11:21:35.264854 20391 solver.cpp:259]     Train net output #0: loss = 1.29928 (* 1 = 1.29928 loss)
I0704 11:21:35.264859 20391 solver.cpp:590] Iteration 8721, lr = 0.00132144
I0704 11:21:42.962106 20391 solver.cpp:243] Iteration 8748, loss = 1.23733
I0704 11:21:42.962194 20391 solver.cpp:259]     Train net output #0: loss = 1.23733 (* 1 = 1.23733 loss)
I0704 11:21:42.962210 20391 solver.cpp:590] Iteration 8748, lr = 0.00131319
I0704 11:21:50.661975 20391 solver.cpp:243] Iteration 8775, loss = 1.30298
I0704 11:21:50.662000 20391 solver.cpp:259]     Train net output #0: loss = 1.30298 (* 1 = 1.30298 loss)
I0704 11:21:50.662005 20391 solver.cpp:590] Iteration 8775, lr = 0.00130498
I0704 11:21:58.334985 20391 solver.cpp:243] Iteration 8802, loss = 1.21103
I0704 11:21:58.335011 20391 solver.cpp:259]     Train net output #0: loss = 1.21103 (* 1 = 1.21103 loss)
I0704 11:21:58.335016 20391 solver.cpp:590] Iteration 8802, lr = 0.00129683
I0704 11:22:06.084846 20391 solver.cpp:243] Iteration 8829, loss = 1.38804
I0704 11:22:06.084873 20391 solver.cpp:259]     Train net output #0: loss = 1.38804 (* 1 = 1.38804 loss)
I0704 11:22:06.084878 20391 solver.cpp:590] Iteration 8829, lr = 0.00128873
I0704 11:22:08.945513 20391 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_8840.caffemodel
I0704 11:22:26.748819 20391 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_8840.solverstate
I0704 11:22:27.788044 20391 solver.cpp:347] Iteration 8840, Testing net (#0)
I0704 11:22:31.162019 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:22:47.012030 20391 solver.cpp:415]     Test net output #0: accuracy = 0.393269
I0704 11:22:47.012055 20391 solver.cpp:415]     Test net output #1: loss = 2.85205 (* 1 = 2.85205 loss)
I0704 11:22:51.111899 20391 solver.cpp:243] Iteration 8856, loss = 1.26893
I0704 11:22:51.111922 20391 solver.cpp:259]     Train net output #0: loss = 1.26893 (* 1 = 1.26893 loss)
I0704 11:22:51.111927 20391 solver.cpp:590] Iteration 8856, lr = 0.00128068
I0704 11:22:58.972112 20391 solver.cpp:243] Iteration 8883, loss = 0.918018
I0704 11:22:58.972245 20391 solver.cpp:259]     Train net output #0: loss = 0.918018 (* 1 = 0.918018 loss)
I0704 11:22:58.972252 20391 solver.cpp:590] Iteration 8883, lr = 0.00127268
I0704 11:23:06.740895 20391 solver.cpp:243] Iteration 8910, loss = 1.47293
I0704 11:23:06.740921 20391 solver.cpp:259]     Train net output #0: loss = 1.47293 (* 1 = 1.47293 loss)
I0704 11:23:06.740926 20391 solver.cpp:590] Iteration 8910, lr = 0.00126473
I0704 11:23:14.474814 20391 solver.cpp:243] Iteration 8937, loss = 1.268
I0704 11:23:14.474841 20391 solver.cpp:259]     Train net output #0: loss = 1.268 (* 1 = 1.268 loss)
I0704 11:23:14.474848 20391 solver.cpp:590] Iteration 8937, lr = 0.00125683
I0704 11:23:22.833516 20391 solver.cpp:243] Iteration 8964, loss = 1.0895
I0704 11:23:22.833540 20391 solver.cpp:259]     Train net output #0: loss = 1.0895 (* 1 = 1.0895 loss)
I0704 11:23:22.833545 20391 solver.cpp:590] Iteration 8964, lr = 0.00124898
I0704 11:23:30.855901 20391 solver.cpp:243] Iteration 8991, loss = 1.36053
I0704 11:23:30.855955 20391 solver.cpp:259]     Train net output #0: loss = 1.36053 (* 1 = 1.36053 loss)
I0704 11:23:30.855962 20391 solver.cpp:590] Iteration 8991, lr = 0.00124118
I0704 11:23:38.705391 20391 solver.cpp:243] Iteration 9018, loss = 1.14934
I0704 11:23:38.705416 20391 solver.cpp:259]     Train net output #0: loss = 1.14934 (* 1 = 1.14934 loss)
I0704 11:23:38.705422 20391 solver.cpp:590] Iteration 9018, lr = 0.00123343
I0704 11:23:46.557742 20391 solver.cpp:243] Iteration 9045, loss = 1.75616
I0704 11:23:46.557770 20391 solver.cpp:259]     Train net output #0: loss = 1.75616 (* 1 = 1.75616 loss)
I0704 11:23:46.557776 20391 solver.cpp:590] Iteration 9045, lr = 0.00122572
I0704 11:23:51.001242 20391 solver.cpp:347] Iteration 9061, Testing net (#0)
I0704 11:24:10.162659 20391 solver.cpp:415]     Test net output #0: accuracy = 0.392788
I0704 11:24:10.162724 20391 solver.cpp:415]     Test net output #1: loss = 2.85751 (* 1 = 2.85751 loss)
I0704 11:24:12.804766 20391 solver.cpp:243] Iteration 9072, loss = 1.59723
I0704 11:24:12.804792 20391 solver.cpp:259]     Train net output #0: loss = 1.59723 (* 1 = 1.59723 loss)
I0704 11:24:12.804798 20391 solver.cpp:590] Iteration 9072, lr = 0.00121807
I0704 11:24:20.621536 20391 solver.cpp:243] Iteration 9099, loss = 1.0614
I0704 11:24:20.621563 20391 solver.cpp:259]     Train net output #0: loss = 1.0614 (* 1 = 1.0614 loss)
I0704 11:24:20.621569 20391 solver.cpp:590] Iteration 9099, lr = 0.00121046
I0704 11:24:28.469420 20391 solver.cpp:243] Iteration 9126, loss = 1.22104
I0704 11:24:28.469449 20391 solver.cpp:259]     Train net output #0: loss = 1.22104 (* 1 = 1.22104 loss)
I0704 11:24:28.469455 20391 solver.cpp:590] Iteration 9126, lr = 0.0012029
I0704 11:24:36.335916 20391 solver.cpp:243] Iteration 9153, loss = 1.55224
I0704 11:24:36.335942 20391 solver.cpp:259]     Train net output #0: loss = 1.55224 (* 1 = 1.55224 loss)
I0704 11:24:36.335947 20391 solver.cpp:590] Iteration 9153, lr = 0.00119539
I0704 11:24:44.194128 20391 solver.cpp:243] Iteration 9180, loss = 1.38595
I0704 11:24:44.194213 20391 solver.cpp:259]     Train net output #0: loss = 1.38595 (* 1 = 1.38595 loss)
I0704 11:24:44.194221 20391 solver.cpp:590] Iteration 9180, lr = 0.00118792
I0704 11:24:52.288980 20391 solver.cpp:243] Iteration 9207, loss = 1.15599
I0704 11:24:52.289005 20391 solver.cpp:259]     Train net output #0: loss = 1.15599 (* 1 = 1.15599 loss)
I0704 11:24:52.289011 20391 solver.cpp:590] Iteration 9207, lr = 0.0011805
I0704 11:25:00.166344 20391 solver.cpp:243] Iteration 9234, loss = 1.55496
I0704 11:25:00.166370 20391 solver.cpp:259]     Train net output #0: loss = 1.55496 (* 1 = 1.55496 loss)
I0704 11:25:00.166376 20391 solver.cpp:590] Iteration 9234, lr = 0.00117312
I0704 11:25:08.027982 20391 solver.cpp:243] Iteration 9261, loss = 1.34027
I0704 11:25:08.028005 20391 solver.cpp:259]     Train net output #0: loss = 1.34027 (* 1 = 1.34027 loss)
I0704 11:25:08.028010 20391 solver.cpp:590] Iteration 9261, lr = 0.0011658
I0704 11:25:14.111111 20391 solver.cpp:347] Iteration 9282, Testing net (#0)
I0704 11:25:21.367660 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:25:33.218655 20391 solver.cpp:415]     Test net output #0: accuracy = 0.397837
I0704 11:25:33.218680 20391 solver.cpp:415]     Test net output #1: loss = 2.8372 (* 1 = 2.8372 loss)
I0704 11:25:34.425745 20391 solver.cpp:243] Iteration 9288, loss = 1.11407
I0704 11:25:34.425768 20391 solver.cpp:259]     Train net output #0: loss = 1.11407 (* 1 = 1.11407 loss)
I0704 11:25:34.425773 20391 solver.cpp:590] Iteration 9288, lr = 0.00115852
I0704 11:25:42.403852 20391 solver.cpp:243] Iteration 9315, loss = 1.16243
I0704 11:25:42.403878 20391 solver.cpp:259]     Train net output #0: loss = 1.16243 (* 1 = 1.16243 loss)
I0704 11:25:42.403884 20391 solver.cpp:590] Iteration 9315, lr = 0.00115128
I0704 11:25:50.250517 20391 solver.cpp:243] Iteration 9342, loss = 1.48641
I0704 11:25:50.250545 20391 solver.cpp:259]     Train net output #0: loss = 1.48641 (* 1 = 1.48641 loss)
I0704 11:25:50.250550 20391 solver.cpp:590] Iteration 9342, lr = 0.00114409
I0704 11:25:58.179841 20391 solver.cpp:243] Iteration 9369, loss = 1.107
I0704 11:25:58.179898 20391 solver.cpp:259]     Train net output #0: loss = 1.107 (* 1 = 1.107 loss)
I0704 11:25:58.179904 20391 solver.cpp:590] Iteration 9369, lr = 0.00113694
I0704 11:26:06.028434 20391 solver.cpp:243] Iteration 9396, loss = 1.22218
I0704 11:26:06.028460 20391 solver.cpp:259]     Train net output #0: loss = 1.22218 (* 1 = 1.22218 loss)
I0704 11:26:06.028465 20391 solver.cpp:590] Iteration 9396, lr = 0.00112984
I0704 11:26:13.731125 20391 solver.cpp:243] Iteration 9423, loss = 1.19636
I0704 11:26:13.731151 20391 solver.cpp:259]     Train net output #0: loss = 1.19636 (* 1 = 1.19636 loss)
I0704 11:26:13.731158 20391 solver.cpp:590] Iteration 9423, lr = 0.00112278
I0704 11:26:21.402204 20391 solver.cpp:243] Iteration 9450, loss = 1.35413
I0704 11:26:21.402230 20391 solver.cpp:259]     Train net output #0: loss = 1.35413 (* 1 = 1.35413 loss)
I0704 11:26:21.402236 20391 solver.cpp:590] Iteration 9450, lr = 0.00111577
I0704 11:26:29.061974 20391 solver.cpp:243] Iteration 9477, loss = 1.49813
I0704 11:26:29.062093 20391 solver.cpp:259]     Train net output #0: loss = 1.49813 (* 1 = 1.49813 loss)
I0704 11:26:29.062100 20391 solver.cpp:590] Iteration 9477, lr = 0.0011088
I0704 11:26:36.213719 20391 solver.cpp:347] Iteration 9503, Testing net (#0)
I0704 11:26:55.306542 20391 solver.cpp:415]     Test net output #0: accuracy = 0.395312
I0704 11:26:55.306569 20391 solver.cpp:415]     Test net output #1: loss = 2.83554 (* 1 = 2.83554 loss)
I0704 11:26:55.449102 20391 solver.cpp:243] Iteration 9504, loss = 1.08018
I0704 11:26:55.449126 20391 solver.cpp:259]     Train net output #0: loss = 1.08018 (* 1 = 1.08018 loss)
I0704 11:26:55.449133 20391 solver.cpp:590] Iteration 9504, lr = 0.00110187
I0704 11:27:02.836568 20391 solver.cpp:243] Iteration 9531, loss = 1.35309
I0704 11:27:02.836639 20391 solver.cpp:259]     Train net output #0: loss = 1.35309 (* 1 = 1.35309 loss)
I0704 11:27:02.836655 20391 solver.cpp:590] Iteration 9531, lr = 0.00109499
I0704 11:27:10.497418 20391 solver.cpp:243] Iteration 9558, loss = 1.23613
I0704 11:27:10.497445 20391 solver.cpp:259]     Train net output #0: loss = 1.23613 (* 1 = 1.23613 loss)
I0704 11:27:10.497450 20391 solver.cpp:590] Iteration 9558, lr = 0.00108815
I0704 11:27:18.223301 20391 solver.cpp:243] Iteration 9585, loss = 1.11978
I0704 11:27:18.223335 20391 solver.cpp:259]     Train net output #0: loss = 1.11978 (* 1 = 1.11978 loss)
I0704 11:27:18.223340 20391 solver.cpp:590] Iteration 9585, lr = 0.00108136
I0704 11:27:25.891058 20391 solver.cpp:243] Iteration 9612, loss = 0.966654
I0704 11:27:25.891086 20391 solver.cpp:259]     Train net output #0: loss = 0.966654 (* 1 = 0.966654 loss)
I0704 11:27:25.891093 20391 solver.cpp:590] Iteration 9612, lr = 0.0010746
I0704 11:27:33.632360 20391 solver.cpp:243] Iteration 9639, loss = 1.21519
I0704 11:27:33.632442 20391 solver.cpp:259]     Train net output #0: loss = 1.21519 (* 1 = 1.21519 loss)
I0704 11:27:33.632448 20391 solver.cpp:590] Iteration 9639, lr = 0.00106789
I0704 11:27:41.303550 20391 solver.cpp:243] Iteration 9666, loss = 1.188
I0704 11:27:41.303575 20391 solver.cpp:259]     Train net output #0: loss = 1.188 (* 1 = 1.188 loss)
I0704 11:27:41.303581 20391 solver.cpp:590] Iteration 9666, lr = 0.00106122
I0704 11:27:48.966347 20391 solver.cpp:243] Iteration 9693, loss = 0.996374
I0704 11:27:48.966383 20391 solver.cpp:259]     Train net output #0: loss = 0.996374 (* 1 = 0.996374 loss)
I0704 11:27:48.966388 20391 solver.cpp:590] Iteration 9693, lr = 0.00105459
I0704 11:27:56.613330 20391 solver.cpp:243] Iteration 9720, loss = 1.04859
I0704 11:27:56.613356 20391 solver.cpp:259]     Train net output #0: loss = 1.04859 (* 1 = 1.04859 loss)
I0704 11:27:56.613363 20391 solver.cpp:590] Iteration 9720, lr = 0.001048
I0704 11:27:57.464776 20391 solver.cpp:347] Iteration 9724, Testing net (#0)
I0704 11:28:08.578985 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:28:16.576133 20391 solver.cpp:415]     Test net output #0: accuracy = 0.397596
I0704 11:28:16.576159 20391 solver.cpp:415]     Test net output #1: loss = 2.82172 (* 1 = 2.82172 loss)
I0704 11:28:22.652927 20391 solver.cpp:243] Iteration 9747, loss = 1.15993
I0704 11:28:22.652953 20391 solver.cpp:259]     Train net output #0: loss = 1.15993 (* 1 = 1.15993 loss)
I0704 11:28:22.652959 20391 solver.cpp:590] Iteration 9747, lr = 0.00104146
I0704 11:28:30.350576 20391 solver.cpp:243] Iteration 9774, loss = 1.36372
I0704 11:28:30.350601 20391 solver.cpp:259]     Train net output #0: loss = 1.36372 (* 1 = 1.36372 loss)
I0704 11:28:30.350607 20391 solver.cpp:590] Iteration 9774, lr = 0.00103495
I0704 11:28:38.043480 20391 solver.cpp:243] Iteration 9801, loss = 1.16035
I0704 11:28:38.043506 20391 solver.cpp:259]     Train net output #0: loss = 1.16035 (* 1 = 1.16035 loss)
I0704 11:28:38.043512 20391 solver.cpp:590] Iteration 9801, lr = 0.00102849
I0704 11:28:45.722664 20391 solver.cpp:243] Iteration 9828, loss = 1.45897
I0704 11:28:45.722724 20391 solver.cpp:259]     Train net output #0: loss = 1.45897 (* 1 = 1.45897 loss)
I0704 11:28:45.722731 20391 solver.cpp:590] Iteration 9828, lr = 0.00102206
I0704 11:28:53.436589 20391 solver.cpp:243] Iteration 9855, loss = 1.03145
I0704 11:28:53.436612 20391 solver.cpp:259]     Train net output #0: loss = 1.03145 (* 1 = 1.03145 loss)
I0704 11:28:53.436619 20391 solver.cpp:590] Iteration 9855, lr = 0.00101568
I0704 11:29:01.179811 20391 solver.cpp:243] Iteration 9882, loss = 1.01708
I0704 11:29:01.179837 20391 solver.cpp:259]     Train net output #0: loss = 1.01708 (* 1 = 1.01708 loss)
I0704 11:29:01.179843 20391 solver.cpp:590] Iteration 9882, lr = 0.00100933
I0704 11:29:08.929267 20391 solver.cpp:243] Iteration 9909, loss = 1.04868
I0704 11:29:08.929296 20391 solver.cpp:259]     Train net output #0: loss = 1.04868 (* 1 = 1.04868 loss)
I0704 11:29:08.929301 20391 solver.cpp:590] Iteration 9909, lr = 0.00100303
I0704 11:29:16.749476 20391 solver.cpp:243] Iteration 9936, loss = 1.193
I0704 11:29:16.749559 20391 solver.cpp:259]     Train net output #0: loss = 1.193 (* 1 = 1.193 loss)
I0704 11:29:16.749567 20391 solver.cpp:590] Iteration 9936, lr = 0.000996765
I0704 11:29:19.050449 20391 solver.cpp:347] Iteration 9945, Testing net (#0)
I0704 11:29:38.162554 20391 solver.cpp:415]     Test net output #0: accuracy = 0.402885
I0704 11:29:38.162578 20391 solver.cpp:415]     Test net output #1: loss = 2.81512 (* 1 = 2.81512 loss)
I0704 11:29:42.769371 20391 solver.cpp:243] Iteration 9963, loss = 1.25449
I0704 11:29:42.769397 20391 solver.cpp:259]     Train net output #0: loss = 1.25449 (* 1 = 1.25449 loss)
I0704 11:29:42.769403 20391 solver.cpp:590] Iteration 9963, lr = 0.000990539
I0704 11:29:50.534271 20391 solver.cpp:243] Iteration 9990, loss = 1.30426
I0704 11:29:50.534348 20391 solver.cpp:259]     Train net output #0: loss = 1.30426 (* 1 = 1.30426 loss)
I0704 11:29:50.534363 20391 solver.cpp:590] Iteration 9990, lr = 0.000984351
I0704 11:29:58.322636 20391 solver.cpp:243] Iteration 10017, loss = 1.15695
I0704 11:29:58.322660 20391 solver.cpp:259]     Train net output #0: loss = 1.15695 (* 1 = 1.15695 loss)
I0704 11:29:58.322666 20391 solver.cpp:590] Iteration 10017, lr = 0.000978203
I0704 11:30:06.037801 20391 solver.cpp:243] Iteration 10044, loss = 1.04577
I0704 11:30:06.037827 20391 solver.cpp:259]     Train net output #0: loss = 1.04577 (* 1 = 1.04577 loss)
I0704 11:30:06.037833 20391 solver.cpp:590] Iteration 10044, lr = 0.000972093
I0704 11:30:13.885653 20391 solver.cpp:243] Iteration 10071, loss = 1.38778
I0704 11:30:13.885677 20391 solver.cpp:259]     Train net output #0: loss = 1.38778 (* 1 = 1.38778 loss)
I0704 11:30:13.885682 20391 solver.cpp:590] Iteration 10071, lr = 0.000966021
I0704 11:30:21.674015 20391 solver.cpp:243] Iteration 10098, loss = 1.2829
I0704 11:30:21.674124 20391 solver.cpp:259]     Train net output #0: loss = 1.2829 (* 1 = 1.2829 loss)
I0704 11:30:21.674130 20391 solver.cpp:590] Iteration 10098, lr = 0.000959987
I0704 11:30:29.435850 20391 solver.cpp:243] Iteration 10125, loss = 1.1024
I0704 11:30:29.435874 20391 solver.cpp:259]     Train net output #0: loss = 1.1024 (* 1 = 1.1024 loss)
I0704 11:30:29.435880 20391 solver.cpp:590] Iteration 10125, lr = 0.000953991
I0704 11:30:37.173620 20391 solver.cpp:243] Iteration 10152, loss = 0.881764
I0704 11:30:37.173645 20391 solver.cpp:259]     Train net output #0: loss = 0.881764 (* 1 = 0.881764 loss)
I0704 11:30:37.173651 20391 solver.cpp:590] Iteration 10152, lr = 0.000948032
I0704 11:30:41.001886 20391 solver.cpp:347] Iteration 10166, Testing net (#0)
I0704 11:30:55.947475 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:31:00.092576 20391 solver.cpp:415]     Test net output #0: accuracy = 0.398077
I0704 11:31:00.092602 20391 solver.cpp:415]     Test net output #1: loss = 2.82096 (* 1 = 2.82096 loss)
I0704 11:31:03.293803 20391 solver.cpp:243] Iteration 10179, loss = 0.866076
I0704 11:31:03.293831 20391 solver.cpp:259]     Train net output #0: loss = 0.866076 (* 1 = 0.866076 loss)
I0704 11:31:03.293838 20391 solver.cpp:590] Iteration 10179, lr = 0.00094211
I0704 11:31:10.998145 20391 solver.cpp:243] Iteration 10206, loss = 0.928432
I0704 11:31:10.998169 20391 solver.cpp:259]     Train net output #0: loss = 0.928432 (* 1 = 0.928432 loss)
I0704 11:31:10.998175 20391 solver.cpp:590] Iteration 10206, lr = 0.000936225
I0704 11:31:18.696070 20391 solver.cpp:243] Iteration 10233, loss = 1.3622
I0704 11:31:18.696096 20391 solver.cpp:259]     Train net output #0: loss = 1.3622 (* 1 = 1.3622 loss)
I0704 11:31:18.696102 20391 solver.cpp:590] Iteration 10233, lr = 0.000930378
I0704 11:31:26.390123 20391 solver.cpp:243] Iteration 10260, loss = 0.886772
I0704 11:31:26.390213 20391 solver.cpp:259]     Train net output #0: loss = 0.886772 (* 1 = 0.886772 loss)
I0704 11:31:26.390220 20391 solver.cpp:590] Iteration 10260, lr = 0.000924566
I0704 11:31:34.582553 20391 solver.cpp:243] Iteration 10287, loss = 1.1893
I0704 11:31:34.582578 20391 solver.cpp:259]     Train net output #0: loss = 1.1893 (* 1 = 1.1893 loss)
I0704 11:31:34.582586 20391 solver.cpp:590] Iteration 10287, lr = 0.000918791
I0704 11:31:42.965297 20391 solver.cpp:243] Iteration 10314, loss = 1.47529
I0704 11:31:42.965323 20391 solver.cpp:259]     Train net output #0: loss = 1.47529 (* 1 = 1.47529 loss)
I0704 11:31:42.965329 20391 solver.cpp:590] Iteration 10314, lr = 0.000913052
I0704 11:31:51.342435 20391 solver.cpp:243] Iteration 10341, loss = 1.07663
I0704 11:31:51.342460 20391 solver.cpp:259]     Train net output #0: loss = 1.07663 (* 1 = 1.07663 loss)
I0704 11:31:51.342465 20391 solver.cpp:590] Iteration 10341, lr = 0.000907349
I0704 11:31:59.710644 20391 solver.cpp:243] Iteration 10368, loss = 1.11559
I0704 11:31:59.710710 20391 solver.cpp:259]     Train net output #0: loss = 1.11559 (* 1 = 1.11559 loss)
I0704 11:31:59.710716 20391 solver.cpp:590] Iteration 10368, lr = 0.000901681
I0704 11:32:04.850353 20391 solver.cpp:347] Iteration 10387, Testing net (#0)
I0704 11:32:23.943800 20391 solver.cpp:415]     Test net output #0: accuracy = 0.401803
I0704 11:32:23.943825 20391 solver.cpp:415]     Test net output #1: loss = 2.81084 (* 1 = 2.81084 loss)
I0704 11:32:25.716825 20391 solver.cpp:243] Iteration 10395, loss = 1.26675
I0704 11:32:25.716859 20391 solver.cpp:259]     Train net output #0: loss = 1.26675 (* 1 = 1.26675 loss)
I0704 11:32:25.716866 20391 solver.cpp:590] Iteration 10395, lr = 0.000896049
I0704 11:32:33.596192 20391 solver.cpp:243] Iteration 10422, loss = 0.840366
I0704 11:32:33.596251 20391 solver.cpp:259]     Train net output #0: loss = 0.840366 (* 1 = 0.840366 loss)
I0704 11:32:33.596257 20391 solver.cpp:590] Iteration 10422, lr = 0.000890452
I0704 11:32:41.351582 20391 solver.cpp:243] Iteration 10449, loss = 0.982698
I0704 11:32:41.351606 20391 solver.cpp:259]     Train net output #0: loss = 0.982698 (* 1 = 0.982698 loss)
I0704 11:32:41.351613 20391 solver.cpp:590] Iteration 10449, lr = 0.00088489
I0704 11:32:49.221271 20391 solver.cpp:243] Iteration 10476, loss = 1.15278
I0704 11:32:49.221297 20391 solver.cpp:259]     Train net output #0: loss = 1.15278 (* 1 = 1.15278 loss)
I0704 11:32:49.221303 20391 solver.cpp:590] Iteration 10476, lr = 0.000879363
I0704 11:32:56.953860 20391 solver.cpp:243] Iteration 10503, loss = 1.2688
I0704 11:32:56.953886 20391 solver.cpp:259]     Train net output #0: loss = 1.2688 (* 1 = 1.2688 loss)
I0704 11:32:56.953891 20391 solver.cpp:590] Iteration 10503, lr = 0.00087387
I0704 11:33:04.708573 20391 solver.cpp:243] Iteration 10530, loss = 1.02094
I0704 11:33:04.708631 20391 solver.cpp:259]     Train net output #0: loss = 1.02094 (* 1 = 1.02094 loss)
I0704 11:33:04.708638 20391 solver.cpp:590] Iteration 10530, lr = 0.000868412
I0704 11:33:12.456303 20391 solver.cpp:243] Iteration 10557, loss = 1.01289
I0704 11:33:12.456331 20391 solver.cpp:259]     Train net output #0: loss = 1.01289 (* 1 = 1.01289 loss)
I0704 11:33:12.456336 20391 solver.cpp:590] Iteration 10557, lr = 0.000862988
I0704 11:33:20.213013 20391 solver.cpp:243] Iteration 10584, loss = 1.61307
I0704 11:33:20.213038 20391 solver.cpp:259]     Train net output #0: loss = 1.61307 (* 1 = 1.61307 loss)
I0704 11:33:20.213044 20391 solver.cpp:590] Iteration 10584, lr = 0.000857597
I0704 11:33:26.844144 20391 solver.cpp:347] Iteration 10608, Testing net (#0)
I0704 11:33:45.636442 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:33:45.935021 20391 solver.cpp:415]     Test net output #0: accuracy = 0.398077
I0704 11:33:45.935045 20391 solver.cpp:415]     Test net output #1: loss = 2.80241 (* 1 = 2.80241 loss)
I0704 11:33:46.285225 20391 solver.cpp:243] Iteration 10611, loss = 1.13188
I0704 11:33:46.285251 20391 solver.cpp:259]     Train net output #0: loss = 1.13188 (* 1 = 1.13188 loss)
I0704 11:33:46.285257 20391 solver.cpp:590] Iteration 10611, lr = 0.000852241
I0704 11:33:54.138712 20391 solver.cpp:243] Iteration 10638, loss = 1.081
I0704 11:33:54.138737 20391 solver.cpp:259]     Train net output #0: loss = 1.081 (* 1 = 1.081 loss)
I0704 11:33:54.138743 20391 solver.cpp:590] Iteration 10638, lr = 0.000846917
I0704 11:34:01.909615 20391 solver.cpp:243] Iteration 10665, loss = 1.08779
I0704 11:34:01.909641 20391 solver.cpp:259]     Train net output #0: loss = 1.08779 (* 1 = 1.08779 loss)
I0704 11:34:01.909647 20391 solver.cpp:590] Iteration 10665, lr = 0.000841627
I0704 11:34:09.687809 20391 solver.cpp:243] Iteration 10692, loss = 0.99844
I0704 11:34:09.687834 20391 solver.cpp:259]     Train net output #0: loss = 0.99844 (* 1 = 0.99844 loss)
I0704 11:34:09.687839 20391 solver.cpp:590] Iteration 10692, lr = 0.00083637
I0704 11:34:17.447587 20391 solver.cpp:243] Iteration 10719, loss = 1.23838
I0704 11:34:17.447659 20391 solver.cpp:259]     Train net output #0: loss = 1.23838 (* 1 = 1.23838 loss)
I0704 11:34:17.447674 20391 solver.cpp:590] Iteration 10719, lr = 0.000831146
I0704 11:34:25.141654 20391 solver.cpp:243] Iteration 10746, loss = 1.22114
I0704 11:34:25.141679 20391 solver.cpp:259]     Train net output #0: loss = 1.22114 (* 1 = 1.22114 loss)
I0704 11:34:25.141685 20391 solver.cpp:590] Iteration 10746, lr = 0.000825954
I0704 11:34:32.909059 20391 solver.cpp:243] Iteration 10773, loss = 0.921639
I0704 11:34:32.909083 20391 solver.cpp:259]     Train net output #0: loss = 0.921639 (* 1 = 0.921639 loss)
I0704 11:34:32.909090 20391 solver.cpp:590] Iteration 10773, lr = 0.000820795
I0704 11:34:40.675199 20391 solver.cpp:243] Iteration 10800, loss = 1.19597
I0704 11:34:40.675225 20391 solver.cpp:259]     Train net output #0: loss = 1.19597 (* 1 = 1.19597 loss)
I0704 11:34:40.675230 20391 solver.cpp:590] Iteration 10800, lr = 0.000815668
I0704 11:34:48.503353 20391 solver.cpp:243] Iteration 10827, loss = 0.870243
I0704 11:34:48.503412 20391 solver.cpp:259]     Train net output #0: loss = 0.870243 (* 1 = 0.870243 loss)
I0704 11:34:48.503418 20391 solver.cpp:590] Iteration 10827, lr = 0.000810574
I0704 11:34:48.790794 20391 solver.cpp:347] Iteration 10829, Testing net (#0)
I0704 11:35:07.883642 20391 solver.cpp:415]     Test net output #0: accuracy = 0.401923
I0704 11:35:07.883667 20391 solver.cpp:415]     Test net output #1: loss = 2.80914 (* 1 = 2.80914 loss)
I0704 11:35:14.586189 20391 solver.cpp:243] Iteration 10854, loss = 1.05109
I0704 11:35:14.586213 20391 solver.cpp:259]     Train net output #0: loss = 1.05109 (* 1 = 1.05109 loss)
I0704 11:35:14.586220 20391 solver.cpp:590] Iteration 10854, lr = 0.000805511
I0704 11:35:22.450325 20391 solver.cpp:243] Iteration 10881, loss = 1.04071
I0704 11:35:22.450381 20391 solver.cpp:259]     Train net output #0: loss = 1.04071 (* 1 = 1.04071 loss)
I0704 11:35:22.450387 20391 solver.cpp:590] Iteration 10881, lr = 0.000800479
I0704 11:35:30.213841 20391 solver.cpp:243] Iteration 10908, loss = 0.854964
I0704 11:35:30.213868 20391 solver.cpp:259]     Train net output #0: loss = 0.854964 (* 1 = 0.854964 loss)
I0704 11:35:30.213874 20391 solver.cpp:590] Iteration 10908, lr = 0.000795479
I0704 11:35:37.899878 20391 solver.cpp:243] Iteration 10935, loss = 0.960232
I0704 11:35:37.899905 20391 solver.cpp:259]     Train net output #0: loss = 0.960232 (* 1 = 0.960232 loss)
I0704 11:35:37.899911 20391 solver.cpp:590] Iteration 10935, lr = 0.00079051
I0704 11:35:45.644369 20391 solver.cpp:243] Iteration 10962, loss = 0.900342
I0704 11:35:45.644395 20391 solver.cpp:259]     Train net output #0: loss = 0.900342 (* 1 = 0.900342 loss)
I0704 11:35:45.644402 20391 solver.cpp:590] Iteration 10962, lr = 0.000785573
I0704 11:35:53.417474 20391 solver.cpp:243] Iteration 10989, loss = 0.920083
I0704 11:35:53.417575 20391 solver.cpp:259]     Train net output #0: loss = 0.920083 (* 1 = 0.920083 loss)
I0704 11:35:53.417582 20391 solver.cpp:590] Iteration 10989, lr = 0.000780666
I0704 11:36:01.114142 20391 solver.cpp:243] Iteration 11016, loss = 1.1942
I0704 11:36:01.114166 20391 solver.cpp:259]     Train net output #0: loss = 1.1942 (* 1 = 1.1942 loss)
I0704 11:36:01.114172 20391 solver.cpp:590] Iteration 11016, lr = 0.00077579
I0704 11:36:08.924556 20391 solver.cpp:243] Iteration 11043, loss = 0.65598
I0704 11:36:08.924582 20391 solver.cpp:259]     Train net output #0: loss = 0.65598 (* 1 = 0.65598 loss)
I0704 11:36:08.924587 20391 solver.cpp:590] Iteration 11043, lr = 0.000770944
I0704 11:36:10.648834 20391 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_11050.caffemodel
I0704 11:36:33.287720 20391 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_11050.solverstate
I0704 11:36:34.315894 20391 solver.cpp:347] Iteration 11050, Testing net (#0)
I0704 11:36:53.362381 20391 solver.cpp:415]     Test net output #0: accuracy = 0.403125
I0704 11:36:53.362406 20391 solver.cpp:415]     Test net output #1: loss = 2.80396 (* 1 = 2.80396 loss)
I0704 11:36:58.563328 20391 solver.cpp:243] Iteration 11070, loss = 1.07729
I0704 11:36:58.563351 20391 solver.cpp:259]     Train net output #0: loss = 1.07729 (* 1 = 1.07729 loss)
I0704 11:36:58.563357 20391 solver.cpp:590] Iteration 11070, lr = 0.000766128
I0704 11:37:06.249554 20391 solver.cpp:243] Iteration 11097, loss = 1.00001
I0704 11:37:06.249635 20391 solver.cpp:259]     Train net output #0: loss = 1.00001 (* 1 = 1.00001 loss)
I0704 11:37:06.249641 20391 solver.cpp:590] Iteration 11097, lr = 0.000761343
I0704 11:37:07.105803 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:37:14.063542 20391 solver.cpp:243] Iteration 11124, loss = 1.30084
I0704 11:37:14.063568 20391 solver.cpp:259]     Train net output #0: loss = 1.30084 (* 1 = 1.30084 loss)
I0704 11:37:14.063575 20391 solver.cpp:590] Iteration 11124, lr = 0.000756587
I0704 11:37:21.988569 20391 solver.cpp:243] Iteration 11151, loss = 1.21452
I0704 11:37:21.988596 20391 solver.cpp:259]     Train net output #0: loss = 1.21452 (* 1 = 1.21452 loss)
I0704 11:37:21.988602 20391 solver.cpp:590] Iteration 11151, lr = 0.000751862
I0704 11:37:29.846441 20391 solver.cpp:243] Iteration 11178, loss = 1.06843
I0704 11:37:29.846465 20391 solver.cpp:259]     Train net output #0: loss = 1.06843 (* 1 = 1.06843 loss)
I0704 11:37:29.846472 20391 solver.cpp:590] Iteration 11178, lr = 0.000747165
I0704 11:37:37.594831 20391 solver.cpp:243] Iteration 11205, loss = 0.898854
I0704 11:37:37.594904 20391 solver.cpp:259]     Train net output #0: loss = 0.898854 (* 1 = 0.898854 loss)
I0704 11:37:37.594921 20391 solver.cpp:590] Iteration 11205, lr = 0.000742498
I0704 11:37:45.357120 20391 solver.cpp:243] Iteration 11232, loss = 0.975396
I0704 11:37:45.357147 20391 solver.cpp:259]     Train net output #0: loss = 0.975396 (* 1 = 0.975396 loss)
I0704 11:37:45.357153 20391 solver.cpp:590] Iteration 11232, lr = 0.00073786
I0704 11:37:53.081970 20391 solver.cpp:243] Iteration 11259, loss = 0.898618
I0704 11:37:53.081993 20391 solver.cpp:259]     Train net output #0: loss = 0.898618 (* 1 = 0.898618 loss)
I0704 11:37:53.082000 20391 solver.cpp:590] Iteration 11259, lr = 0.000733252
I0704 11:37:56.248348 20391 solver.cpp:347] Iteration 11271, Testing net (#0)
I0704 11:38:15.333271 20391 solver.cpp:415]     Test net output #0: accuracy = 0.407332
I0704 11:38:15.333390 20391 solver.cpp:415]     Test net output #1: loss = 2.8037 (* 1 = 2.8037 loss)
I0704 11:38:19.102891 20391 solver.cpp:243] Iteration 11286, loss = 0.850474
I0704 11:38:19.102917 20391 solver.cpp:259]     Train net output #0: loss = 0.850474 (* 1 = 0.850474 loss)
I0704 11:38:19.102923 20391 solver.cpp:590] Iteration 11286, lr = 0.000728672
I0704 11:38:26.858026 20391 solver.cpp:243] Iteration 11313, loss = 0.848159
I0704 11:38:26.858052 20391 solver.cpp:259]     Train net output #0: loss = 0.848159 (* 1 = 0.848159 loss)
I0704 11:38:26.858059 20391 solver.cpp:590] Iteration 11313, lr = 0.00072412
I0704 11:38:34.658336 20391 solver.cpp:243] Iteration 11340, loss = 0.917685
I0704 11:38:34.658360 20391 solver.cpp:259]     Train net output #0: loss = 0.917685 (* 1 = 0.917685 loss)
I0704 11:38:34.658366 20391 solver.cpp:590] Iteration 11340, lr = 0.000719597
I0704 11:38:42.460189 20391 solver.cpp:243] Iteration 11367, loss = 0.894046
I0704 11:38:42.460216 20391 solver.cpp:259]     Train net output #0: loss = 0.894046 (* 1 = 0.894046 loss)
I0704 11:38:42.460222 20391 solver.cpp:590] Iteration 11367, lr = 0.000715102
I0704 11:38:50.190667 20391 solver.cpp:243] Iteration 11394, loss = 0.840908
I0704 11:38:50.190773 20391 solver.cpp:259]     Train net output #0: loss = 0.840908 (* 1 = 0.840908 loss)
I0704 11:38:50.190780 20391 solver.cpp:590] Iteration 11394, lr = 0.000710636
I0704 11:38:57.942569 20391 solver.cpp:243] Iteration 11421, loss = 0.887022
I0704 11:38:57.942591 20391 solver.cpp:259]     Train net output #0: loss = 0.887022 (* 1 = 0.887022 loss)
I0704 11:38:57.942598 20391 solver.cpp:590] Iteration 11421, lr = 0.000706197
I0704 11:39:05.660547 20391 solver.cpp:243] Iteration 11448, loss = 1.00172
I0704 11:39:05.660573 20391 solver.cpp:259]     Train net output #0: loss = 1.00172 (* 1 = 1.00172 loss)
I0704 11:39:05.660578 20391 solver.cpp:590] Iteration 11448, lr = 0.000701786
I0704 11:39:13.299010 20391 solver.cpp:243] Iteration 11475, loss = 1.04502
I0704 11:39:13.299034 20391 solver.cpp:259]     Train net output #0: loss = 1.04502 (* 1 = 1.04502 loss)
I0704 11:39:13.299041 20391 solver.cpp:590] Iteration 11475, lr = 0.000697402
I0704 11:39:17.873605 20391 solver.cpp:347] Iteration 11492, Testing net (#0)
I0704 11:39:36.943220 20391 solver.cpp:415]     Test net output #0: accuracy = 0.405889
I0704 11:39:36.943300 20391 solver.cpp:415]     Test net output #1: loss = 2.7954 (* 1 = 2.7954 loss)
I0704 11:39:39.287735 20391 solver.cpp:243] Iteration 11502, loss = 0.909563
I0704 11:39:39.287763 20391 solver.cpp:259]     Train net output #0: loss = 0.909563 (* 1 = 0.909563 loss)
I0704 11:39:39.287770 20391 solver.cpp:590] Iteration 11502, lr = 0.000693046
I0704 11:39:47.036731 20391 solver.cpp:243] Iteration 11529, loss = 1.09596
I0704 11:39:47.036758 20391 solver.cpp:259]     Train net output #0: loss = 1.09596 (* 1 = 1.09596 loss)
I0704 11:39:47.036764 20391 solver.cpp:590] Iteration 11529, lr = 0.000688717
I0704 11:39:54.810125 20391 solver.cpp:243] Iteration 11556, loss = 0.94551
I0704 11:39:54.810151 20391 solver.cpp:259]     Train net output #0: loss = 0.94551 (* 1 = 0.94551 loss)
I0704 11:39:54.810158 20391 solver.cpp:590] Iteration 11556, lr = 0.000684415
I0704 11:40:02.535141 20391 solver.cpp:243] Iteration 11583, loss = 0.717966
I0704 11:40:02.535166 20391 solver.cpp:259]     Train net output #0: loss = 0.717966 (* 1 = 0.717966 loss)
I0704 11:40:02.535171 20391 solver.cpp:590] Iteration 11583, lr = 0.00068014
I0704 11:40:05.675227 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:40:10.257596 20391 solver.cpp:243] Iteration 11610, loss = 0.823156
I0704 11:40:10.257650 20391 solver.cpp:259]     Train net output #0: loss = 0.823156 (* 1 = 0.823156 loss)
I0704 11:40:10.257658 20391 solver.cpp:590] Iteration 11610, lr = 0.000675892
I0704 11:40:17.992357 20391 solver.cpp:243] Iteration 11637, loss = 0.781785
I0704 11:40:17.992383 20391 solver.cpp:259]     Train net output #0: loss = 0.781785 (* 1 = 0.781785 loss)
I0704 11:40:17.992389 20391 solver.cpp:590] Iteration 11637, lr = 0.00067167
I0704 11:40:25.660665 20391 solver.cpp:243] Iteration 11664, loss = 0.74079
I0704 11:40:25.660692 20391 solver.cpp:259]     Train net output #0: loss = 0.74079 (* 1 = 0.74079 loss)
I0704 11:40:25.660699 20391 solver.cpp:590] Iteration 11664, lr = 0.000667475
I0704 11:40:33.375856 20391 solver.cpp:243] Iteration 11691, loss = 1.03148
I0704 11:40:33.375881 20391 solver.cpp:259]     Train net output #0: loss = 1.03148 (* 1 = 1.03148 loss)
I0704 11:40:33.375886 20391 solver.cpp:590] Iteration 11691, lr = 0.000663305
I0704 11:40:39.404335 20391 solver.cpp:347] Iteration 11713, Testing net (#0)
I0704 11:40:58.611858 20391 solver.cpp:415]     Test net output #0: accuracy = 0.408293
I0704 11:40:58.611954 20391 solver.cpp:415]     Test net output #1: loss = 2.80612 (* 1 = 2.80612 loss)
I0704 11:40:59.529533 20391 solver.cpp:243] Iteration 11718, loss = 0.878326
I0704 11:40:59.529561 20391 solver.cpp:259]     Train net output #0: loss = 0.878326 (* 1 = 0.878326 loss)
I0704 11:40:59.529567 20391 solver.cpp:590] Iteration 11718, lr = 0.000659162
I0704 11:41:07.216363 20391 solver.cpp:243] Iteration 11745, loss = 0.839952
I0704 11:41:07.216388 20391 solver.cpp:259]     Train net output #0: loss = 0.839952 (* 1 = 0.839952 loss)
I0704 11:41:07.216395 20391 solver.cpp:590] Iteration 11745, lr = 0.000655045
I0704 11:41:14.896128 20391 solver.cpp:243] Iteration 11772, loss = 0.97409
I0704 11:41:14.896154 20391 solver.cpp:259]     Train net output #0: loss = 0.97409 (* 1 = 0.97409 loss)
I0704 11:41:14.896160 20391 solver.cpp:590] Iteration 11772, lr = 0.000650953
I0704 11:41:22.566349 20391 solver.cpp:243] Iteration 11799, loss = 0.994827
I0704 11:41:22.566375 20391 solver.cpp:259]     Train net output #0: loss = 0.994827 (* 1 = 0.994827 loss)
I0704 11:41:22.566381 20391 solver.cpp:590] Iteration 11799, lr = 0.000646887
I0704 11:41:30.279978 20391 solver.cpp:243] Iteration 11826, loss = 0.916573
I0704 11:41:30.280040 20391 solver.cpp:259]     Train net output #0: loss = 0.916573 (* 1 = 0.916573 loss)
I0704 11:41:30.280045 20391 solver.cpp:590] Iteration 11826, lr = 0.000642847
I0704 11:41:38.018414 20391 solver.cpp:243] Iteration 11853, loss = 1.02685
I0704 11:41:38.018440 20391 solver.cpp:259]     Train net output #0: loss = 1.02685 (* 1 = 1.02685 loss)
I0704 11:41:38.018447 20391 solver.cpp:590] Iteration 11853, lr = 0.000638831
I0704 11:41:45.765974 20391 solver.cpp:243] Iteration 11880, loss = 0.785702
I0704 11:41:45.766003 20391 solver.cpp:259]     Train net output #0: loss = 0.785702 (* 1 = 0.785702 loss)
I0704 11:41:45.766010 20391 solver.cpp:590] Iteration 11880, lr = 0.000634841
I0704 11:41:53.518057 20391 solver.cpp:243] Iteration 11907, loss = 0.771668
I0704 11:41:53.518084 20391 solver.cpp:259]     Train net output #0: loss = 0.771668 (* 1 = 0.771668 loss)
I0704 11:41:53.518090 20391 solver.cpp:590] Iteration 11907, lr = 0.000630876
I0704 11:42:00.942231 20391 solver.cpp:347] Iteration 11934, Testing net (#0)
I0704 11:42:20.047127 20391 solver.cpp:415]     Test net output #0: accuracy = 0.412019
I0704 11:42:20.047153 20391 solver.cpp:415]     Test net output #1: loss = 2.79746 (* 1 = 2.79746 loss)
I0704 11:42:20.103811 20391 solver.cpp:243] Iteration 11934, loss = 0.61514
I0704 11:42:20.103834 20391 solver.cpp:259]     Train net output #0: loss = 0.61514 (* 1 = 0.61514 loss)
I0704 11:42:20.103840 20391 solver.cpp:590] Iteration 11934, lr = 0.000626935
I0704 11:42:27.310859 20391 solver.cpp:243] Iteration 11961, loss = 0.753321
I0704 11:42:27.310886 20391 solver.cpp:259]     Train net output #0: loss = 0.753321 (* 1 = 0.753321 loss)
I0704 11:42:27.310892 20391 solver.cpp:590] Iteration 11961, lr = 0.000623019
I0704 11:42:35.087616 20391 solver.cpp:243] Iteration 11988, loss = 0.843687
I0704 11:42:35.087671 20391 solver.cpp:259]     Train net output #0: loss = 0.843687 (* 1 = 0.843687 loss)
I0704 11:42:35.087677 20391 solver.cpp:590] Iteration 11988, lr = 0.000619128
I0704 11:42:42.822432 20391 solver.cpp:243] Iteration 12015, loss = 0.918009
I0704 11:42:42.822456 20391 solver.cpp:259]     Train net output #0: loss = 0.918009 (* 1 = 0.918009 loss)
I0704 11:42:42.822463 20391 solver.cpp:590] Iteration 12015, lr = 0.00061526
I0704 11:42:50.502125 20391 solver.cpp:243] Iteration 12042, loss = 0.966075
I0704 11:42:50.502151 20391 solver.cpp:259]     Train net output #0: loss = 0.966075 (* 1 = 0.966075 loss)
I0704 11:42:50.502157 20391 solver.cpp:590] Iteration 12042, lr = 0.000611417
I0704 11:42:58.199326 20391 solver.cpp:243] Iteration 12069, loss = 1.02874
I0704 11:42:58.199353 20391 solver.cpp:259]     Train net output #0: loss = 1.02874 (* 1 = 1.02874 loss)
I0704 11:42:58.199359 20391 solver.cpp:590] Iteration 12069, lr = 0.000607598
I0704 11:43:03.586953 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:43:05.866987 20391 solver.cpp:243] Iteration 12096, loss = 0.852933
I0704 11:43:05.867069 20391 solver.cpp:259]     Train net output #0: loss = 0.852933 (* 1 = 0.852933 loss)
I0704 11:43:05.867074 20391 solver.cpp:590] Iteration 12096, lr = 0.000603803
I0704 11:43:13.525717 20391 solver.cpp:243] Iteration 12123, loss = 0.963578
I0704 11:43:13.525743 20391 solver.cpp:259]     Train net output #0: loss = 0.963578 (* 1 = 0.963578 loss)
I0704 11:43:13.525748 20391 solver.cpp:590] Iteration 12123, lr = 0.000600032
I0704 11:43:21.237705 20391 solver.cpp:243] Iteration 12150, loss = 0.959958
I0704 11:43:21.237732 20391 solver.cpp:259]     Train net output #0: loss = 0.959958 (* 1 = 0.959958 loss)
I0704 11:43:21.237740 20391 solver.cpp:590] Iteration 12150, lr = 0.000596284
I0704 11:43:22.370250 20391 solver.cpp:347] Iteration 12155, Testing net (#0)
I0704 11:43:41.492617 20391 solver.cpp:415]     Test net output #0: accuracy = 0.410337
I0704 11:43:41.492694 20391 solver.cpp:415]     Test net output #1: loss = 2.80257 (* 1 = 2.80257 loss)
I0704 11:43:47.253496 20391 solver.cpp:243] Iteration 12177, loss = 0.914877
I0704 11:43:47.253521 20391 solver.cpp:259]     Train net output #0: loss = 0.914877 (* 1 = 0.914877 loss)
I0704 11:43:47.253527 20391 solver.cpp:590] Iteration 12177, lr = 0.000592559
I0704 11:43:54.982897 20391 solver.cpp:243] Iteration 12204, loss = 0.921739
I0704 11:43:54.982924 20391 solver.cpp:259]     Train net output #0: loss = 0.921739 (* 1 = 0.921739 loss)
I0704 11:43:54.982930 20391 solver.cpp:590] Iteration 12204, lr = 0.000588858
I0704 11:44:02.717643 20391 solver.cpp:243] Iteration 12231, loss = 0.667963
I0704 11:44:02.717669 20391 solver.cpp:259]     Train net output #0: loss = 0.667963 (* 1 = 0.667963 loss)
I0704 11:44:02.717675 20391 solver.cpp:590] Iteration 12231, lr = 0.00058518
I0704 11:44:10.415035 20391 solver.cpp:243] Iteration 12258, loss = 0.807273
I0704 11:44:10.415081 20391 solver.cpp:259]     Train net output #0: loss = 0.807273 (* 1 = 0.807273 loss)
I0704 11:44:10.415089 20391 solver.cpp:590] Iteration 12258, lr = 0.000581525
I0704 11:44:18.317178 20391 solver.cpp:243] Iteration 12285, loss = 0.940683
I0704 11:44:18.317234 20391 solver.cpp:259]     Train net output #0: loss = 0.940683 (* 1 = 0.940683 loss)
I0704 11:44:18.317240 20391 solver.cpp:590] Iteration 12285, lr = 0.000577892
I0704 11:44:25.981034 20391 solver.cpp:243] Iteration 12312, loss = 0.910843
I0704 11:44:25.981058 20391 solver.cpp:259]     Train net output #0: loss = 0.910843 (* 1 = 0.910843 loss)
I0704 11:44:25.981065 20391 solver.cpp:590] Iteration 12312, lr = 0.000574283
I0704 11:44:33.650537 20391 solver.cpp:243] Iteration 12339, loss = 0.776004
I0704 11:44:33.650573 20391 solver.cpp:259]     Train net output #0: loss = 0.776004 (* 1 = 0.776004 loss)
I0704 11:44:33.650578 20391 solver.cpp:590] Iteration 12339, lr = 0.000570695
I0704 11:44:41.401700 20391 solver.cpp:243] Iteration 12366, loss = 1.24724
I0704 11:44:41.401726 20391 solver.cpp:259]     Train net output #0: loss = 1.24724 (* 1 = 1.24724 loss)
I0704 11:44:41.401733 20391 solver.cpp:590] Iteration 12366, lr = 0.000567131
I0704 11:44:43.991458 20391 solver.cpp:347] Iteration 12376, Testing net (#0)
I0704 11:45:03.040175 20391 solver.cpp:415]     Test net output #0: accuracy = 0.411178
I0704 11:45:03.040246 20391 solver.cpp:415]     Test net output #1: loss = 2.79384 (* 1 = 2.79384 loss)
I0704 11:45:07.425669 20391 solver.cpp:243] Iteration 12393, loss = 0.903718
I0704 11:45:07.425694 20391 solver.cpp:259]     Train net output #0: loss = 0.903718 (* 1 = 0.903718 loss)
I0704 11:45:07.425700 20391 solver.cpp:590] Iteration 12393, lr = 0.000563588
I0704 11:45:15.109675 20391 solver.cpp:243] Iteration 12420, loss = 0.922845
I0704 11:45:15.109701 20391 solver.cpp:259]     Train net output #0: loss = 0.922845 (* 1 = 0.922845 loss)
I0704 11:45:15.109707 20391 solver.cpp:590] Iteration 12420, lr = 0.000560068
I0704 11:45:22.800187 20391 solver.cpp:243] Iteration 12447, loss = 0.990759
I0704 11:45:22.800214 20391 solver.cpp:259]     Train net output #0: loss = 0.990759 (* 1 = 0.990759 loss)
I0704 11:45:22.800220 20391 solver.cpp:590] Iteration 12447, lr = 0.00055657
I0704 11:45:30.463302 20391 solver.cpp:243] Iteration 12474, loss = 1.12579
I0704 11:45:30.463327 20391 solver.cpp:259]     Train net output #0: loss = 1.12579 (* 1 = 1.12579 loss)
I0704 11:45:30.463333 20391 solver.cpp:590] Iteration 12474, lr = 0.000553093
I0704 11:45:38.214965 20391 solver.cpp:243] Iteration 12501, loss = 1.00897
I0704 11:45:38.215049 20391 solver.cpp:259]     Train net output #0: loss = 1.00897 (* 1 = 1.00897 loss)
I0704 11:45:38.215057 20391 solver.cpp:590] Iteration 12501, lr = 0.000549638
I0704 11:45:45.970528 20391 solver.cpp:243] Iteration 12528, loss = 0.719578
I0704 11:45:45.970554 20391 solver.cpp:259]     Train net output #0: loss = 0.719578 (* 1 = 0.719578 loss)
I0704 11:45:45.970561 20391 solver.cpp:590] Iteration 12528, lr = 0.000546205
I0704 11:45:53.694702 20391 solver.cpp:243] Iteration 12555, loss = 0.683555
I0704 11:45:53.694727 20391 solver.cpp:259]     Train net output #0: loss = 0.683555 (* 1 = 0.683555 loss)
I0704 11:45:53.694733 20391 solver.cpp:590] Iteration 12555, lr = 0.000542794
I0704 11:46:01.407083 20391 solver.cpp:243] Iteration 12582, loss = 0.884935
I0704 11:46:01.407109 20391 solver.cpp:259]     Train net output #0: loss = 0.884935 (* 1 = 0.884935 loss)
I0704 11:46:01.407114 20391 solver.cpp:590] Iteration 12582, lr = 0.000539403
I0704 11:46:01.407341 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:46:05.400887 20391 solver.cpp:347] Iteration 12597, Testing net (#0)
I0704 11:46:24.459103 20391 solver.cpp:415]     Test net output #0: accuracy = 0.409976
I0704 11:46:24.459167 20391 solver.cpp:415]     Test net output #1: loss = 2.79518 (* 1 = 2.79518 loss)
I0704 11:46:27.374923 20391 solver.cpp:243] Iteration 12609, loss = 0.896922
I0704 11:46:27.374949 20391 solver.cpp:259]     Train net output #0: loss = 0.896922 (* 1 = 0.896922 loss)
I0704 11:46:27.374955 20391 solver.cpp:590] Iteration 12609, lr = 0.000536034
I0704 11:46:35.048373 20391 solver.cpp:243] Iteration 12636, loss = 0.993904
I0704 11:46:35.048399 20391 solver.cpp:259]     Train net output #0: loss = 0.993904 (* 1 = 0.993904 loss)
I0704 11:46:35.048405 20391 solver.cpp:590] Iteration 12636, lr = 0.000532686
I0704 11:46:43.002564 20391 solver.cpp:243] Iteration 12663, loss = 0.749946
I0704 11:46:43.002584 20391 solver.cpp:259]     Train net output #0: loss = 0.749946 (* 1 = 0.749946 loss)
I0704 11:46:43.002590 20391 solver.cpp:590] Iteration 12663, lr = 0.000529358
I0704 11:46:50.986994 20391 solver.cpp:243] Iteration 12690, loss = 0.873984
I0704 11:46:50.987020 20391 solver.cpp:259]     Train net output #0: loss = 0.873984 (* 1 = 0.873984 loss)
I0704 11:46:50.987025 20391 solver.cpp:590] Iteration 12690, lr = 0.000526052
I0704 11:46:58.979146 20391 solver.cpp:243] Iteration 12717, loss = 1.09803
I0704 11:46:58.979202 20391 solver.cpp:259]     Train net output #0: loss = 1.09803 (* 1 = 1.09803 loss)
I0704 11:46:58.979207 20391 solver.cpp:590] Iteration 12717, lr = 0.000522766
I0704 11:47:06.735008 20391 solver.cpp:243] Iteration 12744, loss = 0.788748
I0704 11:47:06.735034 20391 solver.cpp:259]     Train net output #0: loss = 0.788748 (* 1 = 0.788748 loss)
I0704 11:47:06.735040 20391 solver.cpp:590] Iteration 12744, lr = 0.000519501
I0704 11:47:14.628710 20391 solver.cpp:243] Iteration 12771, loss = 0.675714
I0704 11:47:14.628737 20391 solver.cpp:259]     Train net output #0: loss = 0.675714 (* 1 = 0.675714 loss)
I0704 11:47:14.628743 20391 solver.cpp:590] Iteration 12771, lr = 0.000516256
I0704 11:47:22.540946 20391 solver.cpp:243] Iteration 12798, loss = 0.800978
I0704 11:47:22.540972 20391 solver.cpp:259]     Train net output #0: loss = 0.800978 (* 1 = 0.800978 loss)
I0704 11:47:22.540978 20391 solver.cpp:590] Iteration 12798, lr = 0.000513031
I0704 11:47:27.978566 20391 solver.cpp:347] Iteration 12818, Testing net (#0)
I0704 11:47:47.113906 20391 solver.cpp:415]     Test net output #0: accuracy = 0.41274
I0704 11:47:47.114001 20391 solver.cpp:415]     Test net output #1: loss = 2.78963 (* 1 = 2.78963 loss)
I0704 11:47:48.603678 20391 solver.cpp:243] Iteration 12825, loss = 0.650396
I0704 11:47:48.603705 20391 solver.cpp:259]     Train net output #0: loss = 0.650396 (* 1 = 0.650396 loss)
I0704 11:47:48.603710 20391 solver.cpp:590] Iteration 12825, lr = 0.000509827
I0704 11:47:56.317524 20391 solver.cpp:243] Iteration 12852, loss = 0.972573
I0704 11:47:56.317549 20391 solver.cpp:259]     Train net output #0: loss = 0.972573 (* 1 = 0.972573 loss)
I0704 11:47:56.317556 20391 solver.cpp:590] Iteration 12852, lr = 0.000506642
I0704 11:48:04.012080 20391 solver.cpp:243] Iteration 12879, loss = 0.765646
I0704 11:48:04.012106 20391 solver.cpp:259]     Train net output #0: loss = 0.765646 (* 1 = 0.765646 loss)
I0704 11:48:04.012114 20391 solver.cpp:590] Iteration 12879, lr = 0.000503478
I0704 11:48:11.687675 20391 solver.cpp:243] Iteration 12906, loss = 1.16453
I0704 11:48:11.687700 20391 solver.cpp:259]     Train net output #0: loss = 1.16453 (* 1 = 1.16453 loss)
I0704 11:48:11.687706 20391 solver.cpp:590] Iteration 12906, lr = 0.000500333
I0704 11:48:19.477272 20391 solver.cpp:243] Iteration 12933, loss = 0.649706
I0704 11:48:19.477375 20391 solver.cpp:259]     Train net output #0: loss = 0.649706 (* 1 = 0.649706 loss)
I0704 11:48:19.477391 20391 solver.cpp:590] Iteration 12933, lr = 0.000497207
I0704 11:48:27.339851 20391 solver.cpp:243] Iteration 12960, loss = 0.821125
I0704 11:48:27.339876 20391 solver.cpp:259]     Train net output #0: loss = 0.821125 (* 1 = 0.821125 loss)
I0704 11:48:27.339882 20391 solver.cpp:590] Iteration 12960, lr = 0.000494102
I0704 11:48:35.099844 20391 solver.cpp:243] Iteration 12987, loss = 0.91372
I0704 11:48:35.099869 20391 solver.cpp:259]     Train net output #0: loss = 0.91372 (* 1 = 0.91372 loss)
I0704 11:48:35.099875 20391 solver.cpp:590] Iteration 12987, lr = 0.000491015
I0704 11:48:42.815089 20391 solver.cpp:243] Iteration 13014, loss = 0.859721
I0704 11:48:42.815125 20391 solver.cpp:259]     Train net output #0: loss = 0.859721 (* 1 = 0.859721 loss)
I0704 11:48:42.815131 20391 solver.cpp:590] Iteration 13014, lr = 0.000487949
I0704 11:48:49.643892 20391 solver.cpp:347] Iteration 13039, Testing net (#0)
I0704 11:48:52.619956 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:49:08.769817 20391 solver.cpp:415]     Test net output #0: accuracy = 0.414543
I0704 11:49:08.769841 20391 solver.cpp:415]     Test net output #1: loss = 2.77955 (* 1 = 2.77955 loss)
I0704 11:49:08.998664 20391 solver.cpp:243] Iteration 13041, loss = 0.92028
I0704 11:49:08.998688 20391 solver.cpp:259]     Train net output #0: loss = 0.92028 (* 1 = 0.92028 loss)
I0704 11:49:08.998694 20391 solver.cpp:590] Iteration 13041, lr = 0.000484901
I0704 11:49:16.578717 20391 solver.cpp:243] Iteration 13068, loss = 0.767531
I0704 11:49:16.578742 20391 solver.cpp:259]     Train net output #0: loss = 0.767531 (* 1 = 0.767531 loss)
I0704 11:49:16.578749 20391 solver.cpp:590] Iteration 13068, lr = 0.000481872
I0704 11:49:24.276533 20391 solver.cpp:243] Iteration 13095, loss = 0.817151
I0704 11:49:24.276648 20391 solver.cpp:259]     Train net output #0: loss = 0.817151 (* 1 = 0.817151 loss)
I0704 11:49:24.276655 20391 solver.cpp:590] Iteration 13095, lr = 0.000478862
I0704 11:49:31.996032 20391 solver.cpp:243] Iteration 13122, loss = 0.780934
I0704 11:49:31.996059 20391 solver.cpp:259]     Train net output #0: loss = 0.780934 (* 1 = 0.780934 loss)
I0704 11:49:31.996065 20391 solver.cpp:590] Iteration 13122, lr = 0.000475871
I0704 11:49:39.670053 20391 solver.cpp:243] Iteration 13149, loss = 0.798279
I0704 11:49:39.670078 20391 solver.cpp:259]     Train net output #0: loss = 0.798279 (* 1 = 0.798279 loss)
I0704 11:49:39.670084 20391 solver.cpp:590] Iteration 13149, lr = 0.000472898
I0704 11:49:47.369375 20391 solver.cpp:243] Iteration 13176, loss = 0.964125
I0704 11:49:47.369401 20391 solver.cpp:259]     Train net output #0: loss = 0.964125 (* 1 = 0.964125 loss)
I0704 11:49:47.369407 20391 solver.cpp:590] Iteration 13176, lr = 0.000469945
I0704 11:49:55.013634 20391 solver.cpp:243] Iteration 13203, loss = 0.730484
I0704 11:49:55.013721 20391 solver.cpp:259]     Train net output #0: loss = 0.730484 (* 1 = 0.730484 loss)
I0704 11:49:55.013730 20391 solver.cpp:590] Iteration 13203, lr = 0.000467009
I0704 11:50:02.744282 20391 solver.cpp:243] Iteration 13230, loss = 0.752668
I0704 11:50:02.744305 20391 solver.cpp:259]     Train net output #0: loss = 0.752668 (* 1 = 0.752668 loss)
I0704 11:50:02.744312 20391 solver.cpp:590] Iteration 13230, lr = 0.000464092
I0704 11:50:10.409575 20391 solver.cpp:243] Iteration 13257, loss = 0.953433
I0704 11:50:10.409601 20391 solver.cpp:259]     Train net output #0: loss = 0.953433 (* 1 = 0.953433 loss)
I0704 11:50:10.409607 20391 solver.cpp:590] Iteration 13257, lr = 0.000461193
I0704 11:50:10.978582 20391 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_13260.caffemodel
I0704 11:50:27.240942 20391 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_13260.solverstate
I0704 11:50:28.251045 20391 solver.cpp:347] Iteration 13260, Testing net (#0)
I0704 11:50:47.290843 20391 solver.cpp:415]     Test net output #0: accuracy = 0.418029
I0704 11:50:47.290868 20391 solver.cpp:415]     Test net output #1: loss = 2.77809 (* 1 = 2.77809 loss)
I0704 11:50:53.649688 20391 solver.cpp:243] Iteration 13284, loss = 0.831451
I0704 11:50:53.649711 20391 solver.cpp:259]     Train net output #0: loss = 0.831451 (* 1 = 0.831451 loss)
I0704 11:50:53.649718 20391 solver.cpp:590] Iteration 13284, lr = 0.000458313
I0704 11:51:01.359071 20391 solver.cpp:243] Iteration 13311, loss = 0.685216
I0704 11:51:01.359128 20391 solver.cpp:259]     Train net output #0: loss = 0.685216 (* 1 = 0.685216 loss)
I0704 11:51:01.359135 20391 solver.cpp:590] Iteration 13311, lr = 0.00045545
I0704 11:51:09.055575 20391 solver.cpp:243] Iteration 13338, loss = 0.89332
I0704 11:51:09.055603 20391 solver.cpp:259]     Train net output #0: loss = 0.89332 (* 1 = 0.89332 loss)
I0704 11:51:09.055608 20391 solver.cpp:590] Iteration 13338, lr = 0.000452605
I0704 11:51:16.978096 20391 solver.cpp:243] Iteration 13365, loss = 0.887946
I0704 11:51:16.978121 20391 solver.cpp:259]     Train net output #0: loss = 0.887946 (* 1 = 0.887946 loss)
I0704 11:51:16.978127 20391 solver.cpp:590] Iteration 13365, lr = 0.000449778
I0704 11:51:24.822252 20391 solver.cpp:243] Iteration 13392, loss = 0.997403
I0704 11:51:24.822278 20391 solver.cpp:259]     Train net output #0: loss = 0.997403 (* 1 = 0.997403 loss)
I0704 11:51:24.822283 20391 solver.cpp:590] Iteration 13392, lr = 0.000446969
I0704 11:51:32.518326 20391 solver.cpp:243] Iteration 13419, loss = 0.814651
I0704 11:51:32.518385 20391 solver.cpp:259]     Train net output #0: loss = 0.814651 (* 1 = 0.814651 loss)
I0704 11:51:32.518393 20391 solver.cpp:590] Iteration 13419, lr = 0.000444177
I0704 11:51:40.274142 20391 solver.cpp:243] Iteration 13446, loss = 0.74904
I0704 11:51:40.274166 20391 solver.cpp:259]     Train net output #0: loss = 0.74904 (* 1 = 0.74904 loss)
I0704 11:51:40.274173 20391 solver.cpp:590] Iteration 13446, lr = 0.000441402
I0704 11:51:48.022784 20391 solver.cpp:243] Iteration 13473, loss = 0.881729
I0704 11:51:48.022807 20391 solver.cpp:259]     Train net output #0: loss = 0.881729 (* 1 = 0.881729 loss)
I0704 11:51:48.022814 20391 solver.cpp:590] Iteration 13473, lr = 0.000438645
I0704 11:51:50.009496 20391 solver.cpp:347] Iteration 13481, Testing net (#0)
I0704 11:51:56.817127 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:52:09.089337 20391 solver.cpp:415]     Test net output #0: accuracy = 0.416827
I0704 11:52:09.089393 20391 solver.cpp:415]     Test net output #1: loss = 2.79015 (* 1 = 2.79015 loss)
I0704 11:52:13.983731 20391 solver.cpp:243] Iteration 13500, loss = 0.792377
I0704 11:52:13.983758 20391 solver.cpp:259]     Train net output #0: loss = 0.792377 (* 1 = 0.792377 loss)
I0704 11:52:13.983765 20391 solver.cpp:590] Iteration 13500, lr = 0.000435905
I0704 11:52:21.673933 20391 solver.cpp:243] Iteration 13527, loss = 0.906199
I0704 11:52:21.673956 20391 solver.cpp:259]     Train net output #0: loss = 0.906199 (* 1 = 0.906199 loss)
I0704 11:52:21.673962 20391 solver.cpp:590] Iteration 13527, lr = 0.000433182
I0704 11:52:29.385934 20391 solver.cpp:243] Iteration 13554, loss = 0.679593
I0704 11:52:29.385960 20391 solver.cpp:259]     Train net output #0: loss = 0.679593 (* 1 = 0.679593 loss)
I0704 11:52:29.385967 20391 solver.cpp:590] Iteration 13554, lr = 0.000430477
I0704 11:52:37.125061 20391 solver.cpp:243] Iteration 13581, loss = 0.959491
I0704 11:52:37.125087 20391 solver.cpp:259]     Train net output #0: loss = 0.959491 (* 1 = 0.959491 loss)
I0704 11:52:37.125092 20391 solver.cpp:590] Iteration 13581, lr = 0.000427788
I0704 11:52:44.848549 20391 solver.cpp:243] Iteration 13608, loss = 0.929957
I0704 11:52:44.850096 20391 solver.cpp:259]     Train net output #0: loss = 0.929957 (* 1 = 0.929957 loss)
I0704 11:52:44.850113 20391 solver.cpp:590] Iteration 13608, lr = 0.000425116
I0704 11:52:52.538961 20391 solver.cpp:243] Iteration 13635, loss = 0.816518
I0704 11:52:52.538988 20391 solver.cpp:259]     Train net output #0: loss = 0.816518 (* 1 = 0.816518 loss)
I0704 11:52:52.538995 20391 solver.cpp:590] Iteration 13635, lr = 0.00042246
I0704 11:53:00.195320 20391 solver.cpp:243] Iteration 13662, loss = 0.841728
I0704 11:53:00.195348 20391 solver.cpp:259]     Train net output #0: loss = 0.841728 (* 1 = 0.841728 loss)
I0704 11:53:00.195353 20391 solver.cpp:590] Iteration 13662, lr = 0.000419822
I0704 11:53:07.857667 20391 solver.cpp:243] Iteration 13689, loss = 0.71089
I0704 11:53:07.857692 20391 solver.cpp:259]     Train net output #0: loss = 0.71089 (* 1 = 0.71089 loss)
I0704 11:53:07.857698 20391 solver.cpp:590] Iteration 13689, lr = 0.000417199
I0704 11:53:11.270146 20391 solver.cpp:347] Iteration 13702, Testing net (#0)
I0704 11:53:30.351464 20391 solver.cpp:415]     Test net output #0: accuracy = 0.415745
I0704 11:53:30.351541 20391 solver.cpp:415]     Test net output #1: loss = 2.78974 (* 1 = 2.78974 loss)
I0704 11:53:33.850891 20391 solver.cpp:243] Iteration 13716, loss = 1.07115
I0704 11:53:33.850916 20391 solver.cpp:259]     Train net output #0: loss = 1.07115 (* 1 = 1.07115 loss)
I0704 11:53:33.850921 20391 solver.cpp:590] Iteration 13716, lr = 0.000414593
I0704 11:53:41.528841 20391 solver.cpp:243] Iteration 13743, loss = 0.690311
I0704 11:53:41.528868 20391 solver.cpp:259]     Train net output #0: loss = 0.690311 (* 1 = 0.690311 loss)
I0704 11:53:41.528874 20391 solver.cpp:590] Iteration 13743, lr = 0.000412004
I0704 11:53:49.253460 20391 solver.cpp:243] Iteration 13770, loss = 0.673785
I0704 11:53:49.253487 20391 solver.cpp:259]     Train net output #0: loss = 0.673785 (* 1 = 0.673785 loss)
I0704 11:53:49.253494 20391 solver.cpp:590] Iteration 13770, lr = 0.00040943
I0704 11:53:56.934939 20391 solver.cpp:243] Iteration 13797, loss = 0.845554
I0704 11:53:56.934965 20391 solver.cpp:259]     Train net output #0: loss = 0.845554 (* 1 = 0.845554 loss)
I0704 11:53:56.934972 20391 solver.cpp:590] Iteration 13797, lr = 0.000406873
I0704 11:54:04.618867 20391 solver.cpp:243] Iteration 13824, loss = 0.833605
I0704 11:54:04.618948 20391 solver.cpp:259]     Train net output #0: loss = 0.833605 (* 1 = 0.833605 loss)
I0704 11:54:04.618957 20391 solver.cpp:590] Iteration 13824, lr = 0.000404331
I0704 11:54:12.296460 20391 solver.cpp:243] Iteration 13851, loss = 0.833968
I0704 11:54:12.296485 20391 solver.cpp:259]     Train net output #0: loss = 0.833968 (* 1 = 0.833968 loss)
I0704 11:54:12.296492 20391 solver.cpp:590] Iteration 13851, lr = 0.000401806
I0704 11:54:19.950491 20391 solver.cpp:243] Iteration 13878, loss = 0.74516
I0704 11:54:19.950518 20391 solver.cpp:259]     Train net output #0: loss = 0.74516 (* 1 = 0.74516 loss)
I0704 11:54:19.950525 20391 solver.cpp:590] Iteration 13878, lr = 0.000399296
I0704 11:54:27.591266 20391 solver.cpp:243] Iteration 13905, loss = 0.985014
I0704 11:54:27.591295 20391 solver.cpp:259]     Train net output #0: loss = 0.985014 (* 1 = 0.985014 loss)
I0704 11:54:27.591301 20391 solver.cpp:590] Iteration 13905, lr = 0.000396802
I0704 11:54:32.432394 20391 solver.cpp:347] Iteration 13923, Testing net (#0)
I0704 11:54:43.079210 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:54:51.519721 20391 solver.cpp:415]     Test net output #0: accuracy = 0.415745
I0704 11:54:51.519747 20391 solver.cpp:415]     Test net output #1: loss = 2.78846 (* 1 = 2.78846 loss)
I0704 11:54:53.582504 20391 solver.cpp:243] Iteration 13932, loss = 0.835689
I0704 11:54:53.582530 20391 solver.cpp:259]     Train net output #0: loss = 0.835689 (* 1 = 0.835689 loss)
I0704 11:54:53.582535 20391 solver.cpp:590] Iteration 13932, lr = 0.000394323
I0704 11:55:01.287169 20391 solver.cpp:243] Iteration 13959, loss = 0.794412
I0704 11:55:01.287195 20391 solver.cpp:259]     Train net output #0: loss = 0.794412 (* 1 = 0.794412 loss)
I0704 11:55:01.287201 20391 solver.cpp:590] Iteration 13959, lr = 0.00039186
I0704 11:55:08.958195 20391 solver.cpp:243] Iteration 13986, loss = 0.79102
I0704 11:55:08.958220 20391 solver.cpp:259]     Train net output #0: loss = 0.79102 (* 1 = 0.79102 loss)
I0704 11:55:08.958225 20391 solver.cpp:590] Iteration 13986, lr = 0.000389413
I0704 11:55:16.605877 20391 solver.cpp:243] Iteration 14013, loss = 0.935678
I0704 11:55:16.605936 20391 solver.cpp:259]     Train net output #0: loss = 0.935678 (* 1 = 0.935678 loss)
I0704 11:55:16.605942 20391 solver.cpp:590] Iteration 14013, lr = 0.00038698
I0704 11:55:24.302178 20391 solver.cpp:243] Iteration 14040, loss = 0.99671
I0704 11:55:24.302203 20391 solver.cpp:259]     Train net output #0: loss = 0.99671 (* 1 = 0.99671 loss)
I0704 11:55:24.302208 20391 solver.cpp:590] Iteration 14040, lr = 0.000384563
I0704 11:55:31.983714 20391 solver.cpp:243] Iteration 14067, loss = 0.805637
I0704 11:55:31.983741 20391 solver.cpp:259]     Train net output #0: loss = 0.805637 (* 1 = 0.805637 loss)
I0704 11:55:31.983746 20391 solver.cpp:590] Iteration 14067, lr = 0.000382161
I0704 11:55:39.640121 20391 solver.cpp:243] Iteration 14094, loss = 0.975075
I0704 11:55:39.640166 20391 solver.cpp:259]     Train net output #0: loss = 0.975075 (* 1 = 0.975075 loss)
I0704 11:55:39.640172 20391 solver.cpp:590] Iteration 14094, lr = 0.000379774
I0704 11:55:47.281399 20391 solver.cpp:243] Iteration 14121, loss = 0.887794
I0704 11:55:47.281486 20391 solver.cpp:259]     Train net output #0: loss = 0.887794 (* 1 = 0.887794 loss)
I0704 11:55:47.281493 20391 solver.cpp:590] Iteration 14121, lr = 0.000377402
I0704 11:55:53.540323 20391 solver.cpp:347] Iteration 14144, Testing net (#0)
I0704 11:56:12.765657 20391 solver.cpp:415]     Test net output #0: accuracy = 0.416346
I0704 11:56:12.765683 20391 solver.cpp:415]     Test net output #1: loss = 2.78517 (* 1 = 2.78517 loss)
I0704 11:56:13.396435 20391 solver.cpp:243] Iteration 14148, loss = 0.872243
I0704 11:56:13.396461 20391 solver.cpp:259]     Train net output #0: loss = 0.872243 (* 1 = 0.872243 loss)
I0704 11:56:13.396466 20391 solver.cpp:590] Iteration 14148, lr = 0.000375045
I0704 11:56:21.080399 20391 solver.cpp:243] Iteration 14175, loss = 0.623816
I0704 11:56:21.080492 20391 solver.cpp:259]     Train net output #0: loss = 0.623816 (* 1 = 0.623816 loss)
I0704 11:56:21.080500 20391 solver.cpp:590] Iteration 14175, lr = 0.000372702
I0704 11:56:28.768939 20391 solver.cpp:243] Iteration 14202, loss = 0.669893
I0704 11:56:28.768966 20391 solver.cpp:259]     Train net output #0: loss = 0.669893 (* 1 = 0.669893 loss)
I0704 11:56:28.768972 20391 solver.cpp:590] Iteration 14202, lr = 0.000370374
I0704 11:56:36.433030 20391 solver.cpp:243] Iteration 14229, loss = 0.713328
I0704 11:56:36.433056 20391 solver.cpp:259]     Train net output #0: loss = 0.713328 (* 1 = 0.713328 loss)
I0704 11:56:36.433063 20391 solver.cpp:590] Iteration 14229, lr = 0.000368061
I0704 11:56:44.131743 20391 solver.cpp:243] Iteration 14256, loss = 0.755577
I0704 11:56:44.131768 20391 solver.cpp:259]     Train net output #0: loss = 0.755577 (* 1 = 0.755577 loss)
I0704 11:56:44.131774 20391 solver.cpp:590] Iteration 14256, lr = 0.000365762
I0704 11:56:51.860038 20391 solver.cpp:243] Iteration 14283, loss = 0.817392
I0704 11:56:51.860141 20391 solver.cpp:259]     Train net output #0: loss = 0.817392 (* 1 = 0.817392 loss)
I0704 11:56:51.860147 20391 solver.cpp:590] Iteration 14283, lr = 0.000363477
I0704 11:56:59.587499 20391 solver.cpp:243] Iteration 14310, loss = 0.558189
I0704 11:56:59.587525 20391 solver.cpp:259]     Train net output #0: loss = 0.558189 (* 1 = 0.558189 loss)
I0704 11:56:59.587532 20391 solver.cpp:590] Iteration 14310, lr = 0.000361207
I0704 11:57:07.278308 20391 solver.cpp:243] Iteration 14337, loss = 0.778776
I0704 11:57:07.278333 20391 solver.cpp:259]     Train net output #0: loss = 0.778776 (* 1 = 0.778776 loss)
I0704 11:57:07.278339 20391 solver.cpp:590] Iteration 14337, lr = 0.00035895
I0704 11:57:14.940408 20391 solver.cpp:243] Iteration 14364, loss = 0.753144
I0704 11:57:14.940434 20391 solver.cpp:259]     Train net output #0: loss = 0.753144 (* 1 = 0.753144 loss)
I0704 11:57:14.940440 20391 solver.cpp:590] Iteration 14364, lr = 0.000356708
I0704 11:57:14.940652 20391 solver.cpp:347] Iteration 14365, Testing net (#0)
I0704 11:57:29.526391 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 11:57:34.162219 20391 solver.cpp:415]     Test net output #0: accuracy = 0.416106
I0704 11:57:34.162243 20391 solver.cpp:415]     Test net output #1: loss = 2.78323 (* 1 = 2.78323 loss)
I0704 11:57:41.095252 20391 solver.cpp:243] Iteration 14391, loss = 0.653648
I0704 11:57:41.095278 20391 solver.cpp:259]     Train net output #0: loss = 0.653648 (* 1 = 0.653648 loss)
I0704 11:57:41.095284 20391 solver.cpp:590] Iteration 14391, lr = 0.00035448
I0704 11:57:48.800390 20391 solver.cpp:243] Iteration 14418, loss = 0.972415
I0704 11:57:48.800415 20391 solver.cpp:259]     Train net output #0: loss = 0.972415 (* 1 = 0.972415 loss)
I0704 11:57:48.800421 20391 solver.cpp:590] Iteration 14418, lr = 0.000352266
I0704 11:57:56.486367 20391 solver.cpp:243] Iteration 14445, loss = 1.13762
I0704 11:57:56.486394 20391 solver.cpp:259]     Train net output #0: loss = 1.13762 (* 1 = 1.13762 loss)
I0704 11:57:56.486400 20391 solver.cpp:590] Iteration 14445, lr = 0.000350066
I0704 11:58:04.154649 20391 solver.cpp:243] Iteration 14472, loss = 0.830589
I0704 11:58:04.154706 20391 solver.cpp:259]     Train net output #0: loss = 0.830589 (* 1 = 0.830589 loss)
I0704 11:58:04.154713 20391 solver.cpp:590] Iteration 14472, lr = 0.000347879
I0704 11:58:11.844246 20391 solver.cpp:243] Iteration 14499, loss = 0.663743
I0704 11:58:11.844271 20391 solver.cpp:259]     Train net output #0: loss = 0.663743 (* 1 = 0.663743 loss)
I0704 11:58:11.844277 20391 solver.cpp:590] Iteration 14499, lr = 0.000345706
I0704 11:58:19.550717 20391 solver.cpp:243] Iteration 14526, loss = 0.84697
I0704 11:58:19.550747 20391 solver.cpp:259]     Train net output #0: loss = 0.84697 (* 1 = 0.84697 loss)
I0704 11:58:19.550755 20391 solver.cpp:590] Iteration 14526, lr = 0.000343547
I0704 11:58:27.211758 20391 solver.cpp:243] Iteration 14553, loss = 0.662974
I0704 11:58:27.211786 20391 solver.cpp:259]     Train net output #0: loss = 0.662974 (* 1 = 0.662974 loss)
I0704 11:58:27.211792 20391 solver.cpp:590] Iteration 14553, lr = 0.000341401
I0704 11:58:34.926957 20391 solver.cpp:243] Iteration 14580, loss = 0.854732
I0704 11:58:34.927016 20391 solver.cpp:259]     Train net output #0: loss = 0.854732 (* 1 = 0.854732 loss)
I0704 11:58:34.927023 20391 solver.cpp:590] Iteration 14580, lr = 0.000339268
I0704 11:58:36.356180 20391 solver.cpp:347] Iteration 14586, Testing net (#0)
I0704 11:58:55.549211 20391 solver.cpp:415]     Test net output #0: accuracy = 0.412019
I0704 11:58:55.549235 20391 solver.cpp:415]     Test net output #1: loss = 2.79533 (* 1 = 2.79533 loss)
I0704 11:59:01.064154 20391 solver.cpp:243] Iteration 14607, loss = 0.698447
I0704 11:59:01.064179 20391 solver.cpp:259]     Train net output #0: loss = 0.698447 (* 1 = 0.698447 loss)
I0704 11:59:01.064187 20391 solver.cpp:590] Iteration 14607, lr = 0.000337149
I0704 11:59:08.813920 20391 solver.cpp:243] Iteration 14634, loss = 0.71003
I0704 11:59:08.814020 20391 solver.cpp:259]     Train net output #0: loss = 0.71003 (* 1 = 0.71003 loss)
I0704 11:59:08.814028 20391 solver.cpp:590] Iteration 14634, lr = 0.000335043
I0704 11:59:16.559929 20391 solver.cpp:243] Iteration 14661, loss = 0.698114
I0704 11:59:16.559957 20391 solver.cpp:259]     Train net output #0: loss = 0.698114 (* 1 = 0.698114 loss)
I0704 11:59:16.559963 20391 solver.cpp:590] Iteration 14661, lr = 0.000332951
I0704 11:59:24.318367 20391 solver.cpp:243] Iteration 14688, loss = 0.797981
I0704 11:59:24.318392 20391 solver.cpp:259]     Train net output #0: loss = 0.797981 (* 1 = 0.797981 loss)
I0704 11:59:24.318398 20391 solver.cpp:590] Iteration 14688, lr = 0.000330871
I0704 11:59:32.045259 20391 solver.cpp:243] Iteration 14715, loss = 0.751832
I0704 11:59:32.045286 20391 solver.cpp:259]     Train net output #0: loss = 0.751832 (* 1 = 0.751832 loss)
I0704 11:59:32.045292 20391 solver.cpp:590] Iteration 14715, lr = 0.000328804
I0704 11:59:39.685711 20391 solver.cpp:243] Iteration 14742, loss = 0.88402
I0704 11:59:39.685801 20391 solver.cpp:259]     Train net output #0: loss = 0.88402 (* 1 = 0.88402 loss)
I0704 11:59:39.685808 20391 solver.cpp:590] Iteration 14742, lr = 0.00032675
I0704 11:59:47.346766 20391 solver.cpp:243] Iteration 14769, loss = 0.748739
I0704 11:59:47.346807 20391 solver.cpp:259]     Train net output #0: loss = 0.748739 (* 1 = 0.748739 loss)
I0704 11:59:47.346818 20391 solver.cpp:590] Iteration 14769, lr = 0.000324709
I0704 11:59:55.003509 20391 solver.cpp:243] Iteration 14796, loss = 0.7868
I0704 11:59:55.003531 20391 solver.cpp:259]     Train net output #0: loss = 0.7868 (* 1 = 0.7868 loss)
I0704 11:59:55.003537 20391 solver.cpp:590] Iteration 14796, lr = 0.000322681
I0704 11:59:57.852272 20391 solver.cpp:347] Iteration 14807, Testing net (#0)
I0704 12:00:16.201429 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 12:00:16.938796 20391 solver.cpp:415]     Test net output #0: accuracy = 0.415625
I0704 12:00:16.938822 20391 solver.cpp:415]     Test net output #1: loss = 2.79248 (* 1 = 2.79248 loss)
I0704 12:00:20.976361 20391 solver.cpp:243] Iteration 14823, loss = 0.792495
I0704 12:00:20.976387 20391 solver.cpp:259]     Train net output #0: loss = 0.792495 (* 1 = 0.792495 loss)
I0704 12:00:20.976393 20391 solver.cpp:590] Iteration 14823, lr = 0.000320666
I0704 12:00:28.690258 20391 solver.cpp:243] Iteration 14850, loss = 0.631091
I0704 12:00:28.690284 20391 solver.cpp:259]     Train net output #0: loss = 0.631091 (* 1 = 0.631091 loss)
I0704 12:00:28.690290 20391 solver.cpp:590] Iteration 14850, lr = 0.000318663
I0704 12:00:36.446548 20391 solver.cpp:243] Iteration 14877, loss = 0.710208
I0704 12:00:36.446574 20391 solver.cpp:259]     Train net output #0: loss = 0.710208 (* 1 = 0.710208 loss)
I0704 12:00:36.446580 20391 solver.cpp:590] Iteration 14877, lr = 0.000316672
I0704 12:00:44.194741 20391 solver.cpp:243] Iteration 14904, loss = 0.772261
I0704 12:00:44.194763 20391 solver.cpp:259]     Train net output #0: loss = 0.772261 (* 1 = 0.772261 loss)
I0704 12:00:44.194771 20391 solver.cpp:590] Iteration 14904, lr = 0.000314694
I0704 12:00:51.960757 20391 solver.cpp:243] Iteration 14931, loss = 0.959806
I0704 12:00:51.960846 20391 solver.cpp:259]     Train net output #0: loss = 0.959806 (* 1 = 0.959806 loss)
I0704 12:00:51.960853 20391 solver.cpp:590] Iteration 14931, lr = 0.000312729
I0704 12:00:59.668423 20391 solver.cpp:243] Iteration 14958, loss = 0.921947
I0704 12:00:59.668448 20391 solver.cpp:259]     Train net output #0: loss = 0.921947 (* 1 = 0.921947 loss)
I0704 12:00:59.668454 20391 solver.cpp:590] Iteration 14958, lr = 0.000310775
I0704 12:01:07.301705 20391 solver.cpp:243] Iteration 14985, loss = 0.758067
I0704 12:01:07.301731 20391 solver.cpp:259]     Train net output #0: loss = 0.758067 (* 1 = 0.758067 loss)
I0704 12:01:07.301738 20391 solver.cpp:590] Iteration 14985, lr = 0.000308834
I0704 12:01:15.317147 20391 solver.cpp:243] Iteration 15012, loss = 0.627932
I0704 12:01:15.317169 20391 solver.cpp:259]     Train net output #0: loss = 0.627932 (* 1 = 0.627932 loss)
I0704 12:01:15.317174 20391 solver.cpp:590] Iteration 15012, lr = 0.000306905
I0704 12:01:19.786319 20391 solver.cpp:347] Iteration 15028, Testing net (#0)
I0704 12:01:38.906611 20391 solver.cpp:415]     Test net output #0: accuracy = 0.415986
I0704 12:01:38.906690 20391 solver.cpp:415]     Test net output #1: loss = 2.77812 (* 1 = 2.77812 loss)
I0704 12:01:41.539958 20391 solver.cpp:243] Iteration 15039, loss = 0.595802
I0704 12:01:41.539984 20391 solver.cpp:259]     Train net output #0: loss = 0.595802 (* 1 = 0.595802 loss)
I0704 12:01:41.539990 20391 solver.cpp:590] Iteration 15039, lr = 0.000304988
I0704 12:01:49.297961 20391 solver.cpp:243] Iteration 15066, loss = 0.758058
I0704 12:01:49.297988 20391 solver.cpp:259]     Train net output #0: loss = 0.758058 (* 1 = 0.758058 loss)
I0704 12:01:49.297996 20391 solver.cpp:590] Iteration 15066, lr = 0.000303083
I0704 12:01:57.007349 20391 solver.cpp:243] Iteration 15093, loss = 0.664158
I0704 12:01:57.007375 20391 solver.cpp:259]     Train net output #0: loss = 0.664158 (* 1 = 0.664158 loss)
I0704 12:01:57.007382 20391 solver.cpp:590] Iteration 15093, lr = 0.00030119
I0704 12:02:04.880651 20391 solver.cpp:243] Iteration 15120, loss = 0.717266
I0704 12:02:04.880679 20391 solver.cpp:259]     Train net output #0: loss = 0.717266 (* 1 = 0.717266 loss)
I0704 12:02:04.880686 20391 solver.cpp:590] Iteration 15120, lr = 0.000299309
I0704 12:02:12.589210 20391 solver.cpp:243] Iteration 15147, loss = 0.927603
I0704 12:02:12.589287 20391 solver.cpp:259]     Train net output #0: loss = 0.927603 (* 1 = 0.927603 loss)
I0704 12:02:12.589303 20391 solver.cpp:590] Iteration 15147, lr = 0.000297439
I0704 12:02:20.267079 20391 solver.cpp:243] Iteration 15174, loss = 0.614715
I0704 12:02:20.267105 20391 solver.cpp:259]     Train net output #0: loss = 0.614715 (* 1 = 0.614715 loss)
I0704 12:02:20.267112 20391 solver.cpp:590] Iteration 15174, lr = 0.000295581
I0704 12:02:27.933337 20391 solver.cpp:243] Iteration 15201, loss = 0.818463
I0704 12:02:27.933363 20391 solver.cpp:259]     Train net output #0: loss = 0.818463 (* 1 = 0.818463 loss)
I0704 12:02:27.933369 20391 solver.cpp:590] Iteration 15201, lr = 0.000293735
I0704 12:02:35.586220 20391 solver.cpp:243] Iteration 15228, loss = 0.541852
I0704 12:02:35.586248 20391 solver.cpp:259]     Train net output #0: loss = 0.541852 (* 1 = 0.541852 loss)
I0704 12:02:35.586254 20391 solver.cpp:590] Iteration 15228, lr = 0.0002919
I0704 12:02:41.275868 20391 solver.cpp:347] Iteration 15249, Testing net (#0)
I0704 12:03:00.373124 20391 solver.cpp:415]     Test net output #0: accuracy = 0.417909
I0704 12:03:00.373180 20391 solver.cpp:415]     Test net output #1: loss = 2.79159 (* 1 = 2.79159 loss)
I0704 12:03:01.576797 20391 solver.cpp:243] Iteration 15255, loss = 0.68153
I0704 12:03:01.576823 20391 solver.cpp:259]     Train net output #0: loss = 0.68153 (* 1 = 0.68153 loss)
I0704 12:03:01.576830 20391 solver.cpp:590] Iteration 15255, lr = 0.000290077
I0704 12:03:09.263136 20391 solver.cpp:243] Iteration 15282, loss = 0.848952
I0704 12:03:09.263164 20391 solver.cpp:259]     Train net output #0: loss = 0.848952 (* 1 = 0.848952 loss)
I0704 12:03:09.263171 20391 solver.cpp:590] Iteration 15282, lr = 0.000288265
I0704 12:03:12.400790 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 12:03:17.012719 20391 solver.cpp:243] Iteration 15309, loss = 0.659381
I0704 12:03:17.012745 20391 solver.cpp:259]     Train net output #0: loss = 0.659381 (* 1 = 0.659381 loss)
I0704 12:03:17.012750 20391 solver.cpp:590] Iteration 15309, lr = 0.000286464
I0704 12:03:24.721166 20391 solver.cpp:243] Iteration 15336, loss = 1.04111
I0704 12:03:24.721192 20391 solver.cpp:259]     Train net output #0: loss = 1.04111 (* 1 = 1.04111 loss)
I0704 12:03:24.721199 20391 solver.cpp:590] Iteration 15336, lr = 0.000284675
I0704 12:03:32.457191 20391 solver.cpp:243] Iteration 15363, loss = 0.78292
I0704 12:03:32.457288 20391 solver.cpp:259]     Train net output #0: loss = 0.78292 (* 1 = 0.78292 loss)
I0704 12:03:32.457305 20391 solver.cpp:590] Iteration 15363, lr = 0.000282897
I0704 12:03:40.223706 20391 solver.cpp:243] Iteration 15390, loss = 0.691475
I0704 12:03:40.223740 20391 solver.cpp:259]     Train net output #0: loss = 0.691475 (* 1 = 0.691475 loss)
I0704 12:03:40.223747 20391 solver.cpp:590] Iteration 15390, lr = 0.00028113
I0704 12:03:47.984640 20391 solver.cpp:243] Iteration 15417, loss = 0.778424
I0704 12:03:47.984666 20391 solver.cpp:259]     Train net output #0: loss = 0.778424 (* 1 = 0.778424 loss)
I0704 12:03:47.984673 20391 solver.cpp:590] Iteration 15417, lr = 0.000279374
I0704 12:03:55.705514 20391 solver.cpp:243] Iteration 15444, loss = 0.769396
I0704 12:03:55.705540 20391 solver.cpp:259]     Train net output #0: loss = 0.769396 (* 1 = 0.769396 loss)
I0704 12:03:55.705549 20391 solver.cpp:590] Iteration 15444, lr = 0.000277629
I0704 12:04:02.929074 20391 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_15470.caffemodel
I0704 12:04:20.073060 20391 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_15470.solverstate
I0704 12:04:21.260418 20391 solver.cpp:347] Iteration 15470, Testing net (#0)
I0704 12:04:40.345090 20391 solver.cpp:415]     Test net output #0: accuracy = 0.416947
I0704 12:04:40.345211 20391 solver.cpp:415]     Test net output #1: loss = 2.79524 (* 1 = 2.79524 loss)
I0704 12:04:40.488332 20391 solver.cpp:243] Iteration 15471, loss = 0.746581
I0704 12:04:40.488358 20391 solver.cpp:259]     Train net output #0: loss = 0.746581 (* 1 = 0.746581 loss)
I0704 12:04:40.488363 20391 solver.cpp:590] Iteration 15471, lr = 0.000275895
I0704 12:04:47.804800 20391 solver.cpp:243] Iteration 15498, loss = 0.595586
I0704 12:04:47.804824 20391 solver.cpp:259]     Train net output #0: loss = 0.595586 (* 1 = 0.595586 loss)
I0704 12:04:47.804831 20391 solver.cpp:590] Iteration 15498, lr = 0.000274171
I0704 12:04:55.487004 20391 solver.cpp:243] Iteration 15525, loss = 0.588186
I0704 12:04:55.487030 20391 solver.cpp:259]     Train net output #0: loss = 0.588186 (* 1 = 0.588186 loss)
I0704 12:04:55.487036 20391 solver.cpp:590] Iteration 15525, lr = 0.000272459
I0704 12:05:03.197758 20391 solver.cpp:243] Iteration 15552, loss = 0.819525
I0704 12:05:03.197783 20391 solver.cpp:259]     Train net output #0: loss = 0.819525 (* 1 = 0.819525 loss)
I0704 12:05:03.197789 20391 solver.cpp:590] Iteration 15552, lr = 0.000270757
I0704 12:05:10.989928 20391 solver.cpp:243] Iteration 15579, loss = 0.633917
I0704 12:05:10.990008 20391 solver.cpp:259]     Train net output #0: loss = 0.633917 (* 1 = 0.633917 loss)
I0704 12:05:10.990015 20391 solver.cpp:590] Iteration 15579, lr = 0.000269066
I0704 12:05:18.937991 20391 solver.cpp:243] Iteration 15606, loss = 0.826801
I0704 12:05:18.938016 20391 solver.cpp:259]     Train net output #0: loss = 0.826801 (* 1 = 0.826801 loss)
I0704 12:05:18.938022 20391 solver.cpp:590] Iteration 15606, lr = 0.000267385
I0704 12:05:26.738771 20391 solver.cpp:243] Iteration 15633, loss = 0.853836
I0704 12:05:26.738796 20391 solver.cpp:259]     Train net output #0: loss = 0.853836 (* 1 = 0.853836 loss)
I0704 12:05:26.738802 20391 solver.cpp:590] Iteration 15633, lr = 0.000265715
I0704 12:05:34.444959 20391 solver.cpp:243] Iteration 15660, loss = 1.01034
I0704 12:05:34.444985 20391 solver.cpp:259]     Train net output #0: loss = 1.01034 (* 1 = 1.01034 loss)
I0704 12:05:34.444991 20391 solver.cpp:590] Iteration 15660, lr = 0.000264055
I0704 12:05:42.179538 20391 solver.cpp:243] Iteration 15687, loss = 0.782634
I0704 12:05:42.179591 20391 solver.cpp:259]     Train net output #0: loss = 0.782634 (* 1 = 0.782634 loss)
I0704 12:05:42.179599 20391 solver.cpp:590] Iteration 15687, lr = 0.000262406
I0704 12:05:43.032240 20391 solver.cpp:347] Iteration 15691, Testing net (#0)
I0704 12:06:02.101764 20391 solver.cpp:415]     Test net output #0: accuracy = 0.417308
I0704 12:06:02.101790 20391 solver.cpp:415]     Test net output #1: loss = 2.787 (* 1 = 2.787 loss)
I0704 12:06:08.151281 20391 solver.cpp:243] Iteration 15714, loss = 0.695793
I0704 12:06:08.151311 20391 solver.cpp:259]     Train net output #0: loss = 0.695793 (* 1 = 0.695793 loss)
I0704 12:06:08.151317 20391 solver.cpp:590] Iteration 15714, lr = 0.000260767
I0704 12:06:16.944592 20391 solver.cpp:243] Iteration 15741, loss = 0.732871
I0704 12:06:16.944679 20391 solver.cpp:259]     Train net output #0: loss = 0.732871 (* 1 = 0.732871 loss)
I0704 12:06:16.944685 20391 solver.cpp:590] Iteration 15741, lr = 0.000259138
I0704 12:06:25.409790 20391 solver.cpp:243] Iteration 15768, loss = 0.698962
I0704 12:06:25.409814 20391 solver.cpp:259]     Train net output #0: loss = 0.698962 (* 1 = 0.698962 loss)
I0704 12:06:25.409821 20391 solver.cpp:590] Iteration 15768, lr = 0.000257519
I0704 12:06:31.662580 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 12:06:34.236934 20391 solver.cpp:243] Iteration 15795, loss = 0.750725
I0704 12:06:34.236960 20391 solver.cpp:259]     Train net output #0: loss = 0.750725 (* 1 = 0.750725 loss)
I0704 12:06:34.236966 20391 solver.cpp:590] Iteration 15795, lr = 0.000255911
I0704 12:06:43.101388 20391 solver.cpp:243] Iteration 15822, loss = 0.508498
I0704 12:06:43.101413 20391 solver.cpp:259]     Train net output #0: loss = 0.508498 (* 1 = 0.508498 loss)
I0704 12:06:43.101419 20391 solver.cpp:590] Iteration 15822, lr = 0.000254312
I0704 12:06:50.792974 20391 solver.cpp:243] Iteration 15849, loss = 0.562495
I0704 12:06:50.793031 20391 solver.cpp:259]     Train net output #0: loss = 0.562495 (* 1 = 0.562495 loss)
I0704 12:06:50.793038 20391 solver.cpp:590] Iteration 15849, lr = 0.000252724
I0704 12:06:58.518928 20391 solver.cpp:243] Iteration 15876, loss = 0.525909
I0704 12:06:58.518954 20391 solver.cpp:259]     Train net output #0: loss = 0.525909 (* 1 = 0.525909 loss)
I0704 12:06:58.518959 20391 solver.cpp:590] Iteration 15876, lr = 0.000251145
I0704 12:07:06.352327 20391 solver.cpp:243] Iteration 15903, loss = 0.899232
I0704 12:07:06.352352 20391 solver.cpp:259]     Train net output #0: loss = 0.899232 (* 1 = 0.899232 loss)
I0704 12:07:06.352360 20391 solver.cpp:590] Iteration 15903, lr = 0.000249577
I0704 12:07:08.915714 20391 solver.cpp:347] Iteration 15912, Testing net (#0)
I0704 12:07:28.005105 20391 solver.cpp:415]     Test net output #0: accuracy = 0.416587
I0704 12:07:28.005244 20391 solver.cpp:415]     Test net output #1: loss = 2.78906 (* 1 = 2.78906 loss)
I0704 12:07:32.695399 20391 solver.cpp:243] Iteration 15930, loss = 0.683704
I0704 12:07:32.695425 20391 solver.cpp:259]     Train net output #0: loss = 0.683704 (* 1 = 0.683704 loss)
I0704 12:07:32.695430 20391 solver.cpp:590] Iteration 15930, lr = 0.000248018
I0704 12:07:40.381688 20391 solver.cpp:243] Iteration 15957, loss = 0.934282
I0704 12:07:40.381716 20391 solver.cpp:259]     Train net output #0: loss = 0.934282 (* 1 = 0.934282 loss)
I0704 12:07:40.381721 20391 solver.cpp:590] Iteration 15957, lr = 0.000246469
I0704 12:07:48.243810 20391 solver.cpp:243] Iteration 15984, loss = 0.857203
I0704 12:07:48.243841 20391 solver.cpp:259]     Train net output #0: loss = 0.857203 (* 1 = 0.857203 loss)
I0704 12:07:48.243849 20391 solver.cpp:590] Iteration 15984, lr = 0.000244929
I0704 12:07:56.431532 20391 solver.cpp:243] Iteration 16011, loss = 0.759493
I0704 12:07:56.431562 20391 solver.cpp:259]     Train net output #0: loss = 0.759493 (* 1 = 0.759493 loss)
I0704 12:07:56.431571 20391 solver.cpp:590] Iteration 16011, lr = 0.000243399
I0704 12:08:04.658123 20391 solver.cpp:243] Iteration 16038, loss = 0.625956
I0704 12:08:04.658220 20391 solver.cpp:259]     Train net output #0: loss = 0.625956 (* 1 = 0.625956 loss)
I0704 12:08:04.658227 20391 solver.cpp:590] Iteration 16038, lr = 0.000241879
I0704 12:08:12.337354 20391 solver.cpp:243] Iteration 16065, loss = 0.688322
I0704 12:08:12.337378 20391 solver.cpp:259]     Train net output #0: loss = 0.688322 (* 1 = 0.688322 loss)
I0704 12:08:12.337384 20391 solver.cpp:590] Iteration 16065, lr = 0.000240368
I0704 12:08:19.991006 20391 solver.cpp:243] Iteration 16092, loss = 0.499944
I0704 12:08:19.991031 20391 solver.cpp:259]     Train net output #0: loss = 0.499944 (* 1 = 0.499944 loss)
I0704 12:08:19.991036 20391 solver.cpp:590] Iteration 16092, lr = 0.000238867
I0704 12:08:27.693045 20391 solver.cpp:243] Iteration 16119, loss = 0.812792
I0704 12:08:27.693070 20391 solver.cpp:259]     Train net output #0: loss = 0.812792 (* 1 = 0.812792 loss)
I0704 12:08:27.693076 20391 solver.cpp:590] Iteration 16119, lr = 0.000237375
I0704 12:08:31.393976 20391 solver.cpp:347] Iteration 16133, Testing net (#0)
I0704 12:08:50.734774 20391 solver.cpp:415]     Test net output #0: accuracy = 0.41875
I0704 12:08:50.734861 20391 solver.cpp:415]     Test net output #1: loss = 2.78545 (* 1 = 2.78545 loss)
I0704 12:08:53.931529 20391 solver.cpp:243] Iteration 16146, loss = 0.437302
I0704 12:08:53.931555 20391 solver.cpp:259]     Train net output #0: loss = 0.437302 (* 1 = 0.437302 loss)
I0704 12:08:53.931560 20391 solver.cpp:590] Iteration 16146, lr = 0.000235892
I0704 12:09:01.607897 20391 solver.cpp:243] Iteration 16173, loss = 0.895244
I0704 12:09:01.607920 20391 solver.cpp:259]     Train net output #0: loss = 0.895244 (* 1 = 0.895244 loss)
I0704 12:09:01.607926 20391 solver.cpp:590] Iteration 16173, lr = 0.000234418
I0704 12:09:09.283665 20391 solver.cpp:243] Iteration 16200, loss = 0.508056
I0704 12:09:09.283691 20391 solver.cpp:259]     Train net output #0: loss = 0.508056 (* 1 = 0.508056 loss)
I0704 12:09:09.283697 20391 solver.cpp:590] Iteration 16200, lr = 0.000232954
I0704 12:09:16.952983 20391 solver.cpp:243] Iteration 16227, loss = 0.646148
I0704 12:09:16.953007 20391 solver.cpp:259]     Train net output #0: loss = 0.646148 (* 1 = 0.646148 loss)
I0704 12:09:16.953013 20391 solver.cpp:590] Iteration 16227, lr = 0.000231499
I0704 12:09:24.652302 20391 solver.cpp:243] Iteration 16254, loss = 0.778321
I0704 12:09:24.652370 20391 solver.cpp:259]     Train net output #0: loss = 0.778321 (* 1 = 0.778321 loss)
I0704 12:09:24.652386 20391 solver.cpp:590] Iteration 16254, lr = 0.000230053
I0704 12:09:32.300285 20391 solver.cpp:243] Iteration 16281, loss = 0.841224
I0704 12:09:32.300319 20391 solver.cpp:259]     Train net output #0: loss = 0.841224 (* 1 = 0.841224 loss)
I0704 12:09:32.300324 20391 solver.cpp:590] Iteration 16281, lr = 0.000228616
I0704 12:09:32.300537 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 12:09:39.950047 20391 solver.cpp:243] Iteration 16308, loss = 0.729288
I0704 12:09:39.950072 20391 solver.cpp:259]     Train net output #0: loss = 0.729288 (* 1 = 0.729288 loss)
I0704 12:09:39.950078 20391 solver.cpp:590] Iteration 16308, lr = 0.000227188
I0704 12:09:47.606940 20391 solver.cpp:243] Iteration 16335, loss = 0.685389
I0704 12:09:47.606968 20391 solver.cpp:259]     Train net output #0: loss = 0.685389 (* 1 = 0.685389 loss)
I0704 12:09:47.606974 20391 solver.cpp:590] Iteration 16335, lr = 0.000225769
I0704 12:09:52.716912 20391 solver.cpp:347] Iteration 16354, Testing net (#0)
I0704 12:10:12.438921 20391 solver.cpp:415]     Test net output #0: accuracy = 0.416587
I0704 12:10:12.438979 20391 solver.cpp:415]     Test net output #1: loss = 2.78941 (* 1 = 2.78941 loss)
I0704 12:10:14.204769 20391 solver.cpp:243] Iteration 16362, loss = 0.573572
I0704 12:10:14.204795 20391 solver.cpp:259]     Train net output #0: loss = 0.573572 (* 1 = 0.573572 loss)
I0704 12:10:14.204802 20391 solver.cpp:590] Iteration 16362, lr = 0.000224359
I0704 12:10:21.892137 20391 solver.cpp:243] Iteration 16389, loss = 0.751852
I0704 12:10:21.892161 20391 solver.cpp:259]     Train net output #0: loss = 0.751852 (* 1 = 0.751852 loss)
I0704 12:10:21.892166 20391 solver.cpp:590] Iteration 16389, lr = 0.000222957
I0704 12:10:29.589107 20391 solver.cpp:243] Iteration 16416, loss = 0.620982
I0704 12:10:29.589133 20391 solver.cpp:259]     Train net output #0: loss = 0.620982 (* 1 = 0.620982 loss)
I0704 12:10:29.589138 20391 solver.cpp:590] Iteration 16416, lr = 0.000221565
I0704 12:10:37.292556 20391 solver.cpp:243] Iteration 16443, loss = 0.61474
I0704 12:10:37.292580 20391 solver.cpp:259]     Train net output #0: loss = 0.61474 (* 1 = 0.61474 loss)
I0704 12:10:37.292587 20391 solver.cpp:590] Iteration 16443, lr = 0.000220181
I0704 12:10:45.032548 20391 solver.cpp:243] Iteration 16470, loss = 0.612557
I0704 12:10:45.032630 20391 solver.cpp:259]     Train net output #0: loss = 0.612557 (* 1 = 0.612557 loss)
I0704 12:10:45.032636 20391 solver.cpp:590] Iteration 16470, lr = 0.000218806
I0704 12:10:52.740882 20391 solver.cpp:243] Iteration 16497, loss = 0.797678
I0704 12:10:52.740909 20391 solver.cpp:259]     Train net output #0: loss = 0.797678 (* 1 = 0.797678 loss)
I0704 12:10:52.740916 20391 solver.cpp:590] Iteration 16497, lr = 0.000217439
I0704 12:11:00.423851 20391 solver.cpp:243] Iteration 16524, loss = 0.855197
I0704 12:11:00.423876 20391 solver.cpp:259]     Train net output #0: loss = 0.855197 (* 1 = 0.855197 loss)
I0704 12:11:00.423882 20391 solver.cpp:590] Iteration 16524, lr = 0.000216081
I0704 12:11:08.109916 20391 solver.cpp:243] Iteration 16551, loss = 0.759064
I0704 12:11:08.109942 20391 solver.cpp:259]     Train net output #0: loss = 0.759064 (* 1 = 0.759064 loss)
I0704 12:11:08.109947 20391 solver.cpp:590] Iteration 16551, lr = 0.000214731
I0704 12:11:14.675000 20391 solver.cpp:347] Iteration 16575, Testing net (#0)
I0704 12:11:33.967106 20391 solver.cpp:415]     Test net output #0: accuracy = 0.41851
I0704 12:11:33.967213 20391 solver.cpp:415]     Test net output #1: loss = 2.78217 (* 1 = 2.78217 loss)
I0704 12:11:34.319994 20391 solver.cpp:243] Iteration 16578, loss = 0.605348
I0704 12:11:34.320019 20391 solver.cpp:259]     Train net output #0: loss = 0.605348 (* 1 = 0.605348 loss)
I0704 12:11:34.320024 20391 solver.cpp:590] Iteration 16578, lr = 0.00021339
I0704 12:11:42.006099 20391 solver.cpp:243] Iteration 16605, loss = 0.618624
I0704 12:11:42.006124 20391 solver.cpp:259]     Train net output #0: loss = 0.618624 (* 1 = 0.618624 loss)
I0704 12:11:42.006129 20391 solver.cpp:590] Iteration 16605, lr = 0.000212057
I0704 12:11:49.711894 20391 solver.cpp:243] Iteration 16632, loss = 0.8655
I0704 12:11:49.711920 20391 solver.cpp:259]     Train net output #0: loss = 0.8655 (* 1 = 0.8655 loss)
I0704 12:11:49.711925 20391 solver.cpp:590] Iteration 16632, lr = 0.000210732
I0704 12:11:57.397500 20391 solver.cpp:243] Iteration 16659, loss = 0.807403
I0704 12:11:57.397524 20391 solver.cpp:259]     Train net output #0: loss = 0.807403 (* 1 = 0.807403 loss)
I0704 12:11:57.397531 20391 solver.cpp:590] Iteration 16659, lr = 0.000209416
I0704 12:12:05.116760 20391 solver.cpp:243] Iteration 16686, loss = 0.51474
I0704 12:12:05.116875 20391 solver.cpp:259]     Train net output #0: loss = 0.51474 (* 1 = 0.51474 loss)
I0704 12:12:05.116883 20391 solver.cpp:590] Iteration 16686, lr = 0.000208108
I0704 12:12:12.814479 20391 solver.cpp:243] Iteration 16713, loss = 0.667054
I0704 12:12:12.814505 20391 solver.cpp:259]     Train net output #0: loss = 0.667054 (* 1 = 0.667054 loss)
I0704 12:12:12.814512 20391 solver.cpp:590] Iteration 16713, lr = 0.000206808
I0704 12:12:20.508978 20391 solver.cpp:243] Iteration 16740, loss = 0.782557
I0704 12:12:20.509004 20391 solver.cpp:259]     Train net output #0: loss = 0.782557 (* 1 = 0.782557 loss)
I0704 12:12:20.509011 20391 solver.cpp:590] Iteration 16740, lr = 0.000205516
I0704 12:12:28.195394 20391 solver.cpp:243] Iteration 16767, loss = 0.77352
I0704 12:12:28.195420 20391 solver.cpp:259]     Train net output #0: loss = 0.77352 (* 1 = 0.77352 loss)
I0704 12:12:28.195425 20391 solver.cpp:590] Iteration 16767, lr = 0.000204233
I0704 12:12:30.469791 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 12:12:35.918797 20391 solver.cpp:243] Iteration 16794, loss = 0.851134
I0704 12:12:35.918866 20391 solver.cpp:259]     Train net output #0: loss = 0.851134 (* 1 = 0.851134 loss)
I0704 12:12:35.918884 20391 solver.cpp:590] Iteration 16794, lr = 0.000202957
I0704 12:12:36.203608 20391 solver.cpp:347] Iteration 16796, Testing net (#0)
I0704 12:12:55.477269 20391 solver.cpp:415]     Test net output #0: accuracy = 0.417668
I0704 12:12:55.477293 20391 solver.cpp:415]     Test net output #1: loss = 2.78443 (* 1 = 2.78443 loss)
I0704 12:13:02.092603 20391 solver.cpp:243] Iteration 16821, loss = 0.722539
I0704 12:13:02.092630 20391 solver.cpp:259]     Train net output #0: loss = 0.722539 (* 1 = 0.722539 loss)
I0704 12:13:02.092635 20391 solver.cpp:590] Iteration 16821, lr = 0.000201689
I0704 12:13:09.791868 20391 solver.cpp:243] Iteration 16848, loss = 0.673267
I0704 12:13:09.792006 20391 solver.cpp:259]     Train net output #0: loss = 0.673267 (* 1 = 0.673267 loss)
I0704 12:13:09.792013 20391 solver.cpp:590] Iteration 16848, lr = 0.000200429
I0704 12:13:17.462685 20391 solver.cpp:243] Iteration 16875, loss = 0.864825
I0704 12:13:17.462709 20391 solver.cpp:259]     Train net output #0: loss = 0.864825 (* 1 = 0.864825 loss)
I0704 12:13:17.462715 20391 solver.cpp:590] Iteration 16875, lr = 0.000199177
I0704 12:13:25.164796 20391 solver.cpp:243] Iteration 16902, loss = 0.598954
I0704 12:13:25.164821 20391 solver.cpp:259]     Train net output #0: loss = 0.598954 (* 1 = 0.598954 loss)
I0704 12:13:25.164827 20391 solver.cpp:590] Iteration 16902, lr = 0.000197933
I0704 12:13:32.844200 20391 solver.cpp:243] Iteration 16929, loss = 0.528012
I0704 12:13:32.844225 20391 solver.cpp:259]     Train net output #0: loss = 0.528012 (* 1 = 0.528012 loss)
I0704 12:13:32.844230 20391 solver.cpp:590] Iteration 16929, lr = 0.000196697
I0704 12:13:40.507982 20391 solver.cpp:243] Iteration 16956, loss = 0.503602
I0704 12:13:40.508131 20391 solver.cpp:259]     Train net output #0: loss = 0.503602 (* 1 = 0.503602 loss)
I0704 12:13:40.508138 20391 solver.cpp:590] Iteration 16956, lr = 0.000195468
I0704 12:13:48.144924 20391 solver.cpp:243] Iteration 16983, loss = 0.803795
I0704 12:13:48.144949 20391 solver.cpp:259]     Train net output #0: loss = 0.803795 (* 1 = 0.803795 loss)
I0704 12:13:48.144954 20391 solver.cpp:590] Iteration 16983, lr = 0.000194247
I0704 12:13:55.819418 20391 solver.cpp:243] Iteration 17010, loss = 0.670808
I0704 12:13:55.819445 20391 solver.cpp:259]     Train net output #0: loss = 0.670808 (* 1 = 0.670808 loss)
I0704 12:13:55.819452 20391 solver.cpp:590] Iteration 17010, lr = 0.000193034
I0704 12:13:57.525387 20391 solver.cpp:347] Iteration 17017, Testing net (#0)
I0704 12:14:16.637468 20391 solver.cpp:415]     Test net output #0: accuracy = 0.418269
I0704 12:14:16.637609 20391 solver.cpp:415]     Test net output #1: loss = 2.7804 (* 1 = 2.7804 loss)
I0704 12:14:21.816112 20391 solver.cpp:243] Iteration 17037, loss = 0.619982
I0704 12:14:21.816139 20391 solver.cpp:259]     Train net output #0: loss = 0.619982 (* 1 = 0.619982 loss)
I0704 12:14:21.816146 20391 solver.cpp:590] Iteration 17037, lr = 0.000191828
I0704 12:14:29.497447 20391 solver.cpp:243] Iteration 17064, loss = 0.717268
I0704 12:14:29.497473 20391 solver.cpp:259]     Train net output #0: loss = 0.717268 (* 1 = 0.717268 loss)
I0704 12:14:29.497479 20391 solver.cpp:590] Iteration 17064, lr = 0.00019063
I0704 12:14:37.159224 20391 solver.cpp:243] Iteration 17091, loss = 0.710407
I0704 12:14:37.159250 20391 solver.cpp:259]     Train net output #0: loss = 0.710407 (* 1 = 0.710407 loss)
I0704 12:14:37.159256 20391 solver.cpp:590] Iteration 17091, lr = 0.000189439
I0704 12:14:44.856940 20391 solver.cpp:243] Iteration 17118, loss = 0.557381
I0704 12:14:44.856966 20391 solver.cpp:259]     Train net output #0: loss = 0.557381 (* 1 = 0.557381 loss)
I0704 12:14:44.856971 20391 solver.cpp:590] Iteration 17118, lr = 0.000188256
I0704 12:14:52.539000 20391 solver.cpp:243] Iteration 17145, loss = 0.839474
I0704 12:14:52.539115 20391 solver.cpp:259]     Train net output #0: loss = 0.839474 (* 1 = 0.839474 loss)
I0704 12:14:52.539121 20391 solver.cpp:590] Iteration 17145, lr = 0.00018708
I0704 12:15:00.261435 20391 solver.cpp:243] Iteration 17172, loss = 1.02096
I0704 12:15:00.261459 20391 solver.cpp:259]     Train net output #0: loss = 1.02096 (* 1 = 1.02096 loss)
I0704 12:15:00.261466 20391 solver.cpp:590] Iteration 17172, lr = 0.000185912
I0704 12:15:08.014320 20391 solver.cpp:243] Iteration 17199, loss = 0.670475
I0704 12:15:08.014346 20391 solver.cpp:259]     Train net output #0: loss = 0.670475 (* 1 = 0.670475 loss)
I0704 12:15:08.014353 20391 solver.cpp:590] Iteration 17199, lr = 0.00018475
I0704 12:15:15.677561 20391 solver.cpp:243] Iteration 17226, loss = 0.526337
I0704 12:15:15.677587 20391 solver.cpp:259]     Train net output #0: loss = 0.526337 (* 1 = 0.526337 loss)
I0704 12:15:15.677592 20391 solver.cpp:590] Iteration 17226, lr = 0.000183596
I0704 12:15:18.806077 20391 solver.cpp:347] Iteration 17238, Testing net (#0)
I0704 12:15:21.362965 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 12:15:37.927559 20391 solver.cpp:415]     Test net output #0: accuracy = 0.416707
I0704 12:15:37.927655 20391 solver.cpp:415]     Test net output #1: loss = 2.78343 (* 1 = 2.78343 loss)
I0704 12:15:41.697654 20391 solver.cpp:243] Iteration 17253, loss = 0.821853
I0704 12:15:41.697675 20391 solver.cpp:259]     Train net output #0: loss = 0.821853 (* 1 = 0.821853 loss)
I0704 12:15:41.697681 20391 solver.cpp:590] Iteration 17253, lr = 0.00018245
I0704 12:15:49.381582 20391 solver.cpp:243] Iteration 17280, loss = 0.673869
I0704 12:15:49.381609 20391 solver.cpp:259]     Train net output #0: loss = 0.673869 (* 1 = 0.673869 loss)
I0704 12:15:49.381615 20391 solver.cpp:590] Iteration 17280, lr = 0.00018131
I0704 12:15:57.098462 20391 solver.cpp:243] Iteration 17307, loss = 0.670396
I0704 12:15:57.098489 20391 solver.cpp:259]     Train net output #0: loss = 0.670396 (* 1 = 0.670396 loss)
I0704 12:15:57.098495 20391 solver.cpp:590] Iteration 17307, lr = 0.000180178
I0704 12:16:04.825361 20391 solver.cpp:243] Iteration 17334, loss = 0.852319
I0704 12:16:04.825387 20391 solver.cpp:259]     Train net output #0: loss = 0.852319 (* 1 = 0.852319 loss)
I0704 12:16:04.825393 20391 solver.cpp:590] Iteration 17334, lr = 0.000179052
I0704 12:16:12.558990 20391 solver.cpp:243] Iteration 17361, loss = 0.712
I0704 12:16:12.559110 20391 solver.cpp:259]     Train net output #0: loss = 0.712 (* 1 = 0.712 loss)
I0704 12:16:12.559118 20391 solver.cpp:590] Iteration 17361, lr = 0.000177934
I0704 12:16:20.254575 20391 solver.cpp:243] Iteration 17388, loss = 0.739015
I0704 12:16:20.254600 20391 solver.cpp:259]     Train net output #0: loss = 0.739015 (* 1 = 0.739015 loss)
I0704 12:16:20.254606 20391 solver.cpp:590] Iteration 17388, lr = 0.000176822
I0704 12:16:27.978437 20391 solver.cpp:243] Iteration 17415, loss = 0.693163
I0704 12:16:27.978461 20391 solver.cpp:259]     Train net output #0: loss = 0.693163 (* 1 = 0.693163 loss)
I0704 12:16:27.978466 20391 solver.cpp:590] Iteration 17415, lr = 0.000175718
I0704 12:16:35.714227 20391 solver.cpp:243] Iteration 17442, loss = 0.800642
I0704 12:16:35.714253 20391 solver.cpp:259]     Train net output #0: loss = 0.800642 (* 1 = 0.800642 loss)
I0704 12:16:35.714259 20391 solver.cpp:590] Iteration 17442, lr = 0.00017462
I0704 12:16:40.300199 20391 solver.cpp:347] Iteration 17459, Testing net (#0)
I0704 12:16:59.501431 20391 solver.cpp:415]     Test net output #0: accuracy = 0.419351
I0704 12:16:59.501505 20391 solver.cpp:415]     Test net output #1: loss = 2.7861 (* 1 = 2.7861 loss)
I0704 12:17:01.861335 20391 solver.cpp:243] Iteration 17469, loss = 0.612468
I0704 12:17:01.861363 20391 solver.cpp:259]     Train net output #0: loss = 0.612468 (* 1 = 0.612468 loss)
I0704 12:17:01.861369 20391 solver.cpp:590] Iteration 17469, lr = 0.00017353
I0704 12:17:09.551437 20391 solver.cpp:243] Iteration 17496, loss = 0.572289
I0704 12:17:09.551463 20391 solver.cpp:259]     Train net output #0: loss = 0.572289 (* 1 = 0.572289 loss)
I0704 12:17:09.551470 20391 solver.cpp:590] Iteration 17496, lr = 0.000172446
I0704 12:17:17.237679 20391 solver.cpp:243] Iteration 17523, loss = 0.733951
I0704 12:17:17.237714 20391 solver.cpp:259]     Train net output #0: loss = 0.733951 (* 1 = 0.733951 loss)
I0704 12:17:17.237720 20391 solver.cpp:590] Iteration 17523, lr = 0.000171368
I0704 12:17:24.918614 20391 solver.cpp:243] Iteration 17550, loss = 0.724651
I0704 12:17:24.918637 20391 solver.cpp:259]     Train net output #0: loss = 0.724651 (* 1 = 0.724651 loss)
I0704 12:17:24.918643 20391 solver.cpp:590] Iteration 17550, lr = 0.000170298
I0704 12:17:32.633419 20391 solver.cpp:243] Iteration 17577, loss = 0.498457
I0704 12:17:32.633568 20391 solver.cpp:259]     Train net output #0: loss = 0.498457 (* 1 = 0.498457 loss)
I0704 12:17:32.633574 20391 solver.cpp:590] Iteration 17577, lr = 0.000169234
I0704 12:17:40.327996 20391 solver.cpp:243] Iteration 17604, loss = 0.808479
I0704 12:17:40.328022 20391 solver.cpp:259]     Train net output #0: loss = 0.808479 (* 1 = 0.808479 loss)
I0704 12:17:40.328027 20391 solver.cpp:590] Iteration 17604, lr = 0.000168177
I0704 12:17:48.028893 20391 solver.cpp:243] Iteration 17631, loss = 0.699512
I0704 12:17:48.028920 20391 solver.cpp:259]     Train net output #0: loss = 0.699512 (* 1 = 0.699512 loss)
I0704 12:17:48.028925 20391 solver.cpp:590] Iteration 17631, lr = 0.000167127
I0704 12:17:55.734086 20391 solver.cpp:243] Iteration 17658, loss = 0.74095
I0704 12:17:55.734113 20391 solver.cpp:259]     Train net output #0: loss = 0.74095 (* 1 = 0.74095 loss)
I0704 12:17:55.734119 20391 solver.cpp:590] Iteration 17658, lr = 0.000166083
I0704 12:18:01.744285 20391 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_17680.caffemodel
I0704 12:18:22.987900 20391 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_17680.solverstate
I0704 12:18:24.009177 20391 solver.cpp:347] Iteration 17680, Testing net (#0)
I0704 12:18:30.381319 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 12:18:43.189324 20391 solver.cpp:415]     Test net output #0: accuracy = 0.417188
I0704 12:18:43.189350 20391 solver.cpp:415]     Test net output #1: loss = 2.78693 (* 1 = 2.78693 loss)
I0704 12:18:44.108691 20391 solver.cpp:243] Iteration 17685, loss = 0.716855
I0704 12:18:44.108719 20391 solver.cpp:259]     Train net output #0: loss = 0.716855 (* 1 = 0.716855 loss)
I0704 12:18:44.108726 20391 solver.cpp:590] Iteration 17685, lr = 0.000165045
I0704 12:18:51.827000 20391 solver.cpp:243] Iteration 17712, loss = 0.736935
I0704 12:18:51.827028 20391 solver.cpp:259]     Train net output #0: loss = 0.736935 (* 1 = 0.736935 loss)
I0704 12:18:51.827033 20391 solver.cpp:590] Iteration 17712, lr = 0.000164015
I0704 12:18:59.518832 20391 solver.cpp:243] Iteration 17739, loss = 0.887341
I0704 12:18:59.518952 20391 solver.cpp:259]     Train net output #0: loss = 0.887341 (* 1 = 0.887341 loss)
I0704 12:18:59.518959 20391 solver.cpp:590] Iteration 17739, lr = 0.00016299
I0704 12:19:07.196668 20391 solver.cpp:243] Iteration 17766, loss = 0.711547
I0704 12:19:07.196696 20391 solver.cpp:259]     Train net output #0: loss = 0.711547 (* 1 = 0.711547 loss)
I0704 12:19:07.196702 20391 solver.cpp:590] Iteration 17766, lr = 0.000161972
I0704 12:19:14.905587 20391 solver.cpp:243] Iteration 17793, loss = 0.699148
I0704 12:19:14.905613 20391 solver.cpp:259]     Train net output #0: loss = 0.699148 (* 1 = 0.699148 loss)
I0704 12:19:14.905619 20391 solver.cpp:590] Iteration 17793, lr = 0.00016096
I0704 12:19:22.597635 20391 solver.cpp:243] Iteration 17820, loss = 0.830567
I0704 12:19:22.597661 20391 solver.cpp:259]     Train net output #0: loss = 0.830567 (* 1 = 0.830567 loss)
I0704 12:19:22.597668 20391 solver.cpp:590] Iteration 17820, lr = 0.000159955
I0704 12:19:30.263296 20391 solver.cpp:243] Iteration 17847, loss = 0.703865
I0704 12:19:30.263406 20391 solver.cpp:259]     Train net output #0: loss = 0.703865 (* 1 = 0.703865 loss)
I0704 12:19:30.263413 20391 solver.cpp:590] Iteration 17847, lr = 0.000158956
I0704 12:19:37.914125 20391 solver.cpp:243] Iteration 17874, loss = 0.825803
I0704 12:19:37.914150 20391 solver.cpp:259]     Train net output #0: loss = 0.825803 (* 1 = 0.825803 loss)
I0704 12:19:37.914156 20391 solver.cpp:590] Iteration 17874, lr = 0.000157963
I0704 12:19:45.305359 20391 solver.cpp:347] Iteration 17901, Testing net (#0)
I0704 12:20:04.433902 20391 solver.cpp:415]     Test net output #0: accuracy = 0.41863
I0704 12:20:04.434020 20391 solver.cpp:415]     Test net output #1: loss = 2.7839 (* 1 = 2.7839 loss)
I0704 12:20:04.490965 20391 solver.cpp:243] Iteration 17901, loss = 0.827776
I0704 12:20:04.490990 20391 solver.cpp:259]     Train net output #0: loss = 0.827776 (* 1 = 0.827776 loss)
I0704 12:20:04.490996 20391 solver.cpp:590] Iteration 17901, lr = 0.000156976
I0704 12:20:11.612749 20391 solver.cpp:243] Iteration 17928, loss = 0.611257
I0704 12:20:11.612776 20391 solver.cpp:259]     Train net output #0: loss = 0.611257 (* 1 = 0.611257 loss)
I0704 12:20:11.612782 20391 solver.cpp:590] Iteration 17928, lr = 0.000155996
I0704 12:20:19.311637 20391 solver.cpp:243] Iteration 17955, loss = 0.680477
I0704 12:20:19.311661 20391 solver.cpp:259]     Train net output #0: loss = 0.680477 (* 1 = 0.680477 loss)
I0704 12:20:19.311667 20391 solver.cpp:590] Iteration 17955, lr = 0.000155021
I0704 12:20:26.987754 20391 solver.cpp:243] Iteration 17982, loss = 0.703753
I0704 12:20:26.987779 20391 solver.cpp:259]     Train net output #0: loss = 0.703753 (* 1 = 0.703753 loss)
I0704 12:20:26.987785 20391 solver.cpp:590] Iteration 17982, lr = 0.000154053
I0704 12:20:34.686430 20391 solver.cpp:243] Iteration 18009, loss = 0.869972
I0704 12:20:34.686553 20391 solver.cpp:259]     Train net output #0: loss = 0.869972 (* 1 = 0.869972 loss)
I0704 12:20:34.686560 20391 solver.cpp:590] Iteration 18009, lr = 0.000153091
I0704 12:20:42.363646 20391 solver.cpp:243] Iteration 18036, loss = 0.928878
I0704 12:20:42.363670 20391 solver.cpp:259]     Train net output #0: loss = 0.928878 (* 1 = 0.928878 loss)
I0704 12:20:42.363677 20391 solver.cpp:590] Iteration 18036, lr = 0.000152135
I0704 12:20:50.023701 20391 solver.cpp:243] Iteration 18063, loss = 0.793513
I0704 12:20:50.023726 20391 solver.cpp:259]     Train net output #0: loss = 0.793513 (* 1 = 0.793513 loss)
I0704 12:20:50.023732 20391 solver.cpp:590] Iteration 18063, lr = 0.000151184
I0704 12:20:57.704738 20391 solver.cpp:243] Iteration 18090, loss = 0.838742
I0704 12:20:57.704763 20391 solver.cpp:259]     Train net output #0: loss = 0.838742 (* 1 = 0.838742 loss)
I0704 12:20:57.704769 20391 solver.cpp:590] Iteration 18090, lr = 0.00015024
I0704 12:21:05.407443 20391 solver.cpp:243] Iteration 18117, loss = 0.752089
I0704 12:21:05.407529 20391 solver.cpp:259]     Train net output #0: loss = 0.752089 (* 1 = 0.752089 loss)
I0704 12:21:05.407536 20391 solver.cpp:590] Iteration 18117, lr = 0.000149302
I0704 12:21:06.543524 20391 solver.cpp:347] Iteration 18122, Testing net (#0)
I0704 12:21:16.763649 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 12:21:25.655865 20391 solver.cpp:415]     Test net output #0: accuracy = 0.422356
I0704 12:21:25.655891 20391 solver.cpp:415]     Test net output #1: loss = 2.78515 (* 1 = 2.78515 loss)
I0704 12:21:31.430604 20391 solver.cpp:243] Iteration 18144, loss = 0.919403
I0704 12:21:31.430632 20391 solver.cpp:259]     Train net output #0: loss = 0.919403 (* 1 = 0.919403 loss)
I0704 12:21:31.430639 20391 solver.cpp:590] Iteration 18144, lr = 0.000148369
I0704 12:21:39.533923 20391 solver.cpp:243] Iteration 18171, loss = 0.72807
I0704 12:21:39.534004 20391 solver.cpp:259]     Train net output #0: loss = 0.72807 (* 1 = 0.72807 loss)
I0704 12:21:39.534010 20391 solver.cpp:590] Iteration 18171, lr = 0.000147442
I0704 12:21:47.220098 20391 solver.cpp:243] Iteration 18198, loss = 0.758022
I0704 12:21:47.220124 20391 solver.cpp:259]     Train net output #0: loss = 0.758022 (* 1 = 0.758022 loss)
I0704 12:21:47.220130 20391 solver.cpp:590] Iteration 18198, lr = 0.000146521
I0704 12:21:54.994706 20391 solver.cpp:243] Iteration 18225, loss = 0.664885
I0704 12:21:54.994731 20391 solver.cpp:259]     Train net output #0: loss = 0.664885 (* 1 = 0.664885 loss)
I0704 12:21:54.994737 20391 solver.cpp:590] Iteration 18225, lr = 0.000145606
I0704 12:22:02.675845 20391 solver.cpp:243] Iteration 18252, loss = 0.700568
I0704 12:22:02.675870 20391 solver.cpp:259]     Train net output #0: loss = 0.700568 (* 1 = 0.700568 loss)
I0704 12:22:02.675876 20391 solver.cpp:590] Iteration 18252, lr = 0.000144697
I0704 12:22:10.432723 20391 solver.cpp:243] Iteration 18279, loss = 0.606287
I0704 12:22:10.432864 20391 solver.cpp:259]     Train net output #0: loss = 0.606287 (* 1 = 0.606287 loss)
I0704 12:22:10.432873 20391 solver.cpp:590] Iteration 18279, lr = 0.000143793
I0704 12:22:18.180495 20391 solver.cpp:243] Iteration 18306, loss = 0.685693
I0704 12:22:18.180519 20391 solver.cpp:259]     Train net output #0: loss = 0.685693 (* 1 = 0.685693 loss)
I0704 12:22:18.180526 20391 solver.cpp:590] Iteration 18306, lr = 0.000142895
I0704 12:22:25.852603 20391 solver.cpp:243] Iteration 18333, loss = 0.834563
I0704 12:22:25.852630 20391 solver.cpp:259]     Train net output #0: loss = 0.834563 (* 1 = 0.834563 loss)
I0704 12:22:25.852637 20391 solver.cpp:590] Iteration 18333, lr = 0.000142002
I0704 12:22:28.429345 20391 solver.cpp:347] Iteration 18343, Testing net (#0)
I0704 12:22:47.581028 20391 solver.cpp:415]     Test net output #0: accuracy = 0.421394
I0704 12:22:47.581145 20391 solver.cpp:415]     Test net output #1: loss = 2.78457 (* 1 = 2.78457 loss)
I0704 12:22:51.916124 20391 solver.cpp:243] Iteration 18360, loss = 0.73913
I0704 12:22:51.916149 20391 solver.cpp:259]     Train net output #0: loss = 0.73913 (* 1 = 0.73913 loss)
I0704 12:22:51.916154 20391 solver.cpp:590] Iteration 18360, lr = 0.000141115
I0704 12:22:59.632589 20391 solver.cpp:243] Iteration 18387, loss = 0.750514
I0704 12:22:59.632616 20391 solver.cpp:259]     Train net output #0: loss = 0.750514 (* 1 = 0.750514 loss)
I0704 12:22:59.632622 20391 solver.cpp:590] Iteration 18387, lr = 0.000140234
I0704 12:23:07.293906 20391 solver.cpp:243] Iteration 18414, loss = 0.549778
I0704 12:23:07.293931 20391 solver.cpp:259]     Train net output #0: loss = 0.549778 (* 1 = 0.549778 loss)
I0704 12:23:07.293937 20391 solver.cpp:590] Iteration 18414, lr = 0.000139358
I0704 12:23:14.985332 20391 solver.cpp:243] Iteration 18441, loss = 0.667063
I0704 12:23:14.985355 20391 solver.cpp:259]     Train net output #0: loss = 0.667063 (* 1 = 0.667063 loss)
I0704 12:23:14.985361 20391 solver.cpp:590] Iteration 18441, lr = 0.000138487
I0704 12:23:22.666654 20391 solver.cpp:243] Iteration 18468, loss = 0.721849
I0704 12:23:22.666728 20391 solver.cpp:259]     Train net output #0: loss = 0.721849 (* 1 = 0.721849 loss)
I0704 12:23:22.666744 20391 solver.cpp:590] Iteration 18468, lr = 0.000137622
I0704 12:23:30.356762 20391 solver.cpp:243] Iteration 18495, loss = 0.568562
I0704 12:23:30.356788 20391 solver.cpp:259]     Train net output #0: loss = 0.568562 (* 1 = 0.568562 loss)
I0704 12:23:30.356793 20391 solver.cpp:590] Iteration 18495, lr = 0.000136763
I0704 12:23:37.993821 20391 solver.cpp:243] Iteration 18522, loss = 0.712913
I0704 12:23:37.993847 20391 solver.cpp:259]     Train net output #0: loss = 0.712913 (* 1 = 0.712913 loss)
I0704 12:23:37.993854 20391 solver.cpp:590] Iteration 18522, lr = 0.000135908
I0704 12:23:45.666880 20391 solver.cpp:243] Iteration 18549, loss = 0.675348
I0704 12:23:45.666909 20391 solver.cpp:259]     Train net output #0: loss = 0.675348 (* 1 = 0.675348 loss)
I0704 12:23:45.666915 20391 solver.cpp:590] Iteration 18549, lr = 0.000135059
I0704 12:23:49.647352 20391 solver.cpp:347] Iteration 18564, Testing net (#0)
I0704 12:24:03.718699 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 12:24:08.761986 20391 solver.cpp:415]     Test net output #0: accuracy = 0.420312
I0704 12:24:08.762011 20391 solver.cpp:415]     Test net output #1: loss = 2.78391 (* 1 = 2.78391 loss)
I0704 12:24:11.683089 20391 solver.cpp:243] Iteration 18576, loss = 0.921115
I0704 12:24:11.683115 20391 solver.cpp:259]     Train net output #0: loss = 0.921115 (* 1 = 0.921115 loss)
I0704 12:24:11.683120 20391 solver.cpp:590] Iteration 18576, lr = 0.000134216
I0704 12:24:19.360560 20391 solver.cpp:243] Iteration 18603, loss = 0.801364
I0704 12:24:19.360584 20391 solver.cpp:259]     Train net output #0: loss = 0.801364 (* 1 = 0.801364 loss)
I0704 12:24:19.360590 20391 solver.cpp:590] Iteration 18603, lr = 0.000133377
I0704 12:24:27.032833 20391 solver.cpp:243] Iteration 18630, loss = 0.666307
I0704 12:24:27.032860 20391 solver.cpp:259]     Train net output #0: loss = 0.666307 (* 1 = 0.666307 loss)
I0704 12:24:27.032866 20391 solver.cpp:590] Iteration 18630, lr = 0.000132544
I0704 12:24:34.712476 20391 solver.cpp:243] Iteration 18657, loss = 0.729432
I0704 12:24:34.712574 20391 solver.cpp:259]     Train net output #0: loss = 0.729432 (* 1 = 0.729432 loss)
I0704 12:24:34.712589 20391 solver.cpp:590] Iteration 18657, lr = 0.000131716
I0704 12:24:42.820055 20391 solver.cpp:243] Iteration 18684, loss = 0.9359
I0704 12:24:42.820080 20391 solver.cpp:259]     Train net output #0: loss = 0.9359 (* 1 = 0.9359 loss)
I0704 12:24:42.820086 20391 solver.cpp:590] Iteration 18684, lr = 0.000130894
I0704 12:24:50.486018 20391 solver.cpp:243] Iteration 18711, loss = 0.600712
I0704 12:24:50.486042 20391 solver.cpp:259]     Train net output #0: loss = 0.600712 (* 1 = 0.600712 loss)
I0704 12:24:50.486048 20391 solver.cpp:590] Iteration 18711, lr = 0.000130076
I0704 12:24:58.149214 20391 solver.cpp:243] Iteration 18738, loss = 0.720696
I0704 12:24:58.149237 20391 solver.cpp:259]     Train net output #0: loss = 0.720696 (* 1 = 0.720696 loss)
I0704 12:24:58.149243 20391 solver.cpp:590] Iteration 18738, lr = 0.000129264
I0704 12:25:05.821818 20391 solver.cpp:243] Iteration 18765, loss = 0.796499
I0704 12:25:05.821944 20391 solver.cpp:259]     Train net output #0: loss = 0.796499 (* 1 = 0.796499 loss)
I0704 12:25:05.821951 20391 solver.cpp:590] Iteration 18765, lr = 0.000128456
I0704 12:25:11.289538 20391 solver.cpp:347] Iteration 18785, Testing net (#0)
I0704 12:25:30.426025 20391 solver.cpp:415]     Test net output #0: accuracy = 0.420312
I0704 12:25:30.426046 20391 solver.cpp:415]     Test net output #1: loss = 2.78144 (* 1 = 2.78144 loss)
I0704 12:25:31.930402 20391 solver.cpp:243] Iteration 18792, loss = 0.646948
I0704 12:25:31.930428 20391 solver.cpp:259]     Train net output #0: loss = 0.646948 (* 1 = 0.646948 loss)
I0704 12:25:31.930433 20391 solver.cpp:590] Iteration 18792, lr = 0.000127654
I0704 12:25:39.651684 20391 solver.cpp:243] Iteration 18819, loss = 0.660024
I0704 12:25:39.651805 20391 solver.cpp:259]     Train net output #0: loss = 0.660024 (* 1 = 0.660024 loss)
I0704 12:25:39.651813 20391 solver.cpp:590] Iteration 18819, lr = 0.000126856
I0704 12:25:47.359452 20391 solver.cpp:243] Iteration 18846, loss = 0.741853
I0704 12:25:47.359489 20391 solver.cpp:259]     Train net output #0: loss = 0.741853 (* 1 = 0.741853 loss)
I0704 12:25:47.359495 20391 solver.cpp:590] Iteration 18846, lr = 0.000126064
I0704 12:25:55.076674 20391 solver.cpp:243] Iteration 18873, loss = 0.681446
I0704 12:25:55.076700 20391 solver.cpp:259]     Train net output #0: loss = 0.681446 (* 1 = 0.681446 loss)
I0704 12:25:55.076706 20391 solver.cpp:590] Iteration 18873, lr = 0.000125277
I0704 12:26:02.798369 20391 solver.cpp:243] Iteration 18900, loss = 0.672693
I0704 12:26:02.798396 20391 solver.cpp:259]     Train net output #0: loss = 0.672693 (* 1 = 0.672693 loss)
I0704 12:26:02.798403 20391 solver.cpp:590] Iteration 18900, lr = 0.000124494
I0704 12:26:10.456002 20391 solver.cpp:243] Iteration 18927, loss = 0.51619
I0704 12:26:10.456068 20391 solver.cpp:259]     Train net output #0: loss = 0.51619 (* 1 = 0.51619 loss)
I0704 12:26:10.456085 20391 solver.cpp:590] Iteration 18927, lr = 0.000123717
I0704 12:26:18.798997 20391 solver.cpp:243] Iteration 18954, loss = 0.718672
I0704 12:26:18.799024 20391 solver.cpp:259]     Train net output #0: loss = 0.718672 (* 1 = 0.718672 loss)
I0704 12:26:18.799031 20391 solver.cpp:590] Iteration 18954, lr = 0.000122944
I0704 12:26:26.489073 20391 solver.cpp:243] Iteration 18981, loss = 0.785586
I0704 12:26:26.489099 20391 solver.cpp:259]     Train net output #0: loss = 0.785586 (* 1 = 0.785586 loss)
I0704 12:26:26.489106 20391 solver.cpp:590] Iteration 18981, lr = 0.000122176
I0704 12:26:33.369069 20391 solver.cpp:347] Iteration 19006, Testing net (#0)
I0704 12:26:51.913158 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 12:26:53.095237 20391 solver.cpp:415]     Test net output #0: accuracy = 0.420433
I0704 12:26:53.095263 20391 solver.cpp:415]     Test net output #1: loss = 2.7869 (* 1 = 2.7869 loss)
I0704 12:26:53.324730 20391 solver.cpp:243] Iteration 19008, loss = 0.662646
I0704 12:26:53.324753 20391 solver.cpp:259]     Train net output #0: loss = 0.662646 (* 1 = 0.662646 loss)
I0704 12:26:53.324759 20391 solver.cpp:590] Iteration 19008, lr = 0.000121413
I0704 12:27:00.841755 20391 solver.cpp:243] Iteration 19035, loss = 0.665738
I0704 12:27:00.841792 20391 solver.cpp:259]     Train net output #0: loss = 0.665738 (* 1 = 0.665738 loss)
I0704 12:27:00.841799 20391 solver.cpp:590] Iteration 19035, lr = 0.000120654
I0704 12:27:08.550664 20391 solver.cpp:243] Iteration 19062, loss = 0.469839
I0704 12:27:08.550690 20391 solver.cpp:259]     Train net output #0: loss = 0.469839 (* 1 = 0.469839 loss)
I0704 12:27:08.550696 20391 solver.cpp:590] Iteration 19062, lr = 0.000119901
I0704 12:27:16.243322 20391 solver.cpp:243] Iteration 19089, loss = 0.74167
I0704 12:27:16.243348 20391 solver.cpp:259]     Train net output #0: loss = 0.74167 (* 1 = 0.74167 loss)
I0704 12:27:16.243355 20391 solver.cpp:590] Iteration 19089, lr = 0.000119152
I0704 12:27:23.942895 20391 solver.cpp:243] Iteration 19116, loss = 0.780974
I0704 12:27:23.943037 20391 solver.cpp:259]     Train net output #0: loss = 0.780974 (* 1 = 0.780974 loss)
I0704 12:27:23.943044 20391 solver.cpp:590] Iteration 19116, lr = 0.000118408
I0704 12:27:31.610510 20391 solver.cpp:243] Iteration 19143, loss = 0.636517
I0704 12:27:31.610538 20391 solver.cpp:259]     Train net output #0: loss = 0.636517 (* 1 = 0.636517 loss)
I0704 12:27:31.610544 20391 solver.cpp:590] Iteration 19143, lr = 0.000117668
I0704 12:27:39.397023 20391 solver.cpp:243] Iteration 19170, loss = 0.669029
I0704 12:27:39.397048 20391 solver.cpp:259]     Train net output #0: loss = 0.669029 (* 1 = 0.669029 loss)
I0704 12:27:39.397053 20391 solver.cpp:590] Iteration 19170, lr = 0.000116933
I0704 12:27:47.056975 20391 solver.cpp:243] Iteration 19197, loss = 0.561387
I0704 12:27:47.056999 20391 solver.cpp:259]     Train net output #0: loss = 0.561387 (* 1 = 0.561387 loss)
I0704 12:27:47.057006 20391 solver.cpp:590] Iteration 19197, lr = 0.000116203
I0704 12:27:54.763706 20391 solver.cpp:243] Iteration 19224, loss = 0.868154
I0704 12:27:54.763830 20391 solver.cpp:259]     Train net output #0: loss = 0.868154 (* 1 = 0.868154 loss)
I0704 12:27:54.763839 20391 solver.cpp:590] Iteration 19224, lr = 0.000115477
I0704 12:27:55.330911 20391 solver.cpp:347] Iteration 19227, Testing net (#0)
I0704 12:28:14.468746 20391 solver.cpp:415]     Test net output #0: accuracy = 0.420433
I0704 12:28:14.468770 20391 solver.cpp:415]     Test net output #1: loss = 2.78757 (* 1 = 2.78757 loss)
I0704 12:28:20.791242 20391 solver.cpp:243] Iteration 19251, loss = 0.769842
I0704 12:28:20.791270 20391 solver.cpp:259]     Train net output #0: loss = 0.769842 (* 1 = 0.769842 loss)
I0704 12:28:20.791275 20391 solver.cpp:590] Iteration 19251, lr = 0.000114755
I0704 12:28:28.514895 20391 solver.cpp:243] Iteration 19278, loss = 0.775786
I0704 12:28:28.515051 20391 solver.cpp:259]     Train net output #0: loss = 0.775786 (* 1 = 0.775786 loss)
I0704 12:28:28.515059 20391 solver.cpp:590] Iteration 19278, lr = 0.000114039
I0704 12:28:36.180429 20391 solver.cpp:243] Iteration 19305, loss = 0.764878
I0704 12:28:36.180454 20391 solver.cpp:259]     Train net output #0: loss = 0.764878 (* 1 = 0.764878 loss)
I0704 12:28:36.180460 20391 solver.cpp:590] Iteration 19305, lr = 0.000113326
I0704 12:28:43.873236 20391 solver.cpp:243] Iteration 19332, loss = 0.637391
I0704 12:28:43.873262 20391 solver.cpp:259]     Train net output #0: loss = 0.637391 (* 1 = 0.637391 loss)
I0704 12:28:43.873268 20391 solver.cpp:590] Iteration 19332, lr = 0.000112618
I0704 12:28:51.540562 20391 solver.cpp:243] Iteration 19359, loss = 0.542916
I0704 12:28:51.540588 20391 solver.cpp:259]     Train net output #0: loss = 0.542916 (* 1 = 0.542916 loss)
I0704 12:28:51.540594 20391 solver.cpp:590] Iteration 19359, lr = 0.000111915
I0704 12:28:59.256765 20391 solver.cpp:243] Iteration 19386, loss = 0.485419
I0704 12:28:59.256880 20391 solver.cpp:259]     Train net output #0: loss = 0.485419 (* 1 = 0.485419 loss)
I0704 12:28:59.256887 20391 solver.cpp:590] Iteration 19386, lr = 0.000111216
I0704 12:29:06.933490 20391 solver.cpp:243] Iteration 19413, loss = 0.423934
I0704 12:29:06.933516 20391 solver.cpp:259]     Train net output #0: loss = 0.423934 (* 1 = 0.423934 loss)
I0704 12:29:06.933522 20391 solver.cpp:590] Iteration 19413, lr = 0.000110521
I0704 12:29:14.617044 20391 solver.cpp:243] Iteration 19440, loss = 0.723595
I0704 12:29:14.617070 20391 solver.cpp:259]     Train net output #0: loss = 0.723595 (* 1 = 0.723595 loss)
I0704 12:29:14.617076 20391 solver.cpp:590] Iteration 19440, lr = 0.000109831
I0704 12:29:16.617475 20391 solver.cpp:347] Iteration 19448, Testing net (#0)
I0704 12:29:35.729482 20391 solver.cpp:415]     Test net output #0: accuracy = 0.421514
I0704 12:29:35.729560 20391 solver.cpp:415]     Test net output #1: loss = 2.78685 (* 1 = 2.78685 loss)
I0704 12:29:40.649204 20391 solver.cpp:243] Iteration 19467, loss = 0.761264
I0704 12:29:40.649230 20391 solver.cpp:259]     Train net output #0: loss = 0.761264 (* 1 = 0.761264 loss)
I0704 12:29:40.649236 20391 solver.cpp:590] Iteration 19467, lr = 0.000109145
I0704 12:29:46.081437 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 12:29:48.381706 20391 solver.cpp:243] Iteration 19494, loss = 0.36652
I0704 12:29:48.381734 20391 solver.cpp:259]     Train net output #0: loss = 0.36652 (* 1 = 0.36652 loss)
I0704 12:29:48.381741 20391 solver.cpp:590] Iteration 19494, lr = 0.000108463
I0704 12:29:56.077700 20391 solver.cpp:243] Iteration 19521, loss = 0.848304
I0704 12:29:56.077726 20391 solver.cpp:259]     Train net output #0: loss = 0.848304 (* 1 = 0.848304 loss)
I0704 12:29:56.077733 20391 solver.cpp:590] Iteration 19521, lr = 0.000107786
I0704 12:30:03.780936 20391 solver.cpp:243] Iteration 19548, loss = 0.699363
I0704 12:30:03.780962 20391 solver.cpp:259]     Train net output #0: loss = 0.699363 (* 1 = 0.699363 loss)
I0704 12:30:03.780968 20391 solver.cpp:590] Iteration 19548, lr = 0.000107112
I0704 12:30:11.461427 20391 solver.cpp:243] Iteration 19575, loss = 0.817617
I0704 12:30:11.461485 20391 solver.cpp:259]     Train net output #0: loss = 0.817617 (* 1 = 0.817617 loss)
I0704 12:30:11.461491 20391 solver.cpp:590] Iteration 19575, lr = 0.000106443
I0704 12:30:19.106494 20391 solver.cpp:243] Iteration 19602, loss = 0.90391
I0704 12:30:19.106521 20391 solver.cpp:259]     Train net output #0: loss = 0.90391 (* 1 = 0.90391 loss)
I0704 12:30:19.106528 20391 solver.cpp:590] Iteration 19602, lr = 0.000105778
I0704 12:30:26.740865 20391 solver.cpp:243] Iteration 19629, loss = 0.65494
I0704 12:30:26.740892 20391 solver.cpp:259]     Train net output #0: loss = 0.65494 (* 1 = 0.65494 loss)
I0704 12:30:26.740898 20391 solver.cpp:590] Iteration 19629, lr = 0.000105118
I0704 12:30:34.402184 20391 solver.cpp:243] Iteration 19656, loss = 0.682707
I0704 12:30:34.402209 20391 solver.cpp:259]     Train net output #0: loss = 0.682707 (* 1 = 0.682707 loss)
I0704 12:30:34.402215 20391 solver.cpp:590] Iteration 19656, lr = 0.000104461
I0704 12:30:37.802315 20391 solver.cpp:347] Iteration 19669, Testing net (#0)
I0704 12:30:56.911710 20391 solver.cpp:415]     Test net output #0: accuracy = 0.421875
I0704 12:30:56.911799 20391 solver.cpp:415]     Test net output #1: loss = 2.79262 (* 1 = 2.79262 loss)
I0704 12:31:00.397866 20391 solver.cpp:243] Iteration 19683, loss = 0.497109
I0704 12:31:00.397891 20391 solver.cpp:259]     Train net output #0: loss = 0.497109 (* 1 = 0.497109 loss)
I0704 12:31:00.397897 20391 solver.cpp:590] Iteration 19683, lr = 0.000103809
I0704 12:31:08.094301 20391 solver.cpp:243] Iteration 19710, loss = 0.533552
I0704 12:31:08.094326 20391 solver.cpp:259]     Train net output #0: loss = 0.533552 (* 1 = 0.533552 loss)
I0704 12:31:08.094332 20391 solver.cpp:590] Iteration 19710, lr = 0.00010316
I0704 12:31:15.757053 20391 solver.cpp:243] Iteration 19737, loss = 0.592989
I0704 12:31:15.757079 20391 solver.cpp:259]     Train net output #0: loss = 0.592989 (* 1 = 0.592989 loss)
I0704 12:31:15.757086 20391 solver.cpp:590] Iteration 19737, lr = 0.000102516
I0704 12:31:23.467082 20391 solver.cpp:243] Iteration 19764, loss = 0.735856
I0704 12:31:23.467109 20391 solver.cpp:259]     Train net output #0: loss = 0.735856 (* 1 = 0.735856 loss)
I0704 12:31:23.467115 20391 solver.cpp:590] Iteration 19764, lr = 0.000101876
I0704 12:31:31.174288 20391 solver.cpp:243] Iteration 19791, loss = 0.676422
I0704 12:31:31.174371 20391 solver.cpp:259]     Train net output #0: loss = 0.676422 (* 1 = 0.676422 loss)
I0704 12:31:31.174378 20391 solver.cpp:590] Iteration 19791, lr = 0.000101239
I0704 12:31:38.872490 20391 solver.cpp:243] Iteration 19818, loss = 0.683525
I0704 12:31:38.872515 20391 solver.cpp:259]     Train net output #0: loss = 0.683525 (* 1 = 0.683525 loss)
I0704 12:31:38.872521 20391 solver.cpp:590] Iteration 19818, lr = 0.000100607
I0704 12:31:46.523579 20391 solver.cpp:243] Iteration 19845, loss = 0.718295
I0704 12:31:46.523615 20391 solver.cpp:259]     Train net output #0: loss = 0.718295 (* 1 = 0.718295 loss)
I0704 12:31:46.523622 20391 solver.cpp:590] Iteration 19845, lr = 9.99785e-05
I0704 12:31:54.194239 20391 solver.cpp:243] Iteration 19872, loss = 0.742673
I0704 12:31:54.194267 20391 solver.cpp:259]     Train net output #0: loss = 0.742673 (* 1 = 0.742673 loss)
I0704 12:31:54.194272 20391 solver.cpp:590] Iteration 19872, lr = 9.9354e-05
I0704 12:31:59.016824 20391 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_19890.caffemodel
I0704 12:32:06.795065 20391 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_19890.solverstate
I0704 12:32:07.837828 20391 solver.cpp:347] Iteration 19890, Testing net (#0)
I0704 12:32:26.903403 20391 solver.cpp:415]     Test net output #0: accuracy = 0.421034
I0704 12:32:26.903427 20391 solver.cpp:415]     Test net output #1: loss = 2.78608 (* 1 = 2.78608 loss)
I0704 12:32:28.959148 20391 solver.cpp:243] Iteration 19899, loss = 0.760895
I0704 12:32:28.959175 20391 solver.cpp:259]     Train net output #0: loss = 0.760895 (* 1 = 0.760895 loss)
I0704 12:32:28.959182 20391 solver.cpp:590] Iteration 19899, lr = 9.87334e-05
I0704 12:32:36.641772 20391 solver.cpp:243] Iteration 19926, loss = 0.711571
I0704 12:32:36.641796 20391 solver.cpp:259]     Train net output #0: loss = 0.711571 (* 1 = 0.711571 loss)
I0704 12:32:36.641803 20391 solver.cpp:590] Iteration 19926, lr = 9.81167e-05
I0704 12:32:44.301328 20391 solver.cpp:243] Iteration 19953, loss = 0.648691
I0704 12:32:44.301388 20391 solver.cpp:259]     Train net output #0: loss = 0.648691 (* 1 = 0.648691 loss)
I0704 12:32:44.301394 20391 solver.cpp:590] Iteration 19953, lr = 9.75038e-05
I0704 12:32:51.983263 20391 solver.cpp:243] Iteration 19980, loss = 0.635703
I0704 12:32:51.983291 20391 solver.cpp:259]     Train net output #0: loss = 0.635703 (* 1 = 0.635703 loss)
I0704 12:32:51.983296 20391 solver.cpp:590] Iteration 19980, lr = 9.68948e-05
I0704 12:32:51.983510 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 12:32:59.660552 20391 solver.cpp:243] Iteration 20007, loss = 0.508941
I0704 12:32:59.660578 20391 solver.cpp:259]     Train net output #0: loss = 0.508941 (* 1 = 0.508941 loss)
I0704 12:32:59.660583 20391 solver.cpp:590] Iteration 20007, lr = 9.62895e-05
I0704 12:33:07.319164 20391 solver.cpp:243] Iteration 20034, loss = 0.532672
I0704 12:33:07.319190 20391 solver.cpp:259]     Train net output #0: loss = 0.532672 (* 1 = 0.532672 loss)
I0704 12:33:07.319197 20391 solver.cpp:590] Iteration 20034, lr = 9.56881e-05
I0704 12:33:14.953559 20391 solver.cpp:243] Iteration 20061, loss = 0.476111
I0704 12:33:14.953615 20391 solver.cpp:259]     Train net output #0: loss = 0.476111 (* 1 = 0.476111 loss)
I0704 12:33:14.953622 20391 solver.cpp:590] Iteration 20061, lr = 9.50904e-05
I0704 12:33:22.610265 20391 solver.cpp:243] Iteration 20088, loss = 0.720322
I0704 12:33:22.610291 20391 solver.cpp:259]     Train net output #0: loss = 0.720322 (* 1 = 0.720322 loss)
I0704 12:33:22.610297 20391 solver.cpp:590] Iteration 20088, lr = 9.44964e-05
I0704 12:33:28.855450 20391 solver.cpp:347] Iteration 20111, Testing net (#0)
I0704 12:33:47.957144 20391 solver.cpp:415]     Test net output #0: accuracy = 0.419471
I0704 12:33:47.957242 20391 solver.cpp:415]     Test net output #1: loss = 2.78782 (* 1 = 2.78782 loss)
I0704 12:33:48.596002 20391 solver.cpp:243] Iteration 20115, loss = 0.625087
I0704 12:33:48.596027 20391 solver.cpp:259]     Train net output #0: loss = 0.625087 (* 1 = 0.625087 loss)
I0704 12:33:48.596034 20391 solver.cpp:590] Iteration 20115, lr = 9.39062e-05
I0704 12:33:56.355701 20391 solver.cpp:243] Iteration 20142, loss = 0.945689
I0704 12:33:56.355727 20391 solver.cpp:259]     Train net output #0: loss = 0.945689 (* 1 = 0.945689 loss)
I0704 12:33:56.355733 20391 solver.cpp:590] Iteration 20142, lr = 9.33196e-05
I0704 12:34:04.050416 20391 solver.cpp:243] Iteration 20169, loss = 0.671329
I0704 12:34:04.050443 20391 solver.cpp:259]     Train net output #0: loss = 0.671329 (* 1 = 0.671329 loss)
I0704 12:34:04.050449 20391 solver.cpp:590] Iteration 20169, lr = 9.27367e-05
I0704 12:34:11.734408 20391 solver.cpp:243] Iteration 20196, loss = 0.71716
I0704 12:34:11.734434 20391 solver.cpp:259]     Train net output #0: loss = 0.71716 (* 1 = 0.71716 loss)
I0704 12:34:11.734441 20391 solver.cpp:590] Iteration 20196, lr = 9.21575e-05
I0704 12:34:19.423799 20391 solver.cpp:243] Iteration 20223, loss = 0.6893
I0704 12:34:19.423852 20391 solver.cpp:259]     Train net output #0: loss = 0.6893 (* 1 = 0.6893 loss)
I0704 12:34:19.423858 20391 solver.cpp:590] Iteration 20223, lr = 9.15818e-05
I0704 12:34:27.072576 20391 solver.cpp:243] Iteration 20250, loss = 0.617323
I0704 12:34:27.072623 20391 solver.cpp:259]     Train net output #0: loss = 0.617323 (* 1 = 0.617323 loss)
I0704 12:34:27.072630 20391 solver.cpp:590] Iteration 20250, lr = 9.10098e-05
I0704 12:34:34.728806 20391 solver.cpp:243] Iteration 20277, loss = 0.568507
I0704 12:34:34.728845 20391 solver.cpp:259]     Train net output #0: loss = 0.568507 (* 1 = 0.568507 loss)
I0704 12:34:34.728852 20391 solver.cpp:590] Iteration 20277, lr = 9.04413e-05
I0704 12:34:42.384846 20391 solver.cpp:243] Iteration 20304, loss = 0.716717
I0704 12:34:42.384872 20391 solver.cpp:259]     Train net output #0: loss = 0.716717 (* 1 = 0.716717 loss)
I0704 12:34:42.384878 20391 solver.cpp:590] Iteration 20304, lr = 8.98764e-05
I0704 12:34:50.065377 20391 solver.cpp:243] Iteration 20331, loss = 0.670169
I0704 12:34:50.065433 20391 solver.cpp:259]     Train net output #0: loss = 0.670169 (* 1 = 0.670169 loss)
I0704 12:34:50.065438 20391 solver.cpp:590] Iteration 20331, lr = 8.9315e-05
I0704 12:34:50.065657 20391 solver.cpp:347] Iteration 20332, Testing net (#0)
I0704 12:35:09.156850 20391 solver.cpp:415]     Test net output #0: accuracy = 0.421274
I0704 12:35:09.156877 20391 solver.cpp:415]     Test net output #1: loss = 2.78621 (* 1 = 2.78621 loss)
I0704 12:35:16.046283 20391 solver.cpp:243] Iteration 20358, loss = 0.459634
I0704 12:35:16.046310 20391 solver.cpp:259]     Train net output #0: loss = 0.459634 (* 1 = 0.459634 loss)
I0704 12:35:16.046316 20391 solver.cpp:590] Iteration 20358, lr = 8.87571e-05
I0704 12:35:23.730473 20391 solver.cpp:243] Iteration 20385, loss = 0.668513
I0704 12:35:23.730566 20391 solver.cpp:259]     Train net output #0: loss = 0.668513 (* 1 = 0.668513 loss)
I0704 12:35:23.730574 20391 solver.cpp:590] Iteration 20385, lr = 8.82027e-05
I0704 12:35:31.408027 20391 solver.cpp:243] Iteration 20412, loss = 0.814987
I0704 12:35:31.408053 20391 solver.cpp:259]     Train net output #0: loss = 0.814987 (* 1 = 0.814987 loss)
I0704 12:35:31.408059 20391 solver.cpp:590] Iteration 20412, lr = 8.76518e-05
I0704 12:35:39.111807 20391 solver.cpp:243] Iteration 20439, loss = 0.688876
I0704 12:35:39.111835 20391 solver.cpp:259]     Train net output #0: loss = 0.688876 (* 1 = 0.688876 loss)
I0704 12:35:39.111840 20391 solver.cpp:590] Iteration 20439, lr = 8.71043e-05
I0704 12:35:46.774212 20391 solver.cpp:243] Iteration 20466, loss = 0.443827
I0704 12:35:46.774235 20391 solver.cpp:259]     Train net output #0: loss = 0.443827 (* 1 = 0.443827 loss)
I0704 12:35:46.774240 20391 solver.cpp:590] Iteration 20466, lr = 8.65602e-05
I0704 12:35:49.051194 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 12:35:54.432807 20391 solver.cpp:243] Iteration 20493, loss = 0.421029
I0704 12:35:54.432912 20391 solver.cpp:259]     Train net output #0: loss = 0.421029 (* 1 = 0.421029 loss)
I0704 12:35:54.432919 20391 solver.cpp:590] Iteration 20493, lr = 8.60196e-05
I0704 12:36:02.101523 20391 solver.cpp:243] Iteration 20520, loss = 0.800279
I0704 12:36:02.101550 20391 solver.cpp:259]     Train net output #0: loss = 0.800279 (* 1 = 0.800279 loss)
I0704 12:36:02.101557 20391 solver.cpp:590] Iteration 20520, lr = 8.54823e-05
I0704 12:36:09.806251 20391 solver.cpp:243] Iteration 20547, loss = 0.788403
I0704 12:36:09.806277 20391 solver.cpp:259]     Train net output #0: loss = 0.788403 (* 1 = 0.788403 loss)
I0704 12:36:09.806282 20391 solver.cpp:590] Iteration 20547, lr = 8.49483e-05
I0704 12:36:11.243381 20391 solver.cpp:347] Iteration 20553, Testing net (#0)
I0704 12:36:30.331656 20391 solver.cpp:415]     Test net output #0: accuracy = 0.422476
I0704 12:36:30.331751 20391 solver.cpp:415]     Test net output #1: loss = 2.78545 (* 1 = 2.78545 loss)
I0704 12:36:35.837553 20391 solver.cpp:243] Iteration 20574, loss = 0.644191
I0704 12:36:35.837581 20391 solver.cpp:259]     Train net output #0: loss = 0.644191 (* 1 = 0.644191 loss)
I0704 12:36:35.837587 20391 solver.cpp:590] Iteration 20574, lr = 8.44177e-05
I0704 12:36:43.519690 20391 solver.cpp:243] Iteration 20601, loss = 0.513016
I0704 12:36:43.519716 20391 solver.cpp:259]     Train net output #0: loss = 0.513016 (* 1 = 0.513016 loss)
I0704 12:36:43.519722 20391 solver.cpp:590] Iteration 20601, lr = 8.38904e-05
I0704 12:36:51.185961 20391 solver.cpp:243] Iteration 20628, loss = 0.746011
I0704 12:36:51.185986 20391 solver.cpp:259]     Train net output #0: loss = 0.746011 (* 1 = 0.746011 loss)
I0704 12:36:51.185992 20391 solver.cpp:590] Iteration 20628, lr = 8.33664e-05
I0704 12:36:58.877399 20391 solver.cpp:243] Iteration 20655, loss = 0.770855
I0704 12:36:58.877427 20391 solver.cpp:259]     Train net output #0: loss = 0.770855 (* 1 = 0.770855 loss)
I0704 12:36:58.877434 20391 solver.cpp:590] Iteration 20655, lr = 8.28457e-05
I0704 12:37:06.560861 20391 solver.cpp:243] Iteration 20682, loss = 0.724392
I0704 12:37:06.560955 20391 solver.cpp:259]     Train net output #0: loss = 0.724392 (* 1 = 0.724392 loss)
I0704 12:37:06.560962 20391 solver.cpp:590] Iteration 20682, lr = 8.23282e-05
I0704 12:37:14.222200 20391 solver.cpp:243] Iteration 20709, loss = 0.904889
I0704 12:37:14.222225 20391 solver.cpp:259]     Train net output #0: loss = 0.904889 (* 1 = 0.904889 loss)
I0704 12:37:14.222231 20391 solver.cpp:590] Iteration 20709, lr = 8.1814e-05
I0704 12:37:21.863082 20391 solver.cpp:243] Iteration 20736, loss = 0.694382
I0704 12:37:21.863107 20391 solver.cpp:259]     Train net output #0: loss = 0.694382 (* 1 = 0.694382 loss)
I0704 12:37:21.863113 20391 solver.cpp:590] Iteration 20736, lr = 8.13029e-05
I0704 12:37:29.543344 20391 solver.cpp:243] Iteration 20763, loss = 0.578738
I0704 12:37:29.543370 20391 solver.cpp:259]     Train net output #0: loss = 0.578738 (* 1 = 0.578738 loss)
I0704 12:37:29.543376 20391 solver.cpp:590] Iteration 20763, lr = 8.07951e-05
I0704 12:37:32.382987 20391 solver.cpp:347] Iteration 20774, Testing net (#0)
I0704 12:37:51.582638 20391 solver.cpp:415]     Test net output #0: accuracy = 0.423077
I0704 12:37:51.582756 20391 solver.cpp:415]     Test net output #1: loss = 2.79047 (* 1 = 2.79047 loss)
I0704 12:37:55.619621 20391 solver.cpp:243] Iteration 20790, loss = 0.582618
I0704 12:37:55.619650 20391 solver.cpp:259]     Train net output #0: loss = 0.582618 (* 1 = 0.582618 loss)
I0704 12:37:55.619657 20391 solver.cpp:590] Iteration 20790, lr = 8.02904e-05
I0704 12:38:03.291160 20391 solver.cpp:243] Iteration 20817, loss = 0.595747
I0704 12:38:03.291187 20391 solver.cpp:259]     Train net output #0: loss = 0.595747 (* 1 = 0.595747 loss)
I0704 12:38:03.291193 20391 solver.cpp:590] Iteration 20817, lr = 7.97889e-05
I0704 12:38:10.952695 20391 solver.cpp:243] Iteration 20844, loss = 0.496144
I0704 12:38:10.952719 20391 solver.cpp:259]     Train net output #0: loss = 0.496144 (* 1 = 0.496144 loss)
I0704 12:38:10.952725 20391 solver.cpp:590] Iteration 20844, lr = 7.92905e-05
I0704 12:38:18.651661 20391 solver.cpp:243] Iteration 20871, loss = 0.58199
I0704 12:38:18.651686 20391 solver.cpp:259]     Train net output #0: loss = 0.58199 (* 1 = 0.58199 loss)
I0704 12:38:18.651692 20391 solver.cpp:590] Iteration 20871, lr = 7.87953e-05
I0704 12:38:26.382853 20391 solver.cpp:243] Iteration 20898, loss = 0.713221
I0704 12:38:26.382927 20391 solver.cpp:259]     Train net output #0: loss = 0.713221 (* 1 = 0.713221 loss)
I0704 12:38:26.382935 20391 solver.cpp:590] Iteration 20898, lr = 7.83031e-05
I0704 12:38:34.054864 20391 solver.cpp:243] Iteration 20925, loss = 0.796589
I0704 12:38:34.054890 20391 solver.cpp:259]     Train net output #0: loss = 0.796589 (* 1 = 0.796589 loss)
I0704 12:38:34.054896 20391 solver.cpp:590] Iteration 20925, lr = 7.7814e-05
I0704 12:38:41.695063 20391 solver.cpp:243] Iteration 20952, loss = 0.574085
I0704 12:38:41.695087 20391 solver.cpp:259]     Train net output #0: loss = 0.574085 (* 1 = 0.574085 loss)
I0704 12:38:41.695093 20391 solver.cpp:590] Iteration 20952, lr = 7.7328e-05
I0704 12:38:46.256417 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 12:38:49.410857 20391 solver.cpp:243] Iteration 20979, loss = 1.01442
I0704 12:38:49.410883 20391 solver.cpp:259]     Train net output #0: loss = 1.01442 (* 1 = 1.01442 loss)
I0704 12:38:49.410890 20391 solver.cpp:590] Iteration 20979, lr = 7.6845e-05
I0704 12:38:53.660097 20391 solver.cpp:347] Iteration 20995, Testing net (#0)
I0704 12:39:12.774842 20391 solver.cpp:415]     Test net output #0: accuracy = 0.421514
I0704 12:39:12.774937 20391 solver.cpp:415]     Test net output #1: loss = 2.79095 (* 1 = 2.79095 loss)
I0704 12:39:15.393507 20391 solver.cpp:243] Iteration 21006, loss = 0.638378
I0704 12:39:15.393533 20391 solver.cpp:259]     Train net output #0: loss = 0.638378 (* 1 = 0.638378 loss)
I0704 12:39:15.393539 20391 solver.cpp:590] Iteration 21006, lr = 7.6365e-05
I0704 12:39:23.071202 20391 solver.cpp:243] Iteration 21033, loss = 0.501408
I0704 12:39:23.071226 20391 solver.cpp:259]     Train net output #0: loss = 0.501408 (* 1 = 0.501408 loss)
I0704 12:39:23.071233 20391 solver.cpp:590] Iteration 21033, lr = 7.5888e-05
I0704 12:39:30.729930 20391 solver.cpp:243] Iteration 21060, loss = 0.860391
I0704 12:39:30.729956 20391 solver.cpp:259]     Train net output #0: loss = 0.860391 (* 1 = 0.860391 loss)
I0704 12:39:30.729964 20391 solver.cpp:590] Iteration 21060, lr = 7.5414e-05
I0704 12:39:38.416086 20391 solver.cpp:243] Iteration 21087, loss = 0.616172
I0704 12:39:38.416113 20391 solver.cpp:259]     Train net output #0: loss = 0.616172 (* 1 = 0.616172 loss)
I0704 12:39:38.416121 20391 solver.cpp:590] Iteration 21087, lr = 7.49429e-05
I0704 12:39:46.082010 20391 solver.cpp:243] Iteration 21114, loss = 0.792565
I0704 12:39:46.082069 20391 solver.cpp:259]     Train net output #0: loss = 0.792565 (* 1 = 0.792565 loss)
I0704 12:39:46.082077 20391 solver.cpp:590] Iteration 21114, lr = 7.44748e-05
I0704 12:39:53.736661 20391 solver.cpp:243] Iteration 21141, loss = 0.548494
I0704 12:39:53.736686 20391 solver.cpp:259]     Train net output #0: loss = 0.548494 (* 1 = 0.548494 loss)
I0704 12:39:53.736692 20391 solver.cpp:590] Iteration 21141, lr = 7.40096e-05
I0704 12:40:01.363965 20391 solver.cpp:243] Iteration 21168, loss = 0.708086
I0704 12:40:01.364007 20391 solver.cpp:259]     Train net output #0: loss = 0.708086 (* 1 = 0.708086 loss)
I0704 12:40:01.364018 20391 solver.cpp:590] Iteration 21168, lr = 7.35473e-05
I0704 12:40:09.035521 20391 solver.cpp:243] Iteration 21195, loss = 0.514409
I0704 12:40:09.035547 20391 solver.cpp:259]     Train net output #0: loss = 0.514409 (* 1 = 0.514409 loss)
I0704 12:40:09.035552 20391 solver.cpp:590] Iteration 21195, lr = 7.30879e-05
I0704 12:40:14.732358 20391 solver.cpp:347] Iteration 21216, Testing net (#0)
I0704 12:40:34.151571 20391 solver.cpp:415]     Test net output #0: accuracy = 0.420913
I0704 12:40:34.151670 20391 solver.cpp:415]     Test net output #1: loss = 2.79066 (* 1 = 2.79066 loss)
I0704 12:40:35.347564 20391 solver.cpp:243] Iteration 21222, loss = 0.659016
I0704 12:40:35.347590 20391 solver.cpp:259]     Train net output #0: loss = 0.659016 (* 1 = 0.659016 loss)
I0704 12:40:35.347596 20391 solver.cpp:590] Iteration 21222, lr = 7.26314e-05
I0704 12:40:43.026382 20391 solver.cpp:243] Iteration 21249, loss = 0.638442
I0704 12:40:43.026409 20391 solver.cpp:259]     Train net output #0: loss = 0.638442 (* 1 = 0.638442 loss)
I0704 12:40:43.026417 20391 solver.cpp:590] Iteration 21249, lr = 7.21777e-05
I0704 12:40:50.679857 20391 solver.cpp:243] Iteration 21276, loss = 0.364037
I0704 12:40:50.679883 20391 solver.cpp:259]     Train net output #0: loss = 0.364037 (* 1 = 0.364037 loss)
I0704 12:40:50.679889 20391 solver.cpp:590] Iteration 21276, lr = 7.17269e-05
I0704 12:40:58.365578 20391 solver.cpp:243] Iteration 21303, loss = 0.763009
I0704 12:40:58.365603 20391 solver.cpp:259]     Train net output #0: loss = 0.763009 (* 1 = 0.763009 loss)
I0704 12:40:58.365609 20391 solver.cpp:590] Iteration 21303, lr = 7.12789e-05
I0704 12:41:06.044728 20391 solver.cpp:243] Iteration 21330, loss = 0.616936
I0704 12:41:06.044805 20391 solver.cpp:259]     Train net output #0: loss = 0.616936 (* 1 = 0.616936 loss)
I0704 12:41:06.044821 20391 solver.cpp:590] Iteration 21330, lr = 7.08336e-05
I0704 12:41:13.701002 20391 solver.cpp:243] Iteration 21357, loss = 0.743562
I0704 12:41:13.701027 20391 solver.cpp:259]     Train net output #0: loss = 0.743562 (* 1 = 0.743562 loss)
I0704 12:41:13.701033 20391 solver.cpp:590] Iteration 21357, lr = 7.03912e-05
I0704 12:41:21.363802 20391 solver.cpp:243] Iteration 21384, loss = 0.578368
I0704 12:41:21.363827 20391 solver.cpp:259]     Train net output #0: loss = 0.578368 (* 1 = 0.578368 loss)
I0704 12:41:21.363833 20391 solver.cpp:590] Iteration 21384, lr = 6.99515e-05
I0704 12:41:29.022701 20391 solver.cpp:243] Iteration 21411, loss = 0.62111
I0704 12:41:29.022727 20391 solver.cpp:259]     Train net output #0: loss = 0.62111 (* 1 = 0.62111 loss)
I0704 12:41:29.022733 20391 solver.cpp:590] Iteration 21411, lr = 6.95146e-05
I0704 12:41:36.124368 20391 solver.cpp:347] Iteration 21437, Testing net (#0)
I0704 12:41:38.200326 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 12:41:55.239042 20391 solver.cpp:415]     Test net output #0: accuracy = 0.421154
I0704 12:41:55.239068 20391 solver.cpp:415]     Test net output #1: loss = 2.7886 (* 1 = 2.7886 loss)
I0704 12:41:55.381817 20391 solver.cpp:243] Iteration 21438, loss = 0.790396
I0704 12:41:55.381842 20391 solver.cpp:259]     Train net output #0: loss = 0.790396 (* 1 = 0.790396 loss)
I0704 12:41:55.381849 20391 solver.cpp:590] Iteration 21438, lr = 6.90804e-05
I0704 12:42:02.690817 20391 solver.cpp:243] Iteration 21465, loss = 0.65628
I0704 12:42:02.690842 20391 solver.cpp:259]     Train net output #0: loss = 0.65628 (* 1 = 0.65628 loss)
I0704 12:42:02.690848 20391 solver.cpp:590] Iteration 21465, lr = 6.86489e-05
I0704 12:42:10.356180 20391 solver.cpp:243] Iteration 21492, loss = 0.699951
I0704 12:42:10.356241 20391 solver.cpp:259]     Train net output #0: loss = 0.699951 (* 1 = 0.699951 loss)
I0704 12:42:10.356250 20391 solver.cpp:590] Iteration 21492, lr = 6.82201e-05
I0704 12:42:18.046190 20391 solver.cpp:243] Iteration 21519, loss = 0.747921
I0704 12:42:18.046216 20391 solver.cpp:259]     Train net output #0: loss = 0.747921 (* 1 = 0.747921 loss)
I0704 12:42:18.046223 20391 solver.cpp:590] Iteration 21519, lr = 6.7794e-05
I0704 12:42:25.726202 20391 solver.cpp:243] Iteration 21546, loss = 0.830414
I0704 12:42:25.726235 20391 solver.cpp:259]     Train net output #0: loss = 0.830414 (* 1 = 0.830414 loss)
I0704 12:42:25.726243 20391 solver.cpp:590] Iteration 21546, lr = 6.73705e-05
I0704 12:42:33.375056 20391 solver.cpp:243] Iteration 21573, loss = 0.51896
I0704 12:42:33.375082 20391 solver.cpp:259]     Train net output #0: loss = 0.51896 (* 1 = 0.51896 loss)
I0704 12:42:33.375087 20391 solver.cpp:590] Iteration 21573, lr = 6.69497e-05
I0704 12:42:41.022116 20391 solver.cpp:243] Iteration 21600, loss = 0.773389
I0704 12:42:41.022202 20391 solver.cpp:259]     Train net output #0: loss = 0.773389 (* 1 = 0.773389 loss)
I0704 12:42:41.022208 20391 solver.cpp:590] Iteration 21600, lr = 6.65315e-05
I0704 12:42:48.678895 20391 solver.cpp:243] Iteration 21627, loss = 0.781348
I0704 12:42:48.678921 20391 solver.cpp:259]     Train net output #0: loss = 0.781348 (* 1 = 0.781348 loss)
I0704 12:42:48.678927 20391 solver.cpp:590] Iteration 21627, lr = 6.61159e-05
I0704 12:42:56.352736 20391 solver.cpp:243] Iteration 21654, loss = 0.591076
I0704 12:42:56.352762 20391 solver.cpp:259]     Train net output #0: loss = 0.591076 (* 1 = 0.591076 loss)
I0704 12:42:56.352768 20391 solver.cpp:590] Iteration 21654, lr = 6.5703e-05
I0704 12:42:57.207978 20391 solver.cpp:347] Iteration 21658, Testing net (#0)
I0704 12:43:18.889297 20391 solver.cpp:415]     Test net output #0: accuracy = 0.422476
I0704 12:43:18.889356 20391 solver.cpp:415]     Test net output #1: loss = 2.7893 (* 1 = 2.7893 loss)
I0704 12:43:24.935309 20391 solver.cpp:243] Iteration 21681, loss = 0.551806
I0704 12:43:24.935336 20391 solver.cpp:259]     Train net output #0: loss = 0.551806 (* 1 = 0.551806 loss)
I0704 12:43:24.935343 20391 solver.cpp:590] Iteration 21681, lr = 6.52926e-05
I0704 12:43:32.640288 20391 solver.cpp:243] Iteration 21708, loss = 0.783573
I0704 12:43:32.640311 20391 solver.cpp:259]     Train net output #0: loss = 0.783573 (* 1 = 0.783573 loss)
I0704 12:43:32.640317 20391 solver.cpp:590] Iteration 21708, lr = 6.48847e-05
I0704 12:43:40.314709 20391 solver.cpp:243] Iteration 21735, loss = 0.568434
I0704 12:43:40.314736 20391 solver.cpp:259]     Train net output #0: loss = 0.568434 (* 1 = 0.568434 loss)
I0704 12:43:40.314743 20391 solver.cpp:590] Iteration 21735, lr = 6.44794e-05
I0704 12:43:48.038058 20391 solver.cpp:243] Iteration 21762, loss = 0.508615
I0704 12:43:48.038082 20391 solver.cpp:259]     Train net output #0: loss = 0.508615 (* 1 = 0.508615 loss)
I0704 12:43:48.038089 20391 solver.cpp:590] Iteration 21762, lr = 6.40767e-05
I0704 12:43:55.741744 20391 solver.cpp:243] Iteration 21789, loss = 0.600892
I0704 12:43:55.741822 20391 solver.cpp:259]     Train net output #0: loss = 0.600892 (* 1 = 0.600892 loss)
I0704 12:43:55.741829 20391 solver.cpp:590] Iteration 21789, lr = 6.36765e-05
I0704 12:44:03.432442 20391 solver.cpp:243] Iteration 21816, loss = 0.443831
I0704 12:44:03.432468 20391 solver.cpp:259]     Train net output #0: loss = 0.443831 (* 1 = 0.443831 loss)
I0704 12:44:03.432476 20391 solver.cpp:590] Iteration 21816, lr = 6.32787e-05
I0704 12:44:11.090049 20391 solver.cpp:243] Iteration 21843, loss = 0.831448
I0704 12:44:11.090075 20391 solver.cpp:259]     Train net output #0: loss = 0.831448 (* 1 = 0.831448 loss)
I0704 12:44:11.090080 20391 solver.cpp:590] Iteration 21843, lr = 6.28835e-05
I0704 12:44:18.767890 20391 solver.cpp:243] Iteration 21870, loss = 0.646661
I0704 12:44:18.767917 20391 solver.cpp:259]     Train net output #0: loss = 0.646661 (* 1 = 0.646661 loss)
I0704 12:44:18.767923 20391 solver.cpp:590] Iteration 21870, lr = 6.24907e-05
I0704 12:44:21.047327 20391 solver.cpp:347] Iteration 21879, Testing net (#0)
I0704 12:44:26.967023 20391 blocking_queue.cpp:50] Data layer prefetch queue empty
I0704 12:44:40.347626 20391 solver.cpp:415]     Test net output #0: accuracy = 0.422236
I0704 12:44:40.347651 20391 solver.cpp:415]     Test net output #1: loss = 2.79077 (* 1 = 2.79077 loss)
I0704 12:44:44.955034 20391 solver.cpp:243] Iteration 21897, loss = 0.669383
I0704 12:44:44.955065 20391 solver.cpp:259]     Train net output #0: loss = 0.669383 (* 1 = 0.669383 loss)
I0704 12:44:44.955075 20391 solver.cpp:590] Iteration 21897, lr = 6.21003e-05
I0704 12:44:52.633219 20391 solver.cpp:243] Iteration 21924, loss = 0.666935
I0704 12:44:52.633245 20391 solver.cpp:259]     Train net output #0: loss = 0.666935 (* 1 = 0.666935 loss)
I0704 12:44:52.633251 20391 solver.cpp:590] Iteration 21924, lr = 6.17125e-05
I0704 12:45:00.362629 20391 solver.cpp:243] Iteration 21951, loss = 0.848425
I0704 12:45:00.362736 20391 solver.cpp:259]     Train net output #0: loss = 0.848425 (* 1 = 0.848425 loss)
I0704 12:45:00.362743 20391 solver.cpp:590] Iteration 21951, lr = 6.1327e-05
I0704 12:45:08.592113 20391 solver.cpp:243] Iteration 21978, loss = 0.786267
I0704 12:45:08.592138 20391 solver.cpp:259]     Train net output #0: loss = 0.786267 (* 1 = 0.786267 loss)
I0704 12:45:08.592144 20391 solver.cpp:590] Iteration 21978, lr = 6.09439e-05
I0704 12:45:16.762358 20391 solver.cpp:243] Iteration 22005, loss = 0.549081
I0704 12:45:16.762385 20391 solver.cpp:259]     Train net output #0: loss = 0.549081 (* 1 = 0.549081 loss)
I0704 12:45:16.762392 20391 solver.cpp:590] Iteration 22005, lr = 6.05632e-05
I0704 12:45:24.472071 20391 solver.cpp:243] Iteration 22032, loss = 0.638258
I0704 12:45:24.472100 20391 solver.cpp:259]     Train net output #0: loss = 0.638258 (* 1 = 0.638258 loss)
I0704 12:45:24.472106 20391 solver.cpp:590] Iteration 22032, lr = 6.0185e-05
I0704 12:45:32.653867 20391 solver.cpp:243] Iteration 22059, loss = 0.534385
I0704 12:45:32.653931 20391 solver.cpp:259]     Train net output #0: loss = 0.534385 (* 1 = 0.534385 loss)
I0704 12:45:32.653939 20391 solver.cpp:590] Iteration 22059, lr = 5.9809e-05
I0704 12:45:40.758532 20391 solver.cpp:243] Iteration 22086, loss = 0.672011
I0704 12:45:40.758558 20391 solver.cpp:259]     Train net output #0: loss = 0.672011 (* 1 = 0.672011 loss)
I0704 12:45:40.758563 20391 solver.cpp:590] Iteration 22086, lr = 5.94354e-05
I0704 12:45:44.454313 20391 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_22100.caffemodel
I0704 12:47:06.571451 20391 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_22100.solverstate
I0704 12:47:07.605507 20391 solver.cpp:347] Iteration 22100, Testing net (#0)
I0704 12:47:26.878737 20391 solver.cpp:415]     Test net output #0: accuracy = 0.421875
I0704 12:47:26.878762 20391 solver.cpp:415]     Test net output #1: loss = 2.79306 (* 1 = 2.79306 loss)
I0704 12:47:26.878765 20391 solver.cpp:332] Optimization Done.
I0704 12:47:26.878768 20391 caffe.cpp:223] Optimization Done.
