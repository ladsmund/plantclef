I0705 22:46:02.432713 15248 caffe.cpp:192] Using GPUs 0
I0705 22:46:02.614480 15248 solver.cpp:54] Initializing solver from parameters:
test_iter: 260
test_interval: 882
base_lr: 0.01
display: 110
max_iter: 70560
lr_policy: "exp"
gamma: 0.99994212
momentum: 0.9
weight_decay: 0.0001
snapshot: 17640
snapshot_prefix: "snapshot"
solver_mode: GPU
device_id: 0
random_seed: 0
net: "train_val.prototxt"
solver_type: SGD
iter_size: 1
I0705 22:46:02.614933 15248 solver.cpp:97] Creating training net from net file: train_val.prototxt
I0705 22:46:02.615322 15248 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0705 22:46:02.615329 15248 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer label
I0705 22:46:02.615337 15248 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0705 22:46:02.615417 15248 net.cpp:52] Initializing net from parameters:
state {
phase: TRAIN
}
layer {
name: "data"
type: "Data"
top: "data"
include {
phase: TRAIN
}
transform_param {
mean_file: "/home/ffw/scratch/plantClef/scatnet_output/train/a4_m3_s1s2s4_f2/lmdb_mean_coeff.binaryproto"
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/train/a4_m3_s1s2s4_f2/lmdb_data"
batch_size: 32
backend: LMDB
}
}
layer {
name: "label"
type: "Data"
top: "label"
include {
phase: TRAIN
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/train/a4_m3_s1s2s4_f2/lmdb_labels"
batch_size: 32
backend: LMDB
}
}
layer {
name: "pool1"
type: "Pooling"
bottom: "data"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool1"
top: "conv3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "conv4"
type: "Convolution"
bottom: "conv3"
top: "conv4"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu4"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "conv5"
type: "Convolution"
bottom: "conv4"
top: "conv5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
group: 1
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "conv5"
top: "conv5"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "conv5"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fc6"
type: "InnerProduct"
bottom: "pool5"
top: "fc6"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "fc6"
top: "fc6"
}
layer {
name: "drop6"
type: "Dropout"
bottom: "fc6"
top: "fc6"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc7"
type: "InnerProduct"
bottom: "fc6"
top: "fc7"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "fc7"
top: "fc7"
}
layer {
name: "drop7"
type: "Dropout"
bottom: "fc7"
top: "fc7"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc8_species"
type: "InnerProduct"
bottom: "fc7"
top: "fc8_species"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 967
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "fc8_species"
bottom: "label"
top: "loss"
}
I0705 22:46:02.615471 15248 layer_factory.hpp:76] Creating layer data
I0705 22:46:02.615535 15248 net.cpp:109] Creating Layer data
I0705 22:46:02.615540 15248 net.cpp:414] data -> data
I0705 22:46:02.615556 15248 data_transformer.cpp:25] Loading mean file from: /home/ffw/scratch/plantClef/scatnet_output/train/a4_m3_s1s2s4_f2/lmdb_mean_coeff.binaryproto
I0705 22:46:02.619539 15260 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/train/a4_m3_s1s2s4_f2/lmdb_data
I0705 22:46:02.633550 15248 data_layer.cpp:45] output data size: 32,375,47,47
I0705 22:46:02.744109 15248 net.cpp:153] Setting up data
I0705 22:46:02.744132 15248 net.cpp:160] Top shape: 32 375 47 47 (26508000)
I0705 22:46:02.744135 15248 net.cpp:168] Memory required for data: 106032000
I0705 22:46:02.744141 15248 layer_factory.hpp:76] Creating layer label
I0705 22:46:02.744177 15248 net.cpp:109] Creating Layer label
I0705 22:46:02.744181 15248 net.cpp:414] label -> label
I0705 22:46:02.748575 15262 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/train/a4_m3_s1s2s4_f2/lmdb_labels
I0705 22:46:02.754408 15248 data_layer.cpp:45] output data size: 32,1,1,1
I0705 22:46:02.754659 15248 net.cpp:153] Setting up label
I0705 22:46:02.754667 15248 net.cpp:160] Top shape: 32 1 1 1 (32)
I0705 22:46:02.754669 15248 net.cpp:168] Memory required for data: 106032128
I0705 22:46:02.754673 15248 layer_factory.hpp:76] Creating layer pool1
I0705 22:46:02.754683 15248 net.cpp:109] Creating Layer pool1
I0705 22:46:02.754684 15248 net.cpp:457] pool1 <- data
I0705 22:46:02.754693 15248 net.cpp:414] pool1 -> pool1
I0705 22:46:02.754760 15248 net.cpp:153] Setting up pool1
I0705 22:46:02.754765 15248 net.cpp:160] Top shape: 32 375 23 23 (6348000)
I0705 22:46:02.754766 15248 net.cpp:168] Memory required for data: 131424128
I0705 22:46:02.754768 15248 layer_factory.hpp:76] Creating layer conv3
I0705 22:46:02.754775 15248 net.cpp:109] Creating Layer conv3
I0705 22:46:02.754776 15248 net.cpp:457] conv3 <- pool1
I0705 22:46:02.754779 15248 net.cpp:414] conv3 -> conv3
I0705 22:46:02.780586 15248 net.cpp:153] Setting up conv3
I0705 22:46:02.780613 15248 net.cpp:160] Top shape: 32 384 23 23 (6500352)
I0705 22:46:02.780616 15248 net.cpp:168] Memory required for data: 157425536
I0705 22:46:02.780628 15248 layer_factory.hpp:76] Creating layer relu3
I0705 22:46:02.780639 15248 net.cpp:109] Creating Layer relu3
I0705 22:46:02.780643 15248 net.cpp:457] relu3 <- conv3
I0705 22:46:02.780647 15248 net.cpp:400] relu3 -> conv3 (in-place)
I0705 22:46:02.780664 15248 net.cpp:153] Setting up relu3
I0705 22:46:02.780666 15248 net.cpp:160] Top shape: 32 384 23 23 (6500352)
I0705 22:46:02.780668 15248 net.cpp:168] Memory required for data: 183426944
I0705 22:46:02.780670 15248 layer_factory.hpp:76] Creating layer conv4
I0705 22:46:02.780676 15248 net.cpp:109] Creating Layer conv4
I0705 22:46:02.780678 15248 net.cpp:457] conv4 <- conv3
I0705 22:46:02.780680 15248 net.cpp:414] conv4 -> conv4
I0705 22:46:02.793722 15248 net.cpp:153] Setting up conv4
I0705 22:46:02.793737 15248 net.cpp:160] Top shape: 32 384 23 23 (6500352)
I0705 22:46:02.793740 15248 net.cpp:168] Memory required for data: 209428352
I0705 22:46:02.793747 15248 layer_factory.hpp:76] Creating layer relu4
I0705 22:46:02.793753 15248 net.cpp:109] Creating Layer relu4
I0705 22:46:02.793756 15248 net.cpp:457] relu4 <- conv4
I0705 22:46:02.793761 15248 net.cpp:400] relu4 -> conv4 (in-place)
I0705 22:46:02.793781 15248 net.cpp:153] Setting up relu4
I0705 22:46:02.793784 15248 net.cpp:160] Top shape: 32 384 23 23 (6500352)
I0705 22:46:02.793786 15248 net.cpp:168] Memory required for data: 235429760
I0705 22:46:02.793787 15248 layer_factory.hpp:76] Creating layer conv5
I0705 22:46:02.793792 15248 net.cpp:109] Creating Layer conv5
I0705 22:46:02.793794 15248 net.cpp:457] conv5 <- conv4
I0705 22:46:02.793797 15248 net.cpp:414] conv5 -> conv5
I0705 22:46:02.811118 15248 net.cpp:153] Setting up conv5
I0705 22:46:02.811134 15248 net.cpp:160] Top shape: 32 256 23 23 (4333568)
I0705 22:46:02.811136 15248 net.cpp:168] Memory required for data: 252764032
I0705 22:46:02.811144 15248 layer_factory.hpp:76] Creating layer relu5
I0705 22:46:02.811151 15248 net.cpp:109] Creating Layer relu5
I0705 22:46:02.811154 15248 net.cpp:457] relu5 <- conv5
I0705 22:46:02.811158 15248 net.cpp:400] relu5 -> conv5 (in-place)
I0705 22:46:02.811163 15248 net.cpp:153] Setting up relu5
I0705 22:46:02.811166 15248 net.cpp:160] Top shape: 32 256 23 23 (4333568)
I0705 22:46:02.811167 15248 net.cpp:168] Memory required for data: 270098304
I0705 22:46:02.811169 15248 layer_factory.hpp:76] Creating layer pool5
I0705 22:46:02.811173 15248 net.cpp:109] Creating Layer pool5
I0705 22:46:02.811174 15248 net.cpp:457] pool5 <- conv5
I0705 22:46:02.811177 15248 net.cpp:414] pool5 -> pool5
I0705 22:46:02.811197 15248 net.cpp:153] Setting up pool5
I0705 22:46:02.811199 15248 net.cpp:160] Top shape: 32 256 11 11 (991232)
I0705 22:46:02.811202 15248 net.cpp:168] Memory required for data: 274063232
I0705 22:46:02.811203 15248 layer_factory.hpp:76] Creating layer fc6
I0705 22:46:02.811208 15248 net.cpp:109] Creating Layer fc6
I0705 22:46:02.811209 15248 net.cpp:457] fc6 <- pool5
I0705 22:46:02.811213 15248 net.cpp:414] fc6 -> fc6
I0705 22:46:05.151968 15248 net.cpp:153] Setting up fc6
I0705 22:46:05.151984 15248 net.cpp:160] Top shape: 32 4096 (131072)
I0705 22:46:05.151988 15248 net.cpp:168] Memory required for data: 274587520
I0705 22:46:05.151993 15248 layer_factory.hpp:76] Creating layer relu6
I0705 22:46:05.151999 15248 net.cpp:109] Creating Layer relu6
I0705 22:46:05.152003 15248 net.cpp:457] relu6 <- fc6
I0705 22:46:05.152006 15248 net.cpp:400] relu6 -> fc6 (in-place)
I0705 22:46:05.152012 15248 net.cpp:153] Setting up relu6
I0705 22:46:05.152014 15248 net.cpp:160] Top shape: 32 4096 (131072)
I0705 22:46:05.152016 15248 net.cpp:168] Memory required for data: 275111808
I0705 22:46:05.152019 15248 layer_factory.hpp:76] Creating layer drop6
I0705 22:46:05.152026 15248 net.cpp:109] Creating Layer drop6
I0705 22:46:05.152027 15248 net.cpp:457] drop6 <- fc6
I0705 22:46:05.152030 15248 net.cpp:400] drop6 -> fc6 (in-place)
I0705 22:46:05.152045 15248 net.cpp:153] Setting up drop6
I0705 22:46:05.152047 15248 net.cpp:160] Top shape: 32 4096 (131072)
I0705 22:46:05.152050 15248 net.cpp:168] Memory required for data: 275636096
I0705 22:46:05.152050 15248 layer_factory.hpp:76] Creating layer fc7
I0705 22:46:05.152055 15248 net.cpp:109] Creating Layer fc7
I0705 22:46:05.152057 15248 net.cpp:457] fc7 <- fc6
I0705 22:46:05.152060 15248 net.cpp:414] fc7 -> fc7
I0705 22:46:05.454188 15248 net.cpp:153] Setting up fc7
I0705 22:46:05.454207 15248 net.cpp:160] Top shape: 32 4096 (131072)
I0705 22:46:05.454210 15248 net.cpp:168] Memory required for data: 276160384
I0705 22:46:05.454218 15248 layer_factory.hpp:76] Creating layer relu7
I0705 22:46:05.454226 15248 net.cpp:109] Creating Layer relu7
I0705 22:46:05.454227 15248 net.cpp:457] relu7 <- fc7
I0705 22:46:05.454231 15248 net.cpp:400] relu7 -> fc7 (in-place)
I0705 22:46:05.454237 15248 net.cpp:153] Setting up relu7
I0705 22:46:05.454241 15248 net.cpp:160] Top shape: 32 4096 (131072)
I0705 22:46:05.454241 15248 net.cpp:168] Memory required for data: 276684672
I0705 22:46:05.454243 15248 layer_factory.hpp:76] Creating layer drop7
I0705 22:46:05.454246 15248 net.cpp:109] Creating Layer drop7
I0705 22:46:05.454248 15248 net.cpp:457] drop7 <- fc7
I0705 22:46:05.454252 15248 net.cpp:400] drop7 -> fc7 (in-place)
I0705 22:46:05.454283 15248 net.cpp:153] Setting up drop7
I0705 22:46:05.454287 15248 net.cpp:160] Top shape: 32 4096 (131072)
I0705 22:46:05.454288 15248 net.cpp:168] Memory required for data: 277208960
I0705 22:46:05.454290 15248 layer_factory.hpp:76] Creating layer fc8_species
I0705 22:46:05.454295 15248 net.cpp:109] Creating Layer fc8_species
I0705 22:46:05.454298 15248 net.cpp:457] fc8_species <- fc7
I0705 22:46:05.454299 15248 net.cpp:414] fc8_species -> fc8_species
I0705 22:46:05.527094 15248 net.cpp:153] Setting up fc8_species
I0705 22:46:05.527112 15248 net.cpp:160] Top shape: 32 967 (30944)
I0705 22:46:05.527113 15248 net.cpp:168] Memory required for data: 277332736
I0705 22:46:05.527119 15248 layer_factory.hpp:76] Creating layer loss
I0705 22:46:05.527132 15248 net.cpp:109] Creating Layer loss
I0705 22:46:05.527134 15248 net.cpp:457] loss <- fc8_species
I0705 22:46:05.527137 15248 net.cpp:457] loss <- label
I0705 22:46:05.527142 15248 net.cpp:414] loss -> loss
I0705 22:46:05.527148 15248 layer_factory.hpp:76] Creating layer loss
I0705 22:46:05.527525 15248 net.cpp:153] Setting up loss
I0705 22:46:05.527531 15248 net.cpp:160] Top shape: (1)
I0705 22:46:05.527534 15248 net.cpp:163]     with loss weight 1
I0705 22:46:05.527556 15248 net.cpp:168] Memory required for data: 277332740
I0705 22:46:05.527559 15248 net.cpp:229] loss needs backward computation.
I0705 22:46:05.527560 15248 net.cpp:229] fc8_species needs backward computation.
I0705 22:46:05.527562 15248 net.cpp:229] drop7 needs backward computation.
I0705 22:46:05.527565 15248 net.cpp:229] relu7 needs backward computation.
I0705 22:46:05.527565 15248 net.cpp:229] fc7 needs backward computation.
I0705 22:46:05.527567 15248 net.cpp:229] drop6 needs backward computation.
I0705 22:46:05.527570 15248 net.cpp:229] relu6 needs backward computation.
I0705 22:46:05.527571 15248 net.cpp:229] fc6 needs backward computation.
I0705 22:46:05.527573 15248 net.cpp:229] pool5 needs backward computation.
I0705 22:46:05.527575 15248 net.cpp:229] relu5 needs backward computation.
I0705 22:46:05.527577 15248 net.cpp:229] conv5 needs backward computation.
I0705 22:46:05.527580 15248 net.cpp:229] relu4 needs backward computation.
I0705 22:46:05.527581 15248 net.cpp:229] conv4 needs backward computation.
I0705 22:46:05.527582 15248 net.cpp:229] relu3 needs backward computation.
I0705 22:46:05.527585 15248 net.cpp:229] conv3 needs backward computation.
I0705 22:46:05.527586 15248 net.cpp:231] pool1 does not need backward computation.
I0705 22:46:05.527588 15248 net.cpp:231] label does not need backward computation.
I0705 22:46:05.527590 15248 net.cpp:231] data does not need backward computation.
I0705 22:46:05.527592 15248 net.cpp:273] This network produces output loss
I0705 22:46:05.527598 15248 net.cpp:286] Network initialization done.
I0705 22:46:05.528028 15248 solver.cpp:187] Creating test net (#0) specified by net file: train_val.prototxt
I0705 22:46:05.528051 15248 net.cpp:325] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0705 22:46:05.528054 15248 net.cpp:325] The NetState phase (1) differed from the phase (0) specified by a rule in layer label
I0705 22:46:05.528136 15248 net.cpp:52] Initializing net from parameters:
state {
phase: TEST
}
layer {
name: "data"
type: "Data"
top: "data"
include {
phase: TEST
}
transform_param {
mean_file: "/home/ffw/scratch/plantClef/scatnet_output/train/a4_m3_s1s2s4_f2/lmdb_mean_coeff.binaryproto"
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/test/a4_m3_s1s2s4_f2/lmdb_data"
batch_size: 32
backend: LMDB
}
}
layer {
name: "label"
type: "Data"
top: "label"
include {
phase: TEST
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/test/a4_m3_s1s2s4_f2/lmdb_labels"
batch_size: 32
backend: LMDB
}
}
layer {
name: "pool1"
type: "Pooling"
bottom: "data"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool1"
top: "conv3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "conv4"
type: "Convolution"
bottom: "conv3"
top: "conv4"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu4"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "conv5"
type: "Convolution"
bottom: "conv4"
top: "conv5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
group: 1
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "conv5"
top: "conv5"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "conv5"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fc6"
type: "InnerProduct"
bottom: "pool5"
top: "fc6"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "fc6"
top: "fc6"
}
layer {
name: "drop6"
type: "Dropout"
bottom: "fc6"
top: "fc6"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc7"
type: "InnerProduct"
bottom: "fc6"
top: "fc7"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "fc7"
top: "fc7"
}
layer {
name: "drop7"
type: "Dropout"
bottom: "fc7"
top: "fc7"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc8_species"
type: "InnerProduct"
bottom: "fc7"
top: "fc8_species"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 967
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "fc8_species"
bottom: "label"
top: "loss"
}
layer {
name: "accuracy"
type: "Accuracy"
bottom: "fc8_species"
bottom: "label"
top: "accuracy"
include {
phase: TEST
}
}
I0705 22:46:05.528198 15248 layer_factory.hpp:76] Creating layer data
I0705 22:46:05.528244 15248 net.cpp:109] Creating Layer data
I0705 22:46:05.528249 15248 net.cpp:414] data -> data
I0705 22:46:05.528254 15248 data_transformer.cpp:25] Loading mean file from: /home/ffw/scratch/plantClef/scatnet_output/train/a4_m3_s1s2s4_f2/lmdb_mean_coeff.binaryproto
I0705 22:46:05.535909 15266 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/test/a4_m3_s1s2s4_f2/lmdb_data
I0705 22:46:05.560842 15248 data_layer.cpp:45] output data size: 32,375,47,47
I0705 22:46:05.668850 15248 net.cpp:153] Setting up data
I0705 22:46:05.668869 15248 net.cpp:160] Top shape: 32 375 47 47 (26508000)
I0705 22:46:05.668872 15248 net.cpp:168] Memory required for data: 106032000
I0705 22:46:05.668876 15248 layer_factory.hpp:76] Creating layer label
I0705 22:46:05.668918 15248 net.cpp:109] Creating Layer label
I0705 22:46:05.668922 15248 net.cpp:414] label -> label
I0705 22:46:05.673632 15268 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/test/a4_m3_s1s2s4_f2/lmdb_labels
I0705 22:46:05.679006 15248 data_layer.cpp:45] output data size: 32,1,1,1
I0705 22:46:05.679147 15248 net.cpp:153] Setting up label
I0705 22:46:05.679157 15248 net.cpp:160] Top shape: 32 1 1 1 (32)
I0705 22:46:05.679159 15248 net.cpp:168] Memory required for data: 106032128
I0705 22:46:05.679163 15248 layer_factory.hpp:76] Creating layer label_label_0_split
I0705 22:46:05.679172 15248 net.cpp:109] Creating Layer label_label_0_split
I0705 22:46:05.679175 15248 net.cpp:457] label_label_0_split <- label
I0705 22:46:05.679179 15248 net.cpp:414] label_label_0_split -> label_label_0_split_0
I0705 22:46:05.679185 15248 net.cpp:414] label_label_0_split -> label_label_0_split_1
I0705 22:46:05.679303 15248 net.cpp:153] Setting up label_label_0_split
I0705 22:46:05.679313 15248 net.cpp:160] Top shape: 32 1 1 1 (32)
I0705 22:46:05.679316 15248 net.cpp:160] Top shape: 32 1 1 1 (32)
I0705 22:46:05.679318 15248 net.cpp:168] Memory required for data: 106032384
I0705 22:46:05.679321 15248 layer_factory.hpp:76] Creating layer pool1
I0705 22:46:05.679337 15248 net.cpp:109] Creating Layer pool1
I0705 22:46:05.679338 15248 net.cpp:457] pool1 <- data
I0705 22:46:05.679342 15248 net.cpp:414] pool1 -> pool1
I0705 22:46:05.679366 15248 net.cpp:153] Setting up pool1
I0705 22:46:05.679370 15248 net.cpp:160] Top shape: 32 375 23 23 (6348000)
I0705 22:46:05.679373 15248 net.cpp:168] Memory required for data: 131424384
I0705 22:46:05.679374 15248 layer_factory.hpp:76] Creating layer conv3
I0705 22:46:05.679380 15248 net.cpp:109] Creating Layer conv3
I0705 22:46:05.679383 15248 net.cpp:457] conv3 <- pool1
I0705 22:46:05.679385 15248 net.cpp:414] conv3 -> conv3
I0705 22:46:05.705528 15248 net.cpp:153] Setting up conv3
I0705 22:46:05.705546 15248 net.cpp:160] Top shape: 32 384 23 23 (6500352)
I0705 22:46:05.705560 15248 net.cpp:168] Memory required for data: 157425792
I0705 22:46:05.705569 15248 layer_factory.hpp:76] Creating layer relu3
I0705 22:46:05.705576 15248 net.cpp:109] Creating Layer relu3
I0705 22:46:05.705590 15248 net.cpp:457] relu3 <- conv3
I0705 22:46:05.705593 15248 net.cpp:400] relu3 -> conv3 (in-place)
I0705 22:46:05.705600 15248 net.cpp:153] Setting up relu3
I0705 22:46:05.705603 15248 net.cpp:160] Top shape: 32 384 23 23 (6500352)
I0705 22:46:05.705605 15248 net.cpp:168] Memory required for data: 183427200
I0705 22:46:05.705607 15248 layer_factory.hpp:76] Creating layer conv4
I0705 22:46:05.705612 15248 net.cpp:109] Creating Layer conv4
I0705 22:46:05.705615 15248 net.cpp:457] conv4 <- conv3
I0705 22:46:05.705617 15248 net.cpp:414] conv4 -> conv4
I0705 22:46:05.719861 15248 net.cpp:153] Setting up conv4
I0705 22:46:05.719888 15248 net.cpp:160] Top shape: 32 384 23 23 (6500352)
I0705 22:46:05.719892 15248 net.cpp:168] Memory required for data: 209428608
I0705 22:46:05.719899 15248 layer_factory.hpp:76] Creating layer relu4
I0705 22:46:05.719907 15248 net.cpp:109] Creating Layer relu4
I0705 22:46:05.719910 15248 net.cpp:457] relu4 <- conv4
I0705 22:46:05.719914 15248 net.cpp:400] relu4 -> conv4 (in-place)
I0705 22:46:05.719921 15248 net.cpp:153] Setting up relu4
I0705 22:46:05.719924 15248 net.cpp:160] Top shape: 32 384 23 23 (6500352)
I0705 22:46:05.719926 15248 net.cpp:168] Memory required for data: 235430016
I0705 22:46:05.719928 15248 layer_factory.hpp:76] Creating layer conv5
I0705 22:46:05.719935 15248 net.cpp:109] Creating Layer conv5
I0705 22:46:05.719938 15248 net.cpp:457] conv5 <- conv4
I0705 22:46:05.719940 15248 net.cpp:414] conv5 -> conv5
I0705 22:46:05.737898 15248 net.cpp:153] Setting up conv5
I0705 22:46:05.737916 15248 net.cpp:160] Top shape: 32 256 23 23 (4333568)
I0705 22:46:05.737920 15248 net.cpp:168] Memory required for data: 252764288
I0705 22:46:05.737929 15248 layer_factory.hpp:76] Creating layer relu5
I0705 22:46:05.737936 15248 net.cpp:109] Creating Layer relu5
I0705 22:46:05.737939 15248 net.cpp:457] relu5 <- conv5
I0705 22:46:05.737943 15248 net.cpp:400] relu5 -> conv5 (in-place)
I0705 22:46:05.737965 15248 net.cpp:153] Setting up relu5
I0705 22:46:05.737969 15248 net.cpp:160] Top shape: 32 256 23 23 (4333568)
I0705 22:46:05.737972 15248 net.cpp:168] Memory required for data: 270098560
I0705 22:46:05.737973 15248 layer_factory.hpp:76] Creating layer pool5
I0705 22:46:05.737978 15248 net.cpp:109] Creating Layer pool5
I0705 22:46:05.737980 15248 net.cpp:457] pool5 <- conv5
I0705 22:46:05.737983 15248 net.cpp:414] pool5 -> pool5
I0705 22:46:05.738016 15248 net.cpp:153] Setting up pool5
I0705 22:46:05.738020 15248 net.cpp:160] Top shape: 32 256 11 11 (991232)
I0705 22:46:05.738023 15248 net.cpp:168] Memory required for data: 274063488
I0705 22:46:05.738024 15248 layer_factory.hpp:76] Creating layer fc6
I0705 22:46:05.738029 15248 net.cpp:109] Creating Layer fc6
I0705 22:46:05.738031 15248 net.cpp:457] fc6 <- pool5
I0705 22:46:05.738034 15248 net.cpp:414] fc6 -> fc6
I0705 22:46:08.098902 15248 net.cpp:153] Setting up fc6
I0705 22:46:08.098920 15248 net.cpp:160] Top shape: 32 4096 (131072)
I0705 22:46:08.098923 15248 net.cpp:168] Memory required for data: 274587776
I0705 22:46:08.098929 15248 layer_factory.hpp:76] Creating layer relu6
I0705 22:46:08.098937 15248 net.cpp:109] Creating Layer relu6
I0705 22:46:08.098939 15248 net.cpp:457] relu6 <- fc6
I0705 22:46:08.098943 15248 net.cpp:400] relu6 -> fc6 (in-place)
I0705 22:46:08.098950 15248 net.cpp:153] Setting up relu6
I0705 22:46:08.098953 15248 net.cpp:160] Top shape: 32 4096 (131072)
I0705 22:46:08.098954 15248 net.cpp:168] Memory required for data: 275112064
I0705 22:46:08.098956 15248 layer_factory.hpp:76] Creating layer drop6
I0705 22:46:08.098960 15248 net.cpp:109] Creating Layer drop6
I0705 22:46:08.098963 15248 net.cpp:457] drop6 <- fc6
I0705 22:46:08.098964 15248 net.cpp:400] drop6 -> fc6 (in-place)
I0705 22:46:08.098984 15248 net.cpp:153] Setting up drop6
I0705 22:46:08.098986 15248 net.cpp:160] Top shape: 32 4096 (131072)
I0705 22:46:08.098989 15248 net.cpp:168] Memory required for data: 275636352
I0705 22:46:08.098990 15248 layer_factory.hpp:76] Creating layer fc7
I0705 22:46:08.098995 15248 net.cpp:109] Creating Layer fc7
I0705 22:46:08.098996 15248 net.cpp:457] fc7 <- fc6
I0705 22:46:08.098999 15248 net.cpp:414] fc7 -> fc7
I0705 22:46:08.449048 15248 net.cpp:153] Setting up fc7
I0705 22:46:08.449065 15248 net.cpp:160] Top shape: 32 4096 (131072)
I0705 22:46:08.449069 15248 net.cpp:168] Memory required for data: 276160640
I0705 22:46:08.449077 15248 layer_factory.hpp:76] Creating layer relu7
I0705 22:46:08.449084 15248 net.cpp:109] Creating Layer relu7
I0705 22:46:08.449087 15248 net.cpp:457] relu7 <- fc7
I0705 22:46:08.449091 15248 net.cpp:400] relu7 -> fc7 (in-place)
I0705 22:46:08.449097 15248 net.cpp:153] Setting up relu7
I0705 22:46:08.449100 15248 net.cpp:160] Top shape: 32 4096 (131072)
I0705 22:46:08.449102 15248 net.cpp:168] Memory required for data: 276684928
I0705 22:46:08.449103 15248 layer_factory.hpp:76] Creating layer drop7
I0705 22:46:08.449110 15248 net.cpp:109] Creating Layer drop7
I0705 22:46:08.449110 15248 net.cpp:457] drop7 <- fc7
I0705 22:46:08.449113 15248 net.cpp:400] drop7 -> fc7 (in-place)
I0705 22:46:08.449132 15248 net.cpp:153] Setting up drop7
I0705 22:46:08.449136 15248 net.cpp:160] Top shape: 32 4096 (131072)
I0705 22:46:08.449137 15248 net.cpp:168] Memory required for data: 277209216
I0705 22:46:08.449139 15248 layer_factory.hpp:76] Creating layer fc8_species
I0705 22:46:08.449144 15248 net.cpp:109] Creating Layer fc8_species
I0705 22:46:08.449146 15248 net.cpp:457] fc8_species <- fc7
I0705 22:46:08.449149 15248 net.cpp:414] fc8_species -> fc8_species
I0705 22:46:08.522148 15248 net.cpp:153] Setting up fc8_species
I0705 22:46:08.522164 15248 net.cpp:160] Top shape: 32 967 (30944)
I0705 22:46:08.522167 15248 net.cpp:168] Memory required for data: 277332992
I0705 22:46:08.522173 15248 layer_factory.hpp:76] Creating layer fc8_species_fc8_species_0_split
I0705 22:46:08.522179 15248 net.cpp:109] Creating Layer fc8_species_fc8_species_0_split
I0705 22:46:08.522183 15248 net.cpp:457] fc8_species_fc8_species_0_split <- fc8_species
I0705 22:46:08.522204 15248 net.cpp:414] fc8_species_fc8_species_0_split -> fc8_species_fc8_species_0_split_0
I0705 22:46:08.522210 15248 net.cpp:414] fc8_species_fc8_species_0_split -> fc8_species_fc8_species_0_split_1
I0705 22:46:08.522238 15248 net.cpp:153] Setting up fc8_species_fc8_species_0_split
I0705 22:46:08.522241 15248 net.cpp:160] Top shape: 32 967 (30944)
I0705 22:46:08.522244 15248 net.cpp:160] Top shape: 32 967 (30944)
I0705 22:46:08.522245 15248 net.cpp:168] Memory required for data: 277580544
I0705 22:46:08.522248 15248 layer_factory.hpp:76] Creating layer loss
I0705 22:46:08.522251 15248 net.cpp:109] Creating Layer loss
I0705 22:46:08.522253 15248 net.cpp:457] loss <- fc8_species_fc8_species_0_split_0
I0705 22:46:08.522255 15248 net.cpp:457] loss <- label_label_0_split_0
I0705 22:46:08.522258 15248 net.cpp:414] loss -> loss
I0705 22:46:08.522263 15248 layer_factory.hpp:76] Creating layer loss
I0705 22:46:08.522348 15248 net.cpp:153] Setting up loss
I0705 22:46:08.522352 15248 net.cpp:160] Top shape: (1)
I0705 22:46:08.522354 15248 net.cpp:163]     with loss weight 1
I0705 22:46:08.522361 15248 net.cpp:168] Memory required for data: 277580548
I0705 22:46:08.522363 15248 layer_factory.hpp:76] Creating layer accuracy
I0705 22:46:08.522367 15248 net.cpp:109] Creating Layer accuracy
I0705 22:46:08.522369 15248 net.cpp:457] accuracy <- fc8_species_fc8_species_0_split_1
I0705 22:46:08.522372 15248 net.cpp:457] accuracy <- label_label_0_split_1
I0705 22:46:08.522374 15248 net.cpp:414] accuracy -> accuracy
I0705 22:46:08.522379 15248 net.cpp:153] Setting up accuracy
I0705 22:46:08.522382 15248 net.cpp:160] Top shape: (1)
I0705 22:46:08.522382 15248 net.cpp:168] Memory required for data: 277580552
I0705 22:46:08.522384 15248 net.cpp:231] accuracy does not need backward computation.
I0705 22:46:08.522387 15248 net.cpp:229] loss needs backward computation.
I0705 22:46:08.522388 15248 net.cpp:229] fc8_species_fc8_species_0_split needs backward computation.
I0705 22:46:08.522390 15248 net.cpp:229] fc8_species needs backward computation.
I0705 22:46:08.522392 15248 net.cpp:229] drop7 needs backward computation.
I0705 22:46:08.522394 15248 net.cpp:229] relu7 needs backward computation.
I0705 22:46:08.522397 15248 net.cpp:229] fc7 needs backward computation.
I0705 22:46:08.522398 15248 net.cpp:229] drop6 needs backward computation.
I0705 22:46:08.522400 15248 net.cpp:229] relu6 needs backward computation.
I0705 22:46:08.522402 15248 net.cpp:229] fc6 needs backward computation.
I0705 22:46:08.522403 15248 net.cpp:229] pool5 needs backward computation.
I0705 22:46:08.522406 15248 net.cpp:229] relu5 needs backward computation.
I0705 22:46:08.522408 15248 net.cpp:229] conv5 needs backward computation.
I0705 22:46:08.522409 15248 net.cpp:229] relu4 needs backward computation.
I0705 22:46:08.522411 15248 net.cpp:229] conv4 needs backward computation.
I0705 22:46:08.522413 15248 net.cpp:229] relu3 needs backward computation.
I0705 22:46:08.522415 15248 net.cpp:229] conv3 needs backward computation.
I0705 22:46:08.522418 15248 net.cpp:231] pool1 does not need backward computation.
I0705 22:46:08.522420 15248 net.cpp:231] label_label_0_split does not need backward computation.
I0705 22:46:08.522423 15248 net.cpp:231] label does not need backward computation.
I0705 22:46:08.522424 15248 net.cpp:231] data does not need backward computation.
I0705 22:46:08.522425 15248 net.cpp:273] This network produces output accuracy
I0705 22:46:08.522428 15248 net.cpp:273] This network produces output loss
I0705 22:46:08.522435 15248 net.cpp:286] Network initialization done.
I0705 22:46:08.522486 15248 solver.cpp:66] Solver scaffolding done.
I0705 22:46:08.522732 15248 caffe.cpp:220] Starting Optimization
I0705 22:46:08.522734 15248 solver.cpp:294] Solving
I0705 22:46:08.522737 15248 solver.cpp:295] Learning Rate Policy: exp
I0705 22:46:08.523754 15248 solver.cpp:347] Iteration 0, Testing net (#0)
I0705 22:46:09.105933 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0705 22:46:09.378211 15267 blocking_queue.cpp:50] Waiting for data
I0705 22:46:33.520613 15248 solver.cpp:415]     Test net output #0: accuracy = 0.000841346
I0705 22:46:33.520730 15248 solver.cpp:415]     Test net output #1: loss = 6.87965 (* 1 = 6.87965 loss)
I0705 22:46:33.683441 15248 solver.cpp:243] Iteration 0, loss = 6.87064
I0705 22:46:33.683466 15248 solver.cpp:259]     Train net output #0: loss = 6.87064 (* 1 = 6.87064 loss)
I0705 22:46:33.683478 15248 solver.cpp:590] Iteration 0, lr = 0.01
I0705 22:46:55.383069 15248 solver.cpp:243] Iteration 110, loss = 6.63893
I0705 22:46:55.383093 15248 solver.cpp:259]     Train net output #0: loss = 6.63893 (* 1 = 6.63893 loss)
I0705 22:46:55.383100 15248 solver.cpp:590] Iteration 110, lr = 0.00993654
I0705 22:47:16.963069 15248 solver.cpp:243] Iteration 220, loss = 6.64169
I0705 22:47:16.963374 15248 solver.cpp:259]     Train net output #0: loss = 6.64169 (* 1 = 6.64169 loss)
I0705 22:47:16.963382 15248 solver.cpp:590] Iteration 220, lr = 0.00987348
I0705 22:47:38.579365 15248 solver.cpp:243] Iteration 330, loss = 6.74771
I0705 22:47:38.579388 15248 solver.cpp:259]     Train net output #0: loss = 6.74771 (* 1 = 6.74771 loss)
I0705 22:47:38.579394 15248 solver.cpp:590] Iteration 330, lr = 0.00981082
I0705 22:48:00.152920 15248 solver.cpp:243] Iteration 440, loss = 6.42117
I0705 22:48:00.153184 15248 solver.cpp:259]     Train net output #0: loss = 6.42117 (* 1 = 6.42117 loss)
I0705 22:48:00.153192 15248 solver.cpp:590] Iteration 440, lr = 0.00974855
I0705 22:48:21.805923 15248 solver.cpp:243] Iteration 550, loss = 6.36898
I0705 22:48:21.805946 15248 solver.cpp:259]     Train net output #0: loss = 6.36898 (* 1 = 6.36898 loss)
I0705 22:48:21.805951 15248 solver.cpp:590] Iteration 550, lr = 0.00968669
I0705 22:48:43.406332 15248 solver.cpp:243] Iteration 660, loss = 6.48025
I0705 22:48:43.406421 15248 solver.cpp:259]     Train net output #0: loss = 6.48025 (* 1 = 6.48025 loss)
I0705 22:48:43.406436 15248 solver.cpp:590] Iteration 660, lr = 0.00962521
I0705 22:49:04.983034 15248 solver.cpp:243] Iteration 770, loss = 6.35931
I0705 22:49:04.983058 15248 solver.cpp:259]     Train net output #0: loss = 6.35931 (* 1 = 6.35931 loss)
I0705 22:49:04.983064 15248 solver.cpp:590] Iteration 770, lr = 0.00956413
I0705 22:49:26.566537 15248 solver.cpp:243] Iteration 880, loss = 6.36155
I0705 22:49:26.566632 15248 solver.cpp:259]     Train net output #0: loss = 6.36155 (* 1 = 6.36155 loss)
I0705 22:49:26.566639 15248 solver.cpp:590] Iteration 880, lr = 0.00950343
I0705 22:49:26.764397 15248 solver.cpp:347] Iteration 882, Testing net (#0)
I0705 22:49:51.957706 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0149038
I0705 22:49:51.957744 15248 solver.cpp:415]     Test net output #1: loss = 6.32332 (* 1 = 6.32332 loss)
I0705 22:50:13.383138 15248 solver.cpp:243] Iteration 990, loss = 6.5748
I0705 22:50:13.383272 15248 solver.cpp:259]     Train net output #0: loss = 6.5748 (* 1 = 6.5748 loss)
I0705 22:50:13.383280 15248 solver.cpp:590] Iteration 990, lr = 0.00944312
I0705 22:50:34.950700 15248 solver.cpp:243] Iteration 1100, loss = 6.30324
I0705 22:50:34.950726 15248 solver.cpp:259]     Train net output #0: loss = 6.30324 (* 1 = 6.30324 loss)
I0705 22:50:34.950731 15248 solver.cpp:590] Iteration 1100, lr = 0.00938319
I0705 22:50:56.495229 15248 solver.cpp:243] Iteration 1210, loss = 6.3623
I0705 22:50:56.495338 15248 solver.cpp:259]     Train net output #0: loss = 6.3623 (* 1 = 6.3623 loss)
I0705 22:50:56.495358 15248 solver.cpp:590] Iteration 1210, lr = 0.00932364
I0705 22:51:18.094949 15248 solver.cpp:243] Iteration 1320, loss = 6.1119
I0705 22:51:18.094969 15248 solver.cpp:259]     Train net output #0: loss = 6.1119 (* 1 = 6.1119 loss)
I0705 22:51:18.094974 15248 solver.cpp:590] Iteration 1320, lr = 0.00926447
I0705 22:51:39.655128 15248 solver.cpp:243] Iteration 1430, loss = 6.06974
I0705 22:51:39.655202 15248 solver.cpp:259]     Train net output #0: loss = 6.06974 (* 1 = 6.06974 loss)
I0705 22:51:39.655218 15248 solver.cpp:590] Iteration 1430, lr = 0.00920567
I0705 22:52:01.189075 15248 solver.cpp:243] Iteration 1540, loss = 5.90807
I0705 22:52:01.189097 15248 solver.cpp:259]     Train net output #0: loss = 5.90807 (* 1 = 5.90807 loss)
I0705 22:52:01.189103 15248 solver.cpp:590] Iteration 1540, lr = 0.00914725
I0705 22:52:22.722885 15248 solver.cpp:243] Iteration 1650, loss = 5.68156
I0705 22:52:22.722992 15248 solver.cpp:259]     Train net output #0: loss = 5.68156 (* 1 = 5.68156 loss)
I0705 22:52:22.723000 15248 solver.cpp:590] Iteration 1650, lr = 0.0090892
I0705 22:52:44.273569 15248 solver.cpp:243] Iteration 1760, loss = 6.13029
I0705 22:52:44.273591 15248 solver.cpp:259]     Train net output #0: loss = 6.13029 (* 1 = 6.13029 loss)
I0705 22:52:44.273597 15248 solver.cpp:590] Iteration 1760, lr = 0.00903152
I0705 22:52:44.862046 15248 solver.cpp:347] Iteration 1764, Testing net (#0)
I0705 22:53:08.384166 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0204327
I0705 22:53:08.384932 15248 solver.cpp:415]     Test net output #1: loss = 6.03787 (* 1 = 6.03787 loss)
I0705 22:53:29.359282 15248 solver.cpp:243] Iteration 1870, loss = 6.04922
I0705 22:53:29.359305 15248 solver.cpp:259]     Train net output #0: loss = 6.04922 (* 1 = 6.04922 loss)
I0705 22:53:29.359311 15248 solver.cpp:590] Iteration 1870, lr = 0.0089742
I0705 22:53:51.001441 15248 solver.cpp:243] Iteration 1980, loss = 6.20795
I0705 22:53:51.001729 15248 solver.cpp:259]     Train net output #0: loss = 6.20795 (* 1 = 6.20795 loss)
I0705 22:53:51.001736 15248 solver.cpp:590] Iteration 1980, lr = 0.00891725
I0705 22:54:12.614580 15248 solver.cpp:243] Iteration 2090, loss = 6.22627
I0705 22:54:12.614603 15248 solver.cpp:259]     Train net output #0: loss = 6.22627 (* 1 = 6.22627 loss)
I0705 22:54:12.614609 15248 solver.cpp:590] Iteration 2090, lr = 0.00886065
I0705 22:54:34.243084 15248 solver.cpp:243] Iteration 2200, loss = 6.0541
I0705 22:54:34.243176 15248 solver.cpp:259]     Train net output #0: loss = 6.0541 (* 1 = 6.0541 loss)
I0705 22:54:34.243183 15248 solver.cpp:590] Iteration 2200, lr = 0.00880442
I0705 22:54:55.864960 15248 solver.cpp:243] Iteration 2310, loss = 5.77444
I0705 22:54:55.864989 15248 solver.cpp:259]     Train net output #0: loss = 5.77444 (* 1 = 5.77444 loss)
I0705 22:54:55.864996 15248 solver.cpp:590] Iteration 2310, lr = 0.00874855
I0705 22:55:17.500032 15248 solver.cpp:243] Iteration 2420, loss = 6.08983
I0705 22:55:17.500124 15248 solver.cpp:259]     Train net output #0: loss = 6.08983 (* 1 = 6.08983 loss)
I0705 22:55:17.500140 15248 solver.cpp:590] Iteration 2420, lr = 0.00869302
I0705 22:55:39.029690 15248 solver.cpp:243] Iteration 2530, loss = 5.44795
I0705 22:55:39.029712 15248 solver.cpp:259]     Train net output #0: loss = 5.44795 (* 1 = 5.44795 loss)
I0705 22:55:39.029717 15248 solver.cpp:590] Iteration 2530, lr = 0.00863785
I0705 22:56:00.574630 15248 solver.cpp:243] Iteration 2640, loss = 5.58344
I0705 22:56:00.574720 15248 solver.cpp:259]     Train net output #0: loss = 5.58344 (* 1 = 5.58344 loss)
I0705 22:56:00.574736 15248 solver.cpp:590] Iteration 2640, lr = 0.00858304
I0705 22:56:01.553833 15248 solver.cpp:347] Iteration 2646, Testing net (#0)
I0705 22:56:15.293290 15267 blocking_queue.cpp:50] Waiting for data
I0705 22:56:26.619530 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0705 22:56:28.135628 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0282452
I0705 22:56:28.135656 15248 solver.cpp:415]     Test net output #1: loss = 5.81411 (* 1 = 5.81411 loss)
I0705 22:56:48.659487 15248 solver.cpp:243] Iteration 2750, loss = 5.51736
I0705 22:56:48.659584 15248 solver.cpp:259]     Train net output #0: loss = 5.51736 (* 1 = 5.51736 loss)
I0705 22:56:48.659601 15248 solver.cpp:590] Iteration 2750, lr = 0.00852857
I0705 22:57:10.240897 15248 solver.cpp:243] Iteration 2860, loss = 5.80566
I0705 22:57:10.240921 15248 solver.cpp:259]     Train net output #0: loss = 5.80566 (* 1 = 5.80566 loss)
I0705 22:57:10.240926 15248 solver.cpp:590] Iteration 2860, lr = 0.00847444
I0705 22:57:31.872630 15248 solver.cpp:243] Iteration 2970, loss = 5.86049
I0705 22:57:31.872730 15248 solver.cpp:259]     Train net output #0: loss = 5.86049 (* 1 = 5.86049 loss)
I0705 22:57:31.872746 15248 solver.cpp:590] Iteration 2970, lr = 0.00842066
I0705 22:57:53.484458 15248 solver.cpp:243] Iteration 3080, loss = 5.69274
I0705 22:57:53.484482 15248 solver.cpp:259]     Train net output #0: loss = 5.69274 (* 1 = 5.69274 loss)
I0705 22:57:53.484488 15248 solver.cpp:590] Iteration 3080, lr = 0.00836722
I0705 22:58:15.079004 15248 solver.cpp:243] Iteration 3190, loss = 5.75854
I0705 22:58:15.079221 15248 solver.cpp:259]     Train net output #0: loss = 5.75854 (* 1 = 5.75854 loss)
I0705 22:58:15.079229 15248 solver.cpp:590] Iteration 3190, lr = 0.00831412
I0705 22:58:36.693584 15248 solver.cpp:243] Iteration 3300, loss = 5.44228
I0705 22:58:36.693608 15248 solver.cpp:259]     Train net output #0: loss = 5.44228 (* 1 = 5.44228 loss)
I0705 22:58:36.693614 15248 solver.cpp:590] Iteration 3300, lr = 0.00826135
I0705 22:58:58.275138 15248 solver.cpp:243] Iteration 3410, loss = 5.45732
I0705 22:58:58.275213 15248 solver.cpp:259]     Train net output #0: loss = 5.45732 (* 1 = 5.45732 loss)
I0705 22:58:58.275219 15248 solver.cpp:590] Iteration 3410, lr = 0.00820892
I0705 22:59:19.877032 15248 solver.cpp:243] Iteration 3520, loss = 5.55337
I0705 22:59:19.877055 15248 solver.cpp:259]     Train net output #0: loss = 5.55337 (* 1 = 5.55337 loss)
I0705 22:59:19.877061 15248 solver.cpp:590] Iteration 3520, lr = 0.00815683
I0705 22:59:21.249380 15248 solver.cpp:347] Iteration 3528, Testing net (#0)
I0705 22:59:46.442392 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0347356
I0705 22:59:46.442495 15248 solver.cpp:415]     Test net output #1: loss = 5.67662 (* 1 = 5.67662 loss)
I0705 23:00:06.563423 15248 solver.cpp:243] Iteration 3630, loss = 5.24635
I0705 23:00:06.563443 15248 solver.cpp:259]     Train net output #0: loss = 5.24635 (* 1 = 5.24635 loss)
I0705 23:00:06.563449 15248 solver.cpp:590] Iteration 3630, lr = 0.00810506
I0705 23:00:28.114168 15248 solver.cpp:243] Iteration 3740, loss = 5.90504
I0705 23:00:28.114261 15248 solver.cpp:259]     Train net output #0: loss = 5.90504 (* 1 = 5.90504 loss)
I0705 23:00:28.114277 15248 solver.cpp:590] Iteration 3740, lr = 0.00805362
I0705 23:00:49.739558 15248 solver.cpp:243] Iteration 3850, loss = 5.33216
I0705 23:00:49.739580 15248 solver.cpp:259]     Train net output #0: loss = 5.33216 (* 1 = 5.33216 loss)
I0705 23:00:49.739586 15248 solver.cpp:590] Iteration 3850, lr = 0.00800251
I0705 23:01:11.368675 15248 solver.cpp:243] Iteration 3960, loss = 5.53586
I0705 23:01:11.368765 15248 solver.cpp:259]     Train net output #0: loss = 5.53586 (* 1 = 5.53586 loss)
I0705 23:01:11.368772 15248 solver.cpp:590] Iteration 3960, lr = 0.00795173
I0705 23:01:32.958406 15248 solver.cpp:243] Iteration 4070, loss = 5.46659
I0705 23:01:32.958428 15248 solver.cpp:259]     Train net output #0: loss = 5.46659 (* 1 = 5.46659 loss)
I0705 23:01:32.958433 15248 solver.cpp:590] Iteration 4070, lr = 0.00790126
I0705 23:01:54.542572 15248 solver.cpp:243] Iteration 4180, loss = 5.71922
I0705 23:01:54.542665 15248 solver.cpp:259]     Train net output #0: loss = 5.71922 (* 1 = 5.71922 loss)
I0705 23:01:54.542681 15248 solver.cpp:590] Iteration 4180, lr = 0.00785112
I0705 23:02:16.093078 15248 solver.cpp:243] Iteration 4290, loss = 5.27113
I0705 23:02:16.093101 15248 solver.cpp:259]     Train net output #0: loss = 5.27113 (* 1 = 5.27113 loss)
I0705 23:02:16.093106 15248 solver.cpp:590] Iteration 4290, lr = 0.00780129
I0705 23:02:37.692206 15248 solver.cpp:243] Iteration 4400, loss = 5.13202
I0705 23:02:37.692301 15248 solver.cpp:259]     Train net output #0: loss = 5.13202 (* 1 = 5.13202 loss)
I0705 23:02:37.692317 15248 solver.cpp:590] Iteration 4400, lr = 0.00775178
I0705 23:02:39.456789 15248 solver.cpp:347] Iteration 4410, Testing net (#0)
I0705 23:03:03.645401 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0441106
I0705 23:03:03.645429 15248 solver.cpp:415]     Test net output #1: loss = 5.59819 (* 1 = 5.59819 loss)
I0705 23:03:23.453186 15248 solver.cpp:243] Iteration 4510, loss = 5.21563
I0705 23:03:23.453294 15248 solver.cpp:259]     Train net output #0: loss = 5.21563 (* 1 = 5.21563 loss)
I0705 23:03:23.453310 15248 solver.cpp:590] Iteration 4510, lr = 0.00770259
I0705 23:03:45.062328 15248 solver.cpp:243] Iteration 4620, loss = 5.47535
I0705 23:03:45.062353 15248 solver.cpp:259]     Train net output #0: loss = 5.47535 (* 1 = 5.47535 loss)
I0705 23:03:45.062358 15248 solver.cpp:590] Iteration 4620, lr = 0.0076537
I0705 23:04:06.688845 15248 solver.cpp:243] Iteration 4730, loss = 6.09824
I0705 23:04:06.689107 15248 solver.cpp:259]     Train net output #0: loss = 6.09824 (* 1 = 6.09824 loss)
I0705 23:04:06.689118 15248 solver.cpp:590] Iteration 4730, lr = 0.00760513
I0705 23:04:28.401216 15248 solver.cpp:243] Iteration 4840, loss = 5.2285
I0705 23:04:28.401237 15248 solver.cpp:259]     Train net output #0: loss = 5.2285 (* 1 = 5.2285 loss)
I0705 23:04:28.401242 15248 solver.cpp:590] Iteration 4840, lr = 0.00755687
I0705 23:04:50.065642 15248 solver.cpp:243] Iteration 4950, loss = 4.93524
I0705 23:04:50.065733 15248 solver.cpp:259]     Train net output #0: loss = 4.93524 (* 1 = 4.93524 loss)
I0705 23:04:50.065739 15248 solver.cpp:590] Iteration 4950, lr = 0.00750891
I0705 23:05:11.660763 15248 solver.cpp:243] Iteration 5060, loss = 4.89395
I0705 23:05:11.660786 15248 solver.cpp:259]     Train net output #0: loss = 4.89395 (* 1 = 4.89395 loss)
I0705 23:05:11.660792 15248 solver.cpp:590] Iteration 5060, lr = 0.00746125
I0705 23:05:33.271566 15248 solver.cpp:243] Iteration 5170, loss = 4.69973
I0705 23:05:33.271675 15248 solver.cpp:259]     Train net output #0: loss = 4.69973 (* 1 = 4.69973 loss)
I0705 23:05:33.271683 15248 solver.cpp:590] Iteration 5170, lr = 0.0074139
I0705 23:05:54.874083 15248 solver.cpp:243] Iteration 5280, loss = 5.27822
I0705 23:05:54.874106 15248 solver.cpp:259]     Train net output #0: loss = 5.27822 (* 1 = 5.27822 loss)
I0705 23:05:54.874112 15248 solver.cpp:590] Iteration 5280, lr = 0.00736685
I0705 23:05:57.031982 15248 solver.cpp:347] Iteration 5292, Testing net (#0)
I0705 23:06:20.671407 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0520433
I0705 23:06:20.671546 15248 solver.cpp:415]     Test net output #1: loss = 5.47281 (* 1 = 5.47281 loss)
I0705 23:06:39.984279 15248 solver.cpp:243] Iteration 5390, loss = 5.04474
I0705 23:06:39.984303 15248 solver.cpp:259]     Train net output #0: loss = 5.04474 (* 1 = 5.04474 loss)
I0705 23:06:39.984308 15248 solver.cpp:590] Iteration 5390, lr = 0.0073201
I0705 23:07:01.527710 15248 solver.cpp:243] Iteration 5500, loss = 5.35639
I0705 23:07:01.527817 15248 solver.cpp:259]     Train net output #0: loss = 5.35639 (* 1 = 5.35639 loss)
I0705 23:07:01.527824 15248 solver.cpp:590] Iteration 5500, lr = 0.00727364
I0705 23:07:23.173941 15248 solver.cpp:243] Iteration 5610, loss = 4.16125
I0705 23:07:23.173962 15248 solver.cpp:259]     Train net output #0: loss = 4.16125 (* 1 = 4.16125 loss)
I0705 23:07:23.173969 15248 solver.cpp:590] Iteration 5610, lr = 0.00722748
I0705 23:07:44.760923 15248 solver.cpp:243] Iteration 5720, loss = 5.16556
I0705 23:07:44.761010 15248 solver.cpp:259]     Train net output #0: loss = 5.16556 (* 1 = 5.16556 loss)
I0705 23:07:44.761025 15248 solver.cpp:590] Iteration 5720, lr = 0.00718161
I0705 23:08:06.399161 15248 solver.cpp:243] Iteration 5830, loss = 4.50562
I0705 23:08:06.399186 15248 solver.cpp:259]     Train net output #0: loss = 4.50562 (* 1 = 4.50562 loss)
I0705 23:08:06.399193 15248 solver.cpp:590] Iteration 5830, lr = 0.00713604
I0705 23:08:27.924525 15248 solver.cpp:243] Iteration 5940, loss = 5.37952
I0705 23:08:27.924618 15248 solver.cpp:259]     Train net output #0: loss = 5.37952 (* 1 = 5.37952 loss)
I0705 23:08:27.924633 15248 solver.cpp:590] Iteration 5940, lr = 0.00709075
I0705 23:08:49.450520 15248 solver.cpp:243] Iteration 6050, loss = 4.78064
I0705 23:08:49.450542 15248 solver.cpp:259]     Train net output #0: loss = 4.78064 (* 1 = 4.78064 loss)
I0705 23:08:49.450548 15248 solver.cpp:590] Iteration 6050, lr = 0.00704575
I0705 23:09:11.101780 15248 solver.cpp:243] Iteration 6160, loss = 5.76049
I0705 23:09:11.101949 15248 solver.cpp:259]     Train net output #0: loss = 5.76049 (* 1 = 5.76049 loss)
I0705 23:09:11.101958 15248 solver.cpp:590] Iteration 6160, lr = 0.00700103
I0705 23:09:13.653288 15248 solver.cpp:347] Iteration 6174, Testing net (#0)
I0705 23:09:36.667824 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0705 23:09:38.774652 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0530048
I0705 23:09:38.774679 15248 solver.cpp:415]     Test net output #1: loss = 5.51774 (* 1 = 5.51774 loss)
I0705 23:09:57.666165 15248 solver.cpp:243] Iteration 6270, loss = 5.04342
I0705 23:09:57.677911 15248 solver.cpp:259]     Train net output #0: loss = 5.04342 (* 1 = 5.04342 loss)
I0705 23:09:57.677919 15248 solver.cpp:590] Iteration 6270, lr = 0.0069566
I0705 23:10:19.233412 15248 solver.cpp:243] Iteration 6380, loss = 5.13727
I0705 23:10:19.233465 15248 solver.cpp:259]     Train net output #0: loss = 5.13727 (* 1 = 5.13727 loss)
I0705 23:10:19.233476 15248 solver.cpp:590] Iteration 6380, lr = 0.00691245
I0705 23:10:40.876240 15248 solver.cpp:243] Iteration 6490, loss = 4.41859
I0705 23:10:40.886912 15248 solver.cpp:259]     Train net output #0: loss = 4.41859 (* 1 = 4.41859 loss)
I0705 23:10:40.886925 15248 solver.cpp:590] Iteration 6490, lr = 0.00686859
I0705 23:11:02.456791 15248 solver.cpp:243] Iteration 6600, loss = 4.24439
I0705 23:11:02.456816 15248 solver.cpp:259]     Train net output #0: loss = 4.24439 (* 1 = 4.24439 loss)
I0705 23:11:02.456822 15248 solver.cpp:590] Iteration 6600, lr = 0.006825
I0705 23:11:24.118001 15248 solver.cpp:243] Iteration 6710, loss = 4.6047
I0705 23:11:24.118142 15248 solver.cpp:259]     Train net output #0: loss = 4.6047 (* 1 = 4.6047 loss)
I0705 23:11:24.118162 15248 solver.cpp:590] Iteration 6710, lr = 0.00678168
I0705 23:11:45.747843 15248 solver.cpp:243] Iteration 6820, loss = 4.606
I0705 23:11:45.747866 15248 solver.cpp:259]     Train net output #0: loss = 4.606 (* 1 = 4.606 loss)
I0705 23:11:45.747872 15248 solver.cpp:590] Iteration 6820, lr = 0.00673864
I0705 23:12:07.352113 15248 solver.cpp:243] Iteration 6930, loss = 4.0944
I0705 23:12:07.352246 15248 solver.cpp:259]     Train net output #0: loss = 4.0944 (* 1 = 4.0944 loss)
I0705 23:12:07.352252 15248 solver.cpp:590] Iteration 6930, lr = 0.00669588
I0705 23:12:28.975086 15248 solver.cpp:243] Iteration 7040, loss = 4.24991
I0705 23:12:28.975109 15248 solver.cpp:259]     Train net output #0: loss = 4.24991 (* 1 = 4.24991 loss)
I0705 23:12:28.975114 15248 solver.cpp:590] Iteration 7040, lr = 0.00665338
I0705 23:12:31.908828 15248 solver.cpp:347] Iteration 7056, Testing net (#0)
I0705 23:12:45.927709 15267 blocking_queue.cpp:50] Waiting for data
I0705 23:12:56.940996 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0508413
I0705 23:12:56.941025 15248 solver.cpp:415]     Test net output #1: loss = 5.62927 (* 1 = 5.62927 loss)
I0705 23:13:15.516796 15248 solver.cpp:243] Iteration 7150, loss = 5.02031
I0705 23:13:15.516819 15248 solver.cpp:259]     Train net output #0: loss = 5.02031 (* 1 = 5.02031 loss)
I0705 23:13:15.516825 15248 solver.cpp:590] Iteration 7150, lr = 0.00661116
I0705 23:13:37.164469 15248 solver.cpp:243] Iteration 7260, loss = 5.25725
I0705 23:13:37.164557 15248 solver.cpp:259]     Train net output #0: loss = 5.25725 (* 1 = 5.25725 loss)
I0705 23:13:37.164564 15248 solver.cpp:590] Iteration 7260, lr = 0.0065692
I0705 23:13:58.761662 15248 solver.cpp:243] Iteration 7370, loss = 4.55288
I0705 23:13:58.761687 15248 solver.cpp:259]     Train net output #0: loss = 4.55288 (* 1 = 4.55288 loss)
I0705 23:13:58.761693 15248 solver.cpp:590] Iteration 7370, lr = 0.00652751
I0705 23:14:20.397018 15248 solver.cpp:243] Iteration 7480, loss = 4.37522
I0705 23:14:20.397114 15248 solver.cpp:259]     Train net output #0: loss = 4.37522 (* 1 = 4.37522 loss)
I0705 23:14:20.397130 15248 solver.cpp:590] Iteration 7480, lr = 0.00648609
I0705 23:14:41.994904 15248 solver.cpp:243] Iteration 7590, loss = 4.46175
I0705 23:14:41.994927 15248 solver.cpp:259]     Train net output #0: loss = 4.46175 (* 1 = 4.46175 loss)
I0705 23:14:41.994933 15248 solver.cpp:590] Iteration 7590, lr = 0.00644492
I0705 23:15:03.558778 15248 solver.cpp:243] Iteration 7700, loss = 4.30423
I0705 23:15:03.558892 15248 solver.cpp:259]     Train net output #0: loss = 4.30423 (* 1 = 4.30423 loss)
I0705 23:15:03.558909 15248 solver.cpp:590] Iteration 7700, lr = 0.00640402
I0705 23:15:25.265548 15248 solver.cpp:243] Iteration 7810, loss = 3.30988
I0705 23:15:25.265573 15248 solver.cpp:259]     Train net output #0: loss = 3.30988 (* 1 = 3.30988 loss)
I0705 23:15:25.265579 15248 solver.cpp:590] Iteration 7810, lr = 0.00636338
I0705 23:15:46.833895 15248 solver.cpp:243] Iteration 7920, loss = 4.20677
I0705 23:15:46.834116 15248 solver.cpp:259]     Train net output #0: loss = 4.20677 (* 1 = 4.20677 loss)
I0705 23:15:46.834125 15248 solver.cpp:590] Iteration 7920, lr = 0.006323
I0705 23:15:50.157910 15248 solver.cpp:347] Iteration 7938, Testing net (#0)
I0705 23:16:14.020695 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0503606
I0705 23:16:14.020736 15248 solver.cpp:415]     Test net output #1: loss = 5.7126 (* 1 = 5.7126 loss)
I0705 23:16:32.167134 15248 solver.cpp:243] Iteration 8030, loss = 4.45963
I0705 23:16:32.167265 15248 solver.cpp:259]     Train net output #0: loss = 4.45963 (* 1 = 4.45963 loss)
I0705 23:16:32.167273 15248 solver.cpp:590] Iteration 8030, lr = 0.00628287
I0705 23:16:53.827932 15248 solver.cpp:243] Iteration 8140, loss = 4.4234
I0705 23:16:53.827955 15248 solver.cpp:259]     Train net output #0: loss = 4.4234 (* 1 = 4.4234 loss)
I0705 23:16:53.827962 15248 solver.cpp:590] Iteration 8140, lr = 0.00624299
I0705 23:17:15.375633 15248 solver.cpp:243] Iteration 8250, loss = 4.31232
I0705 23:17:15.375721 15248 solver.cpp:259]     Train net output #0: loss = 4.31232 (* 1 = 4.31232 loss)
I0705 23:17:15.375727 15248 solver.cpp:590] Iteration 8250, lr = 0.00620337
I0705 23:17:36.964786 15248 solver.cpp:243] Iteration 8360, loss = 3.78951
I0705 23:17:36.964807 15248 solver.cpp:259]     Train net output #0: loss = 3.78951 (* 1 = 3.78951 loss)
I0705 23:17:36.964812 15248 solver.cpp:590] Iteration 8360, lr = 0.00616401
I0705 23:17:58.534914 15248 solver.cpp:243] Iteration 8470, loss = 4.34819
I0705 23:17:58.535007 15248 solver.cpp:259]     Train net output #0: loss = 4.34819 (* 1 = 4.34819 loss)
I0705 23:17:58.535024 15248 solver.cpp:590] Iteration 8470, lr = 0.00612489
I0705 23:18:20.119657 15248 solver.cpp:243] Iteration 8580, loss = 4.43613
I0705 23:18:20.119679 15248 solver.cpp:259]     Train net output #0: loss = 4.43613 (* 1 = 4.43613 loss)
I0705 23:18:20.119685 15248 solver.cpp:590] Iteration 8580, lr = 0.00608602
I0705 23:18:41.794699 15248 solver.cpp:243] Iteration 8690, loss = 4.19096
I0705 23:18:41.794785 15248 solver.cpp:259]     Train net output #0: loss = 4.19096 (* 1 = 4.19096 loss)
I0705 23:18:41.794795 15248 solver.cpp:590] Iteration 8690, lr = 0.00604739
I0705 23:19:03.391798 15248 solver.cpp:243] Iteration 8800, loss = 4.71539
I0705 23:19:03.391821 15248 solver.cpp:259]     Train net output #0: loss = 4.71539 (* 1 = 4.71539 loss)
I0705 23:19:03.391826 15248 solver.cpp:590] Iteration 8800, lr = 0.00600901
I0705 23:19:07.106756 15248 solver.cpp:347] Iteration 8820, Testing net (#0)
I0705 23:19:31.771987 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0497596
I0705 23:19:31.772114 15248 solver.cpp:415]     Test net output #1: loss = 5.70602 (* 1 = 5.70602 loss)
I0705 23:19:49.614294 15248 solver.cpp:243] Iteration 8910, loss = 4.00974
I0705 23:19:49.614316 15248 solver.cpp:259]     Train net output #0: loss = 4.00974 (* 1 = 4.00974 loss)
I0705 23:19:49.614322 15248 solver.cpp:590] Iteration 8910, lr = 0.00597088
I0705 23:20:11.209558 15248 solver.cpp:243] Iteration 9020, loss = 3.73072
I0705 23:20:11.209652 15248 solver.cpp:259]     Train net output #0: loss = 3.73072 (* 1 = 3.73072 loss)
I0705 23:20:11.209661 15248 solver.cpp:590] Iteration 9020, lr = 0.00593298
I0705 23:20:32.755604 15248 solver.cpp:243] Iteration 9130, loss = 4.08852
I0705 23:20:32.755630 15248 solver.cpp:259]     Train net output #0: loss = 4.08852 (* 1 = 4.08852 loss)
I0705 23:20:32.755635 15248 solver.cpp:590] Iteration 9130, lr = 0.00589533
I0705 23:20:54.413497 15248 solver.cpp:243] Iteration 9240, loss = 4.44016
I0705 23:20:54.413602 15248 solver.cpp:259]     Train net output #0: loss = 4.44016 (* 1 = 4.44016 loss)
I0705 23:20:54.413609 15248 solver.cpp:590] Iteration 9240, lr = 0.00585792
I0705 23:21:15.989498 15248 solver.cpp:243] Iteration 9350, loss = 3.57325
I0705 23:21:15.989521 15248 solver.cpp:259]     Train net output #0: loss = 3.57325 (* 1 = 3.57325 loss)
I0705 23:21:15.989527 15248 solver.cpp:590] Iteration 9350, lr = 0.00582074
I0705 23:21:37.647997 15248 solver.cpp:243] Iteration 9460, loss = 4.51467
I0705 23:21:37.648239 15248 solver.cpp:259]     Train net output #0: loss = 4.51467 (* 1 = 4.51467 loss)
I0705 23:21:37.648248 15248 solver.cpp:590] Iteration 9460, lr = 0.0057838
I0705 23:21:59.236965 15248 solver.cpp:243] Iteration 9570, loss = 4.03975
I0705 23:21:59.236989 15248 solver.cpp:259]     Train net output #0: loss = 4.03975 (* 1 = 4.03975 loss)
I0705 23:21:59.236995 15248 solver.cpp:590] Iteration 9570, lr = 0.0057471
I0705 23:22:20.798578 15248 solver.cpp:243] Iteration 9680, loss = 3.15062
I0705 23:22:20.798666 15248 solver.cpp:259]     Train net output #0: loss = 3.15062 (* 1 = 3.15062 loss)
I0705 23:22:20.798672 15248 solver.cpp:590] Iteration 9680, lr = 0.00571062
I0705 23:22:24.924978 15248 solver.cpp:347] Iteration 9702, Testing net (#0)
I0705 23:22:45.729852 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0705 23:22:48.993746 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0435096
I0705 23:22:48.993789 15248 solver.cpp:415]     Test net output #1: loss = 5.90438 (* 1 = 5.90438 loss)
I0705 23:23:06.470263 15248 solver.cpp:243] Iteration 9790, loss = 2.8163
I0705 23:23:06.470357 15248 solver.cpp:259]     Train net output #0: loss = 2.8163 (* 1 = 2.8163 loss)
I0705 23:23:06.470374 15248 solver.cpp:590] Iteration 9790, lr = 0.00567438
I0705 23:23:28.245023 15248 solver.cpp:243] Iteration 9900, loss = 3.90306
I0705 23:23:28.245044 15248 solver.cpp:259]     Train net output #0: loss = 3.90306 (* 1 = 3.90306 loss)
I0705 23:23:28.245050 15248 solver.cpp:590] Iteration 9900, lr = 0.00563837
I0705 23:23:50.036329 15248 solver.cpp:243] Iteration 10010, loss = 4.57882
I0705 23:23:50.036420 15248 solver.cpp:259]     Train net output #0: loss = 4.57882 (* 1 = 4.57882 loss)
I0705 23:23:50.036428 15248 solver.cpp:590] Iteration 10010, lr = 0.00560259
I0705 23:24:11.777981 15248 solver.cpp:243] Iteration 10120, loss = 3.55304
I0705 23:24:11.778010 15248 solver.cpp:259]     Train net output #0: loss = 3.55304 (* 1 = 3.55304 loss)
I0705 23:24:11.778017 15248 solver.cpp:590] Iteration 10120, lr = 0.00556703
I0705 23:24:33.542038 15248 solver.cpp:243] Iteration 10230, loss = 4.12743
I0705 23:24:33.542225 15248 solver.cpp:259]     Train net output #0: loss = 4.12743 (* 1 = 4.12743 loss)
I0705 23:24:33.542245 15248 solver.cpp:590] Iteration 10230, lr = 0.0055317
I0705 23:24:55.371207 15248 solver.cpp:243] Iteration 10340, loss = 4.51993
I0705 23:24:55.371229 15248 solver.cpp:259]     Train net output #0: loss = 4.51993 (* 1 = 4.51993 loss)
I0705 23:24:55.371235 15248 solver.cpp:590] Iteration 10340, lr = 0.00549659
I0705 23:25:16.971626 15248 solver.cpp:243] Iteration 10450, loss = 4.55999
I0705 23:25:16.971758 15248 solver.cpp:259]     Train net output #0: loss = 4.55999 (* 1 = 4.55999 loss)
I0705 23:25:16.971766 15248 solver.cpp:590] Iteration 10450, lr = 0.00546171
I0705 23:25:38.557209 15248 solver.cpp:243] Iteration 10560, loss = 3.07025
I0705 23:25:38.557234 15248 solver.cpp:259]     Train net output #0: loss = 3.07025 (* 1 = 3.07025 loss)
I0705 23:25:38.557240 15248 solver.cpp:590] Iteration 10560, lr = 0.00542705
I0705 23:25:43.172036 15248 solver.cpp:347] Iteration 10584, Testing net (#0)
I0705 23:26:07.625030 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0429087
I0705 23:26:07.625174 15248 solver.cpp:415]     Test net output #1: loss = 5.99906 (* 1 = 5.99906 loss)
I0705 23:26:24.593996 15248 solver.cpp:243] Iteration 10670, loss = 3.75483
I0705 23:26:24.594019 15248 solver.cpp:259]     Train net output #0: loss = 3.75483 (* 1 = 3.75483 loss)
I0705 23:26:24.594027 15248 solver.cpp:590] Iteration 10670, lr = 0.00539261
I0705 23:26:46.167796 15248 solver.cpp:243] Iteration 10780, loss = 3.08941
I0705 23:26:46.168030 15248 solver.cpp:259]     Train net output #0: loss = 3.08941 (* 1 = 3.08941 loss)
I0705 23:26:46.168037 15248 solver.cpp:590] Iteration 10780, lr = 0.00535838
I0705 23:27:07.764566 15248 solver.cpp:243] Iteration 10890, loss = 3.65958
I0705 23:27:07.764592 15248 solver.cpp:259]     Train net output #0: loss = 3.65958 (* 1 = 3.65958 loss)
I0705 23:27:07.764600 15248 solver.cpp:590] Iteration 10890, lr = 0.00532438
I0705 23:27:29.295212 15248 solver.cpp:243] Iteration 11000, loss = 3.08948
I0705 23:27:29.295302 15248 solver.cpp:259]     Train net output #0: loss = 3.08948 (* 1 = 3.08948 loss)
I0705 23:27:29.295310 15248 solver.cpp:590] Iteration 11000, lr = 0.00529059
I0705 23:27:50.970841 15248 solver.cpp:243] Iteration 11110, loss = 3.08521
I0705 23:27:50.970865 15248 solver.cpp:259]     Train net output #0: loss = 3.08521 (* 1 = 3.08521 loss)
I0705 23:27:50.970870 15248 solver.cpp:590] Iteration 11110, lr = 0.00525701
I0705 23:28:12.615427 15248 solver.cpp:243] Iteration 11220, loss = 3.90619
I0705 23:28:12.615559 15248 solver.cpp:259]     Train net output #0: loss = 3.90619 (* 1 = 3.90619 loss)
I0705 23:28:12.615566 15248 solver.cpp:590] Iteration 11220, lr = 0.00522365
I0705 23:28:34.133369 15248 solver.cpp:243] Iteration 11330, loss = 4.17736
I0705 23:28:34.133389 15248 solver.cpp:259]     Train net output #0: loss = 4.17736 (* 1 = 4.17736 loss)
I0705 23:28:34.133394 15248 solver.cpp:590] Iteration 11330, lr = 0.0051905
I0705 23:28:55.743115 15248 solver.cpp:243] Iteration 11440, loss = 3.63793
I0705 23:28:55.743211 15248 solver.cpp:259]     Train net output #0: loss = 3.63793 (* 1 = 3.63793 loss)
I0705 23:28:55.743217 15248 solver.cpp:590] Iteration 11440, lr = 0.00515756
I0705 23:29:00.653405 15248 solver.cpp:347] Iteration 11466, Testing net (#0)
I0705 23:29:02.792693 15267 blocking_queue.cpp:50] Waiting for data
I0705 23:29:27.209167 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0420673
I0705 23:29:27.209262 15248 solver.cpp:415]     Test net output #1: loss = 6.02806 (* 1 = 6.02806 loss)
I0705 23:29:43.809218 15248 solver.cpp:243] Iteration 11550, loss = 3.52667
I0705 23:29:43.809242 15248 solver.cpp:259]     Train net output #0: loss = 3.52667 (* 1 = 3.52667 loss)
I0705 23:29:43.809247 15248 solver.cpp:590] Iteration 11550, lr = 0.00512483
I0705 23:30:05.404510 15248 solver.cpp:243] Iteration 11660, loss = 3.62093
I0705 23:30:05.404603 15248 solver.cpp:259]     Train net output #0: loss = 3.62093 (* 1 = 3.62093 loss)
I0705 23:30:05.404608 15248 solver.cpp:590] Iteration 11660, lr = 0.0050923
I0705 23:30:27.060822 15248 solver.cpp:243] Iteration 11770, loss = 3.37048
I0705 23:30:27.060845 15248 solver.cpp:259]     Train net output #0: loss = 3.37048 (* 1 = 3.37048 loss)
I0705 23:30:27.060853 15248 solver.cpp:590] Iteration 11770, lr = 0.00505998
I0705 23:30:48.600512 15248 solver.cpp:243] Iteration 11880, loss = 3.19763
I0705 23:30:48.600601 15248 solver.cpp:259]     Train net output #0: loss = 3.19763 (* 1 = 3.19763 loss)
I0705 23:30:48.600617 15248 solver.cpp:590] Iteration 11880, lr = 0.00502787
I0705 23:31:10.217540 15248 solver.cpp:243] Iteration 11990, loss = 3.26605
I0705 23:31:10.217563 15248 solver.cpp:259]     Train net output #0: loss = 3.26605 (* 1 = 3.26605 loss)
I0705 23:31:10.217568 15248 solver.cpp:590] Iteration 11990, lr = 0.00499596
I0705 23:31:31.825126 15248 solver.cpp:243] Iteration 12100, loss = 2.23222
I0705 23:31:31.825242 15248 solver.cpp:259]     Train net output #0: loss = 2.23222 (* 1 = 2.23222 loss)
I0705 23:31:31.825249 15248 solver.cpp:590] Iteration 12100, lr = 0.00496426
I0705 23:31:53.402722 15248 solver.cpp:243] Iteration 12210, loss = 3.17523
I0705 23:31:53.402741 15248 solver.cpp:259]     Train net output #0: loss = 3.17523 (* 1 = 3.17523 loss)
I0705 23:31:53.402747 15248 solver.cpp:590] Iteration 12210, lr = 0.00493275
I0705 23:32:15.004536 15248 solver.cpp:243] Iteration 12320, loss = 3.30998
I0705 23:32:15.004647 15248 solver.cpp:259]     Train net output #0: loss = 3.30998 (* 1 = 3.30998 loss)
I0705 23:32:15.004655 15248 solver.cpp:590] Iteration 12320, lr = 0.00490145
I0705 23:32:20.296157 15248 solver.cpp:347] Iteration 12348, Testing net (#0)
I0705 23:32:45.424275 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0382212
I0705 23:32:45.424907 15248 solver.cpp:415]     Test net output #1: loss = 6.14787 (* 1 = 6.14787 loss)
I0705 23:33:01.633240 15248 solver.cpp:243] Iteration 12430, loss = 2.01072
I0705 23:33:01.633265 15248 solver.cpp:259]     Train net output #0: loss = 2.01072 (* 1 = 2.01072 loss)
I0705 23:33:01.633270 15248 solver.cpp:590] Iteration 12430, lr = 0.00487034
I0705 23:33:23.174067 15248 solver.cpp:243] Iteration 12540, loss = 3.08063
I0705 23:33:23.174155 15248 solver.cpp:259]     Train net output #0: loss = 3.08063 (* 1 = 3.08063 loss)
I0705 23:33:23.174172 15248 solver.cpp:590] Iteration 12540, lr = 0.00483943
I0705 23:33:44.784315 15248 solver.cpp:243] Iteration 12650, loss = 2.97377
I0705 23:33:44.784342 15248 solver.cpp:259]     Train net output #0: loss = 2.97377 (* 1 = 2.97377 loss)
I0705 23:33:44.784348 15248 solver.cpp:590] Iteration 12650, lr = 0.00480872
I0705 23:34:06.376142 15248 solver.cpp:243] Iteration 12760, loss = 2.93182
I0705 23:34:06.376233 15248 solver.cpp:259]     Train net output #0: loss = 2.93182 (* 1 = 2.93182 loss)
I0705 23:34:06.376240 15248 solver.cpp:590] Iteration 12760, lr = 0.0047782
I0705 23:34:28.074440 15248 solver.cpp:243] Iteration 12870, loss = 3.70257
I0705 23:34:28.074465 15248 solver.cpp:259]     Train net output #0: loss = 3.70257 (* 1 = 3.70257 loss)
I0705 23:34:28.074470 15248 solver.cpp:590] Iteration 12870, lr = 0.00474788
I0705 23:34:49.642976 15248 solver.cpp:243] Iteration 12980, loss = 3.75331
I0705 23:34:49.643069 15248 solver.cpp:259]     Train net output #0: loss = 3.75331 (* 1 = 3.75331 loss)
I0705 23:34:49.643086 15248 solver.cpp:590] Iteration 12980, lr = 0.00471775
I0705 23:35:11.203665 15248 solver.cpp:243] Iteration 13090, loss = 3.51794
I0705 23:35:11.203687 15248 solver.cpp:259]     Train net output #0: loss = 3.51794 (* 1 = 3.51794 loss)
I0705 23:35:11.203693 15248 solver.cpp:590] Iteration 13090, lr = 0.00468781
I0705 23:35:32.860036 15248 solver.cpp:243] Iteration 13200, loss = 3.52938
I0705 23:35:32.860129 15248 solver.cpp:259]     Train net output #0: loss = 3.52938 (* 1 = 3.52938 loss)
I0705 23:35:32.860146 15248 solver.cpp:590] Iteration 13200, lr = 0.00465806
I0705 23:35:38.530545 15248 solver.cpp:347] Iteration 13230, Testing net (#0)
I0705 23:35:59.552269 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0705 23:36:01.437544 15267 blocking_queue.cpp:50] Waiting for data
I0705 23:36:03.929795 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0331731
I0705 23:36:03.929882 15248 solver.cpp:415]     Test net output #1: loss = 6.37477 (* 1 = 6.37477 loss)
I0705 23:36:19.791411 15248 solver.cpp:243] Iteration 13310, loss = 3.31915
I0705 23:36:19.791436 15248 solver.cpp:259]     Train net output #0: loss = 3.31915 (* 1 = 3.31915 loss)
I0705 23:36:19.791442 15248 solver.cpp:590] Iteration 13310, lr = 0.00462849
I0705 23:36:41.461412 15248 solver.cpp:243] Iteration 13420, loss = 2.24904
I0705 23:36:41.461493 15248 solver.cpp:259]     Train net output #0: loss = 2.24904 (* 1 = 2.24904 loss)
I0705 23:36:41.461500 15248 solver.cpp:590] Iteration 13420, lr = 0.00459912
I0705 23:37:03.040055 15248 solver.cpp:243] Iteration 13530, loss = 2.62886
I0705 23:37:03.040079 15248 solver.cpp:259]     Train net output #0: loss = 2.62886 (* 1 = 2.62886 loss)
I0705 23:37:03.040086 15248 solver.cpp:590] Iteration 13530, lr = 0.00456993
I0705 23:37:24.680732 15248 solver.cpp:243] Iteration 13640, loss = 3.28311
I0705 23:37:24.680879 15248 solver.cpp:259]     Train net output #0: loss = 3.28311 (* 1 = 3.28311 loss)
I0705 23:37:24.680887 15248 solver.cpp:590] Iteration 13640, lr = 0.00454093
I0705 23:37:46.323297 15248 solver.cpp:243] Iteration 13750, loss = 3.24501
I0705 23:37:46.323320 15248 solver.cpp:259]     Train net output #0: loss = 3.24501 (* 1 = 3.24501 loss)
I0705 23:37:46.323326 15248 solver.cpp:590] Iteration 13750, lr = 0.00451211
I0705 23:38:07.860052 15248 solver.cpp:243] Iteration 13860, loss = 2.8573
I0705 23:38:07.861454 15248 solver.cpp:259]     Train net output #0: loss = 2.8573 (* 1 = 2.8573 loss)
I0705 23:38:07.861462 15248 solver.cpp:590] Iteration 13860, lr = 0.00448348
I0705 23:38:29.495044 15248 solver.cpp:243] Iteration 13970, loss = 3.68318
I0705 23:38:29.495069 15248 solver.cpp:259]     Train net output #0: loss = 3.68318 (* 1 = 3.68318 loss)
I0705 23:38:29.495075 15248 solver.cpp:590] Iteration 13970, lr = 0.00445502
I0705 23:38:51.134832 15248 solver.cpp:243] Iteration 14080, loss = 2.71457
I0705 23:38:51.134924 15248 solver.cpp:259]     Train net output #0: loss = 2.71457 (* 1 = 2.71457 loss)
I0705 23:38:51.134940 15248 solver.cpp:590] Iteration 14080, lr = 0.00442675
I0705 23:38:57.216621 15248 solver.cpp:347] Iteration 14112, Testing net (#0)
I0705 23:39:25.262715 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0362981
I0705 23:39:25.262812 15248 solver.cpp:415]     Test net output #1: loss = 6.2746 (* 1 = 6.2746 loss)
I0705 23:39:40.684321 15248 solver.cpp:243] Iteration 14190, loss = 2.71783
I0705 23:39:40.684346 15248 solver.cpp:259]     Train net output #0: loss = 2.71783 (* 1 = 2.71783 loss)
I0705 23:39:40.684352 15248 solver.cpp:590] Iteration 14190, lr = 0.00439866
I0705 23:40:02.441964 15248 solver.cpp:243] Iteration 14300, loss = 3.73859
I0705 23:40:02.442044 15248 solver.cpp:259]     Train net output #0: loss = 3.73859 (* 1 = 3.73859 loss)
I0705 23:40:02.442059 15248 solver.cpp:590] Iteration 14300, lr = 0.00437074
I0705 23:40:24.069413 15248 solver.cpp:243] Iteration 14410, loss = 2.98009
I0705 23:40:24.069435 15248 solver.cpp:259]     Train net output #0: loss = 2.98009 (* 1 = 2.98009 loss)
I0705 23:40:24.069442 15248 solver.cpp:590] Iteration 14410, lr = 0.004343
I0705 23:40:45.719233 15248 solver.cpp:243] Iteration 14520, loss = 3.33632
I0705 23:40:45.719323 15248 solver.cpp:259]     Train net output #0: loss = 3.33632 (* 1 = 3.33632 loss)
I0705 23:40:45.719329 15248 solver.cpp:590] Iteration 14520, lr = 0.00431544
I0705 23:41:07.247685 15248 solver.cpp:243] Iteration 14630, loss = 3.4722
I0705 23:41:07.247709 15248 solver.cpp:259]     Train net output #0: loss = 3.4722 (* 1 = 3.4722 loss)
I0705 23:41:07.247716 15248 solver.cpp:590] Iteration 14630, lr = 0.00428805
I0705 23:41:28.789613 15248 solver.cpp:243] Iteration 14740, loss = 2.90529
I0705 23:41:28.789705 15248 solver.cpp:259]     Train net output #0: loss = 2.90529 (* 1 = 2.90529 loss)
I0705 23:41:28.789721 15248 solver.cpp:590] Iteration 14740, lr = 0.00426084
I0705 23:41:50.421156 15248 solver.cpp:243] Iteration 14850, loss = 2.96908
I0705 23:41:50.421180 15248 solver.cpp:259]     Train net output #0: loss = 2.96908 (* 1 = 2.96908 loss)
I0705 23:41:50.421186 15248 solver.cpp:590] Iteration 14850, lr = 0.0042338
I0705 23:42:12.025023 15248 solver.cpp:243] Iteration 14960, loss = 3.40235
I0705 23:42:12.025111 15248 solver.cpp:259]     Train net output #0: loss = 3.40235 (* 1 = 3.40235 loss)
I0705 23:42:12.025128 15248 solver.cpp:590] Iteration 14960, lr = 0.00420693
I0705 23:42:18.480208 15248 solver.cpp:347] Iteration 14994, Testing net (#0)
I0705 23:42:42.366678 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0403846
I0705 23:42:42.366814 15248 solver.cpp:415]     Test net output #1: loss = 6.23128 (* 1 = 6.23128 loss)
I0705 23:42:57.532035 15248 solver.cpp:243] Iteration 15070, loss = 2.83623
I0705 23:42:57.532058 15248 solver.cpp:259]     Train net output #0: loss = 2.83623 (* 1 = 2.83623 loss)
I0705 23:42:57.532063 15248 solver.cpp:590] Iteration 15070, lr = 0.00418023
I0705 23:43:19.221665 15248 solver.cpp:243] Iteration 15180, loss = 2.64521
I0705 23:43:19.221771 15248 solver.cpp:259]     Train net output #0: loss = 2.64521 (* 1 = 2.64521 loss)
I0705 23:43:19.221788 15248 solver.cpp:590] Iteration 15180, lr = 0.0041537
I0705 23:43:40.796293 15248 solver.cpp:243] Iteration 15290, loss = 3.17011
I0705 23:43:40.796317 15248 solver.cpp:259]     Train net output #0: loss = 3.17011 (* 1 = 3.17011 loss)
I0705 23:43:40.796324 15248 solver.cpp:590] Iteration 15290, lr = 0.00412734
I0705 23:44:02.453176 15248 solver.cpp:243] Iteration 15400, loss = 2.77987
I0705 23:44:02.473785 15248 solver.cpp:259]     Train net output #0: loss = 2.77987 (* 1 = 2.77987 loss)
I0705 23:44:02.473794 15248 solver.cpp:590] Iteration 15400, lr = 0.00410115
I0705 23:44:24.044832 15248 solver.cpp:243] Iteration 15510, loss = 1.94041
I0705 23:44:24.044857 15248 solver.cpp:259]     Train net output #0: loss = 1.94041 (* 1 = 1.94041 loss)
I0705 23:44:24.044862 15248 solver.cpp:590] Iteration 15510, lr = 0.00407512
I0705 23:44:45.801219 15248 solver.cpp:243] Iteration 15620, loss = 1.96067
I0705 23:44:45.801501 15248 solver.cpp:259]     Train net output #0: loss = 1.96067 (* 1 = 1.96067 loss)
I0705 23:44:45.801508 15248 solver.cpp:590] Iteration 15620, lr = 0.00404926
I0705 23:45:07.374065 15248 solver.cpp:243] Iteration 15730, loss = 2.60648
I0705 23:45:07.374089 15248 solver.cpp:259]     Train net output #0: loss = 2.60648 (* 1 = 2.60648 loss)
I0705 23:45:07.374094 15248 solver.cpp:590] Iteration 15730, lr = 0.00402356
I0705 23:45:28.894523 15248 solver.cpp:243] Iteration 15840, loss = 3.1857
I0705 23:45:28.894614 15248 solver.cpp:259]     Train net output #0: loss = 3.1857 (* 1 = 3.1857 loss)
I0705 23:45:28.894630 15248 solver.cpp:590] Iteration 15840, lr = 0.00399803
I0705 23:45:35.814903 15248 solver.cpp:347] Iteration 15876, Testing net (#0)
I0705 23:46:00.158419 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0370192
I0705 23:46:00.158498 15248 solver.cpp:415]     Test net output #1: loss = 6.23734 (* 1 = 6.23734 loss)
I0705 23:46:14.958943 15248 solver.cpp:243] Iteration 15950, loss = 3.0401
I0705 23:46:14.958967 15248 solver.cpp:259]     Train net output #0: loss = 3.0401 (* 1 = 3.0401 loss)
I0705 23:46:14.958973 15248 solver.cpp:590] Iteration 15950, lr = 0.00397265
I0705 23:46:36.575011 15248 solver.cpp:243] Iteration 16060, loss = 2.37355
I0705 23:46:36.575235 15248 solver.cpp:259]     Train net output #0: loss = 2.37355 (* 1 = 2.37355 loss)
I0705 23:46:36.575243 15248 solver.cpp:590] Iteration 16060, lr = 0.00394744
I0705 23:46:58.171921 15248 solver.cpp:243] Iteration 16170, loss = 2.6054
I0705 23:46:58.171982 15248 solver.cpp:259]     Train net output #0: loss = 2.6054 (* 1 = 2.6054 loss)
I0705 23:46:58.171996 15248 solver.cpp:590] Iteration 16170, lr = 0.00392239
I0705 23:47:19.834249 15248 solver.cpp:243] Iteration 16280, loss = 2.1585
I0705 23:47:19.834650 15248 solver.cpp:259]     Train net output #0: loss = 2.1585 (* 1 = 2.1585 loss)
I0705 23:47:19.834661 15248 solver.cpp:590] Iteration 16280, lr = 0.0038975
I0705 23:47:41.350757 15248 solver.cpp:243] Iteration 16390, loss = 2.26305
I0705 23:47:41.350778 15248 solver.cpp:259]     Train net output #0: loss = 2.26305 (* 1 = 2.26305 loss)
I0705 23:47:41.350785 15248 solver.cpp:590] Iteration 16390, lr = 0.00387276
I0705 23:48:02.952638 15248 solver.cpp:243] Iteration 16500, loss = 2.25975
I0705 23:48:02.952729 15248 solver.cpp:259]     Train net output #0: loss = 2.25975 (* 1 = 2.25975 loss)
I0705 23:48:02.952735 15248 solver.cpp:590] Iteration 16500, lr = 0.00384819
I0705 23:48:24.640450 15248 solver.cpp:243] Iteration 16610, loss = 2.72891
I0705 23:48:24.640471 15248 solver.cpp:259]     Train net output #0: loss = 2.72891 (* 1 = 2.72891 loss)
I0705 23:48:24.640477 15248 solver.cpp:590] Iteration 16610, lr = 0.00382376
I0705 23:48:46.265666 15248 solver.cpp:243] Iteration 16720, loss = 2.42049
I0705 23:48:46.265799 15248 solver.cpp:259]     Train net output #0: loss = 2.42049 (* 1 = 2.42049 loss)
I0705 23:48:46.265807 15248 solver.cpp:590] Iteration 16720, lr = 0.0037995
I0705 23:48:53.576452 15248 solver.cpp:347] Iteration 16758, Testing net (#0)
I0705 23:49:13.211549 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0705 23:49:16.116878 15267 blocking_queue.cpp:50] Waiting for data
I0705 23:49:19.152204 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0394231
I0705 23:49:19.152330 15248 solver.cpp:415]     Test net output #1: loss = 6.31743 (* 1 = 6.31743 loss)
I0705 23:49:33.487298 15248 solver.cpp:243] Iteration 16830, loss = 2.11479
I0705 23:49:33.487323 15248 solver.cpp:259]     Train net output #0: loss = 2.11479 (* 1 = 2.11479 loss)
I0705 23:49:33.487329 15248 solver.cpp:590] Iteration 16830, lr = 0.00377538
I0705 23:49:55.066237 15248 solver.cpp:243] Iteration 16940, loss = 2.39591
I0705 23:49:55.066334 15248 solver.cpp:259]     Train net output #0: loss = 2.39591 (* 1 = 2.39591 loss)
I0705 23:49:55.066341 15248 solver.cpp:590] Iteration 16940, lr = 0.00375142
I0705 23:50:16.679210 15248 solver.cpp:243] Iteration 17050, loss = 2.17544
I0705 23:50:16.679234 15248 solver.cpp:259]     Train net output #0: loss = 2.17544 (* 1 = 2.17544 loss)
I0705 23:50:16.679240 15248 solver.cpp:590] Iteration 17050, lr = 0.00372762
I0705 23:50:38.328397 15248 solver.cpp:243] Iteration 17160, loss = 2.10259
I0705 23:50:38.328619 15248 solver.cpp:259]     Train net output #0: loss = 2.10259 (* 1 = 2.10259 loss)
I0705 23:50:38.328626 15248 solver.cpp:590] Iteration 17160, lr = 0.00370396
I0705 23:50:59.902496 15248 solver.cpp:243] Iteration 17270, loss = 3.25421
I0705 23:50:59.902519 15248 solver.cpp:259]     Train net output #0: loss = 3.25421 (* 1 = 3.25421 loss)
I0705 23:50:59.902525 15248 solver.cpp:590] Iteration 17270, lr = 0.00368045
I0705 23:51:21.657910 15248 solver.cpp:243] Iteration 17380, loss = 1.64887
I0705 23:51:21.658188 15248 solver.cpp:259]     Train net output #0: loss = 1.64887 (* 1 = 1.64887 loss)
I0705 23:51:21.658196 15248 solver.cpp:590] Iteration 17380, lr = 0.0036571
I0705 23:51:43.186502 15248 solver.cpp:243] Iteration 17490, loss = 3.30993
I0705 23:51:43.186527 15248 solver.cpp:259]     Train net output #0: loss = 3.30993 (* 1 = 3.30993 loss)
I0705 23:51:43.186532 15248 solver.cpp:590] Iteration 17490, lr = 0.00363389
I0705 23:52:04.911532 15248 solver.cpp:243] Iteration 17600, loss = 2.04607
I0705 23:52:04.911624 15248 solver.cpp:259]     Train net output #0: loss = 2.04607 (* 1 = 2.04607 loss)
I0705 23:52:04.911631 15248 solver.cpp:590] Iteration 17600, lr = 0.00361082
I0705 23:52:12.573554 15248 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_17640.caffemodel
I0705 23:52:34.123486 15248 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_17640.solverstate
I0705 23:52:36.858223 15248 solver.cpp:347] Iteration 17640, Testing net (#0)
I0705 23:53:03.528753 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0395433
I0705 23:53:03.528781 15248 solver.cpp:415]     Test net output #1: loss = 6.35354 (* 1 = 6.35354 loss)
I0705 23:53:17.376785 15248 solver.cpp:243] Iteration 17710, loss = 1.44782
I0705 23:53:17.376878 15248 solver.cpp:259]     Train net output #0: loss = 1.44782 (* 1 = 1.44782 loss)
I0705 23:53:17.376894 15248 solver.cpp:590] Iteration 17710, lr = 0.00358791
I0705 23:53:38.913130 15248 solver.cpp:243] Iteration 17820, loss = 1.4742
I0705 23:53:38.913154 15248 solver.cpp:259]     Train net output #0: loss = 1.47419 (* 1 = 1.47419 loss)
I0705 23:53:38.913161 15248 solver.cpp:590] Iteration 17820, lr = 0.00356514
I0705 23:54:00.620820 15248 solver.cpp:243] Iteration 17930, loss = 2.1439
I0705 23:54:00.620888 15248 solver.cpp:259]     Train net output #0: loss = 2.1439 (* 1 = 2.1439 loss)
I0705 23:54:00.620894 15248 solver.cpp:590] Iteration 17930, lr = 0.00354251
I0705 23:54:22.250722 15248 solver.cpp:243] Iteration 18040, loss = 2.58348
I0705 23:54:22.250743 15248 solver.cpp:259]     Train net output #0: loss = 2.58348 (* 1 = 2.58348 loss)
I0705 23:54:22.250749 15248 solver.cpp:590] Iteration 18040, lr = 0.00352003
I0705 23:54:43.784135 15248 solver.cpp:243] Iteration 18150, loss = 1.69064
I0705 23:54:43.784281 15248 solver.cpp:259]     Train net output #0: loss = 1.69064 (* 1 = 1.69064 loss)
I0705 23:54:43.784289 15248 solver.cpp:590] Iteration 18150, lr = 0.00349769
I0705 23:55:05.555292 15248 solver.cpp:243] Iteration 18260, loss = 1.52612
I0705 23:55:05.555316 15248 solver.cpp:259]     Train net output #0: loss = 1.52612 (* 1 = 1.52612 loss)
I0705 23:55:05.555322 15248 solver.cpp:590] Iteration 18260, lr = 0.00347549
I0705 23:55:27.084905 15248 solver.cpp:243] Iteration 18370, loss = 2.36591
I0705 23:55:27.085170 15248 solver.cpp:259]     Train net output #0: loss = 2.36591 (* 1 = 2.36591 loss)
I0705 23:55:27.085177 15248 solver.cpp:590] Iteration 18370, lr = 0.00345344
I0705 23:55:48.763340 15248 solver.cpp:243] Iteration 18480, loss = 3.15277
I0705 23:55:48.763365 15248 solver.cpp:259]     Train net output #0: loss = 3.15277 (* 1 = 3.15277 loss)
I0705 23:55:48.763370 15248 solver.cpp:590] Iteration 18480, lr = 0.00343152
I0705 23:55:56.762035 15248 solver.cpp:347] Iteration 18522, Testing net (#0)
I0705 23:56:21.854773 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0408654
I0705 23:56:21.854856 15248 solver.cpp:415]     Test net output #1: loss = 6.40309 (* 1 = 6.40309 loss)
I0705 23:56:35.306571 15248 solver.cpp:243] Iteration 18590, loss = 2.66021
I0705 23:56:35.306594 15248 solver.cpp:259]     Train net output #0: loss = 2.66021 (* 1 = 2.66021 loss)
I0705 23:56:35.306601 15248 solver.cpp:590] Iteration 18590, lr = 0.00340974
I0705 23:56:56.997987 15248 solver.cpp:243] Iteration 18700, loss = 1.98882
I0705 23:56:56.998112 15248 solver.cpp:259]     Train net output #0: loss = 1.98882 (* 1 = 1.98882 loss)
I0705 23:56:56.998121 15248 solver.cpp:590] Iteration 18700, lr = 0.0033881
I0705 23:57:18.773996 15248 solver.cpp:243] Iteration 18810, loss = 2.15844
I0705 23:57:18.774020 15248 solver.cpp:259]     Train net output #0: loss = 2.15844 (* 1 = 2.15844 loss)
I0705 23:57:18.774026 15248 solver.cpp:590] Iteration 18810, lr = 0.0033666
I0705 23:57:40.285719 15248 solver.cpp:243] Iteration 18920, loss = 2.51797
I0705 23:57:40.285810 15248 solver.cpp:259]     Train net output #0: loss = 2.51797 (* 1 = 2.51797 loss)
I0705 23:57:40.285817 15248 solver.cpp:590] Iteration 18920, lr = 0.00334524
I0705 23:58:02.138842 15248 solver.cpp:243] Iteration 19030, loss = 3.3209
I0705 23:58:02.138890 15248 solver.cpp:259]     Train net output #0: loss = 3.3209 (* 1 = 3.3209 loss)
I0705 23:58:02.138900 15248 solver.cpp:590] Iteration 19030, lr = 0.00332401
I0705 23:58:23.684681 15248 solver.cpp:243] Iteration 19140, loss = 1.88126
I0705 23:58:23.684772 15248 solver.cpp:259]     Train net output #0: loss = 1.88126 (* 1 = 1.88126 loss)
I0705 23:58:23.684779 15248 solver.cpp:590] Iteration 19140, lr = 0.00330291
I0705 23:58:45.216286 15248 solver.cpp:243] Iteration 19250, loss = 2.33898
I0705 23:58:45.216310 15248 solver.cpp:259]     Train net output #0: loss = 2.33898 (* 1 = 2.33898 loss)
I0705 23:58:45.216315 15248 solver.cpp:590] Iteration 19250, lr = 0.00328195
I0705 23:59:06.814489 15248 solver.cpp:243] Iteration 19360, loss = 1.86962
I0705 23:59:06.814581 15248 solver.cpp:259]     Train net output #0: loss = 1.86962 (* 1 = 1.86962 loss)
I0705 23:59:06.814589 15248 solver.cpp:590] Iteration 19360, lr = 0.00326112
I0705 23:59:15.201300 15248 solver.cpp:347] Iteration 19404, Testing net (#0)
I0705 23:59:43.136059 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0432692
I0705 23:59:43.136168 15248 solver.cpp:415]     Test net output #1: loss = 6.39106 (* 1 = 6.39106 loss)
I0705 23:59:56.252265 15248 solver.cpp:243] Iteration 19470, loss = 2.1576
I0705 23:59:56.252290 15248 solver.cpp:259]     Train net output #0: loss = 2.1576 (* 1 = 2.1576 loss)
I0705 23:59:56.252296 15248 solver.cpp:590] Iteration 19470, lr = 0.00324043
I0706 00:00:18.085774 15248 solver.cpp:243] Iteration 19580, loss = 2.27439
I0706 00:00:18.085865 15248 solver.cpp:259]     Train net output #0: loss = 2.27439 (* 1 = 2.27439 loss)
I0706 00:00:18.085881 15248 solver.cpp:590] Iteration 19580, lr = 0.00321986
I0706 00:00:39.586508 15248 solver.cpp:243] Iteration 19690, loss = 1.69973
I0706 00:00:39.586537 15248 solver.cpp:259]     Train net output #0: loss = 1.69972 (* 1 = 1.69972 loss)
I0706 00:00:39.586544 15248 solver.cpp:590] Iteration 19690, lr = 0.00319943
I0706 00:01:01.696038 15248 solver.cpp:243] Iteration 19800, loss = 1.52671
I0706 00:01:01.696151 15248 solver.cpp:259]     Train net output #0: loss = 1.52671 (* 1 = 1.52671 loss)
I0706 00:01:01.696158 15248 solver.cpp:590] Iteration 19800, lr = 0.00317912
I0706 00:01:23.250605 15248 solver.cpp:243] Iteration 19910, loss = 1.179
I0706 00:01:23.250632 15248 solver.cpp:259]     Train net output #0: loss = 1.179 (* 1 = 1.179 loss)
I0706 00:01:23.250638 15248 solver.cpp:590] Iteration 19910, lr = 0.00315895
I0706 00:01:45.288261 15248 solver.cpp:243] Iteration 20020, loss = 1.08577
I0706 00:01:45.288522 15248 solver.cpp:259]     Train net output #0: loss = 1.08577 (* 1 = 1.08577 loss)
I0706 00:01:45.288529 15248 solver.cpp:590] Iteration 20020, lr = 0.0031389
I0706 00:02:07.373944 15248 solver.cpp:243] Iteration 20130, loss = 1.8236
I0706 00:02:07.373965 15248 solver.cpp:259]     Train net output #0: loss = 1.8236 (* 1 = 1.8236 loss)
I0706 00:02:07.373970 15248 solver.cpp:590] Iteration 20130, lr = 0.00311898
I0706 00:02:29.032060 15248 solver.cpp:243] Iteration 20240, loss = 2.76442
I0706 00:02:29.032152 15248 solver.cpp:259]     Train net output #0: loss = 2.76442 (* 1 = 2.76442 loss)
I0706 00:02:29.032169 15248 solver.cpp:590] Iteration 20240, lr = 0.00309918
I0706 00:02:38.198073 15248 solver.cpp:347] Iteration 20286, Testing net (#0)
I0706 00:02:44.652160 15267 blocking_queue.cpp:50] Waiting for data
I0706 00:02:57.977804 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 00:03:05.057173 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0435096
I0706 00:03:05.057312 15248 solver.cpp:415]     Test net output #1: loss = 6.42336 (* 1 = 6.42336 loss)
I0706 00:03:18.573282 15248 solver.cpp:243] Iteration 20350, loss = 1.37729
I0706 00:03:18.573305 15248 solver.cpp:259]     Train net output #0: loss = 1.37729 (* 1 = 1.37729 loss)
I0706 00:03:18.573312 15248 solver.cpp:590] Iteration 20350, lr = 0.00307952
I0706 00:03:40.080247 15248 solver.cpp:243] Iteration 20460, loss = 1.70357
I0706 00:03:40.080339 15248 solver.cpp:259]     Train net output #0: loss = 1.70357 (* 1 = 1.70357 loss)
I0706 00:03:40.080355 15248 solver.cpp:590] Iteration 20460, lr = 0.00305997
I0706 00:04:02.119916 15248 solver.cpp:243] Iteration 20570, loss = 1.41121
I0706 00:04:02.119972 15248 solver.cpp:259]     Train net output #0: loss = 1.41121 (* 1 = 1.41121 loss)
I0706 00:04:02.119987 15248 solver.cpp:590] Iteration 20570, lr = 0.00304055
I0706 00:04:23.672796 15248 solver.cpp:243] Iteration 20680, loss = 1.29442
I0706 00:04:23.672883 15248 solver.cpp:259]     Train net output #0: loss = 1.29442 (* 1 = 1.29442 loss)
I0706 00:04:23.672888 15248 solver.cpp:590] Iteration 20680, lr = 0.00302126
I0706 00:04:45.637960 15248 solver.cpp:243] Iteration 20790, loss = 1.8483
I0706 00:04:45.637984 15248 solver.cpp:259]     Train net output #0: loss = 1.84829 (* 1 = 1.84829 loss)
I0706 00:04:45.637990 15248 solver.cpp:590] Iteration 20790, lr = 0.00300208
I0706 00:05:07.836982 15248 solver.cpp:243] Iteration 20900, loss = 1.82876
I0706 00:05:07.837072 15248 solver.cpp:259]     Train net output #0: loss = 1.82876 (* 1 = 1.82876 loss)
I0706 00:05:07.837080 15248 solver.cpp:590] Iteration 20900, lr = 0.00298303
I0706 00:05:29.271500 15248 solver.cpp:243] Iteration 21010, loss = 2.27728
I0706 00:05:29.271524 15248 solver.cpp:259]     Train net output #0: loss = 2.27728 (* 1 = 2.27728 loss)
I0706 00:05:29.271529 15248 solver.cpp:590] Iteration 21010, lr = 0.0029641
I0706 00:05:51.080432 15248 solver.cpp:243] Iteration 21120, loss = 2.60527
I0706 00:05:51.080523 15248 solver.cpp:259]     Train net output #0: loss = 2.60527 (* 1 = 2.60527 loss)
I0706 00:05:51.080539 15248 solver.cpp:590] Iteration 21120, lr = 0.00294529
I0706 00:06:00.283879 15248 solver.cpp:347] Iteration 21168, Testing net (#0)
I0706 00:06:26.277315 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0405048
I0706 00:06:26.277462 15248 solver.cpp:415]     Test net output #1: loss = 6.47248 (* 1 = 6.47248 loss)
I0706 00:06:38.534510 15248 solver.cpp:243] Iteration 21230, loss = 0.938359
I0706 00:06:38.534533 15248 solver.cpp:259]     Train net output #0: loss = 0.938358 (* 1 = 0.938358 loss)
I0706 00:06:38.534539 15248 solver.cpp:590] Iteration 21230, lr = 0.0029266
I0706 00:07:00.112277 15248 solver.cpp:243] Iteration 21340, loss = 2.25606
I0706 00:07:00.112503 15248 solver.cpp:259]     Train net output #0: loss = 2.25606 (* 1 = 2.25606 loss)
I0706 00:07:00.112510 15248 solver.cpp:590] Iteration 21340, lr = 0.00290802
I0706 00:07:21.919163 15248 solver.cpp:243] Iteration 21450, loss = 0.974279
I0706 00:07:21.919189 15248 solver.cpp:259]     Train net output #0: loss = 0.974278 (* 1 = 0.974278 loss)
I0706 00:07:21.919196 15248 solver.cpp:590] Iteration 21450, lr = 0.00288957
I0706 00:07:43.999259 15248 solver.cpp:243] Iteration 21560, loss = 2.24499
I0706 00:07:43.999366 15248 solver.cpp:259]     Train net output #0: loss = 2.24499 (* 1 = 2.24499 loss)
I0706 00:07:43.999373 15248 solver.cpp:590] Iteration 21560, lr = 0.00287123
I0706 00:08:05.911375 15248 solver.cpp:243] Iteration 21670, loss = 1.07644
I0706 00:08:05.911401 15248 solver.cpp:259]     Train net output #0: loss = 1.07644 (* 1 = 1.07644 loss)
I0706 00:08:05.911406 15248 solver.cpp:590] Iteration 21670, lr = 0.00285301
I0706 00:08:27.512979 15248 solver.cpp:243] Iteration 21780, loss = 1.09758
I0706 00:08:27.513072 15248 solver.cpp:259]     Train net output #0: loss = 1.09758 (* 1 = 1.09758 loss)
I0706 00:08:27.513088 15248 solver.cpp:590] Iteration 21780, lr = 0.0028349
I0706 00:08:49.667654 15248 solver.cpp:243] Iteration 21890, loss = 0.843213
I0706 00:08:49.667677 15248 solver.cpp:259]     Train net output #0: loss = 0.843212 (* 1 = 0.843212 loss)
I0706 00:08:49.667683 15248 solver.cpp:590] Iteration 21890, lr = 0.00281691
I0706 00:09:11.144788 15248 solver.cpp:243] Iteration 22000, loss = 1.4269
I0706 00:09:11.144867 15248 solver.cpp:259]     Train net output #0: loss = 1.4269 (* 1 = 1.4269 loss)
I0706 00:09:11.144875 15248 solver.cpp:590] Iteration 22000, lr = 0.00279903
I0706 00:09:20.743969 15248 solver.cpp:347] Iteration 22050, Testing net (#0)
I0706 00:09:48.206244 15248 solver.cpp:415]     Test net output #0: accuracy = 0.046875
I0706 00:09:48.206358 15248 solver.cpp:415]     Test net output #1: loss = 6.46233 (* 1 = 6.46233 loss)
I0706 00:10:00.263466 15248 solver.cpp:243] Iteration 22110, loss = 1.00655
I0706 00:10:00.263490 15248 solver.cpp:259]     Train net output #0: loss = 1.00655 (* 1 = 1.00655 loss)
I0706 00:10:00.263496 15248 solver.cpp:590] Iteration 22110, lr = 0.00278127
I0706 00:10:22.221843 15248 solver.cpp:243] Iteration 22220, loss = 1.23283
I0706 00:10:22.221931 15248 solver.cpp:259]     Train net output #0: loss = 1.23283 (* 1 = 1.23283 loss)
I0706 00:10:22.221938 15248 solver.cpp:590] Iteration 22220, lr = 0.00276362
I0706 00:10:43.834928 15248 solver.cpp:243] Iteration 22330, loss = 1.35066
I0706 00:10:43.834951 15248 solver.cpp:259]     Train net output #0: loss = 1.35065 (* 1 = 1.35065 loss)
I0706 00:10:43.834957 15248 solver.cpp:590] Iteration 22330, lr = 0.00274608
I0706 00:11:06.243988 15248 solver.cpp:243] Iteration 22440, loss = 0.931592
I0706 00:11:06.244084 15248 solver.cpp:259]     Train net output #0: loss = 0.931591 (* 1 = 0.931591 loss)
I0706 00:11:06.244091 15248 solver.cpp:590] Iteration 22440, lr = 0.00272865
I0706 00:11:27.701598 15248 solver.cpp:243] Iteration 22550, loss = 1.15905
I0706 00:11:27.701625 15248 solver.cpp:259]     Train net output #0: loss = 1.15905 (* 1 = 1.15905 loss)
I0706 00:11:27.701632 15248 solver.cpp:590] Iteration 22550, lr = 0.00271133
I0706 00:11:50.241925 15248 solver.cpp:243] Iteration 22660, loss = 0.836792
I0706 00:11:50.242079 15248 solver.cpp:259]     Train net output #0: loss = 0.836791 (* 1 = 0.836791 loss)
I0706 00:11:50.242100 15248 solver.cpp:590] Iteration 22660, lr = 0.00269413
I0706 00:12:11.767325 15248 solver.cpp:243] Iteration 22770, loss = 0.44579
I0706 00:12:11.767377 15248 solver.cpp:259]     Train net output #0: loss = 0.44579 (* 1 = 0.44579 loss)
I0706 00:12:11.767384 15248 solver.cpp:590] Iteration 22770, lr = 0.00267703
I0706 00:12:33.686488 15248 solver.cpp:243] Iteration 22880, loss = 1.27205
I0706 00:12:33.686590 15248 solver.cpp:259]     Train net output #0: loss = 1.27205 (* 1 = 1.27205 loss)
I0706 00:12:33.686600 15248 solver.cpp:590] Iteration 22880, lr = 0.00266004
I0706 00:12:43.969743 15248 solver.cpp:347] Iteration 22932, Testing net (#0)
I0706 00:12:53.620060 15267 blocking_queue.cpp:50] Waiting for data
I0706 00:13:11.265493 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0466346
I0706 00:13:11.266101 15248 solver.cpp:415]     Test net output #1: loss = 6.49866 (* 1 = 6.49866 loss)
I0706 00:13:22.747241 15248 solver.cpp:243] Iteration 22990, loss = 1.12777
I0706 00:13:22.747264 15248 solver.cpp:259]     Train net output #0: loss = 1.12777 (* 1 = 1.12777 loss)
I0706 00:13:22.747270 15248 solver.cpp:590] Iteration 22990, lr = 0.00264316
I0706 00:13:44.269372 15248 solver.cpp:243] Iteration 23100, loss = 1.89776
I0706 00:13:44.269682 15248 solver.cpp:259]     Train net output #0: loss = 1.89776 (* 1 = 1.89776 loss)
I0706 00:13:44.269690 15248 solver.cpp:590] Iteration 23100, lr = 0.00262638
I0706 00:14:06.944710 15248 solver.cpp:243] Iteration 23210, loss = 0.81131
I0706 00:14:06.944736 15248 solver.cpp:259]     Train net output #0: loss = 0.811309 (* 1 = 0.811309 loss)
I0706 00:14:06.944742 15248 solver.cpp:590] Iteration 23210, lr = 0.00260972
I0706 00:14:28.488677 15248 solver.cpp:243] Iteration 23320, loss = 1.06528
I0706 00:14:28.488826 15248 solver.cpp:259]     Train net output #0: loss = 1.06528 (* 1 = 1.06528 loss)
I0706 00:14:28.488842 15248 solver.cpp:590] Iteration 23320, lr = 0.00259315
I0706 00:14:50.442633 15248 solver.cpp:243] Iteration 23430, loss = 1.48933
I0706 00:14:50.442658 15248 solver.cpp:259]     Train net output #0: loss = 1.48933 (* 1 = 1.48933 loss)
I0706 00:14:50.442665 15248 solver.cpp:590] Iteration 23430, lr = 0.0025767
I0706 00:15:12.176417 15248 solver.cpp:243] Iteration 23540, loss = 0.973249
I0706 00:15:12.176523 15248 solver.cpp:259]     Train net output #0: loss = 0.973248 (* 1 = 0.973248 loss)
I0706 00:15:12.176542 15248 solver.cpp:590] Iteration 23540, lr = 0.00256034
I0706 00:15:33.980849 15248 solver.cpp:243] Iteration 23650, loss = 1.2496
I0706 00:15:33.980873 15248 solver.cpp:259]     Train net output #0: loss = 1.2496 (* 1 = 1.2496 loss)
I0706 00:15:33.980880 15248 solver.cpp:590] Iteration 23650, lr = 0.0025441
I0706 00:15:56.452199 15248 solver.cpp:243] Iteration 23760, loss = 1.32117
I0706 00:15:56.452292 15248 solver.cpp:259]     Train net output #0: loss = 1.32117 (* 1 = 1.32117 loss)
I0706 00:15:56.452299 15248 solver.cpp:590] Iteration 23760, lr = 0.00252795
I0706 00:16:06.837550 15248 solver.cpp:347] Iteration 23814, Testing net (#0)
I0706 00:16:23.756302 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 00:16:30.985667 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0481971
I0706 00:16:30.985774 15248 solver.cpp:415]     Test net output #1: loss = 6.59318 (* 1 = 6.59318 loss)
I0706 00:16:42.105397 15248 solver.cpp:243] Iteration 23870, loss = 0.913401
I0706 00:16:42.105420 15248 solver.cpp:259]     Train net output #0: loss = 0.913401 (* 1 = 0.913401 loss)
I0706 00:16:42.105425 15248 solver.cpp:590] Iteration 23870, lr = 0.00251191
I0706 00:17:04.587420 15248 solver.cpp:243] Iteration 23980, loss = 1.75156
I0706 00:17:04.587544 15248 solver.cpp:259]     Train net output #0: loss = 1.75156 (* 1 = 1.75156 loss)
I0706 00:17:04.587553 15248 solver.cpp:590] Iteration 23980, lr = 0.00249597
I0706 00:17:26.084697 15248 solver.cpp:243] Iteration 24090, loss = 0.457111
I0706 00:17:26.084717 15248 solver.cpp:259]     Train net output #0: loss = 0.457111 (* 1 = 0.457111 loss)
I0706 00:17:26.084723 15248 solver.cpp:590] Iteration 24090, lr = 0.00248013
I0706 00:17:48.007752 15248 solver.cpp:243] Iteration 24200, loss = 1.11146
I0706 00:17:48.007856 15248 solver.cpp:259]     Train net output #0: loss = 1.11146 (* 1 = 1.11146 loss)
I0706 00:17:48.007872 15248 solver.cpp:590] Iteration 24200, lr = 0.00246439
I0706 00:18:09.991775 15248 solver.cpp:243] Iteration 24310, loss = 0.590529
I0706 00:18:09.991797 15248 solver.cpp:259]     Train net output #0: loss = 0.590529 (* 1 = 0.590529 loss)
I0706 00:18:09.991802 15248 solver.cpp:590] Iteration 24310, lr = 0.00244875
I0706 00:18:31.615849 15248 solver.cpp:243] Iteration 24420, loss = 0.677955
I0706 00:18:31.616180 15248 solver.cpp:259]     Train net output #0: loss = 0.677955 (* 1 = 0.677955 loss)
I0706 00:18:31.616191 15248 solver.cpp:590] Iteration 24420, lr = 0.00243321
I0706 00:18:53.382180 15248 solver.cpp:243] Iteration 24530, loss = 0.896452
I0706 00:18:53.382203 15248 solver.cpp:259]     Train net output #0: loss = 0.896451 (* 1 = 0.896451 loss)
I0706 00:18:53.382220 15248 solver.cpp:590] Iteration 24530, lr = 0.00241776
I0706 00:19:14.888200 15248 solver.cpp:243] Iteration 24640, loss = 0.413655
I0706 00:19:14.896059 15248 solver.cpp:259]     Train net output #0: loss = 0.413654 (* 1 = 0.413654 loss)
I0706 00:19:14.896073 15248 solver.cpp:590] Iteration 24640, lr = 0.00240242
I0706 00:19:25.757107 15248 solver.cpp:347] Iteration 24696, Testing net (#0)
I0706 00:19:52.590451 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0460337
I0706 00:19:52.590808 15248 solver.cpp:415]     Test net output #1: loss = 6.61571 (* 1 = 6.61571 loss)
I0706 00:20:03.442471 15248 solver.cpp:243] Iteration 24750, loss = 0.389707
I0706 00:20:03.442495 15248 solver.cpp:259]     Train net output #0: loss = 0.389707 (* 1 = 0.389707 loss)
I0706 00:20:03.442502 15248 solver.cpp:590] Iteration 24750, lr = 0.00238717
I0706 00:20:24.979563 15248 solver.cpp:243] Iteration 24860, loss = 1.03225
I0706 00:20:24.979655 15248 solver.cpp:259]     Train net output #0: loss = 1.03225 (* 1 = 1.03225 loss)
I0706 00:20:24.979671 15248 solver.cpp:590] Iteration 24860, lr = 0.00237202
I0706 00:20:46.723953 15248 solver.cpp:243] Iteration 24970, loss = 2.24621
I0706 00:20:46.723976 15248 solver.cpp:259]     Train net output #0: loss = 2.24621 (* 1 = 2.24621 loss)
I0706 00:20:46.723981 15248 solver.cpp:590] Iteration 24970, lr = 0.00235697
I0706 00:21:08.788938 15248 solver.cpp:243] Iteration 25080, loss = 0.625086
I0706 00:21:08.789232 15248 solver.cpp:259]     Train net output #0: loss = 0.625085 (* 1 = 0.625085 loss)
I0706 00:21:08.789240 15248 solver.cpp:590] Iteration 25080, lr = 0.00234201
I0706 00:21:30.437166 15248 solver.cpp:243] Iteration 25190, loss = 0.647388
I0706 00:21:30.437189 15248 solver.cpp:259]     Train net output #0: loss = 0.647388 (* 1 = 0.647388 loss)
I0706 00:21:30.437196 15248 solver.cpp:590] Iteration 25190, lr = 0.00232715
I0706 00:21:52.401645 15248 solver.cpp:243] Iteration 25300, loss = 0.747689
I0706 00:21:52.401880 15248 solver.cpp:259]     Train net output #0: loss = 0.747688 (* 1 = 0.747688 loss)
I0706 00:21:52.401888 15248 solver.cpp:590] Iteration 25300, lr = 0.00231238
I0706 00:22:13.867791 15248 solver.cpp:243] Iteration 25410, loss = 1.10607
I0706 00:22:13.867813 15248 solver.cpp:259]     Train net output #0: loss = 1.10607 (* 1 = 1.10607 loss)
I0706 00:22:13.867820 15248 solver.cpp:590] Iteration 25410, lr = 0.0022977
I0706 00:22:35.833137 15248 solver.cpp:243] Iteration 25520, loss = 1.29045
I0706 00:22:35.833223 15248 solver.cpp:259]     Train net output #0: loss = 1.29045 (* 1 = 1.29045 loss)
I0706 00:22:35.833230 15248 solver.cpp:590] Iteration 25520, lr = 0.00228312
I0706 00:22:46.961910 15248 solver.cpp:347] Iteration 25578, Testing net (#0)
I0706 00:23:13.635066 15248 solver.cpp:415]     Test net output #0: accuracy = 0.050601
I0706 00:23:13.635210 15248 solver.cpp:415]     Test net output #1: loss = 6.5617 (* 1 = 6.5617 loss)
I0706 00:23:23.926564 15248 solver.cpp:243] Iteration 25630, loss = 0.593649
I0706 00:23:23.926590 15248 solver.cpp:259]     Train net output #0: loss = 0.593649 (* 1 = 0.593649 loss)
I0706 00:23:23.926597 15248 solver.cpp:590] Iteration 25630, lr = 0.00226863
I0706 00:23:45.598053 15248 solver.cpp:243] Iteration 25740, loss = 0.45797
I0706 00:23:45.598364 15248 solver.cpp:259]     Train net output #0: loss = 0.45797 (* 1 = 0.45797 loss)
I0706 00:23:45.598415 15248 solver.cpp:590] Iteration 25740, lr = 0.00225424
I0706 00:24:07.309144 15248 solver.cpp:243] Iteration 25850, loss = 1.27764
I0706 00:24:07.309165 15248 solver.cpp:259]     Train net output #0: loss = 1.27764 (* 1 = 1.27764 loss)
I0706 00:24:07.309171 15248 solver.cpp:590] Iteration 25850, lr = 0.00223993
I0706 00:24:28.751938 15248 solver.cpp:243] Iteration 25960, loss = 0.736485
I0706 00:24:28.752197 15248 solver.cpp:259]     Train net output #0: loss = 0.736484 (* 1 = 0.736484 loss)
I0706 00:24:28.752204 15248 solver.cpp:590] Iteration 25960, lr = 0.00222571
I0706 00:24:50.749786 15248 solver.cpp:243] Iteration 26070, loss = 0.548849
I0706 00:24:50.749811 15248 solver.cpp:259]     Train net output #0: loss = 0.548849 (* 1 = 0.548849 loss)
I0706 00:24:50.749819 15248 solver.cpp:590] Iteration 26070, lr = 0.00221159
I0706 00:25:12.281311 15248 solver.cpp:243] Iteration 26180, loss = 1.1184
I0706 00:25:12.281572 15248 solver.cpp:259]     Train net output #0: loss = 1.1184 (* 1 = 1.1184 loss)
I0706 00:25:12.281580 15248 solver.cpp:590] Iteration 26180, lr = 0.00219755
I0706 00:25:34.120779 15248 solver.cpp:243] Iteration 26290, loss = 1.11022
I0706 00:25:34.120801 15248 solver.cpp:259]     Train net output #0: loss = 1.11022 (* 1 = 1.11022 loss)
I0706 00:25:34.120806 15248 solver.cpp:590] Iteration 26290, lr = 0.00218361
I0706 00:25:55.587600 15248 solver.cpp:243] Iteration 26400, loss = 0.51692
I0706 00:25:55.587690 15248 solver.cpp:259]     Train net output #0: loss = 0.51692 (* 1 = 0.51692 loss)
I0706 00:25:55.587707 15248 solver.cpp:590] Iteration 26400, lr = 0.00216975
I0706 00:26:07.068825 15248 solver.cpp:347] Iteration 26460, Testing net (#0)
I0706 00:26:17.157711 15267 blocking_queue.cpp:50] Waiting for data
I0706 00:26:32.152361 15248 solver.cpp:415]     Test net output #0: accuracy = 0.050601
I0706 00:26:32.152503 15248 solver.cpp:415]     Test net output #1: loss = 6.59461 (* 1 = 6.59461 loss)
I0706 00:26:42.366055 15248 solver.cpp:243] Iteration 26510, loss = 0.636186
I0706 00:26:42.366080 15248 solver.cpp:259]     Train net output #0: loss = 0.636186 (* 1 = 0.636186 loss)
I0706 00:26:42.366086 15248 solver.cpp:590] Iteration 26510, lr = 0.00215598
I0706 00:27:04.885603 15248 solver.cpp:243] Iteration 26620, loss = 0.576445
I0706 00:27:04.885853 15248 solver.cpp:259]     Train net output #0: loss = 0.576444 (* 1 = 0.576444 loss)
I0706 00:27:04.885861 15248 solver.cpp:590] Iteration 26620, lr = 0.0021423
I0706 00:27:26.358640 15248 solver.cpp:243] Iteration 26730, loss = 1.3621
I0706 00:27:26.358664 15248 solver.cpp:259]     Train net output #0: loss = 1.3621 (* 1 = 1.3621 loss)
I0706 00:27:26.358670 15248 solver.cpp:590] Iteration 26730, lr = 0.0021287
I0706 00:27:48.413125 15248 solver.cpp:243] Iteration 26840, loss = 0.734647
I0706 00:27:48.414085 15248 solver.cpp:259]     Train net output #0: loss = 0.734647 (* 1 = 0.734647 loss)
I0706 00:27:48.414094 15248 solver.cpp:590] Iteration 26840, lr = 0.00211519
I0706 00:28:10.075407 15248 solver.cpp:243] Iteration 26950, loss = 0.576745
I0706 00:28:10.075435 15248 solver.cpp:259]     Train net output #0: loss = 0.576744 (* 1 = 0.576744 loss)
I0706 00:28:10.075443 15248 solver.cpp:590] Iteration 26950, lr = 0.00210177
I0706 00:28:31.810252 15248 solver.cpp:243] Iteration 27060, loss = 0.22986
I0706 00:28:31.810400 15248 solver.cpp:259]     Train net output #0: loss = 0.22986 (* 1 = 0.22986 loss)
I0706 00:28:31.810408 15248 solver.cpp:590] Iteration 27060, lr = 0.00208843
I0706 00:28:53.690469 15248 solver.cpp:243] Iteration 27170, loss = 0.989683
I0706 00:28:53.690491 15248 solver.cpp:259]     Train net output #0: loss = 0.989683 (* 1 = 0.989683 loss)
I0706 00:28:53.690497 15248 solver.cpp:590] Iteration 27170, lr = 0.00207518
I0706 00:29:15.413262 15248 solver.cpp:243] Iteration 27280, loss = 0.272193
I0706 00:29:15.413374 15248 solver.cpp:259]     Train net output #0: loss = 0.272192 (* 1 = 0.272192 loss)
I0706 00:29:15.413383 15248 solver.cpp:590] Iteration 27280, lr = 0.00206201
I0706 00:29:28.532356 15248 solver.cpp:347] Iteration 27342, Testing net (#0)
I0706 00:29:44.751600 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 00:29:52.915310 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0540865
I0706 00:29:52.915951 15248 solver.cpp:415]     Test net output #1: loss = 6.62634 (* 1 = 6.62634 loss)
I0706 00:30:02.537184 15248 solver.cpp:243] Iteration 27390, loss = 0.687509
I0706 00:30:02.537211 15248 solver.cpp:259]     Train net output #0: loss = 0.687508 (* 1 = 0.687508 loss)
I0706 00:30:02.537217 15248 solver.cpp:590] Iteration 27390, lr = 0.00204892
I0706 00:30:23.959985 15248 solver.cpp:243] Iteration 27500, loss = 0.885307
I0706 00:30:23.960073 15248 solver.cpp:259]     Train net output #0: loss = 0.885307 (* 1 = 0.885307 loss)
I0706 00:30:23.960088 15248 solver.cpp:590] Iteration 27500, lr = 0.00203592
I0706 00:30:46.330034 15248 solver.cpp:243] Iteration 27610, loss = 0.414854
I0706 00:30:46.330056 15248 solver.cpp:259]     Train net output #0: loss = 0.414854 (* 1 = 0.414854 loss)
I0706 00:30:46.330061 15248 solver.cpp:590] Iteration 27610, lr = 0.002023
I0706 00:31:07.845572 15248 solver.cpp:243] Iteration 27720, loss = 0.541115
I0706 00:31:07.845659 15248 solver.cpp:259]     Train net output #0: loss = 0.541115 (* 1 = 0.541115 loss)
I0706 00:31:07.845665 15248 solver.cpp:590] Iteration 27720, lr = 0.00201016
I0706 00:31:29.499662 15248 solver.cpp:243] Iteration 27830, loss = 0.989537
I0706 00:31:29.499686 15248 solver.cpp:259]     Train net output #0: loss = 0.989537 (* 1 = 0.989537 loss)
I0706 00:31:29.499691 15248 solver.cpp:590] Iteration 27830, lr = 0.0019974
I0706 00:31:51.381727 15248 solver.cpp:243] Iteration 27940, loss = 0.196366
I0706 00:31:51.381824 15248 solver.cpp:259]     Train net output #0: loss = 0.196366 (* 1 = 0.196366 loss)
I0706 00:31:51.381841 15248 solver.cpp:590] Iteration 27940, lr = 0.00198472
I0706 00:32:12.903863 15248 solver.cpp:243] Iteration 28050, loss = 0.788357
I0706 00:32:12.903887 15248 solver.cpp:259]     Train net output #0: loss = 0.788357 (* 1 = 0.788357 loss)
I0706 00:32:12.903892 15248 solver.cpp:590] Iteration 28050, lr = 0.00197213
I0706 00:32:35.589949 15248 solver.cpp:243] Iteration 28160, loss = 0.918722
I0706 00:32:35.590041 15248 solver.cpp:259]     Train net output #0: loss = 0.918722 (* 1 = 0.918722 loss)
I0706 00:32:35.590059 15248 solver.cpp:590] Iteration 28160, lr = 0.00195961
I0706 00:32:47.899497 15248 solver.cpp:347] Iteration 28224, Testing net (#0)
I0706 00:33:14.622102 15248 solver.cpp:415]     Test net output #0: accuracy = 0.053125
I0706 00:33:14.622238 15248 solver.cpp:415]     Test net output #1: loss = 6.68152 (* 1 = 6.68152 loss)
I0706 00:33:23.746747 15248 solver.cpp:243] Iteration 28270, loss = 0.350963
I0706 00:33:23.746773 15248 solver.cpp:259]     Train net output #0: loss = 0.350963 (* 1 = 0.350963 loss)
I0706 00:33:23.746778 15248 solver.cpp:590] Iteration 28270, lr = 0.00194718
I0706 00:33:45.937283 15248 solver.cpp:243] Iteration 28380, loss = 0.71346
I0706 00:33:45.937398 15248 solver.cpp:259]     Train net output #0: loss = 0.71346 (* 1 = 0.71346 loss)
I0706 00:33:45.937404 15248 solver.cpp:590] Iteration 28380, lr = 0.00193482
I0706 00:34:07.445278 15248 solver.cpp:243] Iteration 28490, loss = 0.619021
I0706 00:34:07.445303 15248 solver.cpp:259]     Train net output #0: loss = 0.619021 (* 1 = 0.619021 loss)
I0706 00:34:07.445309 15248 solver.cpp:590] Iteration 28490, lr = 0.00192254
I0706 00:34:29.314645 15248 solver.cpp:243] Iteration 28600, loss = 0.568593
I0706 00:34:29.314734 15248 solver.cpp:259]     Train net output #0: loss = 0.568593 (* 1 = 0.568593 loss)
I0706 00:34:29.314741 15248 solver.cpp:590] Iteration 28600, lr = 0.00191034
I0706 00:34:51.185611 15248 solver.cpp:243] Iteration 28710, loss = 0.569556
I0706 00:34:51.185636 15248 solver.cpp:259]     Train net output #0: loss = 0.569557 (* 1 = 0.569557 loss)
I0706 00:34:51.185642 15248 solver.cpp:590] Iteration 28710, lr = 0.00189821
I0706 00:35:12.668520 15248 solver.cpp:243] Iteration 28820, loss = 1.0296
I0706 00:35:12.668625 15248 solver.cpp:259]     Train net output #0: loss = 1.0296 (* 1 = 1.0296 loss)
I0706 00:35:12.668632 15248 solver.cpp:590] Iteration 28820, lr = 0.00188617
I0706 00:35:35.214053 15248 solver.cpp:243] Iteration 28930, loss = 0.283442
I0706 00:35:35.214078 15248 solver.cpp:259]     Train net output #0: loss = 0.283442 (* 1 = 0.283442 loss)
I0706 00:35:35.214084 15248 solver.cpp:590] Iteration 28930, lr = 0.0018742
I0706 00:35:56.702088 15248 solver.cpp:243] Iteration 29040, loss = 0.529962
I0706 00:35:56.702327 15248 solver.cpp:259]     Train net output #0: loss = 0.529962 (* 1 = 0.529962 loss)
I0706 00:35:56.702334 15248 solver.cpp:590] Iteration 29040, lr = 0.0018623
I0706 00:36:09.993094 15248 solver.cpp:347] Iteration 29106, Testing net (#0)
I0706 00:36:35.952137 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0504808
I0706 00:36:35.952394 15248 solver.cpp:415]     Test net output #1: loss = 6.75837 (* 1 = 6.75837 loss)
I0706 00:36:44.773200 15248 solver.cpp:243] Iteration 29150, loss = 1.3795
I0706 00:36:44.773223 15248 solver.cpp:259]     Train net output #0: loss = 1.3795 (* 1 = 1.3795 loss)
I0706 00:36:44.773229 15248 solver.cpp:590] Iteration 29150, lr = 0.00185048
I0706 00:37:06.517947 15248 solver.cpp:243] Iteration 29260, loss = 0.0885282
I0706 00:37:06.518038 15248 solver.cpp:259]     Train net output #0: loss = 0.0885286 (* 1 = 0.0885286 loss)
I0706 00:37:06.518045 15248 solver.cpp:590] Iteration 29260, lr = 0.00183874
I0706 00:37:27.931957 15248 solver.cpp:243] Iteration 29370, loss = 0.397508
I0706 00:37:27.932019 15248 solver.cpp:259]     Train net output #0: loss = 0.397508 (* 1 = 0.397508 loss)
I0706 00:37:27.932031 15248 solver.cpp:590] Iteration 29370, lr = 0.00182707
I0706 00:37:49.986533 15248 solver.cpp:243] Iteration 29480, loss = 0.164881
I0706 00:37:49.986609 15248 solver.cpp:259]     Train net output #0: loss = 0.164881 (* 1 = 0.164881 loss)
I0706 00:37:49.986615 15248 solver.cpp:590] Iteration 29480, lr = 0.00181548
I0706 00:38:11.462667 15248 solver.cpp:243] Iteration 29590, loss = 0.206244
I0706 00:38:11.462693 15248 solver.cpp:259]     Train net output #0: loss = 0.206244 (* 1 = 0.206244 loss)
I0706 00:38:11.462699 15248 solver.cpp:590] Iteration 29590, lr = 0.00180395
I0706 00:38:33.922132 15248 solver.cpp:243] Iteration 29700, loss = 0.319562
I0706 00:38:33.922224 15248 solver.cpp:259]     Train net output #0: loss = 0.319562 (* 1 = 0.319562 loss)
I0706 00:38:33.922232 15248 solver.cpp:590] Iteration 29700, lr = 0.00179251
I0706 00:38:55.406785 15248 solver.cpp:243] Iteration 29810, loss = 0.262064
I0706 00:38:55.406807 15248 solver.cpp:259]     Train net output #0: loss = 0.262065 (* 1 = 0.262065 loss)
I0706 00:38:55.406815 15248 solver.cpp:590] Iteration 29810, lr = 0.00178113
I0706 00:39:17.140373 15248 solver.cpp:243] Iteration 29920, loss = 0.684661
I0706 00:39:17.140513 15248 solver.cpp:259]     Train net output #0: loss = 0.684662 (* 1 = 0.684662 loss)
I0706 00:39:17.140521 15248 solver.cpp:590] Iteration 29920, lr = 0.00176983
I0706 00:39:30.793735 15248 solver.cpp:347] Iteration 29988, Testing net (#0)
I0706 00:39:52.742046 15267 blocking_queue.cpp:50] Waiting for data
I0706 00:39:56.241214 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0558894
I0706 00:39:56.241242 15248 solver.cpp:415]     Test net output #1: loss = 6.68215 (* 1 = 6.68215 loss)
I0706 00:40:04.605890 15248 solver.cpp:243] Iteration 30030, loss = 0.776679
I0706 00:40:04.605912 15248 solver.cpp:259]     Train net output #0: loss = 0.77668 (* 1 = 0.77668 loss)
I0706 00:40:04.605919 15248 solver.cpp:590] Iteration 30030, lr = 0.00175859
I0706 00:40:26.061902 15248 solver.cpp:243] Iteration 30140, loss = 0.417097
I0706 00:40:26.061983 15248 solver.cpp:259]     Train net output #0: loss = 0.417097 (* 1 = 0.417097 loss)
I0706 00:40:26.061990 15248 solver.cpp:590] Iteration 30140, lr = 0.00174743
I0706 00:40:47.879446 15248 solver.cpp:243] Iteration 30250, loss = 0.916868
I0706 00:40:47.879469 15248 solver.cpp:259]     Train net output #0: loss = 0.916869 (* 1 = 0.916869 loss)
I0706 00:40:47.879475 15248 solver.cpp:590] Iteration 30250, lr = 0.00173634
I0706 00:41:09.316237 15248 solver.cpp:243] Iteration 30360, loss = 0.468024
I0706 00:41:09.316349 15248 solver.cpp:259]     Train net output #0: loss = 0.468025 (* 1 = 0.468025 loss)
I0706 00:41:09.316366 15248 solver.cpp:590] Iteration 30360, lr = 0.00172533
I0706 00:41:31.897639 15248 solver.cpp:243] Iteration 30470, loss = 0.556699
I0706 00:41:31.897662 15248 solver.cpp:259]     Train net output #0: loss = 0.556699 (* 1 = 0.556699 loss)
I0706 00:41:31.897668 15248 solver.cpp:590] Iteration 30470, lr = 0.00171438
I0706 00:41:53.432067 15248 solver.cpp:243] Iteration 30580, loss = 0.0303183
I0706 00:41:53.465185 15248 solver.cpp:259]     Train net output #0: loss = 0.030319 (* 1 = 0.030319 loss)
I0706 00:41:53.465198 15248 solver.cpp:590] Iteration 30580, lr = 0.0017035
I0706 00:42:15.171666 15248 solver.cpp:243] Iteration 30690, loss = 0.371372
I0706 00:42:15.171691 15248 solver.cpp:259]     Train net output #0: loss = 0.371373 (* 1 = 0.371373 loss)
I0706 00:42:15.171697 15248 solver.cpp:590] Iteration 30690, lr = 0.00169268
I0706 00:42:36.695448 15248 solver.cpp:243] Iteration 30800, loss = 0.340001
I0706 00:42:36.716778 15248 solver.cpp:259]     Train net output #0: loss = 0.340002 (* 1 = 0.340002 loss)
I0706 00:42:36.716789 15248 solver.cpp:590] Iteration 30800, lr = 0.00168194
I0706 00:42:50.165724 15248 solver.cpp:347] Iteration 30870, Testing net (#0)
I0706 00:43:06.648480 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 00:43:17.973577 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0543269
I0706 00:43:17.975716 15248 solver.cpp:415]     Test net output #1: loss = 6.78594 (* 1 = 6.78594 loss)
I0706 00:43:25.943104 15248 solver.cpp:243] Iteration 30910, loss = 0.606522
I0706 00:43:25.943128 15248 solver.cpp:259]     Train net output #0: loss = 0.606523 (* 1 = 0.606523 loss)
I0706 00:43:25.943135 15248 solver.cpp:590] Iteration 30910, lr = 0.00167127
I0706 00:43:48.315469 15248 solver.cpp:243] Iteration 31020, loss = 0.506866
I0706 00:43:48.315600 15248 solver.cpp:259]     Train net output #0: loss = 0.506866 (* 1 = 0.506866 loss)
I0706 00:43:48.315608 15248 solver.cpp:590] Iteration 31020, lr = 0.00166066
I0706 00:44:09.831583 15248 solver.cpp:243] Iteration 31130, loss = 0.569289
I0706 00:44:09.831606 15248 solver.cpp:259]     Train net output #0: loss = 0.56929 (* 1 = 0.56929 loss)
I0706 00:44:09.831612 15248 solver.cpp:590] Iteration 31130, lr = 0.00165012
I0706 00:44:32.393940 15248 solver.cpp:243] Iteration 31240, loss = 0.15279
I0706 00:44:32.394047 15248 solver.cpp:259]     Train net output #0: loss = 0.152791 (* 1 = 0.152791 loss)
I0706 00:44:32.394054 15248 solver.cpp:590] Iteration 31240, lr = 0.00163965
I0706 00:44:53.890712 15248 solver.cpp:243] Iteration 31350, loss = 0.291908
I0706 00:44:53.890734 15248 solver.cpp:259]     Train net output #0: loss = 0.291909 (* 1 = 0.291909 loss)
I0706 00:44:53.890741 15248 solver.cpp:590] Iteration 31350, lr = 0.00162924
I0706 00:45:16.054492 15248 solver.cpp:243] Iteration 31460, loss = 0.771099
I0706 00:45:16.054589 15248 solver.cpp:259]     Train net output #0: loss = 0.771099 (* 1 = 0.771099 loss)
I0706 00:45:16.054596 15248 solver.cpp:590] Iteration 31460, lr = 0.0016189
I0706 00:45:37.753255 15248 solver.cpp:243] Iteration 31570, loss = 0.620629
I0706 00:45:37.753280 15248 solver.cpp:259]     Train net output #0: loss = 0.620629 (* 1 = 0.620629 loss)
I0706 00:45:37.753288 15248 solver.cpp:590] Iteration 31570, lr = 0.00160863
I0706 00:45:59.673991 15248 solver.cpp:243] Iteration 31680, loss = 0.484916
I0706 00:45:59.674103 15248 solver.cpp:259]     Train net output #0: loss = 0.484916 (* 1 = 0.484916 loss)
I0706 00:45:59.674109 15248 solver.cpp:590] Iteration 31680, lr = 0.00159842
I0706 00:46:14.085001 15248 solver.cpp:347] Iteration 31752, Testing net (#0)
I0706 00:46:40.759124 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0532452
I0706 00:46:40.759320 15248 solver.cpp:415]     Test net output #1: loss = 6.62238 (* 1 = 6.62238 loss)
I0706 00:46:48.355198 15248 solver.cpp:243] Iteration 31790, loss = 0.361931
I0706 00:46:48.355223 15248 solver.cpp:259]     Train net output #0: loss = 0.361932 (* 1 = 0.361932 loss)
I0706 00:46:48.355229 15248 solver.cpp:590] Iteration 31790, lr = 0.00158828
I0706 00:47:09.884325 15248 solver.cpp:243] Iteration 31900, loss = 0.323704
I0706 00:47:09.884348 15248 solver.cpp:259]     Train net output #0: loss = 0.323704 (* 1 = 0.323704 loss)
I0706 00:47:09.884354 15248 solver.cpp:590] Iteration 31900, lr = 0.0015782
I0706 00:47:32.131403 15248 solver.cpp:243] Iteration 32010, loss = 0.619222
I0706 00:47:32.131624 15248 solver.cpp:259]     Train net output #0: loss = 0.619222 (* 1 = 0.619222 loss)
I0706 00:47:32.131633 15248 solver.cpp:590] Iteration 32010, lr = 0.00156818
I0706 00:47:53.616427 15248 solver.cpp:243] Iteration 32120, loss = 0.231667
I0706 00:47:53.616452 15248 solver.cpp:259]     Train net output #0: loss = 0.231667 (* 1 = 0.231667 loss)
I0706 00:47:53.616458 15248 solver.cpp:590] Iteration 32120, lr = 0.00155823
I0706 00:48:15.304524 15248 solver.cpp:243] Iteration 32230, loss = 0.183277
I0706 00:48:15.304749 15248 solver.cpp:259]     Train net output #0: loss = 0.183277 (* 1 = 0.183277 loss)
I0706 00:48:15.304756 15248 solver.cpp:590] Iteration 32230, lr = 0.00154834
I0706 00:48:37.367310 15248 solver.cpp:243] Iteration 32340, loss = 0.071108
I0706 00:48:37.367338 15248 solver.cpp:259]     Train net output #0: loss = 0.0711079 (* 1 = 0.0711079 loss)
I0706 00:48:37.367347 15248 solver.cpp:590] Iteration 32340, lr = 0.00153851
I0706 00:48:58.987646 15248 solver.cpp:243] Iteration 32450, loss = 0.196007
I0706 00:48:58.987746 15248 solver.cpp:259]     Train net output #0: loss = 0.196007 (* 1 = 0.196007 loss)
I0706 00:48:58.987761 15248 solver.cpp:590] Iteration 32450, lr = 0.00152875
I0706 00:49:21.508819 15248 solver.cpp:243] Iteration 32560, loss = 0.194192
I0706 00:49:21.508849 15248 solver.cpp:259]     Train net output #0: loss = 0.194192 (* 1 = 0.194192 loss)
I0706 00:49:21.508857 15248 solver.cpp:590] Iteration 32560, lr = 0.00151905
I0706 00:49:35.935420 15248 solver.cpp:347] Iteration 32634, Testing net (#0)
I0706 00:50:01.055837 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0539663
I0706 00:50:01.055867 15248 solver.cpp:415]     Test net output #1: loss = 6.76877 (* 1 = 6.76877 loss)
I0706 00:50:08.213721 15248 solver.cpp:243] Iteration 32670, loss = 0.331971
I0706 00:50:08.213807 15248 solver.cpp:259]     Train net output #0: loss = 0.331971 (* 1 = 0.331971 loss)
I0706 00:50:08.213814 15248 solver.cpp:590] Iteration 32670, lr = 0.00150941
I0706 00:50:31.072242 15248 solver.cpp:243] Iteration 32780, loss = 0.329837
I0706 00:50:31.072265 15248 solver.cpp:259]     Train net output #0: loss = 0.329838 (* 1 = 0.329838 loss)
I0706 00:50:31.072271 15248 solver.cpp:590] Iteration 32780, lr = 0.00149983
I0706 00:50:53.340507 15248 solver.cpp:243] Iteration 32890, loss = 0.482619
I0706 00:50:53.340603 15248 solver.cpp:259]     Train net output #0: loss = 0.482619 (* 1 = 0.482619 loss)
I0706 00:50:53.340620 15248 solver.cpp:590] Iteration 32890, lr = 0.00149031
I0706 00:51:15.130723 15248 solver.cpp:243] Iteration 33000, loss = 0.309801
I0706 00:51:15.130748 15248 solver.cpp:259]     Train net output #0: loss = 0.309801 (* 1 = 0.309801 loss)
I0706 00:51:15.130755 15248 solver.cpp:590] Iteration 33000, lr = 0.00148085
I0706 00:51:37.179908 15248 solver.cpp:243] Iteration 33110, loss = 0.283486
I0706 00:51:37.179970 15248 solver.cpp:259]     Train net output #0: loss = 0.283487 (* 1 = 0.283487 loss)
I0706 00:51:37.179976 15248 solver.cpp:590] Iteration 33110, lr = 0.00147145
I0706 00:51:58.723229 15248 solver.cpp:243] Iteration 33220, loss = 0.535475
I0706 00:51:58.723254 15248 solver.cpp:259]     Train net output #0: loss = 0.535475 (* 1 = 0.535475 loss)
I0706 00:51:58.723260 15248 solver.cpp:590] Iteration 33220, lr = 0.00146212
I0706 00:52:21.137253 15248 solver.cpp:243] Iteration 33330, loss = 0.230749
I0706 00:52:21.137372 15248 solver.cpp:259]     Train net output #0: loss = 0.230749 (* 1 = 0.230749 loss)
I0706 00:52:21.137379 15248 solver.cpp:590] Iteration 33330, lr = 0.00145284
I0706 00:52:42.608594 15248 solver.cpp:243] Iteration 33440, loss = 0.281302
I0706 00:52:42.608616 15248 solver.cpp:259]     Train net output #0: loss = 0.281302 (* 1 = 0.281302 loss)
I0706 00:52:42.608623 15248 solver.cpp:590] Iteration 33440, lr = 0.00144362
I0706 00:52:57.548122 15248 solver.cpp:347] Iteration 33516, Testing net (#0)
I0706 00:53:03.417932 15267 blocking_queue.cpp:50] Waiting for data
I0706 00:53:22.484653 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0528846
I0706 00:53:22.484683 15248 solver.cpp:415]     Test net output #1: loss = 6.77164 (* 1 = 6.77164 loss)
I0706 00:53:29.339366 15248 solver.cpp:243] Iteration 33550, loss = 0.246186
I0706 00:53:29.339653 15248 solver.cpp:259]     Train net output #0: loss = 0.246186 (* 1 = 0.246186 loss)
I0706 00:53:29.339660 15248 solver.cpp:590] Iteration 33550, lr = 0.00143446
I0706 00:53:51.281627 15248 solver.cpp:243] Iteration 33660, loss = 0.437605
I0706 00:53:51.281651 15248 solver.cpp:259]     Train net output #0: loss = 0.437604 (* 1 = 0.437604 loss)
I0706 00:53:51.281656 15248 solver.cpp:590] Iteration 33660, lr = 0.00142535
I0706 00:54:12.726955 15248 solver.cpp:243] Iteration 33770, loss = 0.167022
I0706 00:54:12.727048 15248 solver.cpp:259]     Train net output #0: loss = 0.167022 (* 1 = 0.167022 loss)
I0706 00:54:12.727056 15248 solver.cpp:590] Iteration 33770, lr = 0.00141631
I0706 00:54:34.787636 15248 solver.cpp:243] Iteration 33880, loss = 0.318678
I0706 00:54:34.787660 15248 solver.cpp:259]     Train net output #0: loss = 0.318678 (* 1 = 0.318678 loss)
I0706 00:54:34.787667 15248 solver.cpp:590] Iteration 33880, lr = 0.00140732
I0706 00:54:56.294116 15248 solver.cpp:243] Iteration 33990, loss = 0.508617
I0706 00:54:56.294209 15248 solver.cpp:259]     Train net output #0: loss = 0.508616 (* 1 = 0.508616 loss)
I0706 00:54:56.294225 15248 solver.cpp:590] Iteration 33990, lr = 0.00139839
I0706 00:55:18.605200 15248 solver.cpp:243] Iteration 34100, loss = 0.0527144
I0706 00:55:18.605224 15248 solver.cpp:259]     Train net output #0: loss = 0.0527141 (* 1 = 0.0527141 loss)
I0706 00:55:18.605232 15248 solver.cpp:590] Iteration 34100, lr = 0.00138951
I0706 00:55:40.104718 15248 solver.cpp:243] Iteration 34210, loss = 0.479196
I0706 00:55:40.104810 15248 solver.cpp:259]     Train net output #0: loss = 0.479196 (* 1 = 0.479196 loss)
I0706 00:55:40.104826 15248 solver.cpp:590] Iteration 34210, lr = 0.00138069
I0706 00:56:01.951004 15248 solver.cpp:243] Iteration 34320, loss = 0.353661
I0706 00:56:01.951028 15248 solver.cpp:259]     Train net output #0: loss = 0.353661 (* 1 = 0.353661 loss)
I0706 00:56:01.951035 15248 solver.cpp:590] Iteration 34320, lr = 0.00137193
I0706 00:56:17.344650 15248 solver.cpp:347] Iteration 34398, Testing net (#0)
I0706 00:56:30.180852 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 00:56:41.979948 15248 solver.cpp:415]     Test net output #0: accuracy = 0.05625
I0706 00:56:41.979976 15248 solver.cpp:415]     Test net output #1: loss = 6.83091 (* 1 = 6.83091 loss)
I0706 00:56:48.364542 15248 solver.cpp:243] Iteration 34430, loss = 0.0606748
I0706 00:56:48.364668 15248 solver.cpp:259]     Train net output #0: loss = 0.0606746 (* 1 = 0.0606746 loss)
I0706 00:56:48.364683 15248 solver.cpp:590] Iteration 34430, lr = 0.00136322
I0706 00:57:09.933527 15248 solver.cpp:243] Iteration 34540, loss = 0.227101
I0706 00:57:09.933550 15248 solver.cpp:259]     Train net output #0: loss = 0.2271 (* 1 = 0.2271 loss)
I0706 00:57:09.933557 15248 solver.cpp:590] Iteration 34540, lr = 0.00135457
I0706 00:57:32.168268 15248 solver.cpp:243] Iteration 34650, loss = 0.0778558
I0706 00:57:32.168362 15248 solver.cpp:259]     Train net output #0: loss = 0.0778555 (* 1 = 0.0778555 loss)
I0706 00:57:32.168380 15248 solver.cpp:590] Iteration 34650, lr = 0.00134598
I0706 00:57:53.754797 15248 solver.cpp:243] Iteration 34760, loss = 0.0497163
I0706 00:57:53.754822 15248 solver.cpp:259]     Train net output #0: loss = 0.0497161 (* 1 = 0.0497161 loss)
I0706 00:57:53.754828 15248 solver.cpp:590] Iteration 34760, lr = 0.00133743
I0706 00:58:15.617905 15248 solver.cpp:243] Iteration 34870, loss = 0.189283
I0706 00:58:15.618011 15248 solver.cpp:259]     Train net output #0: loss = 0.189282 (* 1 = 0.189282 loss)
I0706 00:58:15.618019 15248 solver.cpp:590] Iteration 34870, lr = 0.00132895
I0706 00:58:37.124336 15248 solver.cpp:243] Iteration 34980, loss = 0.137125
I0706 00:58:37.124358 15248 solver.cpp:259]     Train net output #0: loss = 0.137125 (* 1 = 0.137125 loss)
I0706 00:58:37.124366 15248 solver.cpp:590] Iteration 34980, lr = 0.00132051
I0706 00:58:59.053747 15248 solver.cpp:243] Iteration 35090, loss = 0.0454806
I0706 00:58:59.054471 15248 solver.cpp:259]     Train net output #0: loss = 0.0454803 (* 1 = 0.0454803 loss)
I0706 00:58:59.054479 15248 solver.cpp:590] Iteration 35090, lr = 0.00131213
I0706 00:59:21.090071 15248 solver.cpp:243] Iteration 35200, loss = 0.197466
I0706 00:59:21.090097 15248 solver.cpp:259]     Train net output #0: loss = 0.197465 (* 1 = 0.197465 loss)
I0706 00:59:21.090104 15248 solver.cpp:590] Iteration 35200, lr = 0.00130381
I0706 00:59:36.529402 15248 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_35280.caffemodel
I0706 01:00:05.870373 15248 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_35280.solverstate
I0706 01:00:08.649399 15248 solver.cpp:347] Iteration 35280, Testing net (#0)
I0706 01:00:36.084576 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0528846
I0706 01:00:36.084605 15248 solver.cpp:415]     Test net output #1: loss = 6.74332 (* 1 = 6.74332 loss)
I0706 01:00:42.264389 15248 solver.cpp:243] Iteration 35310, loss = 0.499872
I0706 01:00:42.264495 15248 solver.cpp:259]     Train net output #0: loss = 0.499872 (* 1 = 0.499872 loss)
I0706 01:00:42.264503 15248 solver.cpp:590] Iteration 35310, lr = 0.00129553
I0706 01:01:03.780187 15248 solver.cpp:243] Iteration 35420, loss = 0.18296
I0706 01:01:03.780211 15248 solver.cpp:259]     Train net output #0: loss = 0.18296 (* 1 = 0.18296 loss)
I0706 01:01:03.780217 15248 solver.cpp:590] Iteration 35420, lr = 0.00128731
I0706 01:01:25.378757 15248 solver.cpp:243] Iteration 35530, loss = 0.376419
I0706 01:01:25.378890 15248 solver.cpp:259]     Train net output #0: loss = 0.376418 (* 1 = 0.376418 loss)
I0706 01:01:25.378897 15248 solver.cpp:590] Iteration 35530, lr = 0.00127914
I0706 01:01:47.180816 15248 solver.cpp:243] Iteration 35640, loss = 0.0696712
I0706 01:01:47.180842 15248 solver.cpp:259]     Train net output #0: loss = 0.0696709 (* 1 = 0.0696709 loss)
I0706 01:01:47.180848 15248 solver.cpp:590] Iteration 35640, lr = 0.00127102
I0706 01:02:08.629076 15248 solver.cpp:243] Iteration 35750, loss = 0.0136395
I0706 01:02:08.629179 15248 solver.cpp:259]     Train net output #0: loss = 0.0136392 (* 1 = 0.0136392 loss)
I0706 01:02:08.629186 15248 solver.cpp:590] Iteration 35750, lr = 0.00126296
I0706 01:02:30.432231 15248 solver.cpp:243] Iteration 35860, loss = 0.0896991
I0706 01:02:30.432256 15248 solver.cpp:259]     Train net output #0: loss = 0.0896989 (* 1 = 0.0896989 loss)
I0706 01:02:30.432262 15248 solver.cpp:590] Iteration 35860, lr = 0.00125494
I0706 01:02:51.997305 15248 solver.cpp:243] Iteration 35970, loss = 0.338819
I0706 01:02:51.997400 15248 solver.cpp:259]     Train net output #0: loss = 0.338819 (* 1 = 0.338819 loss)
I0706 01:02:51.997407 15248 solver.cpp:590] Iteration 35970, lr = 0.00124698
I0706 01:03:13.581185 15248 solver.cpp:243] Iteration 36080, loss = 0.149004
I0706 01:03:13.581210 15248 solver.cpp:259]     Train net output #0: loss = 0.149004 (* 1 = 0.149004 loss)
I0706 01:03:13.581217 15248 solver.cpp:590] Iteration 36080, lr = 0.00123906
I0706 01:03:29.736503 15248 solver.cpp:347] Iteration 36162, Testing net (#0)
I0706 01:03:49.227603 15267 blocking_queue.cpp:50] Waiting for data
I0706 01:03:53.898705 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0557692
I0706 01:03:53.898733 15248 solver.cpp:415]     Test net output #1: loss = 6.77413 (* 1 = 6.77413 loss)
I0706 01:03:59.516484 15248 solver.cpp:243] Iteration 36190, loss = 0.247115
I0706 01:03:59.516505 15248 solver.cpp:259]     Train net output #0: loss = 0.247115 (* 1 = 0.247115 loss)
I0706 01:03:59.516511 15248 solver.cpp:590] Iteration 36190, lr = 0.0012312
I0706 01:04:21.099014 15248 solver.cpp:243] Iteration 36300, loss = 0.207253
I0706 01:04:21.099134 15248 solver.cpp:259]     Train net output #0: loss = 0.207253 (* 1 = 0.207253 loss)
I0706 01:04:21.099143 15248 solver.cpp:590] Iteration 36300, lr = 0.00122338
I0706 01:04:43.547158 15248 solver.cpp:243] Iteration 36410, loss = 0.284057
I0706 01:04:43.547181 15248 solver.cpp:259]     Train net output #0: loss = 0.284057 (* 1 = 0.284057 loss)
I0706 01:04:43.547188 15248 solver.cpp:590] Iteration 36410, lr = 0.00121562
I0706 01:05:05.058327 15248 solver.cpp:243] Iteration 36520, loss = 0.24596
I0706 01:05:05.058581 15248 solver.cpp:259]     Train net output #0: loss = 0.245959 (* 1 = 0.245959 loss)
I0706 01:05:05.058589 15248 solver.cpp:590] Iteration 36520, lr = 0.00120791
I0706 01:05:27.397258 15248 solver.cpp:243] Iteration 36630, loss = 0.39525
I0706 01:05:27.397318 15248 solver.cpp:259]     Train net output #0: loss = 0.39525 (* 1 = 0.39525 loss)
I0706 01:05:27.397338 15248 solver.cpp:590] Iteration 36630, lr = 0.00120024
I0706 01:05:49.000859 15248 solver.cpp:243] Iteration 36740, loss = 0.14848
I0706 01:05:49.000951 15248 solver.cpp:259]     Train net output #0: loss = 0.14848 (* 1 = 0.14848 loss)
I0706 01:05:49.000958 15248 solver.cpp:590] Iteration 36740, lr = 0.00119262
I0706 01:06:10.572718 15248 solver.cpp:243] Iteration 36850, loss = 0.0499952
I0706 01:06:10.572753 15248 solver.cpp:259]     Train net output #0: loss = 0.0499949 (* 1 = 0.0499949 loss)
I0706 01:06:10.572763 15248 solver.cpp:590] Iteration 36850, lr = 0.00118505
I0706 01:06:32.440840 15248 solver.cpp:243] Iteration 36960, loss = 0.0128181
I0706 01:06:32.440932 15248 solver.cpp:259]     Train net output #0: loss = 0.0128179 (* 1 = 0.0128179 loss)
I0706 01:06:32.440946 15248 solver.cpp:590] Iteration 36960, lr = 0.00117753
I0706 01:06:48.693169 15248 solver.cpp:347] Iteration 37044, Testing net (#0)
I0706 01:07:14.263403 15248 solver.cpp:415]     Test net output #0: accuracy = 0.056851
I0706 01:07:14.263530 15248 solver.cpp:415]     Test net output #1: loss = 6.71262 (* 1 = 6.71262 loss)
I0706 01:07:19.511320 15248 solver.cpp:243] Iteration 37070, loss = 0.163658
I0706 01:07:19.511348 15248 solver.cpp:259]     Train net output #0: loss = 0.163658 (* 1 = 0.163658 loss)
I0706 01:07:19.511356 15248 solver.cpp:590] Iteration 37070, lr = 0.00117006
I0706 01:07:41.570952 15248 solver.cpp:243] Iteration 37180, loss = 0.12487
I0706 01:07:41.570977 15248 solver.cpp:259]     Train net output #0: loss = 0.12487 (* 1 = 0.12487 loss)
I0706 01:07:41.570983 15248 solver.cpp:590] Iteration 37180, lr = 0.00116264
I0706 01:08:03.229343 15248 solver.cpp:243] Iteration 37290, loss = 0.114915
I0706 01:08:03.229437 15248 solver.cpp:259]     Train net output #0: loss = 0.114915 (* 1 = 0.114915 loss)
I0706 01:08:03.229454 15248 solver.cpp:590] Iteration 37290, lr = 0.00115526
I0706 01:08:25.340833 15248 solver.cpp:243] Iteration 37400, loss = 0.0339753
I0706 01:08:25.340894 15248 solver.cpp:259]     Train net output #0: loss = 0.0339754 (* 1 = 0.0339754 loss)
I0706 01:08:25.340910 15248 solver.cpp:590] Iteration 37400, lr = 0.00114792
I0706 01:08:47.016788 15248 solver.cpp:243] Iteration 37510, loss = 0.00843813
I0706 01:08:47.016875 15248 solver.cpp:259]     Train net output #0: loss = 0.00843813 (* 1 = 0.00843813 loss)
I0706 01:08:47.016891 15248 solver.cpp:590] Iteration 37510, lr = 0.00114064
I0706 01:09:08.714941 15248 solver.cpp:243] Iteration 37620, loss = 0.0555497
I0706 01:09:08.714964 15248 solver.cpp:259]     Train net output #0: loss = 0.0555497 (* 1 = 0.0555497 loss)
I0706 01:09:08.714970 15248 solver.cpp:590] Iteration 37620, lr = 0.0011334
I0706 01:09:30.677039 15248 solver.cpp:243] Iteration 37730, loss = 0.100001
I0706 01:09:30.677147 15248 solver.cpp:259]     Train net output #0: loss = 0.100001 (* 1 = 0.100001 loss)
I0706 01:09:30.677155 15248 solver.cpp:590] Iteration 37730, lr = 0.00112621
I0706 01:09:52.142302 15248 solver.cpp:243] Iteration 37840, loss = 0.183029
I0706 01:09:52.142324 15248 solver.cpp:259]     Train net output #0: loss = 0.183029 (* 1 = 0.183029 loss)
I0706 01:09:52.142330 15248 solver.cpp:590] Iteration 37840, lr = 0.00111906
I0706 01:10:10.210719 15248 solver.cpp:347] Iteration 37926, Testing net (#0)
I0706 01:10:23.296520 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 01:10:35.760924 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0588942
I0706 01:10:35.760952 15248 solver.cpp:415]     Test net output #1: loss = 6.79116 (* 1 = 6.79116 loss)
I0706 01:10:40.618052 15248 solver.cpp:243] Iteration 37950, loss = 0.0869859
I0706 01:10:40.618141 15248 solver.cpp:259]     Train net output #0: loss = 0.0869858 (* 1 = 0.0869858 loss)
I0706 01:10:40.618149 15248 solver.cpp:590] Iteration 37950, lr = 0.00111196
I0706 01:11:02.094663 15248 solver.cpp:243] Iteration 38060, loss = 0.107059
I0706 01:11:02.094686 15248 solver.cpp:259]     Train net output #0: loss = 0.107059 (* 1 = 0.107059 loss)
I0706 01:11:02.094691 15248 solver.cpp:590] Iteration 38060, lr = 0.0011049
I0706 01:11:24.248323 15248 solver.cpp:243] Iteration 38170, loss = 0.157563
I0706 01:11:24.248415 15248 solver.cpp:259]     Train net output #0: loss = 0.157563 (* 1 = 0.157563 loss)
I0706 01:11:24.248421 15248 solver.cpp:590] Iteration 38170, lr = 0.00109789
I0706 01:11:45.750476 15248 solver.cpp:243] Iteration 38280, loss = 0.0324734
I0706 01:11:45.750501 15248 solver.cpp:259]     Train net output #0: loss = 0.0324734 (* 1 = 0.0324734 loss)
I0706 01:11:45.750509 15248 solver.cpp:590] Iteration 38280, lr = 0.00109092
I0706 01:12:07.596133 15248 solver.cpp:243] Iteration 38390, loss = 0.194264
I0706 01:12:07.596264 15248 solver.cpp:259]     Train net output #0: loss = 0.194264 (* 1 = 0.194264 loss)
I0706 01:12:07.596272 15248 solver.cpp:590] Iteration 38390, lr = 0.001084
I0706 01:12:29.548164 15248 solver.cpp:243] Iteration 38500, loss = 0.158957
I0706 01:12:29.548184 15248 solver.cpp:259]     Train net output #0: loss = 0.158957 (* 1 = 0.158957 loss)
I0706 01:12:29.548190 15248 solver.cpp:590] Iteration 38500, lr = 0.00107712
I0706 01:12:51.022372 15248 solver.cpp:243] Iteration 38610, loss = 0.120471
I0706 01:12:51.022457 15248 solver.cpp:259]     Train net output #0: loss = 0.120471 (* 1 = 0.120471 loss)
I0706 01:12:51.022464 15248 solver.cpp:590] Iteration 38610, lr = 0.00107028
I0706 01:13:13.447708 15248 solver.cpp:243] Iteration 38720, loss = 0.408335
I0706 01:13:13.447732 15248 solver.cpp:259]     Train net output #0: loss = 0.408335 (* 1 = 0.408335 loss)
I0706 01:13:13.447738 15248 solver.cpp:590] Iteration 38720, lr = 0.00106349
I0706 01:13:30.401473 15248 solver.cpp:347] Iteration 38808, Testing net (#0)
I0706 01:13:55.440088 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0569712
I0706 01:13:55.440117 15248 solver.cpp:415]     Test net output #1: loss = 6.8193 (* 1 = 6.8193 loss)
I0706 01:13:59.889437 15248 solver.cpp:243] Iteration 38830, loss = 0.167074
I0706 01:13:59.889462 15248 solver.cpp:259]     Train net output #0: loss = 0.167075 (* 1 = 0.167075 loss)
I0706 01:13:59.889468 15248 solver.cpp:590] Iteration 38830, lr = 0.00105674
I0706 01:14:22.171046 15248 solver.cpp:243] Iteration 38940, loss = 0.496214
I0706 01:14:22.171138 15248 solver.cpp:259]     Train net output #0: loss = 0.496214 (* 1 = 0.496214 loss)
I0706 01:14:22.171144 15248 solver.cpp:590] Iteration 38940, lr = 0.00105004
I0706 01:14:43.648697 15248 solver.cpp:243] Iteration 39050, loss = 0.00144118
I0706 01:14:43.648720 15248 solver.cpp:259]     Train net output #0: loss = 0.00144131 (* 1 = 0.00144131 loss)
I0706 01:14:43.648726 15248 solver.cpp:590] Iteration 39050, lr = 0.00104337
I0706 01:15:05.721555 15248 solver.cpp:243] Iteration 39160, loss = 0.103272
I0706 01:15:05.721647 15248 solver.cpp:259]     Train net output #0: loss = 0.103272 (* 1 = 0.103272 loss)
I0706 01:15:05.721664 15248 solver.cpp:590] Iteration 39160, lr = 0.00103675
I0706 01:15:27.892891 15248 solver.cpp:243] Iteration 39270, loss = 0.013133
I0706 01:15:27.892915 15248 solver.cpp:259]     Train net output #0: loss = 0.0131332 (* 1 = 0.0131332 loss)
I0706 01:15:27.892920 15248 solver.cpp:590] Iteration 39270, lr = 0.00103017
I0706 01:15:49.413055 15248 solver.cpp:243] Iteration 39380, loss = 0.0624002
I0706 01:15:49.413167 15248 solver.cpp:259]     Train net output #0: loss = 0.0624004 (* 1 = 0.0624004 loss)
I0706 01:15:49.413174 15248 solver.cpp:590] Iteration 39380, lr = 0.00102363
I0706 01:16:11.508751 15248 solver.cpp:243] Iteration 39490, loss = 0.380378
I0706 01:16:11.508775 15248 solver.cpp:259]     Train net output #0: loss = 0.380378 (* 1 = 0.380378 loss)
I0706 01:16:11.508781 15248 solver.cpp:590] Iteration 39490, lr = 0.00101714
I0706 01:16:33.054462 15248 solver.cpp:243] Iteration 39600, loss = 0.064305
I0706 01:16:33.054690 15248 solver.cpp:259]     Train net output #0: loss = 0.0643049 (* 1 = 0.0643049 loss)
I0706 01:16:33.054699 15248 solver.cpp:590] Iteration 39600, lr = 0.00101068
I0706 01:16:51.144695 15248 solver.cpp:347] Iteration 39690, Testing net (#0)
I0706 01:17:17.993111 15267 blocking_queue.cpp:50] Waiting for data
I0706 01:17:19.139226 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0569712
I0706 01:17:19.139264 15248 solver.cpp:415]     Test net output #1: loss = 6.77063 (* 1 = 6.77063 loss)
I0706 01:17:23.307956 15248 solver.cpp:243] Iteration 39710, loss = 0.276737
I0706 01:17:23.307979 15248 solver.cpp:259]     Train net output #0: loss = 0.276737 (* 1 = 0.276737 loss)
I0706 01:17:23.307986 15248 solver.cpp:590] Iteration 39710, lr = 0.00100427
I0706 01:17:45.247275 15248 solver.cpp:243] Iteration 39820, loss = 0.0651236
I0706 01:17:45.247298 15248 solver.cpp:259]     Train net output #0: loss = 0.0651233 (* 1 = 0.0651233 loss)
I0706 01:17:45.247303 15248 solver.cpp:590] Iteration 39820, lr = 0.000997894
I0706 01:18:06.743607 15248 solver.cpp:243] Iteration 39930, loss = 0.293566
I0706 01:18:06.743893 15248 solver.cpp:259]     Train net output #0: loss = 0.293566 (* 1 = 0.293566 loss)
I0706 01:18:06.743901 15248 solver.cpp:590] Iteration 39930, lr = 0.000991561
I0706 01:18:28.947926 15248 solver.cpp:243] Iteration 40040, loss = 0.115879
I0706 01:18:28.947947 15248 solver.cpp:259]     Train net output #0: loss = 0.115879 (* 1 = 0.115879 loss)
I0706 01:18:28.947954 15248 solver.cpp:590] Iteration 40040, lr = 0.000985268
I0706 01:18:50.473336 15248 solver.cpp:243] Iteration 40150, loss = 0.0268171
I0706 01:18:50.473991 15248 solver.cpp:259]     Train net output #0: loss = 0.0268168 (* 1 = 0.0268168 loss)
I0706 01:18:50.474006 15248 solver.cpp:590] Iteration 40150, lr = 0.000979015
I0706 01:19:12.979889 15248 solver.cpp:243] Iteration 40260, loss = 0.0223418
I0706 01:19:12.979955 15248 solver.cpp:259]     Train net output #0: loss = 0.0223415 (* 1 = 0.0223415 loss)
I0706 01:19:12.979974 15248 solver.cpp:590] Iteration 40260, lr = 0.000972802
I0706 01:19:34.597632 15248 solver.cpp:243] Iteration 40370, loss = 0.121597
I0706 01:19:34.597889 15248 solver.cpp:259]     Train net output #0: loss = 0.121596 (* 1 = 0.121596 loss)
I0706 01:19:34.597898 15248 solver.cpp:590] Iteration 40370, lr = 0.000966628
I0706 01:19:56.335871 15248 solver.cpp:243] Iteration 40480, loss = 0.144978
I0706 01:19:56.335894 15248 solver.cpp:259]     Train net output #0: loss = 0.144977 (* 1 = 0.144977 loss)
I0706 01:19:56.335901 15248 solver.cpp:590] Iteration 40480, lr = 0.000960494
I0706 01:20:14.477680 15248 solver.cpp:347] Iteration 40572, Testing net (#0)
I0706 01:20:40.337157 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0574519
I0706 01:20:40.337184 15248 solver.cpp:415]     Test net output #1: loss = 6.86533 (* 1 = 6.86533 loss)
I0706 01:20:43.988615 15248 solver.cpp:243] Iteration 40590, loss = 0.0772213
I0706 01:20:43.988638 15248 solver.cpp:259]     Train net output #0: loss = 0.0772212 (* 1 = 0.0772212 loss)
I0706 01:20:43.988644 15248 solver.cpp:590] Iteration 40590, lr = 0.000954398
I0706 01:21:05.498924 15248 solver.cpp:243] Iteration 40700, loss = 0.0167422
I0706 01:21:05.499037 15248 solver.cpp:259]     Train net output #0: loss = 0.0167423 (* 1 = 0.0167423 loss)
I0706 01:21:05.499055 15248 solver.cpp:590] Iteration 40700, lr = 0.000948341
I0706 01:21:27.246428 15248 solver.cpp:243] Iteration 40810, loss = 0.0819771
I0706 01:21:27.246453 15248 solver.cpp:259]     Train net output #0: loss = 0.081977 (* 1 = 0.081977 loss)
I0706 01:21:27.246459 15248 solver.cpp:590] Iteration 40810, lr = 0.000942323
I0706 01:21:48.805888 15248 solver.cpp:243] Iteration 40920, loss = 0.521451
I0706 01:21:48.826274 15248 solver.cpp:259]     Train net output #0: loss = 0.521451 (* 1 = 0.521451 loss)
I0706 01:21:48.826282 15248 solver.cpp:590] Iteration 40920, lr = 0.000936343
I0706 01:22:10.745645 15248 solver.cpp:243] Iteration 41030, loss = 0.650081
I0706 01:22:10.745668 15248 solver.cpp:259]     Train net output #0: loss = 0.650081 (* 1 = 0.650081 loss)
I0706 01:22:10.745673 15248 solver.cpp:590] Iteration 41030, lr = 0.0009304
I0706 01:22:32.153887 15248 solver.cpp:243] Iteration 41140, loss = 0.00460711
I0706 01:22:32.153975 15248 solver.cpp:259]     Train net output #0: loss = 0.00460687 (* 1 = 0.00460687 loss)
I0706 01:22:32.153982 15248 solver.cpp:590] Iteration 41140, lr = 0.000924496
I0706 01:22:54.059267 15248 solver.cpp:243] Iteration 41250, loss = 0.21029
I0706 01:22:54.059329 15248 solver.cpp:259]     Train net output #0: loss = 0.21029 (* 1 = 0.21029 loss)
I0706 01:22:54.059346 15248 solver.cpp:590] Iteration 41250, lr = 0.000918628
I0706 01:23:15.586246 15248 solver.cpp:243] Iteration 41360, loss = 0.301425
I0706 01:23:15.586338 15248 solver.cpp:259]     Train net output #0: loss = 0.301425 (* 1 = 0.301425 loss)
I0706 01:23:15.586354 15248 solver.cpp:590] Iteration 41360, lr = 0.000912799
I0706 01:23:33.730566 15248 solver.cpp:347] Iteration 41454, Testing net (#0)
I0706 01:23:45.727512 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 01:23:57.627671 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0572115
I0706 01:23:57.627699 15248 solver.cpp:415]     Test net output #1: loss = 6.76146 (* 1 = 6.76146 loss)
I0706 01:24:00.917235 15248 solver.cpp:243] Iteration 41470, loss = 0.114821
I0706 01:24:00.917261 15248 solver.cpp:259]     Train net output #0: loss = 0.114821 (* 1 = 0.114821 loss)
I0706 01:24:00.917268 15248 solver.cpp:590] Iteration 41470, lr = 0.000907006
I0706 01:24:22.925211 15248 solver.cpp:243] Iteration 41580, loss = 0.0423653
I0706 01:24:22.925318 15248 solver.cpp:259]     Train net output #0: loss = 0.042365 (* 1 = 0.042365 loss)
I0706 01:24:22.925325 15248 solver.cpp:590] Iteration 41580, lr = 0.000901249
I0706 01:24:44.342506 15248 solver.cpp:243] Iteration 41690, loss = 0.177957
I0706 01:24:44.342530 15248 solver.cpp:259]     Train net output #0: loss = 0.177956 (* 1 = 0.177956 loss)
I0706 01:24:44.342536 15248 solver.cpp:590] Iteration 41690, lr = 0.00089553
I0706 01:25:06.317345 15248 solver.cpp:243] Iteration 41800, loss = 0.402318
I0706 01:25:06.317461 15248 solver.cpp:259]     Train net output #0: loss = 0.402318 (* 1 = 0.402318 loss)
I0706 01:25:06.317467 15248 solver.cpp:590] Iteration 41800, lr = 0.000889846
I0706 01:25:28.176010 15248 solver.cpp:243] Iteration 41910, loss = 0.00372531
I0706 01:25:28.176034 15248 solver.cpp:259]     Train net output #0: loss = 0.00372507 (* 1 = 0.00372507 loss)
I0706 01:25:28.176040 15248 solver.cpp:590] Iteration 41910, lr = 0.000884199
I0706 01:25:50.484601 15248 solver.cpp:243] Iteration 42020, loss = 0.0873204
I0706 01:25:50.484663 15248 solver.cpp:259]     Train net output #0: loss = 0.0873202 (* 1 = 0.0873202 loss)
I0706 01:25:50.484669 15248 solver.cpp:590] Iteration 42020, lr = 0.000878588
I0706 01:26:12.187449 15248 solver.cpp:243] Iteration 42130, loss = 0.108875
I0706 01:26:12.187474 15248 solver.cpp:259]     Train net output #0: loss = 0.108874 (* 1 = 0.108874 loss)
I0706 01:26:12.187479 15248 solver.cpp:590] Iteration 42130, lr = 0.000873012
I0706 01:26:33.726897 15248 solver.cpp:243] Iteration 42240, loss = 0.143054
I0706 01:26:33.727068 15248 solver.cpp:259]     Train net output #0: loss = 0.143054 (* 1 = 0.143054 loss)
I0706 01:26:33.727085 15248 solver.cpp:590] Iteration 42240, lr = 0.000867472
I0706 01:26:53.042042 15248 solver.cpp:347] Iteration 42336, Testing net (#0)
I0706 01:27:18.633600 15267 blocking_queue.cpp:50] Waiting for data
I0706 01:27:19.946285 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0580529
I0706 01:27:19.946316 15248 solver.cpp:415]     Test net output #1: loss = 6.79403 (* 1 = 6.79403 loss)
I0706 01:27:22.830122 15248 solver.cpp:243] Iteration 42350, loss = 0.0126418
I0706 01:27:22.830143 15248 solver.cpp:259]     Train net output #0: loss = 0.0126417 (* 1 = 0.0126417 loss)
I0706 01:27:22.830149 15248 solver.cpp:590] Iteration 42350, lr = 0.000861966
I0706 01:27:44.345402 15248 solver.cpp:243] Iteration 42460, loss = 1.14536
I0706 01:27:44.345425 15248 solver.cpp:259]     Train net output #0: loss = 1.14536 (* 1 = 1.14536 loss)
I0706 01:27:44.345432 15248 solver.cpp:590] Iteration 42460, lr = 0.000856496
I0706 01:28:06.368409 15248 solver.cpp:243] Iteration 42570, loss = 0.00666796
I0706 01:28:06.368695 15248 solver.cpp:259]     Train net output #0: loss = 0.00666786 (* 1 = 0.00666786 loss)
I0706 01:28:06.368703 15248 solver.cpp:590] Iteration 42570, lr = 0.00085106
I0706 01:28:27.893626 15248 solver.cpp:243] Iteration 42680, loss = 0.204386
I0706 01:28:27.893654 15248 solver.cpp:259]     Train net output #0: loss = 0.204386 (* 1 = 0.204386 loss)
I0706 01:28:27.893662 15248 solver.cpp:590] Iteration 42680, lr = 0.000845659
I0706 01:28:50.188846 15248 solver.cpp:243] Iteration 42790, loss = 0.165141
I0706 01:28:50.189121 15248 solver.cpp:259]     Train net output #0: loss = 0.165141 (* 1 = 0.165141 loss)
I0706 01:28:50.189131 15248 solver.cpp:590] Iteration 42790, lr = 0.000840292
I0706 01:29:11.776242 15248 solver.cpp:243] Iteration 42900, loss = 0.0193969
I0706 01:29:11.776265 15248 solver.cpp:259]     Train net output #0: loss = 0.0193969 (* 1 = 0.0193969 loss)
I0706 01:29:11.776271 15248 solver.cpp:590] Iteration 42900, lr = 0.00083496
I0706 01:29:33.891854 15248 solver.cpp:243] Iteration 43010, loss = 0.0304919
I0706 01:29:33.891944 15248 solver.cpp:259]     Train net output #0: loss = 0.0304919 (* 1 = 0.0304919 loss)
I0706 01:29:33.891952 15248 solver.cpp:590] Iteration 43010, lr = 0.000829661
I0706 01:29:55.881204 15248 solver.cpp:243] Iteration 43120, loss = 0.0275893
I0706 01:29:55.881229 15248 solver.cpp:259]     Train net output #0: loss = 0.0275892 (* 1 = 0.0275892 loss)
I0706 01:29:55.881235 15248 solver.cpp:590] Iteration 43120, lr = 0.000824395
I0706 01:30:14.874245 15248 solver.cpp:347] Iteration 43218, Testing net (#0)
I0706 01:30:39.926859 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0591346
I0706 01:30:39.926887 15248 solver.cpp:415]     Test net output #1: loss = 6.72755 (* 1 = 6.72755 loss)
I0706 01:30:42.410662 15248 solver.cpp:243] Iteration 43230, loss = 0.0876511
I0706 01:30:42.410691 15248 solver.cpp:259]     Train net output #0: loss = 0.0876509 (* 1 = 0.0876509 loss)
I0706 01:30:42.410698 15248 solver.cpp:590] Iteration 43230, lr = 0.000819164
I0706 01:31:04.743851 15248 solver.cpp:243] Iteration 43340, loss = 0.188623
I0706 01:31:04.743939 15248 solver.cpp:259]     Train net output #0: loss = 0.188623 (* 1 = 0.188623 loss)
I0706 01:31:04.743945 15248 solver.cpp:590] Iteration 43340, lr = 0.000813965
I0706 01:31:26.281909 15248 solver.cpp:243] Iteration 43450, loss = 0.283681
I0706 01:31:26.281932 15248 solver.cpp:259]     Train net output #0: loss = 0.283681 (* 1 = 0.283681 loss)
I0706 01:31:26.281939 15248 solver.cpp:590] Iteration 43450, lr = 0.000808799
I0706 01:31:48.299533 15248 solver.cpp:243] Iteration 43560, loss = 0.00184247
I0706 01:31:48.299623 15248 solver.cpp:259]     Train net output #0: loss = 0.00184199 (* 1 = 0.00184199 loss)
I0706 01:31:48.299629 15248 solver.cpp:590] Iteration 43560, lr = 0.000803666
I0706 01:32:10.002851 15248 solver.cpp:243] Iteration 43670, loss = 0.0946499
I0706 01:32:10.002872 15248 solver.cpp:259]     Train net output #0: loss = 0.0946494 (* 1 = 0.0946494 loss)
I0706 01:32:10.002878 15248 solver.cpp:590] Iteration 43670, lr = 0.000798566
I0706 01:32:31.732882 15248 solver.cpp:243] Iteration 43780, loss = 0.224302
I0706 01:32:31.733003 15248 solver.cpp:259]     Train net output #0: loss = 0.224302 (* 1 = 0.224302 loss)
I0706 01:32:31.733011 15248 solver.cpp:590] Iteration 43780, lr = 0.000793498
I0706 01:32:54.432355 15248 solver.cpp:243] Iteration 43890, loss = 0.000613844
I0706 01:32:54.432380 15248 solver.cpp:259]     Train net output #0: loss = 0.000613322 (* 1 = 0.000613322 loss)
I0706 01:32:54.432387 15248 solver.cpp:590] Iteration 43890, lr = 0.000788462
I0706 01:33:15.884492 15248 solver.cpp:243] Iteration 44000, loss = 0.0952718
I0706 01:33:15.884811 15248 solver.cpp:259]     Train net output #0: loss = 0.0952715 (* 1 = 0.0952715 loss)
I0706 01:33:15.884855 15248 solver.cpp:590] Iteration 44000, lr = 0.000783458
I0706 01:33:35.885372 15248 solver.cpp:347] Iteration 44100, Testing net (#0)
I0706 01:34:00.708328 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0591346
I0706 01:34:00.708451 15248 solver.cpp:415]     Test net output #1: loss = 6.79073 (* 1 = 6.79073 loss)
I0706 01:34:02.926627 15248 solver.cpp:243] Iteration 44110, loss = 0.040848
I0706 01:34:02.926651 15248 solver.cpp:259]     Train net output #0: loss = 0.0408478 (* 1 = 0.0408478 loss)
I0706 01:34:02.926657 15248 solver.cpp:590] Iteration 44110, lr = 0.000778486
I0706 01:34:24.381652 15248 solver.cpp:243] Iteration 44220, loss = 0.171136
I0706 01:34:24.381675 15248 solver.cpp:259]     Train net output #0: loss = 0.171135 (* 1 = 0.171135 loss)
I0706 01:34:24.381681 15248 solver.cpp:590] Iteration 44220, lr = 0.000773546
I0706 01:34:45.934648 15248 solver.cpp:243] Iteration 44330, loss = 0.0337426
I0706 01:34:45.934768 15248 solver.cpp:259]     Train net output #0: loss = 0.0337422 (* 1 = 0.0337422 loss)
I0706 01:34:45.934777 15248 solver.cpp:590] Iteration 44330, lr = 0.000768636
I0706 01:35:08.706614 15248 solver.cpp:243] Iteration 44440, loss = 0.0308671
I0706 01:35:08.706640 15248 solver.cpp:259]     Train net output #0: loss = 0.0308668 (* 1 = 0.0308668 loss)
I0706 01:35:08.706645 15248 solver.cpp:590] Iteration 44440, lr = 0.000763758
I0706 01:35:30.183425 15248 solver.cpp:243] Iteration 44550, loss = 0.180343
I0706 01:35:30.183552 15248 solver.cpp:259]     Train net output #0: loss = 0.180342 (* 1 = 0.180342 loss)
I0706 01:35:30.183568 15248 solver.cpp:590] Iteration 44550, lr = 0.000758911
I0706 01:35:52.635484 15248 solver.cpp:243] Iteration 44660, loss = 0.106338
I0706 01:35:52.635509 15248 solver.cpp:259]     Train net output #0: loss = 0.106337 (* 1 = 0.106337 loss)
I0706 01:35:52.635514 15248 solver.cpp:590] Iteration 44660, lr = 0.000754095
I0706 01:36:14.061187 15248 solver.cpp:243] Iteration 44770, loss = 0.00371521
I0706 01:36:14.061282 15248 solver.cpp:259]     Train net output #0: loss = 0.00371488 (* 1 = 0.00371488 loss)
I0706 01:36:14.061300 15248 solver.cpp:590] Iteration 44770, lr = 0.000749309
I0706 01:36:35.969009 15248 solver.cpp:243] Iteration 44880, loss = 0.0383146
I0706 01:36:35.969033 15248 solver.cpp:259]     Train net output #0: loss = 0.0383144 (* 1 = 0.0383144 loss)
I0706 01:36:35.969039 15248 solver.cpp:590] Iteration 44880, lr = 0.000744554
I0706 01:36:55.743685 15248 solver.cpp:347] Iteration 44982, Testing net (#0)
I0706 01:37:09.227278 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 01:37:25.590780 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0584135
I0706 01:37:25.590809 15248 solver.cpp:415]     Test net output #1: loss = 6.78547 (* 1 = 6.78547 loss)
I0706 01:37:27.300082 15248 solver.cpp:243] Iteration 44990, loss = 0.189256
I0706 01:37:27.300192 15248 solver.cpp:259]     Train net output #0: loss = 0.189256 (* 1 = 0.189256 loss)
I0706 01:37:27.300209 15248 solver.cpp:590] Iteration 44990, lr = 0.000739829
I0706 01:37:49.550909 15248 solver.cpp:243] Iteration 45100, loss = 0.00546414
I0706 01:37:49.550932 15248 solver.cpp:259]     Train net output #0: loss = 0.0054638 (* 1 = 0.0054638 loss)
I0706 01:37:49.550938 15248 solver.cpp:590] Iteration 45100, lr = 0.000735134
I0706 01:38:11.725128 15248 solver.cpp:243] Iteration 45210, loss = 0.0244079
I0706 01:38:11.725237 15248 solver.cpp:259]     Train net output #0: loss = 0.0244075 (* 1 = 0.0244075 loss)
I0706 01:38:11.725245 15248 solver.cpp:590] Iteration 45210, lr = 0.000730468
I0706 01:38:33.199723 15248 solver.cpp:243] Iteration 45320, loss = 0.1206
I0706 01:38:33.199779 15248 solver.cpp:259]     Train net output #0: loss = 0.1206 (* 1 = 0.1206 loss)
I0706 01:38:33.199793 15248 solver.cpp:590] Iteration 45320, lr = 0.000725832
I0706 01:38:55.097681 15248 solver.cpp:243] Iteration 45430, loss = 0.0154992
I0706 01:38:55.097909 15248 solver.cpp:259]     Train net output #0: loss = 0.0154988 (* 1 = 0.0154988 loss)
I0706 01:38:55.097918 15248 solver.cpp:590] Iteration 45430, lr = 0.000721226
I0706 01:39:16.574820 15248 solver.cpp:243] Iteration 45540, loss = 0.135795
I0706 01:39:16.574846 15248 solver.cpp:259]     Train net output #0: loss = 0.135794 (* 1 = 0.135794 loss)
I0706 01:39:16.574851 15248 solver.cpp:590] Iteration 45540, lr = 0.000716649
I0706 01:39:38.325276 15248 solver.cpp:243] Iteration 45650, loss = 0.0067372
I0706 01:39:38.325752 15248 solver.cpp:259]     Train net output #0: loss = 0.00673688 (* 1 = 0.00673688 loss)
I0706 01:39:38.325759 15248 solver.cpp:590] Iteration 45650, lr = 0.000712101
I0706 01:39:59.848357 15248 solver.cpp:243] Iteration 45760, loss = 0.0853222
I0706 01:39:59.848382 15248 solver.cpp:259]     Train net output #0: loss = 0.0853218 (* 1 = 0.0853218 loss)
I0706 01:39:59.848388 15248 solver.cpp:590] Iteration 45760, lr = 0.000707582
I0706 01:40:20.353369 15248 solver.cpp:347] Iteration 45864, Testing net (#0)
I0706 01:40:25.250774 15267 blocking_queue.cpp:50] Waiting for data
I0706 01:40:47.263568 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0591346
I0706 01:40:47.263597 15248 solver.cpp:415]     Test net output #1: loss = 6.72253 (* 1 = 6.72253 loss)
I0706 01:40:48.668133 15248 solver.cpp:243] Iteration 45870, loss = 0.0105821
I0706 01:40:48.668159 15248 solver.cpp:259]     Train net output #0: loss = 0.0105817 (* 1 = 0.0105817 loss)
I0706 01:40:48.668164 15248 solver.cpp:590] Iteration 45870, lr = 0.000703091
I0706 01:41:10.317477 15248 solver.cpp:243] Iteration 45980, loss = 0.0899259
I0706 01:41:10.317734 15248 solver.cpp:259]     Train net output #0: loss = 0.0899254 (* 1 = 0.0899254 loss)
I0706 01:41:10.317741 15248 solver.cpp:590] Iteration 45980, lr = 0.000698629
I0706 01:41:31.836221 15248 solver.cpp:243] Iteration 46090, loss = 0.182162
I0706 01:41:31.836274 15248 solver.cpp:259]     Train net output #0: loss = 0.182161 (* 1 = 0.182161 loss)
I0706 01:41:31.836289 15248 solver.cpp:590] Iteration 46090, lr = 0.000694195
I0706 01:41:53.795567 15248 solver.cpp:243] Iteration 46200, loss = 0.0857477
I0706 01:41:53.795846 15248 solver.cpp:259]     Train net output #0: loss = 0.0857473 (* 1 = 0.0857473 loss)
I0706 01:41:53.795853 15248 solver.cpp:590] Iteration 46200, lr = 0.00068979
I0706 01:42:15.380941 15248 solver.cpp:243] Iteration 46310, loss = 0.259998
I0706 01:42:15.380965 15248 solver.cpp:259]     Train net output #0: loss = 0.259997 (* 1 = 0.259997 loss)
I0706 01:42:15.380971 15248 solver.cpp:590] Iteration 46310, lr = 0.000685412
I0706 01:42:37.753939 15248 solver.cpp:243] Iteration 46420, loss = 0.0879634
I0706 01:42:37.754034 15248 solver.cpp:259]     Train net output #0: loss = 0.087963 (* 1 = 0.087963 loss)
I0706 01:42:37.754041 15248 solver.cpp:590] Iteration 46420, lr = 0.000681062
I0706 01:42:59.737320 15248 solver.cpp:243] Iteration 46530, loss = 0.308424
I0706 01:42:59.737344 15248 solver.cpp:259]     Train net output #0: loss = 0.308424 (* 1 = 0.308424 loss)
I0706 01:42:59.737350 15248 solver.cpp:590] Iteration 46530, lr = 0.00067674
I0706 01:43:21.609098 15248 solver.cpp:243] Iteration 46640, loss = 0.0014277
I0706 01:43:21.609231 15248 solver.cpp:259]     Train net output #0: loss = 0.00142736 (* 1 = 0.00142736 loss)
I0706 01:43:21.609239 15248 solver.cpp:590] Iteration 46640, lr = 0.000672445
I0706 01:43:43.402792 15248 solver.cpp:347] Iteration 46746, Testing net (#0)
I0706 01:44:09.769402 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0600962
I0706 01:44:09.769546 15248 solver.cpp:415]     Test net output #1: loss = 6.70562 (* 1 = 6.70562 loss)
I0706 01:44:10.696985 15248 solver.cpp:243] Iteration 46750, loss = 0.0736125
I0706 01:44:10.697010 15248 solver.cpp:259]     Train net output #0: loss = 0.073612 (* 1 = 0.073612 loss)
I0706 01:44:10.697016 15248 solver.cpp:590] Iteration 46750, lr = 0.000668178
I0706 01:44:32.454844 15248 solver.cpp:243] Iteration 46860, loss = 0.162832
I0706 01:44:32.454866 15248 solver.cpp:259]     Train net output #0: loss = 0.162832 (* 1 = 0.162832 loss)
I0706 01:44:32.454872 15248 solver.cpp:590] Iteration 46860, lr = 0.000663937
I0706 01:44:54.848942 15248 solver.cpp:243] Iteration 46970, loss = 0.010863
I0706 01:44:54.859632 15248 solver.cpp:259]     Train net output #0: loss = 0.0108626 (* 1 = 0.0108626 loss)
I0706 01:44:54.859643 15248 solver.cpp:590] Iteration 46970, lr = 0.000659723
I0706 01:45:16.309731 15248 solver.cpp:243] Iteration 47080, loss = 0.0206331
I0706 01:45:16.309754 15248 solver.cpp:259]     Train net output #0: loss = 0.0206327 (* 1 = 0.0206327 loss)
I0706 01:45:16.309759 15248 solver.cpp:590] Iteration 47080, lr = 0.000655537
I0706 01:45:39.044317 15248 solver.cpp:243] Iteration 47190, loss = 0.0754943
I0706 01:45:39.044570 15248 solver.cpp:259]     Train net output #0: loss = 0.0754938 (* 1 = 0.0754938 loss)
I0706 01:45:39.044579 15248 solver.cpp:590] Iteration 47190, lr = 0.000651376
I0706 01:46:00.918998 15248 solver.cpp:243] Iteration 47300, loss = 0.122905
I0706 01:46:00.919024 15248 solver.cpp:259]     Train net output #0: loss = 0.122904 (* 1 = 0.122904 loss)
I0706 01:46:00.919030 15248 solver.cpp:590] Iteration 47300, lr = 0.000647243
I0706 01:46:22.654695 15248 solver.cpp:243] Iteration 47410, loss = 0.208145
I0706 01:46:22.657008 15248 solver.cpp:259]     Train net output #0: loss = 0.208145 (* 1 = 0.208145 loss)
I0706 01:46:22.657017 15248 solver.cpp:590] Iteration 47410, lr = 0.000643135
I0706 01:46:44.151742 15248 solver.cpp:243] Iteration 47520, loss = 0.230491
I0706 01:46:44.151767 15248 solver.cpp:259]     Train net output #0: loss = 0.23049 (* 1 = 0.23049 loss)
I0706 01:46:44.151773 15248 solver.cpp:590] Iteration 47520, lr = 0.000639053
I0706 01:47:05.162644 15248 solver.cpp:347] Iteration 47628, Testing net (#0)
I0706 01:47:30.745479 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0623798
I0706 01:47:30.745508 15248 solver.cpp:415]     Test net output #1: loss = 6.7196 (* 1 = 6.7196 loss)
I0706 01:47:31.272562 15248 solver.cpp:243] Iteration 47630, loss = 0.0421833
I0706 01:47:31.272610 15248 solver.cpp:259]     Train net output #0: loss = 0.0421828 (* 1 = 0.0421828 loss)
I0706 01:47:31.272625 15248 solver.cpp:590] Iteration 47630, lr = 0.000634998
I0706 01:47:53.336472 15248 solver.cpp:243] Iteration 47740, loss = 0.158645
I0706 01:47:53.336563 15248 solver.cpp:259]     Train net output #0: loss = 0.158644 (* 1 = 0.158644 loss)
I0706 01:47:53.336570 15248 solver.cpp:590] Iteration 47740, lr = 0.000630968
I0706 01:48:14.836391 15248 solver.cpp:243] Iteration 47850, loss = 0.00489352
I0706 01:48:14.836416 15248 solver.cpp:259]     Train net output #0: loss = 0.00489307 (* 1 = 0.00489307 loss)
I0706 01:48:14.836421 15248 solver.cpp:590] Iteration 47850, lr = 0.000626964
I0706 01:48:36.917099 15248 solver.cpp:243] Iteration 47960, loss = 0.00535474
I0706 01:48:36.917191 15248 solver.cpp:259]     Train net output #0: loss = 0.00535428 (* 1 = 0.00535428 loss)
I0706 01:48:36.917207 15248 solver.cpp:590] Iteration 47960, lr = 0.000622985
I0706 01:48:58.482146 15248 solver.cpp:243] Iteration 48070, loss = 0.0782133
I0706 01:48:58.482168 15248 solver.cpp:259]     Train net output #0: loss = 0.0782129 (* 1 = 0.0782129 loss)
I0706 01:48:58.482174 15248 solver.cpp:590] Iteration 48070, lr = 0.000619031
I0706 01:49:20.327203 15248 solver.cpp:243] Iteration 48180, loss = 0.152485
I0706 01:49:20.327329 15248 solver.cpp:259]     Train net output #0: loss = 0.152485 (* 1 = 0.152485 loss)
I0706 01:49:20.327347 15248 solver.cpp:590] Iteration 48180, lr = 0.000615102
I0706 01:49:42.411260 15248 solver.cpp:243] Iteration 48290, loss = 0.00276609
I0706 01:49:42.411285 15248 solver.cpp:259]     Train net output #0: loss = 0.00276559 (* 1 = 0.00276559 loss)
I0706 01:49:42.411293 15248 solver.cpp:590] Iteration 48290, lr = 0.000611199
I0706 01:50:04.051431 15248 solver.cpp:243] Iteration 48400, loss = 0.122158
I0706 01:50:04.051690 15248 solver.cpp:259]     Train net output #0: loss = 0.122158 (* 1 = 0.122158 loss)
I0706 01:50:04.051698 15248 solver.cpp:590] Iteration 48400, lr = 0.00060732
I0706 01:50:26.002800 15248 solver.cpp:347] Iteration 48510, Testing net (#0)
I0706 01:50:35.145222 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 01:50:35.254297 15267 blocking_queue.cpp:50] Waiting for data
I0706 01:50:51.822366 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0600962
I0706 01:50:51.822396 15248 solver.cpp:415]     Test net output #1: loss = 6.76174 (* 1 = 6.76174 loss)
I0706 01:50:51.964341 15248 solver.cpp:243] Iteration 48510, loss = 0.292045
I0706 01:50:51.964368 15248 solver.cpp:259]     Train net output #0: loss = 0.292044 (* 1 = 0.292044 loss)
I0706 01:50:51.964375 15248 solver.cpp:590] Iteration 48510, lr = 0.000603466
I0706 01:51:13.489128 15248 solver.cpp:243] Iteration 48620, loss = 0.00342663
I0706 01:51:13.489383 15248 solver.cpp:259]     Train net output #0: loss = 0.00342618 (* 1 = 0.00342618 loss)
I0706 01:51:13.489392 15248 solver.cpp:590] Iteration 48620, lr = 0.000599636
I0706 01:51:35.953027 15248 solver.cpp:243] Iteration 48730, loss = 0.0330087
I0706 01:51:35.953086 15248 solver.cpp:259]     Train net output #0: loss = 0.0330082 (* 1 = 0.0330082 loss)
I0706 01:51:35.953102 15248 solver.cpp:590] Iteration 48730, lr = 0.00059583
I0706 01:51:57.519487 15248 solver.cpp:243] Iteration 48840, loss = 0.000868909
I0706 01:51:57.519717 15248 solver.cpp:259]     Train net output #0: loss = 0.0008684 (* 1 = 0.0008684 loss)
I0706 01:51:57.519726 15248 solver.cpp:590] Iteration 48840, lr = 0.000592049
I0706 01:52:19.104073 15248 solver.cpp:243] Iteration 48950, loss = 0.0511561
I0706 01:52:19.104094 15248 solver.cpp:259]     Train net output #0: loss = 0.0511556 (* 1 = 0.0511556 loss)
I0706 01:52:19.104100 15248 solver.cpp:590] Iteration 48950, lr = 0.000588292
I0706 01:52:41.129323 15248 solver.cpp:243] Iteration 49060, loss = 0.0333827
I0706 01:52:41.129415 15248 solver.cpp:259]     Train net output #0: loss = 0.0333822 (* 1 = 0.0333822 loss)
I0706 01:52:41.129422 15248 solver.cpp:590] Iteration 49060, lr = 0.000584558
I0706 01:53:02.750095 15248 solver.cpp:243] Iteration 49170, loss = 0.215808
I0706 01:53:02.750118 15248 solver.cpp:259]     Train net output #0: loss = 0.215808 (* 1 = 0.215808 loss)
I0706 01:53:02.750124 15248 solver.cpp:590] Iteration 49170, lr = 0.000580848
I0706 01:53:25.096421 15248 solver.cpp:243] Iteration 49280, loss = 0.120549
I0706 01:53:25.096511 15248 solver.cpp:259]     Train net output #0: loss = 0.120549 (* 1 = 0.120549 loss)
I0706 01:53:25.096518 15248 solver.cpp:590] Iteration 49280, lr = 0.000577162
I0706 01:53:46.565762 15248 solver.cpp:243] Iteration 49390, loss = 0.0226574
I0706 01:53:46.565785 15248 solver.cpp:259]     Train net output #0: loss = 0.022657 (* 1 = 0.022657 loss)
I0706 01:53:46.565791 15248 solver.cpp:590] Iteration 49390, lr = 0.000573499
I0706 01:53:46.760753 15248 solver.cpp:347] Iteration 49392, Testing net (#0)
I0706 01:54:10.173483 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0594952
I0706 01:54:10.173611 15248 solver.cpp:415]     Test net output #1: loss = 6.79379 (* 1 = 6.79379 loss)
I0706 01:54:32.452451 15248 solver.cpp:243] Iteration 49500, loss = 0.00858374
I0706 01:54:32.452476 15248 solver.cpp:259]     Train net output #0: loss = 0.00858327 (* 1 = 0.00858327 loss)
I0706 01:54:32.452482 15248 solver.cpp:590] Iteration 49500, lr = 0.00056986
I0706 01:54:54.322810 15248 solver.cpp:243] Iteration 49610, loss = 0.0361281
I0706 01:54:54.322928 15248 solver.cpp:259]     Train net output #0: loss = 0.0361275 (* 1 = 0.0361275 loss)
I0706 01:54:54.322937 15248 solver.cpp:590] Iteration 49610, lr = 0.000566243
I0706 01:55:16.001868 15248 solver.cpp:243] Iteration 49720, loss = 0.062308
I0706 01:55:16.001920 15248 solver.cpp:259]     Train net output #0: loss = 0.0623074 (* 1 = 0.0623074 loss)
I0706 01:55:16.001935 15248 solver.cpp:590] Iteration 49720, lr = 0.00056265
I0706 01:55:38.121423 15248 solver.cpp:243] Iteration 49830, loss = 0.181696
I0706 01:55:38.122048 15248 solver.cpp:259]     Train net output #0: loss = 0.181696 (* 1 = 0.181696 loss)
I0706 01:55:38.122061 15248 solver.cpp:590] Iteration 49830, lr = 0.000559079
I0706 01:55:59.793328 15248 solver.cpp:243] Iteration 49940, loss = 0.00359958
I0706 01:55:59.793352 15248 solver.cpp:259]     Train net output #0: loss = 0.00359898 (* 1 = 0.00359898 loss)
I0706 01:55:59.793359 15248 solver.cpp:590] Iteration 49940, lr = 0.000555531
I0706 01:56:22.616922 15248 solver.cpp:243] Iteration 50050, loss = 0.11463
I0706 01:56:22.617184 15248 solver.cpp:259]     Train net output #0: loss = 0.114629 (* 1 = 0.114629 loss)
I0706 01:56:22.617192 15248 solver.cpp:590] Iteration 50050, lr = 0.000552005
I0706 01:56:44.146656 15248 solver.cpp:243] Iteration 50160, loss = 0.00677823
I0706 01:56:44.146680 15248 solver.cpp:259]     Train net output #0: loss = 0.00677744 (* 1 = 0.00677744 loss)
I0706 01:56:44.146687 15248 solver.cpp:590] Iteration 50160, lr = 0.000548502
I0706 01:57:06.842448 15248 solver.cpp:243] Iteration 50270, loss = 0.0460899
I0706 01:57:06.842757 15248 solver.cpp:259]     Train net output #0: loss = 0.0460892 (* 1 = 0.0460892 loss)
I0706 01:57:06.842778 15248 solver.cpp:590] Iteration 50270, lr = 0.000545021
I0706 01:57:07.509145 15248 solver.cpp:347] Iteration 50274, Testing net (#0)
I0706 01:57:33.983670 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0592548
I0706 01:57:33.983698 15248 solver.cpp:415]     Test net output #1: loss = 6.71969 (* 1 = 6.71969 loss)
I0706 01:57:54.932313 15248 solver.cpp:243] Iteration 50380, loss = 0.170321
I0706 01:57:54.932600 15248 solver.cpp:259]     Train net output #0: loss = 0.17032 (* 1 = 0.17032 loss)
I0706 01:57:54.932616 15248 solver.cpp:590] Iteration 50380, lr = 0.000541562
I0706 01:58:16.604670 15248 solver.cpp:243] Iteration 50490, loss = 0.0411106
I0706 01:58:16.604694 15248 solver.cpp:259]     Train net output #0: loss = 0.0411098 (* 1 = 0.0411098 loss)
I0706 01:58:16.604701 15248 solver.cpp:590] Iteration 50490, lr = 0.000538125
I0706 01:58:38.262264 15248 solver.cpp:243] Iteration 50600, loss = 0.00226302
I0706 01:58:38.262500 15248 solver.cpp:259]     Train net output #0: loss = 0.00226225 (* 1 = 0.00226225 loss)
I0706 01:58:38.262507 15248 solver.cpp:590] Iteration 50600, lr = 0.00053471
I0706 01:58:59.786502 15248 solver.cpp:243] Iteration 50710, loss = 0.0923582
I0706 01:58:59.786530 15248 solver.cpp:259]     Train net output #0: loss = 0.0923576 (* 1 = 0.0923576 loss)
I0706 01:58:59.786537 15248 solver.cpp:590] Iteration 50710, lr = 0.000531317
I0706 01:59:21.754886 15248 solver.cpp:243] Iteration 50820, loss = 0.0387353
I0706 01:59:21.755167 15248 solver.cpp:259]     Train net output #0: loss = 0.0387346 (* 1 = 0.0387346 loss)
I0706 01:59:21.755174 15248 solver.cpp:590] Iteration 50820, lr = 0.000527945
I0706 01:59:43.223134 15248 solver.cpp:243] Iteration 50930, loss = 0.2437
I0706 01:59:43.223156 15248 solver.cpp:259]     Train net output #0: loss = 0.243699 (* 1 = 0.243699 loss)
I0706 01:59:43.223163 15248 solver.cpp:590] Iteration 50930, lr = 0.000524594
I0706 02:00:05.661026 15248 solver.cpp:243] Iteration 51040, loss = 0.0462461
I0706 02:00:05.661254 15248 solver.cpp:259]     Train net output #0: loss = 0.0462455 (* 1 = 0.0462455 loss)
I0706 02:00:05.661262 15248 solver.cpp:590] Iteration 51040, lr = 0.000521265
I0706 02:00:27.198351 15248 solver.cpp:243] Iteration 51150, loss = 0.260041
I0706 02:00:27.198375 15248 solver.cpp:259]     Train net output #0: loss = 0.26004 (* 1 = 0.26004 loss)
I0706 02:00:27.198382 15248 solver.cpp:590] Iteration 51150, lr = 0.000517957
I0706 02:00:28.178566 15248 solver.cpp:347] Iteration 51156, Testing net (#0)
I0706 02:00:55.210916 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0592548
I0706 02:00:55.211472 15248 solver.cpp:415]     Test net output #1: loss = 6.74795 (* 1 = 6.74795 loss)
I0706 02:01:16.033077 15248 solver.cpp:243] Iteration 51260, loss = 0.0279187
I0706 02:01:16.033098 15248 solver.cpp:259]     Train net output #0: loss = 0.0279181 (* 1 = 0.0279181 loss)
I0706 02:01:16.033104 15248 solver.cpp:590] Iteration 51260, lr = 0.00051467
I0706 02:01:37.719543 15248 solver.cpp:243] Iteration 51370, loss = 0.0139887
I0706 02:01:37.719718 15248 solver.cpp:259]     Train net output #0: loss = 0.0139881 (* 1 = 0.0139881 loss)
I0706 02:01:37.719727 15248 solver.cpp:590] Iteration 51370, lr = 0.000511403
I0706 02:01:59.297369 15248 solver.cpp:243] Iteration 51480, loss = 0.156012
I0706 02:01:59.297431 15248 solver.cpp:259]     Train net output #0: loss = 0.156012 (* 1 = 0.156012 loss)
I0706 02:01:59.297448 15248 solver.cpp:590] Iteration 51480, lr = 0.000508158
I0706 02:02:21.388337 15248 solver.cpp:243] Iteration 51590, loss = 0.000565741
I0706 02:02:21.388432 15248 solver.cpp:259]     Train net output #0: loss = 0.000565039 (* 1 = 0.000565039 loss)
I0706 02:02:21.388438 15248 solver.cpp:590] Iteration 51590, lr = 0.000504933
I0706 02:02:42.913645 15248 solver.cpp:243] Iteration 51700, loss = 0.0578948
I0706 02:02:42.913673 15248 solver.cpp:259]     Train net output #0: loss = 0.0578941 (* 1 = 0.0578941 loss)
I0706 02:02:42.913679 15248 solver.cpp:590] Iteration 51700, lr = 0.000501728
I0706 02:03:05.592958 15248 solver.cpp:243] Iteration 51810, loss = 0.00498004
I0706 02:03:05.593050 15248 solver.cpp:259]     Train net output #0: loss = 0.00497924 (* 1 = 0.00497924 loss)
I0706 02:03:05.593056 15248 solver.cpp:590] Iteration 51810, lr = 0.000498544
I0706 02:03:27.182384 15248 solver.cpp:243] Iteration 51920, loss = 0.0167497
I0706 02:03:27.182410 15248 solver.cpp:259]     Train net output #0: loss = 0.0167488 (* 1 = 0.0167488 loss)
I0706 02:03:27.182415 15248 solver.cpp:590] Iteration 51920, lr = 0.00049538
I0706 02:03:49.116791 15248 solver.cpp:243] Iteration 52030, loss = 0.0395059
I0706 02:03:49.116881 15248 solver.cpp:259]     Train net output #0: loss = 0.0395052 (* 1 = 0.0395052 loss)
I0706 02:03:49.116899 15248 solver.cpp:590] Iteration 52030, lr = 0.000492236
I0706 02:03:50.500541 15248 solver.cpp:347] Iteration 52038, Testing net (#0)
I0706 02:03:58.619313 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 02:04:03.758445 15267 blocking_queue.cpp:50] Waiting for data
I0706 02:04:15.924373 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0592548
I0706 02:04:15.924403 15248 solver.cpp:415]     Test net output #1: loss = 6.76101 (* 1 = 6.76101 loss)
I0706 02:04:36.292223 15248 solver.cpp:243] Iteration 52140, loss = 0.00727209
I0706 02:04:36.292346 15248 solver.cpp:259]     Train net output #0: loss = 0.00727136 (* 1 = 0.00727136 loss)
I0706 02:04:36.292354 15248 solver.cpp:590] Iteration 52140, lr = 0.000489113
I0706 02:04:57.827411 15248 solver.cpp:243] Iteration 52250, loss = 0.194759
I0706 02:04:57.827443 15248 solver.cpp:259]     Train net output #0: loss = 0.194758 (* 1 = 0.194758 loss)
I0706 02:04:57.827450 15248 solver.cpp:590] Iteration 52250, lr = 0.000486008
I0706 02:05:20.789283 15248 solver.cpp:243] Iteration 52360, loss = 0.233828
I0706 02:05:20.789376 15248 solver.cpp:259]     Train net output #0: loss = 0.233827 (* 1 = 0.233827 loss)
I0706 02:05:20.789382 15248 solver.cpp:590] Iteration 52360, lr = 0.000482924
I0706 02:05:42.306252 15248 solver.cpp:243] Iteration 52470, loss = 0.0053429
I0706 02:05:42.306277 15248 solver.cpp:259]     Train net output #0: loss = 0.00534211 (* 1 = 0.00534211 loss)
I0706 02:05:42.306282 15248 solver.cpp:590] Iteration 52470, lr = 0.000479859
I0706 02:06:04.826776 15248 solver.cpp:243] Iteration 52580, loss = 0.00962709
I0706 02:06:04.826884 15248 solver.cpp:259]     Train net output #0: loss = 0.00962634 (* 1 = 0.00962634 loss)
I0706 02:06:04.826892 15248 solver.cpp:590] Iteration 52580, lr = 0.000476814
I0706 02:06:26.348919 15248 solver.cpp:243] Iteration 52690, loss = 0.00543249
I0706 02:06:26.348944 15248 solver.cpp:259]     Train net output #0: loss = 0.00543178 (* 1 = 0.00543178 loss)
I0706 02:06:26.348950 15248 solver.cpp:590] Iteration 52690, lr = 0.000473788
I0706 02:06:48.783074 15248 solver.cpp:243] Iteration 52800, loss = 0.121061
I0706 02:06:48.783371 15248 solver.cpp:259]     Train net output #0: loss = 0.12106 (* 1 = 0.12106 loss)
I0706 02:06:48.783380 15248 solver.cpp:590] Iteration 52800, lr = 0.000470781
I0706 02:07:10.875977 15248 solver.cpp:243] Iteration 52910, loss = 0.0279509
I0706 02:07:10.876000 15248 solver.cpp:259]     Train net output #0: loss = 0.0279502 (* 1 = 0.0279502 loss)
I0706 02:07:10.876008 15248 solver.cpp:590] Iteration 52910, lr = 0.000467793
I0706 02:07:12.635134 15248 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_52920.caffemodel
I0706 02:07:32.880132 15248 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_52920.solverstate
I0706 02:07:35.484313 15248 solver.cpp:347] Iteration 52920, Testing net (#0)
I0706 02:08:01.530205 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0608173
I0706 02:08:01.530232 15248 solver.cpp:415]     Test net output #1: loss = 6.72453 (* 1 = 6.72453 loss)
I0706 02:08:21.186897 15248 solver.cpp:243] Iteration 53020, loss = 0.0414561
I0706 02:08:21.186955 15248 solver.cpp:259]     Train net output #0: loss = 0.0414553 (* 1 = 0.0414553 loss)
I0706 02:08:21.186962 15248 solver.cpp:590] Iteration 53020, lr = 0.000464825
I0706 02:08:42.640836 15248 solver.cpp:243] Iteration 53130, loss = 0.0446123
I0706 02:08:42.640856 15248 solver.cpp:259]     Train net output #0: loss = 0.0446116 (* 1 = 0.0446116 loss)
I0706 02:08:42.640861 15248 solver.cpp:590] Iteration 53130, lr = 0.000461875
I0706 02:09:04.769928 15248 solver.cpp:243] Iteration 53240, loss = 0.00532967
I0706 02:09:04.770020 15248 solver.cpp:259]     Train net output #0: loss = 0.00532893 (* 1 = 0.00532893 loss)
I0706 02:09:04.770027 15248 solver.cpp:590] Iteration 53240, lr = 0.000458943
I0706 02:09:26.318639 15248 solver.cpp:243] Iteration 53350, loss = 0.113036
I0706 02:09:26.318662 15248 solver.cpp:259]     Train net output #0: loss = 0.113035 (* 1 = 0.113035 loss)
I0706 02:09:26.318668 15248 solver.cpp:590] Iteration 53350, lr = 0.000456031
I0706 02:09:47.791992 15248 solver.cpp:243] Iteration 53460, loss = 0.0160356
I0706 02:09:47.792085 15248 solver.cpp:259]     Train net output #0: loss = 0.0160348 (* 1 = 0.0160348 loss)
I0706 02:09:47.792101 15248 solver.cpp:590] Iteration 53460, lr = 0.000453137
I0706 02:10:09.463686 15248 solver.cpp:243] Iteration 53570, loss = 0.177531
I0706 02:10:09.463708 15248 solver.cpp:259]     Train net output #0: loss = 0.17753 (* 1 = 0.17753 loss)
I0706 02:10:09.463714 15248 solver.cpp:590] Iteration 53570, lr = 0.000450261
I0706 02:10:31.058603 15248 solver.cpp:243] Iteration 53680, loss = 0.00603798
I0706 02:10:31.058699 15248 solver.cpp:259]     Train net output #0: loss = 0.00603717 (* 1 = 0.00603717 loss)
I0706 02:10:31.058706 15248 solver.cpp:590] Iteration 53680, lr = 0.000447403
I0706 02:10:52.915860 15248 solver.cpp:243] Iteration 53790, loss = 0.0175515
I0706 02:10:52.915884 15248 solver.cpp:259]     Train net output #0: loss = 0.0175506 (* 1 = 0.0175506 loss)
I0706 02:10:52.915890 15248 solver.cpp:590] Iteration 53790, lr = 0.000444564
I0706 02:10:55.058171 15248 solver.cpp:347] Iteration 53802, Testing net (#0)
I0706 02:11:20.774031 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0614183
I0706 02:11:20.774140 15248 solver.cpp:415]     Test net output #1: loss = 6.74084 (* 1 = 6.74084 loss)
I0706 02:11:40.132854 15248 solver.cpp:243] Iteration 53900, loss = 0.0141808
I0706 02:11:40.132879 15248 solver.cpp:259]     Train net output #0: loss = 0.01418 (* 1 = 0.01418 loss)
I0706 02:11:40.132885 15248 solver.cpp:590] Iteration 53900, lr = 0.000441743
I0706 02:12:02.058583 15248 solver.cpp:243] Iteration 54010, loss = 0.0390661
I0706 02:12:02.058692 15248 solver.cpp:259]     Train net output #0: loss = 0.0390652 (* 1 = 0.0390652 loss)
I0706 02:12:02.058701 15248 solver.cpp:590] Iteration 54010, lr = 0.000438939
I0706 02:12:23.584280 15248 solver.cpp:243] Iteration 54120, loss = 0.043095
I0706 02:12:23.584306 15248 solver.cpp:259]     Train net output #0: loss = 0.0430941 (* 1 = 0.0430941 loss)
I0706 02:12:23.584311 15248 solver.cpp:590] Iteration 54120, lr = 0.000436154
I0706 02:12:45.531793 15248 solver.cpp:243] Iteration 54230, loss = 0.070064
I0706 02:12:45.540411 15248 solver.cpp:259]     Train net output #0: loss = 0.0700632 (* 1 = 0.0700632 loss)
I0706 02:12:45.540421 15248 solver.cpp:590] Iteration 54230, lr = 0.000433386
I0706 02:13:07.108248 15248 solver.cpp:243] Iteration 54340, loss = 0.000811119
I0706 02:13:07.108273 15248 solver.cpp:259]     Train net output #0: loss = 0.0008103 (* 1 = 0.0008103 loss)
I0706 02:13:07.108280 15248 solver.cpp:590] Iteration 54340, lr = 0.000430635
I0706 02:13:28.594655 15248 solver.cpp:243] Iteration 54450, loss = 0.00491781
I0706 02:13:28.594751 15248 solver.cpp:259]     Train net output #0: loss = 0.00491692 (* 1 = 0.00491692 loss)
I0706 02:13:28.594758 15248 solver.cpp:590] Iteration 54450, lr = 0.000427902
I0706 02:13:50.747665 15248 solver.cpp:243] Iteration 54560, loss = 0.355592
I0706 02:13:50.747691 15248 solver.cpp:259]     Train net output #0: loss = 0.355592 (* 1 = 0.355592 loss)
I0706 02:13:50.747697 15248 solver.cpp:590] Iteration 54560, lr = 0.000425187
I0706 02:14:12.369278 15248 solver.cpp:243] Iteration 54670, loss = 0.204016
I0706 02:14:12.369411 15248 solver.cpp:259]     Train net output #0: loss = 0.204015 (* 1 = 0.204015 loss)
I0706 02:14:12.369420 15248 solver.cpp:590] Iteration 54670, lr = 0.000422488
I0706 02:14:14.922024 15248 solver.cpp:347] Iteration 54684, Testing net (#0)
I0706 02:14:22.817981 15267 blocking_queue.cpp:50] Waiting for data
I0706 02:14:40.674729 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0612981
I0706 02:14:40.674758 15248 solver.cpp:415]     Test net output #1: loss = 6.7108 (* 1 = 6.7108 loss)
I0706 02:15:00.377843 15248 solver.cpp:243] Iteration 54780, loss = 0.152788
I0706 02:15:00.377934 15248 solver.cpp:259]     Train net output #0: loss = 0.152787 (* 1 = 0.152787 loss)
I0706 02:15:00.377950 15248 solver.cpp:590] Iteration 54780, lr = 0.000419807
I0706 02:15:22.052160 15248 solver.cpp:243] Iteration 54890, loss = 0.125601
I0706 02:15:22.052184 15248 solver.cpp:259]     Train net output #0: loss = 0.125601 (* 1 = 0.125601 loss)
I0706 02:15:22.052191 15248 solver.cpp:590] Iteration 54890, lr = 0.000417143
I0706 02:15:43.970335 15248 solver.cpp:243] Iteration 55000, loss = 0.228657
I0706 02:15:43.970423 15248 solver.cpp:259]     Train net output #0: loss = 0.228656 (* 1 = 0.228656 loss)
I0706 02:15:43.970440 15248 solver.cpp:590] Iteration 55000, lr = 0.000414496
I0706 02:16:06.607610 15248 solver.cpp:243] Iteration 55110, loss = 0.227428
I0706 02:16:06.607635 15248 solver.cpp:259]     Train net output #0: loss = 0.227427 (* 1 = 0.227427 loss)
I0706 02:16:06.607640 15248 solver.cpp:590] Iteration 55110, lr = 0.000411865
I0706 02:16:28.463753 15248 solver.cpp:243] Iteration 55220, loss = 0.0613356
I0706 02:16:28.463891 15248 solver.cpp:259]     Train net output #0: loss = 0.0613348 (* 1 = 0.0613348 loss)
I0706 02:16:28.463898 15248 solver.cpp:590] Iteration 55220, lr = 0.000409251
I0706 02:16:51.919700 15248 solver.cpp:243] Iteration 55330, loss = 0.00544414
I0706 02:16:51.919723 15248 solver.cpp:259]     Train net output #0: loss = 0.00544335 (* 1 = 0.00544335 loss)
I0706 02:16:51.919728 15248 solver.cpp:590] Iteration 55330, lr = 0.000406654
I0706 02:17:13.421896 15248 solver.cpp:243] Iteration 55440, loss = 0.00974
I0706 02:17:13.421993 15248 solver.cpp:259]     Train net output #0: loss = 0.00973922 (* 1 = 0.00973922 loss)
I0706 02:17:13.422008 15248 solver.cpp:590] Iteration 55440, lr = 0.000404073
I0706 02:17:35.551412 15248 solver.cpp:243] Iteration 55550, loss = 0.00126741
I0706 02:17:35.551437 15248 solver.cpp:259]     Train net output #0: loss = 0.00126661 (* 1 = 0.00126661 loss)
I0706 02:17:35.551442 15248 solver.cpp:590] Iteration 55550, lr = 0.000401509
I0706 02:17:38.486851 15248 solver.cpp:347] Iteration 55566, Testing net (#0)
I0706 02:17:45.855280 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 02:18:03.358615 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0620192
I0706 02:18:03.358644 15248 solver.cpp:415]     Test net output #1: loss = 6.75816 (* 1 = 6.75816 loss)
I0706 02:18:21.938280 15248 solver.cpp:243] Iteration 55660, loss = 0.0040536
I0706 02:18:21.938493 15248 solver.cpp:259]     Train net output #0: loss = 0.00405276 (* 1 = 0.00405276 loss)
I0706 02:18:21.938500 15248 solver.cpp:590] Iteration 55660, lr = 0.000398961
I0706 02:18:43.847215 15248 solver.cpp:243] Iteration 55770, loss = 0.0171627
I0706 02:18:43.847240 15248 solver.cpp:259]     Train net output #0: loss = 0.0171619 (* 1 = 0.0171619 loss)
I0706 02:18:43.847247 15248 solver.cpp:590] Iteration 55770, lr = 0.000396429
I0706 02:19:06.143616 15248 solver.cpp:243] Iteration 55880, loss = 0.0543514
I0706 02:19:06.143702 15248 solver.cpp:259]     Train net output #0: loss = 0.0543506 (* 1 = 0.0543506 loss)
I0706 02:19:06.143709 15248 solver.cpp:590] Iteration 55880, lr = 0.000393913
I0706 02:19:27.850829 15248 solver.cpp:243] Iteration 55990, loss = 0.00841921
I0706 02:19:27.850852 15248 solver.cpp:259]     Train net output #0: loss = 0.00841849 (* 1 = 0.00841849 loss)
I0706 02:19:27.850858 15248 solver.cpp:590] Iteration 55990, lr = 0.000391413
I0706 02:19:49.980099 15248 solver.cpp:243] Iteration 56100, loss = 0.00539328
I0706 02:19:49.980224 15248 solver.cpp:259]     Train net output #0: loss = 0.00539262 (* 1 = 0.00539262 loss)
I0706 02:19:49.980239 15248 solver.cpp:590] Iteration 56100, lr = 0.000388929
I0706 02:20:11.541225 15248 solver.cpp:243] Iteration 56210, loss = 0.00852731
I0706 02:20:11.541250 15248 solver.cpp:259]     Train net output #0: loss = 0.0085266 (* 1 = 0.0085266 loss)
I0706 02:20:11.541257 15248 solver.cpp:590] Iteration 56210, lr = 0.000386461
I0706 02:20:33.457672 15248 solver.cpp:243] Iteration 56320, loss = 0.00714102
I0706 02:20:33.458611 15248 solver.cpp:259]     Train net output #0: loss = 0.00714029 (* 1 = 0.00714029 loss)
I0706 02:20:33.458617 15248 solver.cpp:590] Iteration 56320, lr = 0.000384008
I0706 02:20:55.031303 15248 solver.cpp:243] Iteration 56430, loss = 0.1431
I0706 02:20:55.031329 15248 solver.cpp:259]     Train net output #0: loss = 0.1431 (* 1 = 0.1431 loss)
I0706 02:20:55.031335 15248 solver.cpp:590] Iteration 56430, lr = 0.000381571
I0706 02:20:58.373440 15248 solver.cpp:347] Iteration 56448, Testing net (#0)
I0706 02:21:24.455261 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0633413
I0706 02:21:24.455379 15248 solver.cpp:415]     Test net output #1: loss = 6.7576 (* 1 = 6.7576 loss)
I0706 02:21:43.300978 15248 solver.cpp:243] Iteration 56540, loss = 0.269711
I0706 02:21:43.301003 15248 solver.cpp:259]     Train net output #0: loss = 0.269711 (* 1 = 0.269711 loss)
I0706 02:21:43.301009 15248 solver.cpp:590] Iteration 56540, lr = 0.000379149
I0706 02:22:05.582428 15248 solver.cpp:243] Iteration 56650, loss = 0.0033675
I0706 02:22:05.582525 15248 solver.cpp:259]     Train net output #0: loss = 0.0033668 (* 1 = 0.0033668 loss)
I0706 02:22:05.582531 15248 solver.cpp:590] Iteration 56650, lr = 0.000376743
I0706 02:22:27.514761 15248 solver.cpp:243] Iteration 56760, loss = 0.0462318
I0706 02:22:27.514786 15248 solver.cpp:259]     Train net output #0: loss = 0.0462311 (* 1 = 0.0462311 loss)
I0706 02:22:27.514792 15248 solver.cpp:590] Iteration 56760, lr = 0.000374352
I0706 02:22:49.903626 15248 solver.cpp:243] Iteration 56870, loss = 0.000115082
I0706 02:22:49.903724 15248 solver.cpp:259]     Train net output #0: loss = 0.000114433 (* 1 = 0.000114433 loss)
I0706 02:22:49.903733 15248 solver.cpp:590] Iteration 56870, lr = 0.000371977
I0706 02:23:11.452316 15248 solver.cpp:243] Iteration 56980, loss = 0.000281043
I0706 02:23:11.452337 15248 solver.cpp:259]     Train net output #0: loss = 0.000280371 (* 1 = 0.000280371 loss)
I0706 02:23:11.452344 15248 solver.cpp:590] Iteration 56980, lr = 0.000369616
I0706 02:23:33.562744 15248 solver.cpp:243] Iteration 57090, loss = 0.0154008
I0706 02:23:33.562892 15248 solver.cpp:259]     Train net output #0: loss = 0.0154002 (* 1 = 0.0154002 loss)
I0706 02:23:33.562901 15248 solver.cpp:590] Iteration 57090, lr = 0.00036727
I0706 02:23:55.055927 15248 solver.cpp:243] Iteration 57200, loss = 0.00340718
I0706 02:23:55.055949 15248 solver.cpp:259]     Train net output #0: loss = 0.0034065 (* 1 = 0.0034065 loss)
I0706 02:23:55.055955 15248 solver.cpp:590] Iteration 57200, lr = 0.000364939
I0706 02:24:16.953263 15248 solver.cpp:243] Iteration 57310, loss = 0.00182742
I0706 02:24:16.953594 15248 solver.cpp:259]     Train net output #0: loss = 0.00182675 (* 1 = 0.00182675 loss)
I0706 02:24:16.953616 15248 solver.cpp:590] Iteration 57310, lr = 0.000362623
I0706 02:24:20.764644 15248 solver.cpp:347] Iteration 57330, Testing net (#0)
I0706 02:24:42.660992 15267 blocking_queue.cpp:50] Waiting for data
I0706 02:24:45.599448 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0647837
I0706 02:24:45.599477 15248 solver.cpp:415]     Test net output #1: loss = 6.73211 (* 1 = 6.73211 loss)
I0706 02:25:03.461666 15248 solver.cpp:243] Iteration 57420, loss = 0.0147341
I0706 02:25:03.461731 15248 solver.cpp:259]     Train net output #0: loss = 0.0147336 (* 1 = 0.0147336 loss)
I0706 02:25:03.461738 15248 solver.cpp:590] Iteration 57420, lr = 0.000360322
I0706 02:25:25.029222 15248 solver.cpp:243] Iteration 57530, loss = 0.0270731
I0706 02:25:25.029273 15248 solver.cpp:259]     Train net output #0: loss = 0.0270725 (* 1 = 0.0270725 loss)
I0706 02:25:25.029287 15248 solver.cpp:590] Iteration 57530, lr = 0.000358035
I0706 02:25:47.334197 15248 solver.cpp:243] Iteration 57640, loss = 0.0628092
I0706 02:25:47.334326 15248 solver.cpp:259]     Train net output #0: loss = 0.0628087 (* 1 = 0.0628087 loss)
I0706 02:25:47.334333 15248 solver.cpp:590] Iteration 57640, lr = 0.000355763
I0706 02:26:08.857111 15248 solver.cpp:243] Iteration 57750, loss = 0.0326702
I0706 02:26:08.857136 15248 solver.cpp:259]     Train net output #0: loss = 0.0326697 (* 1 = 0.0326697 loss)
I0706 02:26:08.857142 15248 solver.cpp:590] Iteration 57750, lr = 0.000353505
I0706 02:26:31.276943 15248 solver.cpp:243] Iteration 57860, loss = 0.129318
I0706 02:26:31.277025 15248 solver.cpp:259]     Train net output #0: loss = 0.129317 (* 1 = 0.129317 loss)
I0706 02:26:31.277036 15248 solver.cpp:590] Iteration 57860, lr = 0.000351262
I0706 02:26:52.885087 15248 solver.cpp:243] Iteration 57970, loss = 0.012025
I0706 02:26:52.885112 15248 solver.cpp:259]     Train net output #0: loss = 0.0120246 (* 1 = 0.0120246 loss)
I0706 02:26:52.885118 15248 solver.cpp:590] Iteration 57970, lr = 0.000349033
I0706 02:27:14.689877 15248 solver.cpp:243] Iteration 58080, loss = 0.00506356
I0706 02:27:14.689970 15248 solver.cpp:259]     Train net output #0: loss = 0.00506316 (* 1 = 0.00506316 loss)
I0706 02:27:14.689978 15248 solver.cpp:590] Iteration 58080, lr = 0.000346817
I0706 02:27:36.712249 15248 solver.cpp:243] Iteration 58190, loss = 0.110871
I0706 02:27:36.712273 15248 solver.cpp:259]     Train net output #0: loss = 0.110871 (* 1 = 0.110871 loss)
I0706 02:27:36.712280 15248 solver.cpp:590] Iteration 58190, lr = 0.000344616
I0706 02:27:40.831766 15248 solver.cpp:347] Iteration 58212, Testing net (#0)
I0706 02:28:04.914366 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0635817
I0706 02:28:04.914463 15248 solver.cpp:415]     Test net output #1: loss = 6.78014 (* 1 = 6.78014 loss)
I0706 02:28:22.410843 15248 solver.cpp:243] Iteration 58300, loss = 0.175687
I0706 02:28:22.410867 15248 solver.cpp:259]     Train net output #0: loss = 0.175686 (* 1 = 0.175686 loss)
I0706 02:28:22.410874 15248 solver.cpp:590] Iteration 58300, lr = 0.000342429
I0706 02:28:45.587126 15248 solver.cpp:243] Iteration 58410, loss = 0.0262628
I0706 02:28:45.587229 15248 solver.cpp:259]     Train net output #0: loss = 0.0262623 (* 1 = 0.0262623 loss)
I0706 02:28:45.587237 15248 solver.cpp:590] Iteration 58410, lr = 0.000340256
I0706 02:29:07.108023 15248 solver.cpp:243] Iteration 58520, loss = 0.352711
I0706 02:29:07.108047 15248 solver.cpp:259]     Train net output #0: loss = 0.352711 (* 1 = 0.352711 loss)
I0706 02:29:07.108052 15248 solver.cpp:590] Iteration 58520, lr = 0.000338097
I0706 02:29:29.875206 15248 solver.cpp:243] Iteration 58630, loss = 0.000916812
I0706 02:29:29.875473 15248 solver.cpp:259]     Train net output #0: loss = 0.000916337 (* 1 = 0.000916337 loss)
I0706 02:29:29.875481 15248 solver.cpp:590] Iteration 58630, lr = 0.000335951
I0706 02:29:51.420001 15248 solver.cpp:243] Iteration 58740, loss = 0.000952729
I0706 02:29:51.420024 15248 solver.cpp:259]     Train net output #0: loss = 0.000952253 (* 1 = 0.000952253 loss)
I0706 02:29:51.420030 15248 solver.cpp:590] Iteration 58740, lr = 0.000333819
I0706 02:30:13.848285 15248 solver.cpp:243] Iteration 58850, loss = 0.0384077
I0706 02:30:13.848582 15248 solver.cpp:259]     Train net output #0: loss = 0.0384073 (* 1 = 0.0384073 loss)
I0706 02:30:13.848588 15248 solver.cpp:590] Iteration 58850, lr = 0.000331701
I0706 02:30:35.401243 15248 solver.cpp:243] Iteration 58960, loss = 0.00182229
I0706 02:30:35.401268 15248 solver.cpp:259]     Train net output #0: loss = 0.00182196 (* 1 = 0.00182196 loss)
I0706 02:30:35.401274 15248 solver.cpp:590] Iteration 58960, lr = 0.000329595
I0706 02:30:57.002862 15248 solver.cpp:243] Iteration 59070, loss = 0.249903
I0706 02:30:57.003082 15248 solver.cpp:259]     Train net output #0: loss = 0.249903 (* 1 = 0.249903 loss)
I0706 02:30:57.003090 15248 solver.cpp:590] Iteration 59070, lr = 0.000327504
I0706 02:31:01.736146 15248 solver.cpp:347] Iteration 59094, Testing net (#0)
I0706 02:31:07.784138 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 02:31:25.389207 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0635817
I0706 02:31:25.389251 15248 solver.cpp:415]     Test net output #1: loss = 6.72922 (* 1 = 6.72922 loss)
I0706 02:31:42.633054 15248 solver.cpp:243] Iteration 59180, loss = 0.109381
I0706 02:31:42.633522 15248 solver.cpp:259]     Train net output #0: loss = 0.109381 (* 1 = 0.109381 loss)
I0706 02:31:42.633532 15248 solver.cpp:590] Iteration 59180, lr = 0.000325425
I0706 02:32:04.199350 15248 solver.cpp:243] Iteration 59290, loss = 4.12189e-05
I0706 02:32:04.199373 15248 solver.cpp:259]     Train net output #0: loss = 4.08556e-05 (* 1 = 4.08556e-05 loss)
I0706 02:32:04.199380 15248 solver.cpp:590] Iteration 59290, lr = 0.00032336
I0706 02:32:26.522567 15248 solver.cpp:243] Iteration 59400, loss = 0.130771
I0706 02:32:26.522855 15248 solver.cpp:259]     Train net output #0: loss = 0.130771 (* 1 = 0.130771 loss)
I0706 02:32:26.522862 15248 solver.cpp:590] Iteration 59400, lr = 0.000321308
I0706 02:32:47.985437 15248 solver.cpp:243] Iteration 59510, loss = 0.0770293
I0706 02:32:47.985468 15248 solver.cpp:259]     Train net output #0: loss = 0.0770289 (* 1 = 0.0770289 loss)
I0706 02:32:47.985476 15248 solver.cpp:590] Iteration 59510, lr = 0.000319269
I0706 02:33:09.987843 15248 solver.cpp:243] Iteration 59620, loss = 0.000274593
I0706 02:33:10.004357 15248 solver.cpp:259]     Train net output #0: loss = 0.000274181 (* 1 = 0.000274181 loss)
I0706 02:33:10.004365 15248 solver.cpp:590] Iteration 59620, lr = 0.000317243
I0706 02:33:31.781110 15248 solver.cpp:243] Iteration 59730, loss = 0.328221
I0706 02:33:31.781133 15248 solver.cpp:259]     Train net output #0: loss = 0.32822 (* 1 = 0.32822 loss)
I0706 02:33:31.781138 15248 solver.cpp:590] Iteration 59730, lr = 0.000315229
I0706 02:33:54.050312 15248 solver.cpp:243] Iteration 59840, loss = 0.000833932
I0706 02:33:54.050721 15248 solver.cpp:259]     Train net output #0: loss = 0.000833564 (* 1 = 0.000833564 loss)
I0706 02:33:54.050730 15248 solver.cpp:590] Iteration 59840, lr = 0.000313229
I0706 02:34:15.835197 15248 solver.cpp:243] Iteration 59950, loss = 0.00378489
I0706 02:34:15.835222 15248 solver.cpp:259]     Train net output #0: loss = 0.00378456 (* 1 = 0.00378456 loss)
I0706 02:34:15.835228 15248 solver.cpp:590] Iteration 59950, lr = 0.000311241
I0706 02:34:20.712550 15248 solver.cpp:347] Iteration 59976, Testing net (#0)
I0706 02:34:44.918928 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0637019
I0706 02:34:44.919414 15248 solver.cpp:415]     Test net output #1: loss = 6.71987 (* 1 = 6.71987 loss)
I0706 02:35:01.511484 15248 solver.cpp:243] Iteration 60060, loss = 0.261311
I0706 02:35:01.511508 15248 solver.cpp:259]     Train net output #0: loss = 0.261311 (* 1 = 0.261311 loss)
I0706 02:35:01.511514 15248 solver.cpp:590] Iteration 60060, lr = 0.000309266
I0706 02:35:23.926972 15248 solver.cpp:243] Iteration 60170, loss = 0.212383
I0706 02:35:23.927263 15248 solver.cpp:259]     Train net output #0: loss = 0.212382 (* 1 = 0.212382 loss)
I0706 02:35:23.927269 15248 solver.cpp:590] Iteration 60170, lr = 0.000307303
I0706 02:35:45.871935 15248 solver.cpp:243] Iteration 60280, loss = 0.0277732
I0706 02:35:45.871959 15248 solver.cpp:259]     Train net output #0: loss = 0.0277729 (* 1 = 0.0277729 loss)
I0706 02:35:45.871965 15248 solver.cpp:590] Iteration 60280, lr = 0.000305353
I0706 02:36:08.340421 15248 solver.cpp:243] Iteration 60390, loss = 0.105794
I0706 02:36:08.340518 15248 solver.cpp:259]     Train net output #0: loss = 0.105794 (* 1 = 0.105794 loss)
I0706 02:36:08.340535 15248 solver.cpp:590] Iteration 60390, lr = 0.000303415
I0706 02:36:30.217744 15248 solver.cpp:243] Iteration 60500, loss = 0.00350193
I0706 02:36:30.217772 15248 solver.cpp:259]     Train net output #0: loss = 0.00350151 (* 1 = 0.00350151 loss)
I0706 02:36:30.217778 15248 solver.cpp:590] Iteration 60500, lr = 0.000301489
I0706 02:36:52.550108 15248 solver.cpp:243] Iteration 60610, loss = 0.000879738
I0706 02:36:52.550242 15248 solver.cpp:259]     Train net output #0: loss = 0.00087934 (* 1 = 0.00087934 loss)
I0706 02:36:52.550251 15248 solver.cpp:590] Iteration 60610, lr = 0.000299576
I0706 02:37:14.424245 15248 solver.cpp:243] Iteration 60720, loss = 0.00425411
I0706 02:37:14.424269 15248 solver.cpp:259]     Train net output #0: loss = 0.00425377 (* 1 = 0.00425377 loss)
I0706 02:37:14.424275 15248 solver.cpp:590] Iteration 60720, lr = 0.000297675
I0706 02:37:36.293988 15248 solver.cpp:243] Iteration 60830, loss = 0.0168903
I0706 02:37:36.294095 15248 solver.cpp:259]     Train net output #0: loss = 0.01689 (* 1 = 0.01689 loss)
I0706 02:37:36.294102 15248 solver.cpp:590] Iteration 60830, lr = 0.000295786
I0706 02:37:41.793651 15248 solver.cpp:347] Iteration 60858, Testing net (#0)
I0706 02:38:06.455087 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0629808
I0706 02:38:06.455174 15248 solver.cpp:415]     Test net output #1: loss = 6.71074 (* 1 = 6.71074 loss)
I0706 02:38:23.538765 15248 solver.cpp:243] Iteration 60940, loss = 0.161665
I0706 02:38:23.538789 15248 solver.cpp:259]     Train net output #0: loss = 0.161665 (* 1 = 0.161665 loss)
I0706 02:38:23.538795 15248 solver.cpp:590] Iteration 60940, lr = 0.000293908
I0706 02:38:45.029145 15248 solver.cpp:243] Iteration 61050, loss = 0.000850064
I0706 02:38:45.029232 15248 solver.cpp:259]     Train net output #0: loss = 0.000849799 (* 1 = 0.000849799 loss)
I0706 02:38:45.029238 15248 solver.cpp:590] Iteration 61050, lr = 0.000292043
I0706 02:39:07.216300 15248 solver.cpp:243] Iteration 61160, loss = 0.0393255
I0706 02:39:07.216325 15248 solver.cpp:259]     Train net output #0: loss = 0.0393252 (* 1 = 0.0393252 loss)
I0706 02:39:07.216331 15248 solver.cpp:590] Iteration 61160, lr = 0.00029019
I0706 02:39:29.804316 15248 solver.cpp:243] Iteration 61270, loss = 0.0505138
I0706 02:39:29.804409 15248 solver.cpp:259]     Train net output #0: loss = 0.0505136 (* 1 = 0.0505136 loss)
I0706 02:39:29.804425 15248 solver.cpp:590] Iteration 61270, lr = 0.000288348
I0706 02:39:52.279189 15248 solver.cpp:243] Iteration 61380, loss = 0.00282001
I0706 02:39:52.279213 15248 solver.cpp:259]     Train net output #0: loss = 0.00281978 (* 1 = 0.00281978 loss)
I0706 02:39:52.279219 15248 solver.cpp:590] Iteration 61380, lr = 0.000286518
I0706 02:40:14.344034 15248 solver.cpp:243] Iteration 61490, loss = 0.14827
I0706 02:40:14.344133 15248 solver.cpp:259]     Train net output #0: loss = 0.14827 (* 1 = 0.14827 loss)
I0706 02:40:14.344141 15248 solver.cpp:590] Iteration 61490, lr = 0.0002847
I0706 02:40:36.114317 15248 solver.cpp:243] Iteration 61600, loss = 0.00988536
I0706 02:40:36.114343 15248 solver.cpp:259]     Train net output #0: loss = 0.00988513 (* 1 = 0.00988513 loss)
I0706 02:40:36.114349 15248 solver.cpp:590] Iteration 61600, lr = 0.000282893
I0706 02:40:58.920655 15248 solver.cpp:243] Iteration 61710, loss = 0.0333451
I0706 02:40:58.920883 15248 solver.cpp:259]     Train net output #0: loss = 0.0333448 (* 1 = 0.0333448 loss)
I0706 02:40:58.920892 15248 solver.cpp:590] Iteration 61710, lr = 0.000281098
I0706 02:41:04.611296 15248 solver.cpp:347] Iteration 61740, Testing net (#0)
I0706 02:41:30.594014 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0600962
I0706 02:41:30.594122 15248 solver.cpp:415]     Test net output #1: loss = 6.74352 (* 1 = 6.74352 loss)
I0706 02:41:46.367184 15248 solver.cpp:243] Iteration 61820, loss = 0.00409266
I0706 02:41:46.367208 15248 solver.cpp:259]     Train net output #0: loss = 0.00409246 (* 1 = 0.00409246 loss)
I0706 02:41:46.367213 15248 solver.cpp:590] Iteration 61820, lr = 0.000279314
I0706 02:42:09.585649 15248 solver.cpp:243] Iteration 61930, loss = 0.00416887
I0706 02:42:09.585741 15248 solver.cpp:259]     Train net output #0: loss = 0.00416862 (* 1 = 0.00416862 loss)
I0706 02:42:09.585757 15248 solver.cpp:590] Iteration 61930, lr = 0.000277541
I0706 02:42:31.236529 15248 solver.cpp:243] Iteration 62040, loss = 0.15395
I0706 02:42:31.236553 15248 solver.cpp:259]     Train net output #0: loss = 0.15395 (* 1 = 0.15395 loss)
I0706 02:42:31.236559 15248 solver.cpp:590] Iteration 62040, lr = 0.00027578
I0706 02:42:52.974805 15248 solver.cpp:243] Iteration 62150, loss = 0.017445
I0706 02:42:52.974923 15248 solver.cpp:259]     Train net output #0: loss = 0.0174448 (* 1 = 0.0174448 loss)
I0706 02:42:52.974931 15248 solver.cpp:590] Iteration 62150, lr = 0.00027403
I0706 02:43:14.691715 15248 solver.cpp:243] Iteration 62260, loss = 0.0539132
I0706 02:43:14.691740 15248 solver.cpp:259]     Train net output #0: loss = 0.053913 (* 1 = 0.053913 loss)
I0706 02:43:14.691745 15248 solver.cpp:590] Iteration 62260, lr = 0.00027229
I0706 02:43:36.486456 15248 solver.cpp:243] Iteration 62370, loss = 0.000489563
I0706 02:43:36.486590 15248 solver.cpp:259]     Train net output #0: loss = 0.000489372 (* 1 = 0.000489372 loss)
I0706 02:43:36.486598 15248 solver.cpp:590] Iteration 62370, lr = 0.000270562
I0706 02:43:58.852005 15248 solver.cpp:243] Iteration 62480, loss = 0.00491106
I0706 02:43:58.852031 15248 solver.cpp:259]     Train net output #0: loss = 0.00491089 (* 1 = 0.00491089 loss)
I0706 02:43:58.852037 15248 solver.cpp:590] Iteration 62480, lr = 0.000268845
I0706 02:44:20.370198 15248 solver.cpp:243] Iteration 62590, loss = 0.169974
I0706 02:44:20.370286 15248 solver.cpp:259]     Train net output #0: loss = 0.169974 (* 1 = 0.169974 loss)
I0706 02:44:20.370295 15248 solver.cpp:590] Iteration 62590, lr = 0.000267139
I0706 02:44:26.629042 15248 solver.cpp:347] Iteration 62622, Testing net (#0)
I0706 02:44:31.950300 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 02:44:42.781549 15267 blocking_queue.cpp:50] Waiting for data
I0706 02:44:50.961094 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0623798
I0706 02:44:50.961199 15248 solver.cpp:415]     Test net output #1: loss = 6.71926 (* 1 = 6.71926 loss)
I0706 02:45:07.282101 15248 solver.cpp:243] Iteration 62700, loss = 0.0181065
I0706 02:45:07.282125 15248 solver.cpp:259]     Train net output #0: loss = 0.0181064 (* 1 = 0.0181064 loss)
I0706 02:45:07.282131 15248 solver.cpp:590] Iteration 62700, lr = 0.000265444
I0706 02:45:29.152765 15248 solver.cpp:243] Iteration 62810, loss = 0.00979171
I0706 02:45:29.152829 15248 solver.cpp:259]     Train net output #0: loss = 0.00979149 (* 1 = 0.00979149 loss)
I0706 02:45:29.152837 15248 solver.cpp:590] Iteration 62810, lr = 0.000263759
I0706 02:45:51.157775 15248 solver.cpp:243] Iteration 62920, loss = 0.030208
I0706 02:45:51.157799 15248 solver.cpp:259]     Train net output #0: loss = 0.0302078 (* 1 = 0.0302078 loss)
I0706 02:45:51.157805 15248 solver.cpp:590] Iteration 62920, lr = 0.000262085
I0706 02:46:12.860671 15248 solver.cpp:243] Iteration 63030, loss = 0.00162284
I0706 02:46:12.860780 15248 solver.cpp:259]     Train net output #0: loss = 0.00162257 (* 1 = 0.00162257 loss)
I0706 02:46:12.860788 15248 solver.cpp:590] Iteration 63030, lr = 0.000260422
I0706 02:46:34.431179 15248 solver.cpp:243] Iteration 63140, loss = 0.000670749
I0706 02:46:34.431205 15248 solver.cpp:259]     Train net output #0: loss = 0.000670477 (* 1 = 0.000670477 loss)
I0706 02:46:34.431213 15248 solver.cpp:590] Iteration 63140, lr = 0.000258769
I0706 02:46:56.167145 15248 solver.cpp:243] Iteration 63250, loss = 0.008474
I0706 02:46:56.167238 15248 solver.cpp:259]     Train net output #0: loss = 0.00847372 (* 1 = 0.00847372 loss)
I0706 02:46:56.167254 15248 solver.cpp:590] Iteration 63250, lr = 0.000257127
I0706 02:47:17.577690 15248 solver.cpp:243] Iteration 63360, loss = 0.00607525
I0706 02:47:17.577718 15248 solver.cpp:259]     Train net output #0: loss = 0.00607503 (* 1 = 0.00607503 loss)
I0706 02:47:17.577724 15248 solver.cpp:590] Iteration 63360, lr = 0.000255495
I0706 02:47:39.659909 15248 solver.cpp:243] Iteration 63470, loss = 0.00578246
I0706 02:47:39.660130 15248 solver.cpp:259]     Train net output #0: loss = 0.00578224 (* 1 = 0.00578224 loss)
I0706 02:47:39.660136 15248 solver.cpp:590] Iteration 63470, lr = 0.000253874
I0706 02:47:46.209638 15248 solver.cpp:347] Iteration 63504, Testing net (#0)
I0706 02:48:13.310045 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0635817
I0706 02:48:13.310148 15248 solver.cpp:415]     Test net output #1: loss = 6.73619 (* 1 = 6.73619 loss)
I0706 02:48:28.274122 15248 solver.cpp:243] Iteration 63580, loss = 0.00376591
I0706 02:48:28.274147 15248 solver.cpp:259]     Train net output #0: loss = 0.00376567 (* 1 = 0.00376567 loss)
I0706 02:48:28.274153 15248 solver.cpp:590] Iteration 63580, lr = 0.000252263
I0706 02:48:50.549103 15248 solver.cpp:243] Iteration 63690, loss = 0.0142931
I0706 02:48:50.549223 15248 solver.cpp:259]     Train net output #0: loss = 0.0142929 (* 1 = 0.0142929 loss)
I0706 02:48:50.549231 15248 solver.cpp:590] Iteration 63690, lr = 0.000250662
I0706 02:49:12.321635 15248 solver.cpp:243] Iteration 63800, loss = 0.00281534
I0706 02:49:12.321661 15248 solver.cpp:259]     Train net output #0: loss = 0.00281497 (* 1 = 0.00281497 loss)
I0706 02:49:12.321667 15248 solver.cpp:590] Iteration 63800, lr = 0.000249071
I0706 02:49:34.256306 15248 solver.cpp:243] Iteration 63910, loss = 0.00777589
I0706 02:49:34.256371 15248 solver.cpp:259]     Train net output #0: loss = 0.0077756 (* 1 = 0.0077756 loss)
I0706 02:49:34.256378 15248 solver.cpp:590] Iteration 63910, lr = 0.00024749
I0706 02:49:56.880290 15248 solver.cpp:243] Iteration 64020, loss = 0.00769812
I0706 02:49:56.880313 15248 solver.cpp:259]     Train net output #0: loss = 0.00769787 (* 1 = 0.00769787 loss)
I0706 02:49:56.880319 15248 solver.cpp:590] Iteration 64020, lr = 0.00024592
I0706 02:50:18.407393 15248 solver.cpp:243] Iteration 64130, loss = 0.00572612
I0706 02:50:18.407483 15248 solver.cpp:259]     Train net output #0: loss = 0.00572586 (* 1 = 0.00572586 loss)
I0706 02:50:18.407500 15248 solver.cpp:590] Iteration 64130, lr = 0.000244359
I0706 02:50:41.523059 15248 solver.cpp:243] Iteration 64240, loss = 0.0152604
I0706 02:50:41.523080 15248 solver.cpp:259]     Train net output #0: loss = 0.0152602 (* 1 = 0.0152602 loss)
I0706 02:50:41.523087 15248 solver.cpp:590] Iteration 64240, lr = 0.000242808
I0706 02:51:03.036260 15248 solver.cpp:243] Iteration 64350, loss = 0.000609979
I0706 02:51:03.036396 15248 solver.cpp:259]     Train net output #0: loss = 0.00060968 (* 1 = 0.00060968 loss)
I0706 02:51:03.036404 15248 solver.cpp:590] Iteration 64350, lr = 0.000241267
I0706 02:51:09.992413 15248 solver.cpp:347] Iteration 64386, Testing net (#0)
I0706 02:51:35.292183 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0628606
I0706 02:51:35.292389 15248 solver.cpp:415]     Test net output #1: loss = 6.75298 (* 1 = 6.75298 loss)
I0706 02:51:50.581423 15248 solver.cpp:243] Iteration 64460, loss = 0.0370877
I0706 02:51:50.581449 15248 solver.cpp:259]     Train net output #0: loss = 0.0370874 (* 1 = 0.0370874 loss)
I0706 02:51:50.581454 15248 solver.cpp:590] Iteration 64460, lr = 0.000239736
I0706 02:52:12.269754 15248 solver.cpp:243] Iteration 64570, loss = 0.0729631
I0706 02:52:12.269987 15248 solver.cpp:259]     Train net output #0: loss = 0.0729627 (* 1 = 0.0729627 loss)
I0706 02:52:12.269995 15248 solver.cpp:590] Iteration 64570, lr = 0.000238215
I0706 02:52:33.818519 15248 solver.cpp:243] Iteration 64680, loss = 0.0146055
I0706 02:52:33.818543 15248 solver.cpp:259]     Train net output #0: loss = 0.0146051 (* 1 = 0.0146051 loss)
I0706 02:52:33.818550 15248 solver.cpp:590] Iteration 64680, lr = 0.000236703
I0706 02:52:55.842907 15248 solver.cpp:243] Iteration 64790, loss = 0.000440434
I0706 02:52:55.843008 15248 solver.cpp:259]     Train net output #0: loss = 0.000440094 (* 1 = 0.000440094 loss)
I0706 02:52:55.843014 15248 solver.cpp:590] Iteration 64790, lr = 0.000235201
I0706 02:53:17.410521 15248 solver.cpp:243] Iteration 64900, loss = 0.0706675
I0706 02:53:17.410543 15248 solver.cpp:259]     Train net output #0: loss = 0.0706672 (* 1 = 0.0706672 loss)
I0706 02:53:17.410548 15248 solver.cpp:590] Iteration 64900, lr = 0.000233708
I0706 02:53:39.719244 15248 solver.cpp:243] Iteration 65010, loss = 0.0355193
I0706 02:53:39.719357 15248 solver.cpp:259]     Train net output #0: loss = 0.0355191 (* 1 = 0.0355191 loss)
I0706 02:53:39.719364 15248 solver.cpp:590] Iteration 65010, lr = 0.000232225
I0706 02:54:01.188632 15248 solver.cpp:243] Iteration 65120, loss = 0.00215259
I0706 02:54:01.188654 15248 solver.cpp:259]     Train net output #0: loss = 0.00215243 (* 1 = 0.00215243 loss)
I0706 02:54:01.188660 15248 solver.cpp:590] Iteration 65120, lr = 0.000230751
I0706 02:54:23.199525 15248 solver.cpp:243] Iteration 65230, loss = 0.0166464
I0706 02:54:23.199620 15248 solver.cpp:259]     Train net output #0: loss = 0.0166462 (* 1 = 0.0166462 loss)
I0706 02:54:23.199626 15248 solver.cpp:590] Iteration 65230, lr = 0.000229287
I0706 02:54:30.673421 15248 solver.cpp:347] Iteration 65268, Testing net (#0)
I0706 02:54:55.996646 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0635817
I0706 02:54:55.996729 15248 solver.cpp:415]     Test net output #1: loss = 6.77189 (* 1 = 6.77189 loss)
I0706 02:55:10.173741 15248 solver.cpp:243] Iteration 65340, loss = 0.00261726
I0706 02:55:10.173761 15248 solver.cpp:259]     Train net output #0: loss = 0.00261702 (* 1 = 0.00261702 loss)
I0706 02:55:10.173768 15248 solver.cpp:590] Iteration 65340, lr = 0.000227831
I0706 02:55:32.695684 15248 solver.cpp:243] Iteration 65450, loss = 0.0295342
I0706 02:55:32.695775 15248 solver.cpp:259]     Train net output #0: loss = 0.0295339 (* 1 = 0.0295339 loss)
I0706 02:55:32.695782 15248 solver.cpp:590] Iteration 65450, lr = 0.000226385
I0706 02:55:54.827025 15248 solver.cpp:243] Iteration 65560, loss = 0.112089
I0706 02:55:54.827050 15248 solver.cpp:259]     Train net output #0: loss = 0.112089 (* 1 = 0.112089 loss)
I0706 02:55:54.827056 15248 solver.cpp:590] Iteration 65560, lr = 0.000224949
I0706 02:56:16.538767 15248 solver.cpp:243] Iteration 65670, loss = 0.0274827
I0706 02:56:16.538828 15248 solver.cpp:259]     Train net output #0: loss = 0.0274825 (* 1 = 0.0274825 loss)
I0706 02:56:16.538836 15248 solver.cpp:590] Iteration 65670, lr = 0.000223521
I0706 02:56:39.338551 15248 solver.cpp:243] Iteration 65780, loss = 0.0445376
I0706 02:56:39.338574 15248 solver.cpp:259]     Train net output #0: loss = 0.0445374 (* 1 = 0.0445374 loss)
I0706 02:56:39.338580 15248 solver.cpp:590] Iteration 65780, lr = 0.000222103
I0706 02:57:00.765013 15248 solver.cpp:243] Iteration 65890, loss = 0.146209
I0706 02:57:00.765120 15248 solver.cpp:259]     Train net output #0: loss = 0.146209 (* 1 = 0.146209 loss)
I0706 02:57:00.765144 15248 solver.cpp:590] Iteration 65890, lr = 0.000220693
I0706 02:57:23.294513 15248 solver.cpp:243] Iteration 66000, loss = 0.0415551
I0706 02:57:23.294574 15248 solver.cpp:259]     Train net output #0: loss = 0.0415549 (* 1 = 0.0415549 loss)
I0706 02:57:23.294590 15248 solver.cpp:590] Iteration 66000, lr = 0.000219293
I0706 02:57:44.815155 15248 solver.cpp:243] Iteration 66110, loss = 0.0118807
I0706 02:57:44.815419 15248 solver.cpp:259]     Train net output #0: loss = 0.0118804 (* 1 = 0.0118804 loss)
I0706 02:57:44.815428 15248 solver.cpp:590] Iteration 66110, lr = 0.000217901
I0706 02:57:52.473692 15248 solver.cpp:347] Iteration 66150, Testing net (#0)
I0706 02:57:56.278079 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 02:58:08.002037 15267 blocking_queue.cpp:50] Waiting for data
I0706 02:58:19.264997 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0623798
I0706 02:58:19.265101 15248 solver.cpp:415]     Test net output #1: loss = 6.77994 (* 1 = 6.77994 loss)
I0706 02:58:33.329066 15248 solver.cpp:243] Iteration 66220, loss = 0.00484736
I0706 02:58:33.329116 15248 solver.cpp:259]     Train net output #0: loss = 0.00484714 (* 1 = 0.00484714 loss)
I0706 02:58:33.329128 15248 solver.cpp:590] Iteration 66220, lr = 0.000216518
I0706 02:58:55.364059 15248 solver.cpp:243] Iteration 66330, loss = 0.0722295
I0706 02:58:55.370260 15248 solver.cpp:259]     Train net output #0: loss = 0.0722293 (* 1 = 0.0722293 loss)
I0706 02:58:55.370270 15248 solver.cpp:590] Iteration 66330, lr = 0.000215144
I0706 02:59:17.003509 15248 solver.cpp:243] Iteration 66440, loss = 0.0335917
I0706 02:59:17.003532 15248 solver.cpp:259]     Train net output #0: loss = 0.0335915 (* 1 = 0.0335915 loss)
I0706 02:59:17.003538 15248 solver.cpp:590] Iteration 66440, lr = 0.000213778
I0706 02:59:39.376611 15248 solver.cpp:243] Iteration 66550, loss = 0.293196
I0706 02:59:39.376829 15248 solver.cpp:259]     Train net output #0: loss = 0.293196 (* 1 = 0.293196 loss)
I0706 02:59:39.376837 15248 solver.cpp:590] Iteration 66550, lr = 0.000212422
I0706 03:00:01.011608 15248 solver.cpp:243] Iteration 66660, loss = 0.000668221
I0706 03:00:01.011631 15248 solver.cpp:259]     Train net output #0: loss = 0.000667998 (* 1 = 0.000667998 loss)
I0706 03:00:01.011637 15248 solver.cpp:590] Iteration 66660, lr = 0.000211074
I0706 03:00:23.137616 15248 solver.cpp:243] Iteration 66770, loss = 0.00181523
I0706 03:00:23.137878 15248 solver.cpp:259]     Train net output #0: loss = 0.00181502 (* 1 = 0.00181502 loss)
I0706 03:00:23.137887 15248 solver.cpp:590] Iteration 66770, lr = 0.000209734
I0706 03:00:44.647313 15248 solver.cpp:243] Iteration 66880, loss = 0.0557638
I0706 03:00:44.647337 15248 solver.cpp:259]     Train net output #0: loss = 0.0557636 (* 1 = 0.0557636 loss)
I0706 03:00:44.647343 15248 solver.cpp:590] Iteration 66880, lr = 0.000208403
I0706 03:01:06.764503 15248 solver.cpp:243] Iteration 66990, loss = 0.010824
I0706 03:01:06.765054 15248 solver.cpp:259]     Train net output #0: loss = 0.0108239 (* 1 = 0.0108239 loss)
I0706 03:01:06.765064 15248 solver.cpp:590] Iteration 66990, lr = 0.00020708
I0706 03:01:14.967352 15248 solver.cpp:347] Iteration 67032, Testing net (#0)
I0706 03:01:38.613315 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0626202
I0706 03:01:38.613414 15248 solver.cpp:415]     Test net output #1: loss = 6.74576 (* 1 = 6.74576 loss)
I0706 03:01:51.982280 15248 solver.cpp:243] Iteration 67100, loss = 0.0416562
I0706 03:01:51.982301 15248 solver.cpp:259]     Train net output #0: loss = 0.0416561 (* 1 = 0.0416561 loss)
I0706 03:01:51.982307 15248 solver.cpp:590] Iteration 67100, lr = 0.000205766
I0706 03:02:13.443904 15248 solver.cpp:243] Iteration 67210, loss = 0.016797
I0706 03:02:13.444021 15248 solver.cpp:259]     Train net output #0: loss = 0.0167969 (* 1 = 0.0167969 loss)
I0706 03:02:13.444037 15248 solver.cpp:590] Iteration 67210, lr = 0.00020446
I0706 03:02:35.335453 15248 solver.cpp:243] Iteration 67320, loss = 0.0103443
I0706 03:02:35.335479 15248 solver.cpp:259]     Train net output #0: loss = 0.0103442 (* 1 = 0.0103442 loss)
I0706 03:02:35.335485 15248 solver.cpp:590] Iteration 67320, lr = 0.000203163
I0706 03:02:56.765151 15248 solver.cpp:243] Iteration 67430, loss = 0.00139793
I0706 03:02:56.768800 15248 solver.cpp:259]     Train net output #0: loss = 0.00139789 (* 1 = 0.00139789 loss)
I0706 03:02:56.768808 15248 solver.cpp:590] Iteration 67430, lr = 0.000201874
I0706 03:03:19.010329 15248 solver.cpp:243] Iteration 67540, loss = 0.000643209
I0706 03:03:19.010351 15248 solver.cpp:259]     Train net output #0: loss = 0.000643287 (* 1 = 0.000643287 loss)
I0706 03:03:19.010359 15248 solver.cpp:590] Iteration 67540, lr = 0.000200592
I0706 03:03:40.487668 15248 solver.cpp:243] Iteration 67650, loss = 0.00906736
I0706 03:03:40.487927 15248 solver.cpp:259]     Train net output #0: loss = 0.00906734 (* 1 = 0.00906734 loss)
I0706 03:03:40.487936 15248 solver.cpp:590] Iteration 67650, lr = 0.000199319
I0706 03:04:02.612728 15248 solver.cpp:243] Iteration 67760, loss = 0.000530785
I0706 03:04:02.612784 15248 solver.cpp:259]     Train net output #0: loss = 0.000530726 (* 1 = 0.000530726 loss)
I0706 03:04:02.612797 15248 solver.cpp:590] Iteration 67760, lr = 0.000198054
I0706 03:04:24.102411 15248 solver.cpp:243] Iteration 67870, loss = 0.00453357
I0706 03:04:24.102638 15248 solver.cpp:259]     Train net output #0: loss = 0.00453344 (* 1 = 0.00453344 loss)
I0706 03:04:24.102648 15248 solver.cpp:590] Iteration 67870, lr = 0.000196797
I0706 03:04:32.523278 15248 solver.cpp:347] Iteration 67914, Testing net (#0)
I0706 03:04:57.006667 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0617788
I0706 03:04:57.006769 15248 solver.cpp:415]     Test net output #1: loss = 6.74836 (* 1 = 6.74836 loss)
I0706 03:05:10.340607 15248 solver.cpp:243] Iteration 67980, loss = 0.116262
I0706 03:05:10.340629 15248 solver.cpp:259]     Train net output #0: loss = 0.116261 (* 1 = 0.116261 loss)
I0706 03:05:10.340636 15248 solver.cpp:590] Iteration 67980, lr = 0.000195549
I0706 03:05:32.353253 15248 solver.cpp:243] Iteration 68090, loss = 0.0446064
I0706 03:05:32.353505 15248 solver.cpp:259]     Train net output #0: loss = 0.0446063 (* 1 = 0.0446063 loss)
I0706 03:05:32.353514 15248 solver.cpp:590] Iteration 68090, lr = 0.000194308
I0706 03:05:54.001241 15248 solver.cpp:243] Iteration 68200, loss = 0.0170076
I0706 03:05:54.001267 15248 solver.cpp:259]     Train net output #0: loss = 0.0170075 (* 1 = 0.0170075 loss)
I0706 03:05:54.001273 15248 solver.cpp:590] Iteration 68200, lr = 0.000193074
I0706 03:06:16.161304 15248 solver.cpp:243] Iteration 68310, loss = 0.00177592
I0706 03:06:16.161561 15248 solver.cpp:259]     Train net output #0: loss = 0.00177575 (* 1 = 0.00177575 loss)
I0706 03:06:16.161571 15248 solver.cpp:590] Iteration 68310, lr = 0.000191849
I0706 03:06:37.614346 15248 solver.cpp:243] Iteration 68420, loss = 0.00291826
I0706 03:06:37.614372 15248 solver.cpp:259]     Train net output #0: loss = 0.00291812 (* 1 = 0.00291812 loss)
I0706 03:06:37.614377 15248 solver.cpp:590] Iteration 68420, lr = 0.000190632
I0706 03:06:59.676349 15248 solver.cpp:243] Iteration 68530, loss = 0.0526327
I0706 03:06:59.676458 15248 solver.cpp:259]     Train net output #0: loss = 0.0526325 (* 1 = 0.0526325 loss)
I0706 03:06:59.676465 15248 solver.cpp:590] Iteration 68530, lr = 0.000189422
I0706 03:07:21.140070 15248 solver.cpp:243] Iteration 68640, loss = 0.00937647
I0706 03:07:21.140095 15248 solver.cpp:259]     Train net output #0: loss = 0.00937632 (* 1 = 0.00937632 loss)
I0706 03:07:21.140101 15248 solver.cpp:590] Iteration 68640, lr = 0.00018822
I0706 03:07:43.278365 15248 solver.cpp:243] Iteration 68750, loss = 0.000100207
I0706 03:07:43.278455 15248 solver.cpp:259]     Train net output #0: loss = 0.000100085 (* 1 = 0.000100085 loss)
I0706 03:07:43.278472 15248 solver.cpp:590] Iteration 68750, lr = 0.000187025
I0706 03:07:52.326858 15248 solver.cpp:347] Iteration 68796, Testing net (#0)
I0706 03:08:19.382840 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0625
I0706 03:08:19.383002 15248 solver.cpp:415]     Test net output #1: loss = 6.72871 (* 1 = 6.72871 loss)
I0706 03:08:32.037922 15248 solver.cpp:243] Iteration 68860, loss = 0.0657024
I0706 03:08:32.037947 15248 solver.cpp:259]     Train net output #0: loss = 0.0657023 (* 1 = 0.0657023 loss)
I0706 03:08:32.037955 15248 solver.cpp:590] Iteration 68860, lr = 0.000185838
I0706 03:08:53.742568 15248 solver.cpp:243] Iteration 68970, loss = 0.000870373
I0706 03:08:53.742892 15248 solver.cpp:259]     Train net output #0: loss = 0.00087028 (* 1 = 0.00087028 loss)
I0706 03:08:53.742913 15248 solver.cpp:590] Iteration 68970, lr = 0.000184659
I0706 03:09:15.898803 15248 solver.cpp:243] Iteration 69080, loss = 0.000210716
I0706 03:09:15.898829 15248 solver.cpp:259]     Train net output #0: loss = 0.000210661 (* 1 = 0.000210661 loss)
I0706 03:09:15.898835 15248 solver.cpp:590] Iteration 69080, lr = 0.000183487
I0706 03:09:37.362862 15248 solver.cpp:243] Iteration 69190, loss = 0.00747837
I0706 03:09:37.362974 15248 solver.cpp:259]     Train net output #0: loss = 0.00747832 (* 1 = 0.00747832 loss)
I0706 03:09:37.362982 15248 solver.cpp:590] Iteration 69190, lr = 0.000182322
I0706 03:09:59.815035 15248 solver.cpp:243] Iteration 69300, loss = 0.146432
I0706 03:09:59.815059 15248 solver.cpp:259]     Train net output #0: loss = 0.146432 (* 1 = 0.146432 loss)
I0706 03:09:59.815065 15248 solver.cpp:590] Iteration 69300, lr = 0.000181165
I0706 03:10:21.281472 15248 solver.cpp:243] Iteration 69410, loss = 0.00553448
I0706 03:10:21.281563 15248 solver.cpp:259]     Train net output #0: loss = 0.00553441 (* 1 = 0.00553441 loss)
I0706 03:10:21.281579 15248 solver.cpp:590] Iteration 69410, lr = 0.000180016
I0706 03:10:43.697468 15248 solver.cpp:243] Iteration 69520, loss = 0.00121556
I0706 03:10:43.697490 15248 solver.cpp:259]     Train net output #0: loss = 0.00121552 (* 1 = 0.00121552 loss)
I0706 03:10:43.697497 15248 solver.cpp:590] Iteration 69520, lr = 0.000178873
I0706 03:11:05.480280 15248 solver.cpp:243] Iteration 69630, loss = 0.000545822
I0706 03:11:05.480365 15248 solver.cpp:259]     Train net output #0: loss = 0.00054575 (* 1 = 0.00054575 loss)
I0706 03:11:05.480371 15248 solver.cpp:590] Iteration 69630, lr = 0.000177738
I0706 03:11:14.670075 15248 solver.cpp:347] Iteration 69678, Testing net (#0)
I0706 03:11:16.852136 15248 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 03:11:37.726471 15267 blocking_queue.cpp:50] Waiting for data
I0706 03:11:42.283067 15248 solver.cpp:415]     Test net output #0: accuracy = 0.061899
I0706 03:11:42.283095 15248 solver.cpp:415]     Test net output #1: loss = 6.73638 (* 1 = 6.73638 loss)
I0706 03:11:55.290930 15248 solver.cpp:243] Iteration 69740, loss = 0.189848
I0706 03:11:55.290954 15248 solver.cpp:259]     Train net output #0: loss = 0.189848 (* 1 = 0.189848 loss)
I0706 03:11:55.290961 15248 solver.cpp:590] Iteration 69740, lr = 0.00017661
I0706 03:12:17.616170 15248 solver.cpp:243] Iteration 69850, loss = 0.000120415
I0706 03:12:17.616262 15248 solver.cpp:259]     Train net output #0: loss = 0.00012036 (* 1 = 0.00012036 loss)
I0706 03:12:17.616268 15248 solver.cpp:590] Iteration 69850, lr = 0.000175489
I0706 03:12:39.140916 15248 solver.cpp:243] Iteration 69960, loss = 0.41409
I0706 03:12:39.140940 15248 solver.cpp:259]     Train net output #0: loss = 0.41409 (* 1 = 0.41409 loss)
I0706 03:12:39.140946 15248 solver.cpp:590] Iteration 69960, lr = 0.000174375
I0706 03:13:01.136245 15248 solver.cpp:243] Iteration 70070, loss = 0.0643709
I0706 03:13:01.136368 15248 solver.cpp:259]     Train net output #0: loss = 0.0643708 (* 1 = 0.0643708 loss)
I0706 03:13:01.136385 15248 solver.cpp:590] Iteration 70070, lr = 0.000173269
I0706 03:13:22.640166 15248 solver.cpp:243] Iteration 70180, loss = 0.000948936
I0706 03:13:22.640190 15248 solver.cpp:259]     Train net output #0: loss = 0.000948836 (* 1 = 0.000948836 loss)
I0706 03:13:22.640197 15248 solver.cpp:590] Iteration 70180, lr = 0.000172169
I0706 03:13:45.567678 15248 solver.cpp:243] Iteration 70290, loss = 0.0152628
I0706 03:13:45.567802 15248 solver.cpp:259]     Train net output #0: loss = 0.0152627 (* 1 = 0.0152627 loss)
I0706 03:13:45.567809 15248 solver.cpp:590] Iteration 70290, lr = 0.000171077
I0706 03:14:07.010682 15248 solver.cpp:243] Iteration 70400, loss = 0.00100294
I0706 03:14:07.010707 15248 solver.cpp:259]     Train net output #0: loss = 0.00100283 (* 1 = 0.00100283 loss)
I0706 03:14:07.010713 15248 solver.cpp:590] Iteration 70400, lr = 0.000169991
I0706 03:14:28.912628 15248 solver.cpp:243] Iteration 70510, loss = 0.0001347
I0706 03:14:28.912884 15248 solver.cpp:259]     Train net output #0: loss = 0.000134584 (* 1 = 0.000134584 loss)
I0706 03:14:28.912892 15248 solver.cpp:590] Iteration 70510, lr = 0.000168912
I0706 03:14:39.270161 15248 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_70560.caffemodel
I0706 03:15:14.672515 15248 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_70560.solverstate
I0706 03:15:17.292711 15248 solver.cpp:347] Iteration 70560, Testing net (#0)
I0706 03:15:43.505722 15248 solver.cpp:415]     Test net output #0: accuracy = 0.0629808
I0706 03:15:43.505753 15248 solver.cpp:415]     Test net output #1: loss = 6.75043 (* 1 = 6.75043 loss)
I0706 03:15:43.505756 15248 solver.cpp:332] Optimization Done.
I0706 03:15:43.505759 15248 caffe.cpp:223] Optimization Done.
