I0706 13:33:59.895310  1643 caffe.cpp:192] Using GPUs 0
I0706 13:34:00.081326  1643 solver.cpp:54] Initializing solver from parameters:
test_iter: 130
test_interval: 441
base_lr: 0.01
display: 55
max_iter: 35280
lr_policy: "exp"
gamma: 0.99982464
momentum: 0.9
weight_decay: 0.0001
snapshot: 4410
snapshot_prefix: "snapshot"
solver_mode: GPU
device_id: 0
random_seed: 0
net: "train_val.prototxt"
solver_type: SGD
iter_size: 1
I0706 13:34:00.081533  1643 solver.cpp:97] Creating training net from net file: train_val.prototxt
I0706 13:34:00.081874  1643 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0706 13:34:00.081881  1643 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer label
I0706 13:34:00.081888  1643 net.cpp:325] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0706 13:34:00.081965  1643 net.cpp:52] Initializing net from parameters:
state {
phase: TRAIN
}
layer {
name: "data"
type: "Data"
top: "data"
include {
phase: TRAIN
}
transform_param {
mean_file: "/home/ffw/scratch/plantClef/scatnet_output/train/a4_m3_s1s2s4_f2/lmdb_mean_coeff.binaryproto"
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/train/a4_m3_s1s2s4_f2/lmdb_data"
batch_size: 64
backend: LMDB
}
}
layer {
name: "label"
type: "Data"
top: "label"
include {
phase: TRAIN
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/train/a4_m3_s1s2s4_f2/lmdb_labels"
batch_size: 64
backend: LMDB
}
}
layer {
name: "pool1"
type: "Pooling"
bottom: "data"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 6
stride: 5
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool1"
top: "conv3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "conv4"
type: "Convolution"
bottom: "conv3"
top: "conv4"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu4"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "conv5"
type: "Convolution"
bottom: "conv4"
top: "conv5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
group: 1
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "conv5"
top: "conv5"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "conv5"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fc6"
type: "InnerProduct"
bottom: "pool5"
top: "fc6"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "fc6"
top: "fc6"
}
layer {
name: "drop6"
type: "Dropout"
bottom: "fc6"
top: "fc6"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc7"
type: "InnerProduct"
bottom: "fc6"
top: "fc7"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "fc7"
top: "fc7"
}
layer {
name: "drop7"
type: "Dropout"
bottom: "fc7"
top: "fc7"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc8_species"
type: "InnerProduct"
bottom: "fc7"
top: "fc8_species"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 967
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "fc8_species"
bottom: "label"
top: "loss"
}
I0706 13:34:00.082020  1643 layer_factory.hpp:76] Creating layer data
I0706 13:34:00.082092  1643 net.cpp:109] Creating Layer data
I0706 13:34:00.082105  1643 net.cpp:414] data -> data
I0706 13:34:00.082118  1643 data_transformer.cpp:25] Loading mean file from: /home/ffw/scratch/plantClef/scatnet_output/train/a4_m3_s1s2s4_f2/lmdb_mean_coeff.binaryproto
I0706 13:34:00.086784  1655 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/train/a4_m3_s1s2s4_f2/lmdb_data
I0706 13:34:00.099761  1643 data_layer.cpp:45] output data size: 64,375,47,47
I0706 13:34:00.322435  1643 net.cpp:153] Setting up data
I0706 13:34:00.322468  1643 net.cpp:160] Top shape: 64 375 47 47 (53016000)
I0706 13:34:00.322471  1643 net.cpp:168] Memory required for data: 212064000
I0706 13:34:00.322475  1643 layer_factory.hpp:76] Creating layer label
I0706 13:34:00.322640  1643 net.cpp:109] Creating Layer label
I0706 13:34:00.322649  1643 net.cpp:414] label -> label
I0706 13:34:00.328887  1657 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/train/a4_m3_s1s2s4_f2/lmdb_labels
I0706 13:34:00.341603  1643 data_layer.cpp:45] output data size: 64,1,1,1
I0706 13:34:00.341734  1643 net.cpp:153] Setting up label
I0706 13:34:00.341742  1643 net.cpp:160] Top shape: 64 1 1 1 (64)
I0706 13:34:00.341745  1643 net.cpp:168] Memory required for data: 212064256
I0706 13:34:00.341748  1643 layer_factory.hpp:76] Creating layer pool1
I0706 13:34:00.341758  1643 net.cpp:109] Creating Layer pool1
I0706 13:34:00.341759  1643 net.cpp:457] pool1 <- data
I0706 13:34:00.341768  1643 net.cpp:414] pool1 -> pool1
I0706 13:34:00.341809  1643 net.cpp:153] Setting up pool1
I0706 13:34:00.341812  1643 net.cpp:160] Top shape: 64 375 10 10 (2400000)
I0706 13:34:00.341814  1643 net.cpp:168] Memory required for data: 221664256
I0706 13:34:00.341816  1643 layer_factory.hpp:76] Creating layer conv3
I0706 13:34:00.341822  1643 net.cpp:109] Creating Layer conv3
I0706 13:34:00.341825  1643 net.cpp:457] conv3 <- pool1
I0706 13:34:00.341827  1643 net.cpp:414] conv3 -> conv3
I0706 13:34:00.367624  1643 net.cpp:153] Setting up conv3
I0706 13:34:00.367645  1643 net.cpp:160] Top shape: 64 384 10 10 (2457600)
I0706 13:34:00.367647  1643 net.cpp:168] Memory required for data: 231494656
I0706 13:34:00.367660  1643 layer_factory.hpp:76] Creating layer relu3
I0706 13:34:00.367669  1643 net.cpp:109] Creating Layer relu3
I0706 13:34:00.367672  1643 net.cpp:457] relu3 <- conv3
I0706 13:34:00.367676  1643 net.cpp:400] relu3 -> conv3 (in-place)
I0706 13:34:00.367686  1643 net.cpp:153] Setting up relu3
I0706 13:34:00.367688  1643 net.cpp:160] Top shape: 64 384 10 10 (2457600)
I0706 13:34:00.367691  1643 net.cpp:168] Memory required for data: 241325056
I0706 13:34:00.367692  1643 layer_factory.hpp:76] Creating layer conv4
I0706 13:34:00.367698  1643 net.cpp:109] Creating Layer conv4
I0706 13:34:00.367700  1643 net.cpp:457] conv4 <- conv3
I0706 13:34:00.367704  1643 net.cpp:414] conv4 -> conv4
I0706 13:34:00.380962  1643 net.cpp:153] Setting up conv4
I0706 13:34:00.380981  1643 net.cpp:160] Top shape: 64 384 10 10 (2457600)
I0706 13:34:00.380983  1643 net.cpp:168] Memory required for data: 251155456
I0706 13:34:00.380993  1643 layer_factory.hpp:76] Creating layer relu4
I0706 13:34:00.381001  1643 net.cpp:109] Creating Layer relu4
I0706 13:34:00.381006  1643 net.cpp:457] relu4 <- conv4
I0706 13:34:00.381009  1643 net.cpp:400] relu4 -> conv4 (in-place)
I0706 13:34:00.381041  1643 net.cpp:153] Setting up relu4
I0706 13:34:00.381044  1643 net.cpp:160] Top shape: 64 384 10 10 (2457600)
I0706 13:34:00.381047  1643 net.cpp:168] Memory required for data: 260985856
I0706 13:34:00.381048  1643 layer_factory.hpp:76] Creating layer conv5
I0706 13:34:00.381054  1643 net.cpp:109] Creating Layer conv5
I0706 13:34:00.381057  1643 net.cpp:457] conv5 <- conv4
I0706 13:34:00.381060  1643 net.cpp:414] conv5 -> conv5
I0706 13:34:00.398676  1643 net.cpp:153] Setting up conv5
I0706 13:34:00.398694  1643 net.cpp:160] Top shape: 64 256 10 10 (1638400)
I0706 13:34:00.398696  1643 net.cpp:168] Memory required for data: 267539456
I0706 13:34:00.398705  1643 layer_factory.hpp:76] Creating layer relu5
I0706 13:34:00.398713  1643 net.cpp:109] Creating Layer relu5
I0706 13:34:00.398717  1643 net.cpp:457] relu5 <- conv5
I0706 13:34:00.398721  1643 net.cpp:400] relu5 -> conv5 (in-place)
I0706 13:34:00.398728  1643 net.cpp:153] Setting up relu5
I0706 13:34:00.398732  1643 net.cpp:160] Top shape: 64 256 10 10 (1638400)
I0706 13:34:00.398733  1643 net.cpp:168] Memory required for data: 274093056
I0706 13:34:00.398736  1643 layer_factory.hpp:76] Creating layer pool5
I0706 13:34:00.398741  1643 net.cpp:109] Creating Layer pool5
I0706 13:34:00.398742  1643 net.cpp:457] pool5 <- conv5
I0706 13:34:00.398746  1643 net.cpp:414] pool5 -> pool5
I0706 13:34:00.398775  1643 net.cpp:153] Setting up pool5
I0706 13:34:00.398778  1643 net.cpp:160] Top shape: 64 256 5 5 (409600)
I0706 13:34:00.398780  1643 net.cpp:168] Memory required for data: 275731456
I0706 13:34:00.398782  1643 layer_factory.hpp:76] Creating layer fc6
I0706 13:34:00.398787  1643 net.cpp:109] Creating Layer fc6
I0706 13:34:00.398790  1643 net.cpp:457] fc6 <- pool5
I0706 13:34:00.398793  1643 net.cpp:414] fc6 -> fc6
I0706 13:34:00.595369  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:34:00.890580  1643 net.cpp:153] Setting up fc6
I0706 13:34:00.890596  1643 net.cpp:160] Top shape: 64 4096 (262144)
I0706 13:34:00.890599  1643 net.cpp:168] Memory required for data: 276780032
I0706 13:34:00.890604  1643 layer_factory.hpp:76] Creating layer relu6
I0706 13:34:00.890610  1643 net.cpp:109] Creating Layer relu6
I0706 13:34:00.890614  1643 net.cpp:457] relu6 <- fc6
I0706 13:34:00.890616  1643 net.cpp:400] relu6 -> fc6 (in-place)
I0706 13:34:00.890624  1643 net.cpp:153] Setting up relu6
I0706 13:34:00.890625  1643 net.cpp:160] Top shape: 64 4096 (262144)
I0706 13:34:00.890627  1643 net.cpp:168] Memory required for data: 277828608
I0706 13:34:00.890630  1643 layer_factory.hpp:76] Creating layer drop6
I0706 13:34:00.890637  1643 net.cpp:109] Creating Layer drop6
I0706 13:34:00.890640  1643 net.cpp:457] drop6 <- fc6
I0706 13:34:00.890642  1643 net.cpp:400] drop6 -> fc6 (in-place)
I0706 13:34:00.890657  1643 net.cpp:153] Setting up drop6
I0706 13:34:00.890661  1643 net.cpp:160] Top shape: 64 4096 (262144)
I0706 13:34:00.890662  1643 net.cpp:168] Memory required for data: 278877184
I0706 13:34:00.890664  1643 layer_factory.hpp:76] Creating layer fc7
I0706 13:34:00.890668  1643 net.cpp:109] Creating Layer fc7
I0706 13:34:00.890671  1643 net.cpp:457] fc7 <- fc6
I0706 13:34:00.890673  1643 net.cpp:414] fc7 -> fc7
I0706 13:34:01.193694  1643 net.cpp:153] Setting up fc7
I0706 13:34:01.193711  1643 net.cpp:160] Top shape: 64 4096 (262144)
I0706 13:34:01.193712  1643 net.cpp:168] Memory required for data: 279925760
I0706 13:34:01.193720  1643 layer_factory.hpp:76] Creating layer relu7
I0706 13:34:01.193727  1643 net.cpp:109] Creating Layer relu7
I0706 13:34:01.193728  1643 net.cpp:457] relu7 <- fc7
I0706 13:34:01.193732  1643 net.cpp:400] relu7 -> fc7 (in-place)
I0706 13:34:01.193738  1643 net.cpp:153] Setting up relu7
I0706 13:34:01.193742  1643 net.cpp:160] Top shape: 64 4096 (262144)
I0706 13:34:01.193742  1643 net.cpp:168] Memory required for data: 280974336
I0706 13:34:01.193744  1643 layer_factory.hpp:76] Creating layer drop7
I0706 13:34:01.193748  1643 net.cpp:109] Creating Layer drop7
I0706 13:34:01.193750  1643 net.cpp:457] drop7 <- fc7
I0706 13:34:01.193765  1643 net.cpp:400] drop7 -> fc7 (in-place)
I0706 13:34:01.193778  1643 net.cpp:153] Setting up drop7
I0706 13:34:01.193781  1643 net.cpp:160] Top shape: 64 4096 (262144)
I0706 13:34:01.193783  1643 net.cpp:168] Memory required for data: 282022912
I0706 13:34:01.193784  1643 layer_factory.hpp:76] Creating layer fc8_species
I0706 13:34:01.193790  1643 net.cpp:109] Creating Layer fc8_species
I0706 13:34:01.193791  1643 net.cpp:457] fc8_species <- fc7
I0706 13:34:01.193794  1643 net.cpp:414] fc8_species -> fc8_species
I0706 13:34:01.270161  1643 net.cpp:153] Setting up fc8_species
I0706 13:34:01.270179  1643 net.cpp:160] Top shape: 64 967 (61888)
I0706 13:34:01.270181  1643 net.cpp:168] Memory required for data: 282270464
I0706 13:34:01.270187  1643 layer_factory.hpp:76] Creating layer loss
I0706 13:34:01.270195  1643 net.cpp:109] Creating Layer loss
I0706 13:34:01.270197  1643 net.cpp:457] loss <- fc8_species
I0706 13:34:01.270201  1643 net.cpp:457] loss <- label
I0706 13:34:01.270205  1643 net.cpp:414] loss -> loss
I0706 13:34:01.270220  1643 layer_factory.hpp:76] Creating layer loss
I0706 13:34:01.270711  1643 net.cpp:153] Setting up loss
I0706 13:34:01.270730  1643 net.cpp:160] Top shape: (1)
I0706 13:34:01.270732  1643 net.cpp:163]     with loss weight 1
I0706 13:34:01.270756  1643 net.cpp:168] Memory required for data: 282270468
I0706 13:34:01.270759  1643 net.cpp:229] loss needs backward computation.
I0706 13:34:01.270761  1643 net.cpp:229] fc8_species needs backward computation.
I0706 13:34:01.270763  1643 net.cpp:229] drop7 needs backward computation.
I0706 13:34:01.270766  1643 net.cpp:229] relu7 needs backward computation.
I0706 13:34:01.270767  1643 net.cpp:229] fc7 needs backward computation.
I0706 13:34:01.270769  1643 net.cpp:229] drop6 needs backward computation.
I0706 13:34:01.270771  1643 net.cpp:229] relu6 needs backward computation.
I0706 13:34:01.270773  1643 net.cpp:229] fc6 needs backward computation.
I0706 13:34:01.270776  1643 net.cpp:229] pool5 needs backward computation.
I0706 13:34:01.270778  1643 net.cpp:229] relu5 needs backward computation.
I0706 13:34:01.270781  1643 net.cpp:229] conv5 needs backward computation.
I0706 13:34:01.270781  1643 net.cpp:229] relu4 needs backward computation.
I0706 13:34:01.270783  1643 net.cpp:229] conv4 needs backward computation.
I0706 13:34:01.270786  1643 net.cpp:229] relu3 needs backward computation.
I0706 13:34:01.270787  1643 net.cpp:229] conv3 needs backward computation.
I0706 13:34:01.270789  1643 net.cpp:231] pool1 does not need backward computation.
I0706 13:34:01.270792  1643 net.cpp:231] label does not need backward computation.
I0706 13:34:01.270793  1643 net.cpp:231] data does not need backward computation.
I0706 13:34:01.270795  1643 net.cpp:273] This network produces output loss
I0706 13:34:01.270802  1643 net.cpp:286] Network initialization done.
I0706 13:34:01.272426  1643 solver.cpp:187] Creating test net (#0) specified by net file: train_val.prototxt
I0706 13:34:01.272480  1643 net.cpp:325] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0706 13:34:01.272482  1643 net.cpp:325] The NetState phase (1) differed from the phase (0) specified by a rule in layer label
I0706 13:34:01.272586  1643 net.cpp:52] Initializing net from parameters:
state {
phase: TEST
}
layer {
name: "data"
type: "Data"
top: "data"
include {
phase: TEST
}
transform_param {
mean_file: "/home/ffw/scratch/plantClef/scatnet_output/train/a4_m3_s1s2s4_f2/lmdb_mean_coeff.binaryproto"
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/test/a4_m3_s1s2s4_f2/lmdb_data"
batch_size: 64
backend: LMDB
}
}
layer {
name: "label"
type: "Data"
top: "label"
include {
phase: TEST
}
data_param {
source: "/home/ffw/scratch/plantClef/scatnet_output/test/a4_m3_s1s2s4_f2/lmdb_labels"
batch_size: 64
backend: LMDB
}
}
layer {
name: "pool1"
type: "Pooling"
bottom: "data"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 6
stride: 5
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool1"
top: "conv3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "conv4"
type: "Convolution"
bottom: "conv3"
top: "conv4"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu4"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "conv5"
type: "Convolution"
bottom: "conv4"
top: "conv5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
group: 1
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "conv5"
top: "conv5"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "conv5"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fc6"
type: "InnerProduct"
bottom: "pool5"
top: "fc6"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "fc6"
top: "fc6"
}
layer {
name: "drop6"
type: "Dropout"
bottom: "fc6"
top: "fc6"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc7"
type: "InnerProduct"
bottom: "fc6"
top: "fc7"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "fc7"
top: "fc7"
}
layer {
name: "drop7"
type: "Dropout"
bottom: "fc7"
top: "fc7"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc8_species"
type: "InnerProduct"
bottom: "fc7"
top: "fc8_species"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 967
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "fc8_species"
bottom: "label"
top: "loss"
}
layer {
name: "accuracy"
type: "Accuracy"
bottom: "fc8_species"
bottom: "label"
top: "accuracy"
include {
phase: TEST
}
}
I0706 13:34:01.272651  1643 layer_factory.hpp:76] Creating layer data
I0706 13:34:01.272716  1643 net.cpp:109] Creating Layer data
I0706 13:34:01.272722  1643 net.cpp:414] data -> data
I0706 13:34:01.272727  1643 data_transformer.cpp:25] Loading mean file from: /home/ffw/scratch/plantClef/scatnet_output/train/a4_m3_s1s2s4_f2/lmdb_mean_coeff.binaryproto
I0706 13:34:01.276962  1659 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/test/a4_m3_s1s2s4_f2/lmdb_data
I0706 13:34:01.286473  1643 data_layer.cpp:45] output data size: 64,375,47,47
I0706 13:34:01.505431  1643 net.cpp:153] Setting up data
I0706 13:34:01.505448  1643 net.cpp:160] Top shape: 64 375 47 47 (53016000)
I0706 13:34:01.505451  1643 net.cpp:168] Memory required for data: 212064000
I0706 13:34:01.505455  1643 layer_factory.hpp:76] Creating layer label
I0706 13:34:01.505506  1643 net.cpp:109] Creating Layer label
I0706 13:34:01.505534  1643 net.cpp:414] label -> label
I0706 13:34:01.699642  1661 db_lmdb.cpp:36] Opened lmdb /home/ffw/scratch/plantClef/scatnet_output/test/a4_m3_s1s2s4_f2/lmdb_labels
I0706 13:34:01.744729  1643 data_layer.cpp:45] output data size: 64,1,1,1
I0706 13:34:01.744979  1643 net.cpp:153] Setting up label
I0706 13:34:01.744992  1643 net.cpp:160] Top shape: 64 1 1 1 (64)
I0706 13:34:01.744994  1643 net.cpp:168] Memory required for data: 212064256
I0706 13:34:01.744998  1643 layer_factory.hpp:76] Creating layer label_label_0_split
I0706 13:34:01.745012  1643 net.cpp:109] Creating Layer label_label_0_split
I0706 13:34:01.745018  1643 net.cpp:457] label_label_0_split <- label
I0706 13:34:01.745021  1643 net.cpp:414] label_label_0_split -> label_label_0_split_0
I0706 13:34:01.745038  1643 net.cpp:414] label_label_0_split -> label_label_0_split_1
I0706 13:34:01.745241  1643 net.cpp:153] Setting up label_label_0_split
I0706 13:34:01.745262  1643 net.cpp:160] Top shape: 64 1 1 1 (64)
I0706 13:34:01.745265  1643 net.cpp:160] Top shape: 64 1 1 1 (64)
I0706 13:34:01.745267  1643 net.cpp:168] Memory required for data: 212064768
I0706 13:34:01.745270  1643 layer_factory.hpp:76] Creating layer pool1
I0706 13:34:01.745276  1643 net.cpp:109] Creating Layer pool1
I0706 13:34:01.745288  1643 net.cpp:457] pool1 <- data
I0706 13:34:01.745292  1643 net.cpp:414] pool1 -> pool1
I0706 13:34:01.745318  1643 net.cpp:153] Setting up pool1
I0706 13:34:01.745321  1643 net.cpp:160] Top shape: 64 375 10 10 (2400000)
I0706 13:34:01.745323  1643 net.cpp:168] Memory required for data: 221664768
I0706 13:34:01.745326  1643 layer_factory.hpp:76] Creating layer conv3
I0706 13:34:01.745332  1643 net.cpp:109] Creating Layer conv3
I0706 13:34:01.745344  1643 net.cpp:457] conv3 <- pool1
I0706 13:34:01.745347  1643 net.cpp:414] conv3 -> conv3
I0706 13:34:01.771412  1643 net.cpp:153] Setting up conv3
I0706 13:34:01.771442  1643 net.cpp:160] Top shape: 64 384 10 10 (2457600)
I0706 13:34:01.771446  1643 net.cpp:168] Memory required for data: 231495168
I0706 13:34:01.771455  1643 layer_factory.hpp:76] Creating layer relu3
I0706 13:34:01.771461  1643 net.cpp:109] Creating Layer relu3
I0706 13:34:01.771464  1643 net.cpp:457] relu3 <- conv3
I0706 13:34:01.771468  1643 net.cpp:400] relu3 -> conv3 (in-place)
I0706 13:34:01.771484  1643 net.cpp:153] Setting up relu3
I0706 13:34:01.771487  1643 net.cpp:160] Top shape: 64 384 10 10 (2457600)
I0706 13:34:01.771489  1643 net.cpp:168] Memory required for data: 241325568
I0706 13:34:01.771492  1643 layer_factory.hpp:76] Creating layer conv4
I0706 13:34:01.771497  1643 net.cpp:109] Creating Layer conv4
I0706 13:34:01.771499  1643 net.cpp:457] conv4 <- conv3
I0706 13:34:01.771502  1643 net.cpp:414] conv4 -> conv4
I0706 13:34:01.784982  1643 net.cpp:153] Setting up conv4
I0706 13:34:01.785001  1643 net.cpp:160] Top shape: 64 384 10 10 (2457600)
I0706 13:34:01.785003  1643 net.cpp:168] Memory required for data: 251155968
I0706 13:34:01.785013  1643 layer_factory.hpp:76] Creating layer relu4
I0706 13:34:01.785022  1643 net.cpp:109] Creating Layer relu4
I0706 13:34:01.785025  1643 net.cpp:457] relu4 <- conv4
I0706 13:34:01.785030  1643 net.cpp:400] relu4 -> conv4 (in-place)
I0706 13:34:01.785037  1643 net.cpp:153] Setting up relu4
I0706 13:34:01.785040  1643 net.cpp:160] Top shape: 64 384 10 10 (2457600)
I0706 13:34:01.785043  1643 net.cpp:168] Memory required for data: 260986368
I0706 13:34:01.785045  1643 layer_factory.hpp:76] Creating layer conv5
I0706 13:34:01.785053  1643 net.cpp:109] Creating Layer conv5
I0706 13:34:01.785054  1643 net.cpp:457] conv5 <- conv4
I0706 13:34:01.785059  1643 net.cpp:414] conv5 -> conv5
I0706 13:34:01.802928  1643 net.cpp:153] Setting up conv5
I0706 13:34:01.802945  1643 net.cpp:160] Top shape: 64 256 10 10 (1638400)
I0706 13:34:01.802948  1643 net.cpp:168] Memory required for data: 267539968
I0706 13:34:01.802968  1643 layer_factory.hpp:76] Creating layer relu5
I0706 13:34:01.802978  1643 net.cpp:109] Creating Layer relu5
I0706 13:34:01.802981  1643 net.cpp:457] relu5 <- conv5
I0706 13:34:01.803004  1643 net.cpp:400] relu5 -> conv5 (in-place)
I0706 13:34:01.803021  1643 net.cpp:153] Setting up relu5
I0706 13:34:01.803025  1643 net.cpp:160] Top shape: 64 256 10 10 (1638400)
I0706 13:34:01.803035  1643 net.cpp:168] Memory required for data: 274093568
I0706 13:34:01.803037  1643 layer_factory.hpp:76] Creating layer pool5
I0706 13:34:01.803042  1643 net.cpp:109] Creating Layer pool5
I0706 13:34:01.803045  1643 net.cpp:457] pool5 <- conv5
I0706 13:34:01.803048  1643 net.cpp:414] pool5 -> pool5
I0706 13:34:01.803084  1643 net.cpp:153] Setting up pool5
I0706 13:34:01.803088  1643 net.cpp:160] Top shape: 64 256 5 5 (409600)
I0706 13:34:01.803091  1643 net.cpp:168] Memory required for data: 275731968
I0706 13:34:01.803092  1643 layer_factory.hpp:76] Creating layer fc6
I0706 13:34:01.803097  1643 net.cpp:109] Creating Layer fc6
I0706 13:34:01.803099  1643 net.cpp:457] fc6 <- pool5
I0706 13:34:01.803102  1643 net.cpp:414] fc6 -> fc6
I0706 13:34:02.324744  1643 net.cpp:153] Setting up fc6
I0706 13:34:02.324762  1643 net.cpp:160] Top shape: 64 4096 (262144)
I0706 13:34:02.324764  1643 net.cpp:168] Memory required for data: 276780544
I0706 13:34:02.324770  1643 layer_factory.hpp:76] Creating layer relu6
I0706 13:34:02.324776  1643 net.cpp:109] Creating Layer relu6
I0706 13:34:02.324779  1643 net.cpp:457] relu6 <- fc6
I0706 13:34:02.324784  1643 net.cpp:400] relu6 -> fc6 (in-place)
I0706 13:34:02.324790  1643 net.cpp:153] Setting up relu6
I0706 13:34:02.324792  1643 net.cpp:160] Top shape: 64 4096 (262144)
I0706 13:34:02.324795  1643 net.cpp:168] Memory required for data: 277829120
I0706 13:34:02.324795  1643 layer_factory.hpp:76] Creating layer drop6
I0706 13:34:02.324800  1643 net.cpp:109] Creating Layer drop6
I0706 13:34:02.324801  1643 net.cpp:457] drop6 <- fc6
I0706 13:34:02.324805  1643 net.cpp:400] drop6 -> fc6 (in-place)
I0706 13:34:02.324816  1643 net.cpp:153] Setting up drop6
I0706 13:34:02.324820  1643 net.cpp:160] Top shape: 64 4096 (262144)
I0706 13:34:02.324820  1643 net.cpp:168] Memory required for data: 278877696
I0706 13:34:02.324822  1643 layer_factory.hpp:76] Creating layer fc7
I0706 13:34:02.324827  1643 net.cpp:109] Creating Layer fc7
I0706 13:34:02.324828  1643 net.cpp:457] fc7 <- fc6
I0706 13:34:02.324831  1643 net.cpp:414] fc7 -> fc7
I0706 13:34:02.651509  1643 net.cpp:153] Setting up fc7
I0706 13:34:02.651525  1643 net.cpp:160] Top shape: 64 4096 (262144)
I0706 13:34:02.651527  1643 net.cpp:168] Memory required for data: 279926272
I0706 13:34:02.651535  1643 layer_factory.hpp:76] Creating layer relu7
I0706 13:34:02.651551  1643 net.cpp:109] Creating Layer relu7
I0706 13:34:02.651554  1643 net.cpp:457] relu7 <- fc7
I0706 13:34:02.651559  1643 net.cpp:400] relu7 -> fc7 (in-place)
I0706 13:34:02.651567  1643 net.cpp:153] Setting up relu7
I0706 13:34:02.651569  1643 net.cpp:160] Top shape: 64 4096 (262144)
I0706 13:34:02.651571  1643 net.cpp:168] Memory required for data: 280974848
I0706 13:34:02.651573  1643 layer_factory.hpp:76] Creating layer drop7
I0706 13:34:02.651578  1643 net.cpp:109] Creating Layer drop7
I0706 13:34:02.651590  1643 net.cpp:457] drop7 <- fc7
I0706 13:34:02.651593  1643 net.cpp:400] drop7 -> fc7 (in-place)
I0706 13:34:02.651617  1643 net.cpp:153] Setting up drop7
I0706 13:34:02.651619  1643 net.cpp:160] Top shape: 64 4096 (262144)
I0706 13:34:02.651620  1643 net.cpp:168] Memory required for data: 282023424
I0706 13:34:02.651623  1643 layer_factory.hpp:76] Creating layer fc8_species
I0706 13:34:02.651628  1643 net.cpp:109] Creating Layer fc8_species
I0706 13:34:02.651629  1643 net.cpp:457] fc8_species <- fc7
I0706 13:34:02.651633  1643 net.cpp:414] fc8_species -> fc8_species
I0706 13:34:02.730448  1643 net.cpp:153] Setting up fc8_species
I0706 13:34:02.730469  1643 net.cpp:160] Top shape: 64 967 (61888)
I0706 13:34:02.730473  1643 net.cpp:168] Memory required for data: 282270976
I0706 13:34:02.730478  1643 layer_factory.hpp:76] Creating layer fc8_species_fc8_species_0_split
I0706 13:34:02.730484  1643 net.cpp:109] Creating Layer fc8_species_fc8_species_0_split
I0706 13:34:02.730511  1643 net.cpp:457] fc8_species_fc8_species_0_split <- fc8_species
I0706 13:34:02.730516  1643 net.cpp:414] fc8_species_fc8_species_0_split -> fc8_species_fc8_species_0_split_0
I0706 13:34:02.730521  1643 net.cpp:414] fc8_species_fc8_species_0_split -> fc8_species_fc8_species_0_split_1
I0706 13:34:02.730553  1643 net.cpp:153] Setting up fc8_species_fc8_species_0_split
I0706 13:34:02.730556  1643 net.cpp:160] Top shape: 64 967 (61888)
I0706 13:34:02.730559  1643 net.cpp:160] Top shape: 64 967 (61888)
I0706 13:34:02.730561  1643 net.cpp:168] Memory required for data: 282766080
I0706 13:34:02.730562  1643 layer_factory.hpp:76] Creating layer loss
I0706 13:34:02.730566  1643 net.cpp:109] Creating Layer loss
I0706 13:34:02.730567  1643 net.cpp:457] loss <- fc8_species_fc8_species_0_split_0
I0706 13:34:02.730569  1643 net.cpp:457] loss <- label_label_0_split_0
I0706 13:34:02.730572  1643 net.cpp:414] loss -> loss
I0706 13:34:02.730576  1643 layer_factory.hpp:76] Creating layer loss
I0706 13:34:02.730665  1643 net.cpp:153] Setting up loss
I0706 13:34:02.730669  1643 net.cpp:160] Top shape: (1)
I0706 13:34:02.730669  1643 net.cpp:163]     with loss weight 1
I0706 13:34:02.730676  1643 net.cpp:168] Memory required for data: 282766084
I0706 13:34:02.730679  1643 layer_factory.hpp:76] Creating layer accuracy
I0706 13:34:02.730682  1643 net.cpp:109] Creating Layer accuracy
I0706 13:34:02.730684  1643 net.cpp:457] accuracy <- fc8_species_fc8_species_0_split_1
I0706 13:34:02.730686  1643 net.cpp:457] accuracy <- label_label_0_split_1
I0706 13:34:02.730690  1643 net.cpp:414] accuracy -> accuracy
I0706 13:34:02.730693  1643 net.cpp:153] Setting up accuracy
I0706 13:34:02.730695  1643 net.cpp:160] Top shape: (1)
I0706 13:34:02.730696  1643 net.cpp:168] Memory required for data: 282766088
I0706 13:34:02.730698  1643 net.cpp:231] accuracy does not need backward computation.
I0706 13:34:02.730700  1643 net.cpp:229] loss needs backward computation.
I0706 13:34:02.730702  1643 net.cpp:229] fc8_species_fc8_species_0_split needs backward computation.
I0706 13:34:02.730705  1643 net.cpp:229] fc8_species needs backward computation.
I0706 13:34:02.730706  1643 net.cpp:229] drop7 needs backward computation.
I0706 13:34:02.730708  1643 net.cpp:229] relu7 needs backward computation.
I0706 13:34:02.730710  1643 net.cpp:229] fc7 needs backward computation.
I0706 13:34:02.730712  1643 net.cpp:229] drop6 needs backward computation.
I0706 13:34:02.730713  1643 net.cpp:229] relu6 needs backward computation.
I0706 13:34:02.730715  1643 net.cpp:229] fc6 needs backward computation.
I0706 13:34:02.730717  1643 net.cpp:229] pool5 needs backward computation.
I0706 13:34:02.730720  1643 net.cpp:229] relu5 needs backward computation.
I0706 13:34:02.730721  1643 net.cpp:229] conv5 needs backward computation.
I0706 13:34:02.730723  1643 net.cpp:229] relu4 needs backward computation.
I0706 13:34:02.730726  1643 net.cpp:229] conv4 needs backward computation.
I0706 13:34:02.730727  1643 net.cpp:229] relu3 needs backward computation.
I0706 13:34:02.730728  1643 net.cpp:229] conv3 needs backward computation.
I0706 13:34:02.730731  1643 net.cpp:231] pool1 does not need backward computation.
I0706 13:34:02.730733  1643 net.cpp:231] label_label_0_split does not need backward computation.
I0706 13:34:02.730736  1643 net.cpp:231] label does not need backward computation.
I0706 13:34:02.730737  1643 net.cpp:231] data does not need backward computation.
I0706 13:34:02.730738  1643 net.cpp:273] This network produces output accuracy
I0706 13:34:02.730741  1643 net.cpp:273] This network produces output loss
I0706 13:34:02.730748  1643 net.cpp:286] Network initialization done.
I0706 13:34:02.730795  1643 solver.cpp:66] Solver scaffolding done.
I0706 13:34:02.731034  1643 caffe.cpp:220] Starting Optimization
I0706 13:34:02.731037  1643 solver.cpp:294] Solving
I0706 13:34:02.731039  1643 solver.cpp:295] Learning Rate Policy: exp
I0706 13:34:02.731885  1643 solver.cpp:347] Iteration 0, Testing net (#0)
I0706 13:34:02.864439  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 13:34:18.164885  1660 blocking_queue.cpp:50] Waiting for data
I0706 13:34:29.959405  1643 solver.cpp:415]     Test net output #0: accuracy = 0.000360577
I0706 13:34:29.959597  1643 solver.cpp:415]     Test net output #1: loss = 6.87862 (* 1 = 6.87862 loss)
I0706 13:34:30.052659  1643 solver.cpp:243] Iteration 0, loss = 6.89572
I0706 13:34:30.052722  1643 solver.cpp:259]     Train net output #0: loss = 6.89572 (* 1 = 6.89572 loss)
I0706 13:34:30.052758  1643 solver.cpp:590] Iteration 0, lr = 0.01
I0706 13:34:37.891268  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:34:43.292022  1643 solver.cpp:243] Iteration 55, loss = 6.68413
I0706 13:34:43.292062  1643 solver.cpp:259]     Train net output #0: loss = 6.68413 (* 1 = 6.68413 loss)
I0706 13:34:43.292070  1643 solver.cpp:590] Iteration 55, lr = 0.00990401
I0706 13:34:55.698086  1643 solver.cpp:243] Iteration 110, loss = 6.69225
I0706 13:34:55.698117  1643 solver.cpp:259]     Train net output #0: loss = 6.69225 (* 1 = 6.69225 loss)
I0706 13:34:55.698124  1643 solver.cpp:590] Iteration 110, lr = 0.00980894
I0706 13:35:03.724227  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:35:08.464670  1643 solver.cpp:243] Iteration 165, loss = 6.77159
I0706 13:35:08.464694  1643 solver.cpp:259]     Train net output #0: loss = 6.77159 (* 1 = 6.77159 loss)
I0706 13:35:08.464699  1643 solver.cpp:590] Iteration 165, lr = 0.00971478
I0706 13:35:18.940780  1643 solver.cpp:243] Iteration 220, loss = 6.46748
I0706 13:35:18.940809  1643 solver.cpp:259]     Train net output #0: loss = 6.46748 (* 1 = 6.46748 loss)
I0706 13:35:18.940815  1643 solver.cpp:590] Iteration 220, lr = 0.00962153
I0706 13:35:31.620656  1643 solver.cpp:243] Iteration 275, loss = 6.37073
I0706 13:35:31.620682  1643 solver.cpp:259]     Train net output #0: loss = 6.37073 (* 1 = 6.37073 loss)
I0706 13:35:31.620688  1643 solver.cpp:590] Iteration 275, lr = 0.00952917
I0706 13:35:42.240844  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:35:43.326833  1643 solver.cpp:243] Iteration 330, loss = 6.43407
I0706 13:35:43.326859  1643 solver.cpp:259]     Train net output #0: loss = 6.43407 (* 1 = 6.43407 loss)
I0706 13:35:43.326865  1643 solver.cpp:590] Iteration 330, lr = 0.0094377
I0706 13:35:56.167181  1643 solver.cpp:243] Iteration 385, loss = 6.57012
I0706 13:35:56.167207  1643 solver.cpp:259]     Train net output #0: loss = 6.57012 (* 1 = 6.57012 loss)
I0706 13:35:56.167214  1643 solver.cpp:590] Iteration 385, lr = 0.00934711
I0706 13:36:03.340746  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:36:08.776888  1643 solver.cpp:243] Iteration 440, loss = 6.20481
I0706 13:36:08.776914  1643 solver.cpp:259]     Train net output #0: loss = 6.20481 (* 1 = 6.20481 loss)
I0706 13:36:08.776921  1643 solver.cpp:590] Iteration 440, lr = 0.00925738
I0706 13:36:08.777173  1643 solver.cpp:347] Iteration 441, Testing net (#0)
I0706 13:36:34.601800  1643 solver.cpp:415]     Test net output #0: accuracy = 0.0121394
I0706 13:36:34.601903  1643 solver.cpp:415]     Test net output #1: loss = 6.29072 (* 1 = 6.29072 loss)
I0706 13:36:40.764700  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:36:44.442376  1643 solver.cpp:243] Iteration 495, loss = 6.39228
I0706 13:36:44.442414  1643 solver.cpp:259]     Train net output #0: loss = 6.39228 (* 1 = 6.39228 loss)
I0706 13:36:44.442421  1643 solver.cpp:590] Iteration 495, lr = 0.00916852
I0706 13:36:55.806437  1643 solver.cpp:243] Iteration 550, loss = 6.30768
I0706 13:36:55.806463  1643 solver.cpp:259]     Train net output #0: loss = 6.30768 (* 1 = 6.30768 loss)
I0706 13:36:55.806468  1643 solver.cpp:590] Iteration 550, lr = 0.00908051
I0706 13:37:05.335366  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:37:08.256124  1643 solver.cpp:243] Iteration 605, loss = 6.15774
I0706 13:37:08.256152  1643 solver.cpp:259]     Train net output #0: loss = 6.15774 (* 1 = 6.15774 loss)
I0706 13:37:08.256160  1643 solver.cpp:590] Iteration 605, lr = 0.00899335
I0706 13:37:20.872056  1643 solver.cpp:243] Iteration 660, loss = 5.96683
I0706 13:37:20.872087  1643 solver.cpp:259]     Train net output #0: loss = 5.96683 (* 1 = 5.96683 loss)
I0706 13:37:20.872095  1643 solver.cpp:590] Iteration 660, lr = 0.00890702
I0706 13:37:31.361868  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:37:32.119343  1643 solver.cpp:243] Iteration 715, loss = 5.85162
I0706 13:37:32.119370  1643 solver.cpp:259]     Train net output #0: loss = 5.85162 (* 1 = 5.85162 loss)
I0706 13:37:32.119377  1643 solver.cpp:590] Iteration 715, lr = 0.00882152
I0706 13:37:40.932287  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 13:37:44.458750  1643 solver.cpp:243] Iteration 770, loss = 5.87178
I0706 13:37:44.458796  1643 solver.cpp:259]     Train net output #0: loss = 5.87178 (* 1 = 5.87178 loss)
I0706 13:37:44.458803  1643 solver.cpp:590] Iteration 770, lr = 0.00873684
I0706 13:37:55.673354  1643 solver.cpp:243] Iteration 825, loss = 5.87176
I0706 13:37:55.673382  1643 solver.cpp:259]     Train net output #0: loss = 5.87176 (* 1 = 5.87176 loss)
I0706 13:37:55.673389  1643 solver.cpp:590] Iteration 825, lr = 0.00865297
I0706 13:38:00.481964  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:38:07.924859  1643 solver.cpp:243] Iteration 880, loss = 5.83009
I0706 13:38:07.924890  1643 solver.cpp:259]     Train net output #0: loss = 5.83009 (* 1 = 5.83009 loss)
I0706 13:38:07.924904  1643 solver.cpp:590] Iteration 880, lr = 0.00856991
I0706 13:38:08.102190  1643 solver.cpp:347] Iteration 882, Testing net (#0)
I0706 13:38:16.456687  1660 blocking_queue.cpp:50] Waiting for data
I0706 13:38:34.079582  1643 solver.cpp:415]     Test net output #0: accuracy = 0.0286058
I0706 13:38:34.079609  1643 solver.cpp:415]     Test net output #1: loss = 5.85968 (* 1 = 5.85968 loss)
I0706 13:38:42.847121  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:38:44.172817  1643 solver.cpp:243] Iteration 935, loss = 6.03769
I0706 13:38:44.172844  1643 solver.cpp:259]     Train net output #0: loss = 6.03769 (* 1 = 6.03769 loss)
I0706 13:38:44.172852  1643 solver.cpp:590] Iteration 935, lr = 0.00848765
I0706 13:38:55.222115  1643 solver.cpp:243] Iteration 990, loss = 5.85203
I0706 13:38:55.222208  1643 solver.cpp:259]     Train net output #0: loss = 5.85203 (* 1 = 5.85203 loss)
I0706 13:38:55.222218  1643 solver.cpp:590] Iteration 990, lr = 0.00840618
I0706 13:39:03.811621  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:39:07.359232  1643 solver.cpp:243] Iteration 1045, loss = 5.89845
I0706 13:39:07.359258  1643 solver.cpp:259]     Train net output #0: loss = 5.89845 (* 1 = 5.89845 loss)
I0706 13:39:07.359266  1643 solver.cpp:590] Iteration 1045, lr = 0.00832548
I0706 13:39:19.008487  1643 solver.cpp:243] Iteration 1100, loss = 5.74369
I0706 13:39:19.008523  1643 solver.cpp:259]     Train net output #0: loss = 5.74369 (* 1 = 5.74369 loss)
I0706 13:39:19.008533  1643 solver.cpp:590] Iteration 1100, lr = 0.00824557
I0706 13:39:22.661520  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:39:30.293179  1643 solver.cpp:243] Iteration 1155, loss = 5.40762
I0706 13:39:30.293257  1643 solver.cpp:259]     Train net output #0: loss = 5.40762 (* 1 = 5.40762 loss)
I0706 13:39:30.293267  1643 solver.cpp:590] Iteration 1155, lr = 0.00816642
I0706 13:39:42.564801  1643 solver.cpp:243] Iteration 1210, loss = 5.2475
I0706 13:39:42.564831  1643 solver.cpp:259]     Train net output #0: loss = 5.2475 (* 1 = 5.2475 loss)
I0706 13:39:42.564841  1643 solver.cpp:590] Iteration 1210, lr = 0.00808803
I0706 13:39:43.835019  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:39:52.781960  1643 solver.cpp:243] Iteration 1265, loss = 5.23013
I0706 13:39:52.781997  1643 solver.cpp:259]     Train net output #0: loss = 5.23013 (* 1 = 5.23013 loss)
I0706 13:39:52.782006  1643 solver.cpp:590] Iteration 1265, lr = 0.00801039
I0706 13:40:04.587486  1643 solver.cpp:243] Iteration 1320, loss = 5.46704
I0706 13:40:04.587628  1643 solver.cpp:259]     Train net output #0: loss = 5.46704 (* 1 = 5.46704 loss)
I0706 13:40:04.587635  1643 solver.cpp:590] Iteration 1320, lr = 0.0079335
I0706 13:40:05.012544  1643 solver.cpp:347] Iteration 1323, Testing net (#0)
I0706 13:40:05.595777  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:40:30.081864  1643 solver.cpp:415]     Test net output #0: accuracy = 0.0399038
I0706 13:40:30.081900  1643 solver.cpp:415]     Test net output #1: loss = 5.61598 (* 1 = 5.61598 loss)
I0706 13:40:36.289145  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:40:40.647716  1643 solver.cpp:243] Iteration 1375, loss = 5.41873
I0706 13:40:40.647740  1643 solver.cpp:259]     Train net output #0: loss = 5.41873 (* 1 = 5.41873 loss)
I0706 13:40:40.647748  1643 solver.cpp:590] Iteration 1375, lr = 0.00785734
I0706 13:40:52.736294  1643 solver.cpp:243] Iteration 1430, loss = 5.42317
I0706 13:40:52.736325  1643 solver.cpp:259]     Train net output #0: loss = 5.42317 (* 1 = 5.42317 loss)
I0706 13:40:52.736335  1643 solver.cpp:590] Iteration 1430, lr = 0.00778192
I0706 13:41:04.636411  1643 solver.cpp:243] Iteration 1485, loss = 5.62917
I0706 13:41:04.636438  1643 solver.cpp:259]     Train net output #0: loss = 5.62917 (* 1 = 5.62917 loss)
I0706 13:41:04.636446  1643 solver.cpp:590] Iteration 1485, lr = 0.00770722
I0706 13:41:06.274376  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:41:09.345270  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 13:41:16.948230  1643 solver.cpp:243] Iteration 1540, loss = 5.52978
I0706 13:41:16.948256  1643 solver.cpp:259]     Train net output #0: loss = 5.52978 (* 1 = 5.52978 loss)
I0706 13:41:16.948263  1643 solver.cpp:590] Iteration 1540, lr = 0.00763324
I0706 13:41:26.299592  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:41:28.963526  1643 solver.cpp:243] Iteration 1595, loss = 5.20628
I0706 13:41:28.963557  1643 solver.cpp:259]     Train net output #0: loss = 5.20628 (* 1 = 5.20628 loss)
I0706 13:41:28.963567  1643 solver.cpp:590] Iteration 1595, lr = 0.00755996
I0706 13:41:42.110467  1643 solver.cpp:243] Iteration 1650, loss = 5.32507
I0706 13:41:42.111070  1643 solver.cpp:259]     Train net output #0: loss = 5.32507 (* 1 = 5.32507 loss)
I0706 13:41:42.111088  1643 solver.cpp:590] Iteration 1650, lr = 0.00748739
I0706 13:41:45.756491  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:41:54.965054  1643 solver.cpp:243] Iteration 1705, loss = 4.79993
I0706 13:41:54.965085  1643 solver.cpp:259]     Train net output #0: loss = 4.79993 (* 1 = 4.79993 loss)
I0706 13:41:54.965097  1643 solver.cpp:590] Iteration 1705, lr = 0.00741552
I0706 13:42:01.370095  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:42:07.100368  1643 solver.cpp:243] Iteration 1760, loss = 4.98131
I0706 13:42:07.100396  1643 solver.cpp:259]     Train net output #0: loss = 4.98131 (* 1 = 4.98131 loss)
I0706 13:42:07.100404  1643 solver.cpp:590] Iteration 1760, lr = 0.00734434
I0706 13:42:07.651383  1643 solver.cpp:347] Iteration 1764, Testing net (#0)
I0706 13:42:18.405063  1660 blocking_queue.cpp:50] Waiting for data
I0706 13:42:34.974876  1643 solver.cpp:415]     Test net output #0: accuracy = 0.0621394
I0706 13:42:34.974903  1643 solver.cpp:415]     Test net output #1: loss = 5.22213 (* 1 = 5.22213 loss)
I0706 13:42:44.091188  1643 solver.cpp:243] Iteration 1815, loss = 4.86023
I0706 13:42:44.091217  1643 solver.cpp:259]     Train net output #0: loss = 4.86023 (* 1 = 4.86023 loss)
I0706 13:42:44.091224  1643 solver.cpp:590] Iteration 1815, lr = 0.00727384
I0706 13:42:49.273039  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:42:56.381528  1643 solver.cpp:243] Iteration 1870, loss = 5.25338
I0706 13:42:56.381556  1643 solver.cpp:259]     Train net output #0: loss = 5.25338 (* 1 = 5.25338 loss)
I0706 13:42:56.381563  1643 solver.cpp:590] Iteration 1870, lr = 0.00720402
I0706 13:43:08.253911  1643 solver.cpp:243] Iteration 1925, loss = 5.18816
I0706 13:43:08.253939  1643 solver.cpp:259]     Train net output #0: loss = 5.18816 (* 1 = 5.18816 loss)
I0706 13:43:08.253947  1643 solver.cpp:590] Iteration 1925, lr = 0.00713487
I0706 13:43:12.771432  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:43:19.976503  1643 solver.cpp:243] Iteration 1980, loss = 5.16267
I0706 13:43:19.976610  1643 solver.cpp:259]     Train net output #0: loss = 5.16267 (* 1 = 5.16267 loss)
I0706 13:43:19.976635  1643 solver.cpp:590] Iteration 1980, lr = 0.00706638
I0706 13:43:31.243518  1643 solver.cpp:243] Iteration 2035, loss = 5.18913
I0706 13:43:31.243558  1643 solver.cpp:259]     Train net output #0: loss = 5.18913 (* 1 = 5.18913 loss)
I0706 13:43:31.243576  1643 solver.cpp:590] Iteration 2035, lr = 0.00699855
I0706 13:43:32.015733  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:43:42.954401  1643 solver.cpp:243] Iteration 2090, loss = 5.26768
I0706 13:43:42.954455  1643 solver.cpp:259]     Train net output #0: loss = 5.26768 (* 1 = 5.26768 loss)
I0706 13:43:42.954465  1643 solver.cpp:590] Iteration 2090, lr = 0.00693137
I0706 13:43:49.692332  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:43:56.775272  1643 solver.cpp:243] Iteration 2145, loss = 4.87095
I0706 13:43:56.775357  1643 solver.cpp:259]     Train net output #0: loss = 4.87095 (* 1 = 4.87095 loss)
I0706 13:43:56.775382  1643 solver.cpp:590] Iteration 2145, lr = 0.00686483
I0706 13:44:07.202894  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:44:10.563258  1643 solver.cpp:243] Iteration 2200, loss = 4.67658
I0706 13:44:10.563292  1643 solver.cpp:259]     Train net output #0: loss = 4.67658 (* 1 = 4.67658 loss)
I0706 13:44:10.563300  1643 solver.cpp:590] Iteration 2200, lr = 0.00679894
I0706 13:44:11.947785  1643 solver.cpp:347] Iteration 2205, Testing net (#0)
I0706 13:44:23.524308  1660 blocking_queue.cpp:50] Waiting for data
I0706 13:44:40.278580  1643 solver.cpp:415]     Test net output #0: accuracy = 0.0742788
I0706 13:44:40.279160  1643 solver.cpp:415]     Test net output #1: loss = 5.1222 (* 1 = 5.1222 loss)
I0706 13:44:50.035390  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:44:51.391947  1643 solver.cpp:243] Iteration 2255, loss = 4.87085
I0706 13:44:51.391973  1643 solver.cpp:259]     Train net output #0: loss = 4.87085 (* 1 = 4.87085 loss)
I0706 13:44:51.391981  1643 solver.cpp:590] Iteration 2255, lr = 0.00673367
I0706 13:44:53.042032  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 13:45:05.537679  1643 solver.cpp:243] Iteration 2310, loss = 4.73369
I0706 13:45:05.537706  1643 solver.cpp:259]     Train net output #0: loss = 4.73369 (* 1 = 4.73369 loss)
I0706 13:45:05.537714  1643 solver.cpp:590] Iteration 2310, lr = 0.00666904
I0706 13:45:09.646785  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:45:18.681646  1643 solver.cpp:243] Iteration 2365, loss = 4.73863
I0706 13:45:18.682155  1643 solver.cpp:259]     Train net output #0: loss = 4.73863 (* 1 = 4.73863 loss)
I0706 13:45:18.682165  1643 solver.cpp:590] Iteration 2365, lr = 0.00660502
I0706 13:45:31.117916  1643 solver.cpp:243] Iteration 2420, loss = 4.54916
I0706 13:45:31.117987  1643 solver.cpp:259]     Train net output #0: loss = 4.54916 (* 1 = 4.54916 loss)
I0706 13:45:31.118002  1643 solver.cpp:590] Iteration 2420, lr = 0.00654162
I0706 13:45:35.565984  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:45:45.322676  1643 solver.cpp:243] Iteration 2475, loss = 4.46721
I0706 13:45:45.322703  1643 solver.cpp:259]     Train net output #0: loss = 4.46721 (* 1 = 4.46721 loss)
I0706 13:45:45.322711  1643 solver.cpp:590] Iteration 2475, lr = 0.00647882
I0706 13:45:56.506439  1643 solver.cpp:243] Iteration 2530, loss = 4.39162
I0706 13:45:56.506500  1643 solver.cpp:259]     Train net output #0: loss = 4.39162 (* 1 = 4.39162 loss)
I0706 13:45:56.506508  1643 solver.cpp:590] Iteration 2530, lr = 0.00641663
I0706 13:46:03.724500  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:46:08.552475  1643 solver.cpp:243] Iteration 2585, loss = 3.91998
I0706 13:46:08.552506  1643 solver.cpp:259]     Train net output #0: loss = 3.91998 (* 1 = 3.91998 loss)
I0706 13:46:08.552515  1643 solver.cpp:590] Iteration 2585, lr = 0.00635504
I0706 13:46:21.384861  1643 solver.cpp:243] Iteration 2640, loss = 4.398
I0706 13:46:21.384888  1643 solver.cpp:259]     Train net output #0: loss = 4.398 (* 1 = 4.398 loss)
I0706 13:46:21.384896  1643 solver.cpp:590] Iteration 2640, lr = 0.00629403
I0706 13:46:21.448374  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:46:22.282074  1643 solver.cpp:347] Iteration 2646, Testing net (#0)
I0706 13:46:49.787924  1643 solver.cpp:415]     Test net output #0: accuracy = 0.0875
I0706 13:46:49.788080  1643 solver.cpp:415]     Test net output #1: loss = 5.0463 (* 1 = 5.0463 loss)
I0706 13:46:51.820824  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:47:01.658754  1643 solver.cpp:243] Iteration 2695, loss = 4.23082
I0706 13:47:01.658783  1643 solver.cpp:259]     Train net output #0: loss = 4.23082 (* 1 = 4.23082 loss)
I0706 13:47:01.658795  1643 solver.cpp:590] Iteration 2695, lr = 0.00623362
I0706 13:47:09.786834  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:47:14.490100  1643 solver.cpp:243] Iteration 2750, loss = 4.49943
I0706 13:47:14.490128  1643 solver.cpp:259]     Train net output #0: loss = 4.49943 (* 1 = 4.49943 loss)
I0706 13:47:14.490135  1643 solver.cpp:590] Iteration 2750, lr = 0.00617378
I0706 13:47:26.240507  1643 solver.cpp:243] Iteration 2805, loss = 3.95323
I0706 13:47:26.241027  1643 solver.cpp:259]     Train net output #0: loss = 3.95323 (* 1 = 3.95323 loss)
I0706 13:47:26.241037  1643 solver.cpp:590] Iteration 2805, lr = 0.00611452
I0706 13:47:28.697149  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:47:39.427369  1643 solver.cpp:243] Iteration 2860, loss = 4.59406
I0706 13:47:39.427399  1643 solver.cpp:259]     Train net output #0: loss = 4.59406 (* 1 = 4.59406 loss)
I0706 13:47:39.427407  1643 solver.cpp:590] Iteration 2860, lr = 0.00605582
I0706 13:47:48.427420  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:47:54.081351  1643 solver.cpp:243] Iteration 2915, loss = 4.08127
I0706 13:47:54.081403  1643 solver.cpp:259]     Train net output #0: loss = 4.08127 (* 1 = 4.08127 loss)
I0706 13:47:54.081413  1643 solver.cpp:590] Iteration 2915, lr = 0.00599769
I0706 13:48:05.178792  1643 solver.cpp:243] Iteration 2970, loss = 4.00612
I0706 13:48:05.179432  1643 solver.cpp:259]     Train net output #0: loss = 4.00612 (* 1 = 4.00612 loss)
I0706 13:48:05.179446  1643 solver.cpp:590] Iteration 2970, lr = 0.00594012
I0706 13:48:05.772032  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:48:17.824218  1643 solver.cpp:243] Iteration 3025, loss = 4.10506
I0706 13:48:17.824245  1643 solver.cpp:259]     Train net output #0: loss = 4.10506 (* 1 = 4.10506 loss)
I0706 13:48:17.824254  1643 solver.cpp:590] Iteration 3025, lr = 0.0058831
I0706 13:48:24.538502  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:48:30.305131  1643 solver.cpp:243] Iteration 3080, loss = 4.58535
I0706 13:48:30.305157  1643 solver.cpp:259]     Train net output #0: loss = 4.58535 (* 1 = 4.58535 loss)
I0706 13:48:30.305166  1643 solver.cpp:590] Iteration 3080, lr = 0.00582663
I0706 13:48:33.062783  1643 solver.cpp:347] Iteration 3087, Testing net (#0)
I0706 13:48:35.208433  1660 blocking_queue.cpp:50] Waiting for data
I0706 13:48:42.926448  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 13:48:57.523624  1643 solver.cpp:415]     Test net output #0: accuracy = 0.0920673
I0706 13:48:57.523651  1643 solver.cpp:415]     Test net output #1: loss = 5.04968 (* 1 = 5.04968 loss)
I0706 13:49:08.922641  1643 solver.cpp:243] Iteration 3135, loss = 3.76123
I0706 13:49:08.923084  1643 solver.cpp:259]     Train net output #0: loss = 3.76123 (* 1 = 3.76123 loss)
I0706 13:49:08.923095  1643 solver.cpp:590] Iteration 3135, lr = 0.0057707
I0706 13:49:11.317260  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:49:24.520674  1643 solver.cpp:243] Iteration 3190, loss = 4.01672
I0706 13:49:24.520701  1643 solver.cpp:259]     Train net output #0: loss = 4.01672 (* 1 = 4.01672 loss)
I0706 13:49:24.520709  1643 solver.cpp:590] Iteration 3190, lr = 0.0057153
I0706 13:49:34.225396  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:49:36.038311  1643 solver.cpp:243] Iteration 3245, loss = 3.64808
I0706 13:49:36.038341  1643 solver.cpp:259]     Train net output #0: loss = 3.64808 (* 1 = 3.64808 loss)
I0706 13:49:36.038350  1643 solver.cpp:590] Iteration 3245, lr = 0.00566044
I0706 13:49:48.082535  1643 solver.cpp:243] Iteration 3300, loss = 3.98067
I0706 13:49:48.082959  1643 solver.cpp:259]     Train net output #0: loss = 3.98067 (* 1 = 3.98067 loss)
I0706 13:49:48.082970  1643 solver.cpp:590] Iteration 3300, lr = 0.00560611
I0706 13:49:59.641088  1643 solver.cpp:243] Iteration 3355, loss = 3.81345
I0706 13:49:59.641115  1643 solver.cpp:259]     Train net output #0: loss = 3.81345 (* 1 = 3.81345 loss)
I0706 13:49:59.641122  1643 solver.cpp:590] Iteration 3355, lr = 0.00555229
I0706 13:50:01.462667  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:50:10.862313  1643 solver.cpp:243] Iteration 3410, loss = 4.09021
I0706 13:50:10.862339  1643 solver.cpp:259]     Train net output #0: loss = 4.09021 (* 1 = 4.09021 loss)
I0706 13:50:10.862346  1643 solver.cpp:590] Iteration 3410, lr = 0.005499
I0706 13:50:23.033306  1643 solver.cpp:243] Iteration 3465, loss = 3.44053
I0706 13:50:23.034026  1643 solver.cpp:259]     Train net output #0: loss = 3.44053 (* 1 = 3.44053 loss)
I0706 13:50:23.034035  1643 solver.cpp:590] Iteration 3465, lr = 0.00544621
I0706 13:50:27.166503  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:50:34.054095  1643 solver.cpp:243] Iteration 3520, loss = 3.88576
I0706 13:50:34.054122  1643 solver.cpp:259]     Train net output #0: loss = 3.88576 (* 1 = 3.88576 loss)
I0706 13:50:34.054131  1643 solver.cpp:590] Iteration 3520, lr = 0.00539393
I0706 13:50:35.298758  1643 solver.cpp:347] Iteration 3528, Testing net (#0)
I0706 13:50:43.548269  1660 blocking_queue.cpp:50] Waiting for data
I0706 13:51:04.897137  1643 solver.cpp:415]     Test net output #0: accuracy = 0.0933894
I0706 13:51:04.897253  1643 solver.cpp:415]     Test net output #1: loss = 5.0912 (* 1 = 5.0912 loss)
I0706 13:51:12.807957  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:51:14.897651  1643 solver.cpp:243] Iteration 3575, loss = 3.59425
I0706 13:51:14.897678  1643 solver.cpp:259]     Train net output #0: loss = 3.59425 (* 1 = 3.59425 loss)
I0706 13:51:14.897686  1643 solver.cpp:590] Iteration 3575, lr = 0.00534216
I0706 13:51:24.690052  1643 solver.cpp:243] Iteration 3630, loss = 4.14521
I0706 13:51:24.690079  1643 solver.cpp:259]     Train net output #0: loss = 4.14521 (* 1 = 4.14521 loss)
I0706 13:51:24.690086  1643 solver.cpp:590] Iteration 3630, lr = 0.00529088
I0706 13:51:36.715868  1643 solver.cpp:243] Iteration 3685, loss = 3.38583
I0706 13:51:36.715958  1643 solver.cpp:259]     Train net output #0: loss = 3.38583 (* 1 = 3.38583 loss)
I0706 13:51:36.715966  1643 solver.cpp:590] Iteration 3685, lr = 0.00524009
I0706 13:51:45.913271  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:51:47.714573  1643 solver.cpp:243] Iteration 3740, loss = 3.68152
I0706 13:51:47.714612  1643 solver.cpp:259]     Train net output #0: loss = 3.68152 (* 1 = 3.68152 loss)
I0706 13:51:47.714625  1643 solver.cpp:590] Iteration 3740, lr = 0.00518979
I0706 13:51:59.599364  1643 solver.cpp:243] Iteration 3795, loss = 3.53532
I0706 13:51:59.599391  1643 solver.cpp:259]     Train net output #0: loss = 3.53532 (* 1 = 3.53532 loss)
I0706 13:51:59.599400  1643 solver.cpp:590] Iteration 3795, lr = 0.00513997
I0706 13:52:12.073048  1643 solver.cpp:243] Iteration 3850, loss = 3.80855
I0706 13:52:12.073146  1643 solver.cpp:259]     Train net output #0: loss = 3.80855 (* 1 = 3.80855 loss)
I0706 13:52:12.073153  1643 solver.cpp:590] Iteration 3850, lr = 0.00509063
I0706 13:52:13.519443  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:52:21.771525  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 13:52:24.330260  1643 solver.cpp:243] Iteration 3905, loss = 2.82824
I0706 13:52:24.330286  1643 solver.cpp:259]     Train net output #0: loss = 2.82824 (* 1 = 2.82824 loss)
I0706 13:52:24.330292  1643 solver.cpp:590] Iteration 3905, lr = 0.00504177
I0706 13:52:32.801741  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:52:35.583029  1643 solver.cpp:243] Iteration 3960, loss = 3.17749
I0706 13:52:35.583055  1643 solver.cpp:259]     Train net output #0: loss = 3.17749 (* 1 = 3.17749 loss)
I0706 13:52:35.583062  1643 solver.cpp:590] Iteration 3960, lr = 0.00499337
I0706 13:52:37.320864  1643 solver.cpp:347] Iteration 3969, Testing net (#0)
I0706 13:53:03.649492  1643 solver.cpp:415]     Test net output #0: accuracy = 0.104447
I0706 13:53:03.649617  1643 solver.cpp:415]     Test net output #1: loss = 5.01169 (* 1 = 5.01169 loss)
I0706 13:53:06.300207  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:53:13.508631  1643 solver.cpp:243] Iteration 4015, loss = 3.5231
I0706 13:53:13.508663  1643 solver.cpp:259]     Train net output #0: loss = 3.5231 (* 1 = 3.5231 loss)
I0706 13:53:13.508671  1643 solver.cpp:590] Iteration 4015, lr = 0.00494544
I0706 13:53:22.391880  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:53:25.146251  1643 solver.cpp:243] Iteration 4070, loss = 3.90308
I0706 13:53:25.146278  1643 solver.cpp:259]     Train net output #0: loss = 3.90308 (* 1 = 3.90308 loss)
I0706 13:53:25.146286  1643 solver.cpp:590] Iteration 4070, lr = 0.00489797
I0706 13:53:38.319378  1643 solver.cpp:243] Iteration 4125, loss = 3.80574
I0706 13:53:38.319818  1643 solver.cpp:259]     Train net output #0: loss = 3.80574 (* 1 = 3.80574 loss)
I0706 13:53:38.319836  1643 solver.cpp:590] Iteration 4125, lr = 0.00485095
I0706 13:53:48.184938  1643 solver.cpp:243] Iteration 4180, loss = 3.48826
I0706 13:53:48.184988  1643 solver.cpp:259]     Train net output #0: loss = 3.48826 (* 1 = 3.48826 loss)
I0706 13:53:48.185001  1643 solver.cpp:590] Iteration 4180, lr = 0.00480439
I0706 13:53:49.022207  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:53:59.481150  1643 solver.cpp:243] Iteration 4235, loss = 3.25028
I0706 13:53:59.481178  1643 solver.cpp:259]     Train net output #0: loss = 3.25028 (* 1 = 3.25028 loss)
I0706 13:53:59.481184  1643 solver.cpp:590] Iteration 4235, lr = 0.00475827
I0706 13:54:11.213529  1643 solver.cpp:243] Iteration 4290, loss = 3.04862
I0706 13:54:11.214190  1643 solver.cpp:259]     Train net output #0: loss = 3.04862 (* 1 = 3.04862 loss)
I0706 13:54:11.214203  1643 solver.cpp:590] Iteration 4290, lr = 0.00471259
I0706 13:54:18.336124  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:54:22.227581  1643 solver.cpp:243] Iteration 4345, loss = 2.98677
I0706 13:54:22.227608  1643 solver.cpp:259]     Train net output #0: loss = 2.98677 (* 1 = 2.98677 loss)
I0706 13:54:22.227617  1643 solver.cpp:590] Iteration 4345, lr = 0.00466736
I0706 13:54:32.716285  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:54:34.439683  1643 solver.cpp:243] Iteration 4400, loss = 3.2856
I0706 13:54:34.439721  1643 solver.cpp:259]     Train net output #0: loss = 3.2856 (* 1 = 3.2856 loss)
I0706 13:54:34.439733  1643 solver.cpp:590] Iteration 4400, lr = 0.00462255
I0706 13:54:36.342860  1643 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_4410.caffemodel
I0706 13:54:40.889523  1643 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_4410.solverstate
I0706 13:54:41.736703  1643 solver.cpp:347] Iteration 4410, Testing net (#0)
I0706 13:55:06.400748  1643 solver.cpp:415]     Test net output #0: accuracy = 0.101322
I0706 13:55:06.400771  1643 solver.cpp:415]     Test net output #1: loss = 5.17609 (* 1 = 5.17609 loss)
I0706 13:55:15.105568  1643 solver.cpp:243] Iteration 4455, loss = 2.79331
I0706 13:55:15.105772  1643 solver.cpp:259]     Train net output #0: loss = 2.79331 (* 1 = 2.79331 loss)
I0706 13:55:15.105790  1643 solver.cpp:590] Iteration 4455, lr = 0.00457818
I0706 13:55:15.375211  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:55:27.995731  1643 solver.cpp:243] Iteration 4510, loss = 2.40317
I0706 13:55:27.995759  1643 solver.cpp:259]     Train net output #0: loss = 2.40317 (* 1 = 2.40317 loss)
I0706 13:55:27.995767  1643 solver.cpp:590] Iteration 4510, lr = 0.00453423
I0706 13:55:39.232092  1643 solver.cpp:243] Iteration 4565, loss = 3.32764
I0706 13:55:39.232147  1643 solver.cpp:259]     Train net output #0: loss = 3.32764 (* 1 = 3.32764 loss)
I0706 13:55:39.232164  1643 solver.cpp:590] Iteration 4565, lr = 0.00449071
I0706 13:55:40.668350  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:55:51.106150  1643 solver.cpp:243] Iteration 4620, loss = 2.84456
I0706 13:55:51.106263  1643 solver.cpp:259]     Train net output #0: loss = 2.84456 (* 1 = 2.84456 loss)
I0706 13:55:51.106273  1643 solver.cpp:590] Iteration 4620, lr = 0.0044476
I0706 13:55:56.298780  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 13:56:02.958333  1643 solver.cpp:243] Iteration 4675, loss = 3.05295
I0706 13:56:02.958360  1643 solver.cpp:259]     Train net output #0: loss = 3.05295 (* 1 = 3.05295 loss)
I0706 13:56:02.958369  1643 solver.cpp:590] Iteration 4675, lr = 0.00440491
I0706 13:56:12.861510  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:56:14.282541  1643 solver.cpp:243] Iteration 4730, loss = 3.0839
I0706 13:56:14.282569  1643 solver.cpp:259]     Train net output #0: loss = 3.0839 (* 1 = 3.0839 loss)
I0706 13:56:14.282580  1643 solver.cpp:590] Iteration 4730, lr = 0.00436263
I0706 13:56:26.964388  1643 solver.cpp:243] Iteration 4785, loss = 2.63912
I0706 13:56:26.965005  1643 solver.cpp:259]     Train net output #0: loss = 2.63912 (* 1 = 2.63912 loss)
I0706 13:56:26.965023  1643 solver.cpp:590] Iteration 4785, lr = 0.00432075
I0706 13:56:33.182176  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:56:38.954048  1643 solver.cpp:243] Iteration 4840, loss = 2.78579
I0706 13:56:38.954077  1643 solver.cpp:259]     Train net output #0: loss = 2.78579 (* 1 = 2.78579 loss)
I0706 13:56:38.954085  1643 solver.cpp:590] Iteration 4840, lr = 0.00427927
I0706 13:56:42.323500  1643 solver.cpp:347] Iteration 4851, Testing net (#0)
I0706 13:57:01.985035  1660 blocking_queue.cpp:50] Waiting for data
I0706 13:57:08.249747  1643 solver.cpp:415]     Test net output #0: accuracy = 0.104928
I0706 13:57:08.249776  1643 solver.cpp:415]     Test net output #1: loss = 5.10087 (* 1 = 5.10087 loss)
I0706 13:57:17.046465  1643 solver.cpp:243] Iteration 4895, loss = 2.18965
I0706 13:57:17.046491  1643 solver.cpp:259]     Train net output #0: loss = 2.18965 (* 1 = 2.18965 loss)
I0706 13:57:17.046499  1643 solver.cpp:590] Iteration 4895, lr = 0.0042382
I0706 13:57:25.451113  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:57:29.642616  1643 solver.cpp:243] Iteration 4950, loss = 2.66433
I0706 13:57:29.642663  1643 solver.cpp:259]     Train net output #0: loss = 2.66433 (* 1 = 2.66433 loss)
I0706 13:57:29.642676  1643 solver.cpp:590] Iteration 4950, lr = 0.00419751
I0706 13:57:42.153015  1643 solver.cpp:243] Iteration 5005, loss = 2.97965
I0706 13:57:42.153108  1643 solver.cpp:259]     Train net output #0: loss = 2.97965 (* 1 = 2.97965 loss)
I0706 13:57:42.153115  1643 solver.cpp:590] Iteration 5005, lr = 0.00415722
I0706 13:57:53.322005  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:57:54.820596  1643 solver.cpp:243] Iteration 5060, loss = 2.12079
I0706 13:57:54.820619  1643 solver.cpp:259]     Train net output #0: loss = 2.12079 (* 1 = 2.12079 loss)
I0706 13:57:54.820626  1643 solver.cpp:590] Iteration 5060, lr = 0.00411732
I0706 13:58:07.901171  1643 solver.cpp:243] Iteration 5115, loss = 2.44089
I0706 13:58:07.901206  1643 solver.cpp:259]     Train net output #0: loss = 2.44089 (* 1 = 2.44089 loss)
I0706 13:58:07.901214  1643 solver.cpp:590] Iteration 5115, lr = 0.00407779
I0706 13:58:19.896216  1643 solver.cpp:243] Iteration 5170, loss = 2.20267
I0706 13:58:19.896335  1643 solver.cpp:259]     Train net output #0: loss = 2.20267 (* 1 = 2.20267 loss)
I0706 13:58:19.896349  1643 solver.cpp:590] Iteration 5170, lr = 0.00403865
I0706 13:58:21.167526  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:58:32.205374  1643 solver.cpp:243] Iteration 5225, loss = 2.12586
I0706 13:58:32.205402  1643 solver.cpp:259]     Train net output #0: loss = 2.12586 (* 1 = 2.12586 loss)
I0706 13:58:32.205410  1643 solver.cpp:590] Iteration 5225, lr = 0.00399988
I0706 13:58:44.686561  1643 solver.cpp:243] Iteration 5280, loss = 2.09439
I0706 13:58:44.686583  1643 solver.cpp:259]     Train net output #0: loss = 2.09439 (* 1 = 2.09439 loss)
I0706 13:58:44.686589  1643 solver.cpp:590] Iteration 5280, lr = 0.00396149
I0706 13:58:45.698092  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:58:47.188220  1643 solver.cpp:347] Iteration 5292, Testing net (#0)
I0706 13:59:09.157038  1660 blocking_queue.cpp:50] Waiting for data
I0706 13:59:15.138725  1643 solver.cpp:415]     Test net output #0: accuracy = 0.103365
I0706 13:59:15.138759  1643 solver.cpp:415]     Test net output #1: loss = 5.18263 (* 1 = 5.18263 loss)
I0706 13:59:24.551730  1643 solver.cpp:243] Iteration 5335, loss = 2.12904
I0706 13:59:24.551784  1643 solver.cpp:259]     Train net output #0: loss = 2.12904 (* 1 = 2.12904 loss)
I0706 13:59:24.551803  1643 solver.cpp:590] Iteration 5335, lr = 0.00392346
I0706 13:59:33.513723  1656 blocking_queue.cpp:50] Waiting for data
I0706 13:59:36.993989  1643 solver.cpp:243] Iteration 5390, loss = 2.87528
I0706 13:59:36.994016  1643 solver.cpp:259]     Train net output #0: loss = 2.87528 (* 1 = 2.87528 loss)
I0706 13:59:36.994024  1643 solver.cpp:590] Iteration 5390, lr = 0.0038858
I0706 13:59:38.804615  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 13:59:49.768599  1643 solver.cpp:243] Iteration 5445, loss = 2.04631
I0706 13:59:49.769083  1643 solver.cpp:259]     Train net output #0: loss = 2.04631 (* 1 = 2.04631 loss)
I0706 13:59:49.769093  1643 solver.cpp:590] Iteration 5445, lr = 0.0038485
I0706 14:00:01.631608  1643 solver.cpp:243] Iteration 5500, loss = 2.38656
I0706 14:00:01.631647  1643 solver.cpp:259]     Train net output #0: loss = 2.38656 (* 1 = 2.38656 loss)
I0706 14:00:01.631657  1643 solver.cpp:590] Iteration 5500, lr = 0.00381156
I0706 14:00:03.859299  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:00:16.202014  1643 solver.cpp:243] Iteration 5555, loss = 2.17222
I0706 14:00:16.202042  1643 solver.cpp:259]     Train net output #0: loss = 2.17222 (* 1 = 2.17222 loss)
I0706 14:00:16.202049  1643 solver.cpp:590] Iteration 5555, lr = 0.00377497
I0706 14:00:28.613579  1643 solver.cpp:243] Iteration 5610, loss = 2.21161
I0706 14:00:28.614229  1643 solver.cpp:259]     Train net output #0: loss = 2.21161 (* 1 = 2.21161 loss)
I0706 14:00:28.614248  1643 solver.cpp:590] Iteration 5610, lr = 0.00373873
I0706 14:00:28.980285  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:00:40.158426  1643 solver.cpp:243] Iteration 5665, loss = 2.18754
I0706 14:00:40.158452  1643 solver.cpp:259]     Train net output #0: loss = 2.18754 (* 1 = 2.18754 loss)
I0706 14:00:40.158458  1643 solver.cpp:590] Iteration 5665, lr = 0.00370284
I0706 14:00:52.825388  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:00:52.929497  1643 solver.cpp:243] Iteration 5720, loss = 2.13136
I0706 14:00:52.929522  1643 solver.cpp:259]     Train net output #0: loss = 2.13136 (* 1 = 2.13136 loss)
I0706 14:00:52.929528  1643 solver.cpp:590] Iteration 5720, lr = 0.0036673
I0706 14:00:55.674134  1643 solver.cpp:347] Iteration 5733, Testing net (#0)
I0706 14:01:18.423874  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:01:24.442986  1643 solver.cpp:415]     Test net output #0: accuracy = 0.103966
I0706 14:01:24.443012  1643 solver.cpp:415]     Test net output #1: loss = 5.30118 (* 1 = 5.30118 loss)
I0706 14:01:32.075727  1643 solver.cpp:243] Iteration 5775, loss = 2.12015
I0706 14:01:32.075773  1643 solver.cpp:259]     Train net output #0: loss = 2.12015 (* 1 = 2.12015 loss)
I0706 14:01:32.075783  1643 solver.cpp:590] Iteration 5775, lr = 0.0036321
I0706 14:01:43.377285  1643 solver.cpp:243] Iteration 5830, loss = 1.86631
I0706 14:01:43.377337  1643 solver.cpp:259]     Train net output #0: loss = 1.86631 (* 1 = 1.86631 loss)
I0706 14:01:43.377346  1643 solver.cpp:590] Iteration 5830, lr = 0.00359723
I0706 14:01:54.111057  1643 solver.cpp:243] Iteration 5885, loss = 1.82986
I0706 14:01:54.111430  1643 solver.cpp:259]     Train net output #0: loss = 1.82986 (* 1 = 1.82986 loss)
I0706 14:01:54.111444  1643 solver.cpp:590] Iteration 5885, lr = 0.0035627
I0706 14:02:05.537047  1643 solver.cpp:243] Iteration 5940, loss = 1.68642
I0706 14:02:05.537076  1643 solver.cpp:259]     Train net output #0: loss = 1.68642 (* 1 = 1.68642 loss)
I0706 14:02:05.537086  1643 solver.cpp:590] Iteration 5940, lr = 0.0035285
I0706 14:02:06.109149  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:02:18.559691  1643 solver.cpp:243] Iteration 5995, loss = 2.34164
I0706 14:02:18.559720  1643 solver.cpp:259]     Train net output #0: loss = 2.34164 (* 1 = 2.34164 loss)
I0706 14:02:18.559726  1643 solver.cpp:590] Iteration 5995, lr = 0.00349463
I0706 14:02:29.754319  1643 solver.cpp:243] Iteration 6050, loss = 2.48175
I0706 14:02:29.754401  1643 solver.cpp:259]     Train net output #0: loss = 2.48175 (* 1 = 2.48175 loss)
I0706 14:02:29.754410  1643 solver.cpp:590] Iteration 6050, lr = 0.00346109
I0706 14:02:38.971024  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:02:42.700733  1643 solver.cpp:243] Iteration 6105, loss = 2.10924
I0706 14:02:42.700762  1643 solver.cpp:259]     Train net output #0: loss = 2.10924 (* 1 = 2.10924 loss)
I0706 14:02:42.700770  1643 solver.cpp:590] Iteration 6105, lr = 0.00342786
I0706 14:02:54.233505  1643 solver.cpp:243] Iteration 6160, loss = 1.83984
I0706 14:02:54.233532  1643 solver.cpp:259]     Train net output #0: loss = 1.83984 (* 1 = 1.83984 loss)
I0706 14:02:54.233541  1643 solver.cpp:590] Iteration 6160, lr = 0.00339496
I0706 14:02:57.359284  1643 solver.cpp:347] Iteration 6174, Testing net (#0)
I0706 14:02:58.719707  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:03:21.709203  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 14:03:26.333742  1643 solver.cpp:415]     Test net output #0: accuracy = 0.100841
I0706 14:03:26.333770  1643 solver.cpp:415]     Test net output #1: loss = 5.49794 (* 1 = 5.49794 loss)
I0706 14:03:33.397953  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:03:34.477195  1643 solver.cpp:243] Iteration 6215, loss = 1.37474
I0706 14:03:34.477218  1643 solver.cpp:259]     Train net output #0: loss = 1.37474 (* 1 = 1.37474 loss)
I0706 14:03:34.477226  1643 solver.cpp:590] Iteration 6215, lr = 0.00336237
I0706 14:03:47.206557  1643 solver.cpp:243] Iteration 6270, loss = 1.53657
I0706 14:03:47.206584  1643 solver.cpp:259]     Train net output #0: loss = 1.53657 (* 1 = 1.53657 loss)
I0706 14:03:47.206593  1643 solver.cpp:590] Iteration 6270, lr = 0.0033301
I0706 14:03:49.728606  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:03:58.610368  1643 solver.cpp:243] Iteration 6325, loss = 1.43383
I0706 14:03:58.610780  1643 solver.cpp:259]     Train net output #0: loss = 1.43383 (* 1 = 1.43383 loss)
I0706 14:03:58.610803  1643 solver.cpp:590] Iteration 6325, lr = 0.00329813
I0706 14:04:10.067123  1643 solver.cpp:243] Iteration 6380, loss = 1.4243
I0706 14:04:10.067152  1643 solver.cpp:259]     Train net output #0: loss = 1.4243 (* 1 = 1.4243 loss)
I0706 14:04:10.067160  1643 solver.cpp:590] Iteration 6380, lr = 0.00326647
I0706 14:04:22.258787  1643 solver.cpp:243] Iteration 6435, loss = 1.40506
I0706 14:04:22.258816  1643 solver.cpp:259]     Train net output #0: loss = 1.40506 (* 1 = 1.40506 loss)
I0706 14:04:22.258822  1643 solver.cpp:590] Iteration 6435, lr = 0.00323512
I0706 14:04:24.702343  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:04:34.921376  1643 solver.cpp:243] Iteration 6490, loss = 1.24192
I0706 14:04:34.921525  1643 solver.cpp:259]     Train net output #0: loss = 1.24192 (* 1 = 1.24192 loss)
I0706 14:04:34.921535  1643 solver.cpp:590] Iteration 6490, lr = 0.00320406
I0706 14:04:47.351784  1643 solver.cpp:243] Iteration 6545, loss = 1.11895
I0706 14:04:47.351814  1643 solver.cpp:259]     Train net output #0: loss = 1.11895 (* 1 = 1.11895 loss)
I0706 14:04:47.351821  1643 solver.cpp:590] Iteration 6545, lr = 0.00317331
I0706 14:04:51.832206  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:04:59.270844  1643 solver.cpp:243] Iteration 6600, loss = 0.994309
I0706 14:04:59.270876  1643 solver.cpp:259]     Train net output #0: loss = 0.994309 (* 1 = 0.994309 loss)
I0706 14:04:59.270895  1643 solver.cpp:590] Iteration 6600, lr = 0.00314284
I0706 14:05:02.007851  1643 solver.cpp:347] Iteration 6615, Testing net (#0)
I0706 14:05:08.745240  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:05:29.153101  1643 solver.cpp:415]     Test net output #0: accuracy = 0.113341
I0706 14:05:29.153129  1643 solver.cpp:415]     Test net output #1: loss = 5.5697 (* 1 = 5.5697 loss)
I0706 14:05:37.354073  1643 solver.cpp:243] Iteration 6655, loss = 1.29875
I0706 14:05:37.354099  1643 solver.cpp:259]     Train net output #0: loss = 1.29875 (* 1 = 1.29875 loss)
I0706 14:05:37.354107  1643 solver.cpp:590] Iteration 6655, lr = 0.00311268
I0706 14:05:37.761956  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:05:48.999590  1643 solver.cpp:243] Iteration 6710, loss = 1.42253
I0706 14:05:48.999845  1643 solver.cpp:259]     Train net output #0: loss = 1.42253 (* 1 = 1.42253 loss)
I0706 14:05:48.999863  1643 solver.cpp:590] Iteration 6710, lr = 0.0030828
I0706 14:05:55.874986  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:06:00.940421  1643 solver.cpp:243] Iteration 6765, loss = 1.33038
I0706 14:06:00.940448  1643 solver.cpp:259]     Train net output #0: loss = 1.33038 (* 1 = 1.33038 loss)
I0706 14:06:00.940455  1643 solver.cpp:590] Iteration 6765, lr = 0.00305321
I0706 14:06:12.037852  1643 solver.cpp:243] Iteration 6820, loss = 1.0639
I0706 14:06:12.037878  1643 solver.cpp:259]     Train net output #0: loss = 1.0639 (* 1 = 1.0639 loss)
I0706 14:06:12.037886  1643 solver.cpp:590] Iteration 6820, lr = 0.0030239
I0706 14:06:21.754868  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:06:24.671968  1643 solver.cpp:243] Iteration 6875, loss = 1.63822
I0706 14:06:24.672013  1643 solver.cpp:259]     Train net output #0: loss = 1.63822 (* 1 = 1.63822 loss)
I0706 14:06:24.672024  1643 solver.cpp:590] Iteration 6875, lr = 0.00299487
I0706 14:06:36.477080  1643 solver.cpp:243] Iteration 6930, loss = 1.5278
I0706 14:06:36.477109  1643 solver.cpp:259]     Train net output #0: loss = 1.5278 (* 1 = 1.5278 loss)
I0706 14:06:36.477118  1643 solver.cpp:590] Iteration 6930, lr = 0.00296612
I0706 14:06:48.993787  1643 solver.cpp:243] Iteration 6985, loss = 1.22067
I0706 14:06:48.993811  1643 solver.cpp:259]     Train net output #0: loss = 1.22067 (* 1 = 1.22067 loss)
I0706 14:06:48.993819  1643 solver.cpp:590] Iteration 6985, lr = 0.00293765
I0706 14:06:52.089678  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:06:58.512336  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 14:07:00.635803  1643 solver.cpp:243] Iteration 7040, loss = 1.29406
I0706 14:07:00.635829  1643 solver.cpp:259]     Train net output #0: loss = 1.29406 (* 1 = 1.29406 loss)
I0706 14:07:00.635836  1643 solver.cpp:590] Iteration 7040, lr = 0.00290945
I0706 14:07:03.564616  1643 solver.cpp:347] Iteration 7056, Testing net (#0)
I0706 14:07:03.653951  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:07:31.031080  1643 solver.cpp:415]     Test net output #0: accuracy = 0.109255
I0706 14:07:31.031162  1643 solver.cpp:415]     Test net output #1: loss = 5.60872 (* 1 = 5.60872 loss)
I0706 14:07:35.499641  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:07:38.176947  1643 solver.cpp:243] Iteration 7095, loss = 0.952023
I0706 14:07:38.176970  1643 solver.cpp:259]     Train net output #0: loss = 0.952023 (* 1 = 0.952023 loss)
I0706 14:07:38.176976  1643 solver.cpp:590] Iteration 7095, lr = 0.00288152
I0706 14:07:51.960983  1643 solver.cpp:243] Iteration 7150, loss = 0.983305
I0706 14:07:51.961036  1643 solver.cpp:259]     Train net output #0: loss = 0.983305 (* 1 = 0.983305 loss)
I0706 14:07:51.961046  1643 solver.cpp:590] Iteration 7150, lr = 0.00285386
I0706 14:07:58.828104  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:08:04.450582  1643 solver.cpp:243] Iteration 7205, loss = 0.956501
I0706 14:08:04.450701  1643 solver.cpp:259]     Train net output #0: loss = 0.9565 (* 1 = 0.9565 loss)
I0706 14:08:04.450722  1643 solver.cpp:590] Iteration 7205, lr = 0.00282647
I0706 14:08:16.716259  1643 solver.cpp:243] Iteration 7260, loss = 1.17224
I0706 14:08:16.716289  1643 solver.cpp:259]     Train net output #0: loss = 1.17224 (* 1 = 1.17224 loss)
I0706 14:08:16.716301  1643 solver.cpp:590] Iteration 7260, lr = 0.00279934
I0706 14:08:29.322778  1643 solver.cpp:243] Iteration 7315, loss = 1.3491
I0706 14:08:29.322823  1643 solver.cpp:259]     Train net output #0: loss = 1.3491 (* 1 = 1.3491 loss)
I0706 14:08:29.322836  1643 solver.cpp:590] Iteration 7315, lr = 0.00277247
I0706 14:08:32.338838  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:08:42.368033  1643 solver.cpp:243] Iteration 7370, loss = 0.932965
I0706 14:08:42.368134  1643 solver.cpp:259]     Train net output #0: loss = 0.932965 (* 1 = 0.932965 loss)
I0706 14:08:42.368144  1643 solver.cpp:590] Iteration 7370, lr = 0.00274585
I0706 14:08:53.266774  1643 solver.cpp:243] Iteration 7425, loss = 0.755758
I0706 14:08:53.266803  1643 solver.cpp:259]     Train net output #0: loss = 0.755758 (* 1 = 0.755758 loss)
I0706 14:08:53.266810  1643 solver.cpp:590] Iteration 7425, lr = 0.00271949
I0706 14:08:59.396044  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:09:06.324753  1643 solver.cpp:243] Iteration 7480, loss = 0.721622
I0706 14:09:06.324779  1643 solver.cpp:259]     Train net output #0: loss = 0.721622 (* 1 = 0.721622 loss)
I0706 14:09:06.324785  1643 solver.cpp:590] Iteration 7480, lr = 0.00269339
I0706 14:09:09.541149  1643 solver.cpp:347] Iteration 7497, Testing net (#0)
I0706 14:09:11.989856  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:09:37.286614  1643 solver.cpp:415]     Test net output #0: accuracy = 0.103365
I0706 14:09:37.287221  1643 solver.cpp:415]     Test net output #1: loss = 5.63577 (* 1 = 5.63577 loss)
I0706 14:09:44.264155  1643 solver.cpp:243] Iteration 7535, loss = 0.70485
I0706 14:09:44.264186  1643 solver.cpp:259]     Train net output #0: loss = 0.704849 (* 1 = 0.704849 loss)
I0706 14:09:44.264196  1643 solver.cpp:590] Iteration 7535, lr = 0.00266754
I0706 14:09:55.576390  1643 solver.cpp:243] Iteration 7590, loss = 0.60132
I0706 14:09:55.576416  1643 solver.cpp:259]     Train net output #0: loss = 0.601319 (* 1 = 0.601319 loss)
I0706 14:09:55.576422  1643 solver.cpp:590] Iteration 7590, lr = 0.00264193
I0706 14:09:56.147433  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:10:08.082783  1643 solver.cpp:243] Iteration 7645, loss = 1.07999
I0706 14:10:08.082888  1643 solver.cpp:259]     Train net output #0: loss = 1.07999 (* 1 = 1.07999 loss)
I0706 14:10:08.082897  1643 solver.cpp:590] Iteration 7645, lr = 0.00261657
I0706 14:10:21.193123  1643 solver.cpp:243] Iteration 7700, loss = 0.730537
I0706 14:10:21.193168  1643 solver.cpp:259]     Train net output #0: loss = 0.730536 (* 1 = 0.730536 loss)
I0706 14:10:21.193174  1643 solver.cpp:590] Iteration 7700, lr = 0.00259145
I0706 14:10:25.213274  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:10:33.139456  1643 solver.cpp:243] Iteration 7755, loss = 0.867338
I0706 14:10:33.139515  1643 solver.cpp:259]     Train net output #0: loss = 0.867338 (* 1 = 0.867338 loss)
I0706 14:10:33.139536  1643 solver.cpp:590] Iteration 7755, lr = 0.00256658
I0706 14:10:39.941110  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 14:10:45.196049  1643 solver.cpp:243] Iteration 7810, loss = 0.90683
I0706 14:10:45.196074  1643 solver.cpp:259]     Train net output #0: loss = 0.90683 (* 1 = 0.90683 loss)
I0706 14:10:45.196080  1643 solver.cpp:590] Iteration 7810, lr = 0.00254194
I0706 14:10:56.043864  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:10:58.711957  1643 solver.cpp:243] Iteration 7865, loss = 0.945555
I0706 14:10:58.711987  1643 solver.cpp:259]     Train net output #0: loss = 0.945555 (* 1 = 0.945555 loss)
I0706 14:10:58.711994  1643 solver.cpp:590] Iteration 7865, lr = 0.00251754
I0706 14:11:10.801116  1643 solver.cpp:243] Iteration 7920, loss = 0.965153
I0706 14:11:10.801614  1643 solver.cpp:259]     Train net output #0: loss = 0.965153 (* 1 = 0.965153 loss)
I0706 14:11:10.801623  1643 solver.cpp:590] Iteration 7920, lr = 0.00249337
I0706 14:11:14.037355  1643 solver.cpp:347] Iteration 7938, Testing net (#0)
I0706 14:11:15.821835  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:11:40.020972  1643 solver.cpp:415]     Test net output #0: accuracy = 0.109135
I0706 14:11:40.021000  1643 solver.cpp:415]     Test net output #1: loss = 5.76599 (* 1 = 5.76599 loss)
I0706 14:11:46.532328  1643 solver.cpp:243] Iteration 7975, loss = 0.660994
I0706 14:11:46.532629  1643 solver.cpp:259]     Train net output #0: loss = 0.660994 (* 1 = 0.660994 loss)
I0706 14:11:46.532649  1643 solver.cpp:590] Iteration 7975, lr = 0.00246944
I0706 14:11:52.482018  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:11:59.773949  1643 solver.cpp:243] Iteration 8030, loss = 0.650668
I0706 14:11:59.773993  1643 solver.cpp:259]     Train net output #0: loss = 0.650668 (* 1 = 0.650668 loss)
I0706 14:11:59.774004  1643 solver.cpp:590] Iteration 8030, lr = 0.00244574
I0706 14:12:10.260701  1643 solver.cpp:243] Iteration 8085, loss = 1.01148
I0706 14:12:10.260726  1643 solver.cpp:259]     Train net output #0: loss = 1.01148 (* 1 = 1.01148 loss)
I0706 14:12:10.260733  1643 solver.cpp:590] Iteration 8085, lr = 0.00242226
I0706 14:12:21.404733  1643 solver.cpp:243] Iteration 8140, loss = 0.627807
I0706 14:12:21.405369  1643 solver.cpp:259]     Train net output #0: loss = 0.627807 (* 1 = 0.627807 loss)
I0706 14:12:21.405385  1643 solver.cpp:590] Iteration 8140, lr = 0.00239901
I0706 14:12:24.525907  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:12:32.984611  1643 solver.cpp:243] Iteration 8195, loss = 1.28481
I0706 14:12:32.984634  1643 solver.cpp:259]     Train net output #0: loss = 1.28481 (* 1 = 1.28481 loss)
I0706 14:12:32.984642  1643 solver.cpp:590] Iteration 8195, lr = 0.00237598
I0706 14:12:43.880079  1643 solver.cpp:243] Iteration 8250, loss = 0.735375
I0706 14:12:43.880123  1643 solver.cpp:259]     Train net output #0: loss = 0.735375 (* 1 = 0.735375 loss)
I0706 14:12:43.880136  1643 solver.cpp:590] Iteration 8250, lr = 0.00235317
I0706 14:12:53.661599  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:12:56.114193  1643 solver.cpp:243] Iteration 8305, loss = 0.635777
I0706 14:12:56.114222  1643 solver.cpp:259]     Train net output #0: loss = 0.635777 (* 1 = 0.635777 loss)
I0706 14:12:56.114228  1643 solver.cpp:590] Iteration 8305, lr = 0.00233058
I0706 14:13:07.785804  1643 solver.cpp:243] Iteration 8360, loss = 0.379409
I0706 14:13:07.785831  1643 solver.cpp:259]     Train net output #0: loss = 0.379409 (* 1 = 0.379409 loss)
I0706 14:13:07.785840  1643 solver.cpp:590] Iteration 8360, lr = 0.00230821
I0706 14:13:11.147755  1643 solver.cpp:347] Iteration 8379, Testing net (#0)
I0706 14:13:12.523926  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:13:37.954280  1643 solver.cpp:415]     Test net output #0: accuracy = 0.117188
I0706 14:13:37.954700  1643 solver.cpp:415]     Test net output #1: loss = 5.84224 (* 1 = 5.84224 loss)
I0706 14:13:44.199738  1643 solver.cpp:243] Iteration 8415, loss = 0.772412
I0706 14:13:44.199760  1643 solver.cpp:259]     Train net output #0: loss = 0.772412 (* 1 = 0.772412 loss)
I0706 14:13:44.199767  1643 solver.cpp:590] Iteration 8415, lr = 0.00228606
I0706 14:13:52.609977  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:13:56.635422  1643 solver.cpp:243] Iteration 8470, loss = 1.1949
I0706 14:13:56.635452  1643 solver.cpp:259]     Train net output #0: loss = 1.1949 (* 1 = 1.1949 loss)
I0706 14:13:56.635462  1643 solver.cpp:590] Iteration 8470, lr = 0.00226411
I0706 14:14:07.184932  1643 solver.cpp:243] Iteration 8525, loss = 0.58541
I0706 14:14:07.184989  1643 solver.cpp:259]     Train net output #0: loss = 0.58541 (* 1 = 0.58541 loss)
I0706 14:14:07.185014  1643 solver.cpp:590] Iteration 8525, lr = 0.00224238
I0706 14:14:10.017776  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 14:14:19.258994  1643 solver.cpp:243] Iteration 8580, loss = 0.646601
I0706 14:14:19.259021  1643 solver.cpp:259]     Train net output #0: loss = 0.646601 (* 1 = 0.646601 loss)
I0706 14:14:19.259028  1643 solver.cpp:590] Iteration 8580, lr = 0.00222085
I0706 14:14:27.953572  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:14:29.943267  1643 solver.cpp:243] Iteration 8635, loss = 0.747303
I0706 14:14:29.943300  1643 solver.cpp:259]     Train net output #0: loss = 0.747303 (* 1 = 0.747303 loss)
I0706 14:14:29.943306  1643 solver.cpp:590] Iteration 8635, lr = 0.00219953
I0706 14:14:44.730877  1643 solver.cpp:243] Iteration 8690, loss = 0.346388
I0706 14:14:44.739512  1643 solver.cpp:259]     Train net output #0: loss = 0.346388 (* 1 = 0.346388 loss)
I0706 14:14:44.739521  1643 solver.cpp:590] Iteration 8690, lr = 0.00217842
I0706 14:14:54.459470  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:14:57.112465  1643 solver.cpp:243] Iteration 8745, loss = 0.465658
I0706 14:14:57.112514  1643 solver.cpp:259]     Train net output #0: loss = 0.465658 (* 1 = 0.465658 loss)
I0706 14:14:57.112522  1643 solver.cpp:590] Iteration 8745, lr = 0.00215751
I0706 14:15:08.575194  1643 solver.cpp:243] Iteration 8800, loss = 0.492019
I0706 14:15:08.575224  1643 solver.cpp:259]     Train net output #0: loss = 0.492018 (* 1 = 0.492018 loss)
I0706 14:15:08.575234  1643 solver.cpp:590] Iteration 8800, lr = 0.0021368
I0706 14:15:11.801344  1643 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_8820.caffemodel
I0706 14:15:15.120671  1643 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_8820.solverstate
I0706 14:15:15.978577  1643 solver.cpp:347] Iteration 8820, Testing net (#0)
I0706 14:15:37.268267  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:15:44.472093  1643 solver.cpp:415]     Test net output #0: accuracy = 0.114423
I0706 14:15:44.472121  1643 solver.cpp:415]     Test net output #1: loss = 5.81997 (* 1 = 5.81997 loss)
I0706 14:15:50.580215  1643 solver.cpp:243] Iteration 8855, loss = 0.421579
I0706 14:15:50.580694  1643 solver.cpp:259]     Train net output #0: loss = 0.421579 (* 1 = 0.421579 loss)
I0706 14:15:50.580703  1643 solver.cpp:590] Iteration 8855, lr = 0.00211629
I0706 14:16:02.729306  1643 solver.cpp:243] Iteration 8910, loss = 0.628842
I0706 14:16:02.729334  1643 solver.cpp:259]     Train net output #0: loss = 0.628842 (* 1 = 0.628842 loss)
I0706 14:16:02.729341  1643 solver.cpp:590] Iteration 8910, lr = 0.00209597
I0706 14:16:13.981842  1643 solver.cpp:243] Iteration 8965, loss = 0.745319
I0706 14:16:13.981868  1643 solver.cpp:259]     Train net output #0: loss = 0.745319 (* 1 = 0.745319 loss)
I0706 14:16:13.981874  1643 solver.cpp:590] Iteration 8965, lr = 0.00207585
I0706 14:16:24.890266  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:16:26.094954  1643 solver.cpp:243] Iteration 9020, loss = 0.663904
I0706 14:16:26.094981  1643 solver.cpp:259]     Train net output #0: loss = 0.663904 (* 1 = 0.663904 loss)
I0706 14:16:26.094990  1643 solver.cpp:590] Iteration 9020, lr = 0.00205593
I0706 14:16:38.161236  1643 solver.cpp:243] Iteration 9075, loss = 0.21952
I0706 14:16:38.161267  1643 solver.cpp:259]     Train net output #0: loss = 0.21952 (* 1 = 0.21952 loss)
I0706 14:16:38.161274  1643 solver.cpp:590] Iteration 9075, lr = 0.00203619
I0706 14:16:48.606873  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:16:50.572319  1643 solver.cpp:243] Iteration 9130, loss = 0.569201
I0706 14:16:50.572345  1643 solver.cpp:259]     Train net output #0: loss = 0.569201 (* 1 = 0.569201 loss)
I0706 14:16:50.572352  1643 solver.cpp:590] Iteration 9130, lr = 0.00201665
I0706 14:17:02.942013  1643 solver.cpp:243] Iteration 9185, loss = 0.174304
I0706 14:17:02.942101  1643 solver.cpp:259]     Train net output #0: loss = 0.174304 (* 1 = 0.174304 loss)
I0706 14:17:02.942109  1643 solver.cpp:590] Iteration 9185, lr = 0.00199729
I0706 14:17:11.051025  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:17:13.865677  1643 solver.cpp:243] Iteration 9240, loss = 0.463406
I0706 14:17:13.865703  1643 solver.cpp:259]     Train net output #0: loss = 0.463405 (* 1 = 0.463405 loss)
I0706 14:17:13.865710  1643 solver.cpp:590] Iteration 9240, lr = 0.00197812
I0706 14:17:18.647588  1643 solver.cpp:347] Iteration 9261, Testing net (#0)
I0706 14:17:43.802232  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:17:46.710590  1643 solver.cpp:415]     Test net output #0: accuracy = 0.117428
I0706 14:17:46.710628  1643 solver.cpp:415]     Test net output #1: loss = 5.95803 (* 1 = 5.95803 loss)
I0706 14:17:51.730221  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 14:17:52.589424  1643 solver.cpp:243] Iteration 9295, loss = 0.393806
I0706 14:17:52.589449  1643 solver.cpp:259]     Train net output #0: loss = 0.393806 (* 1 = 0.393806 loss)
I0706 14:17:52.589457  1643 solver.cpp:590] Iteration 9295, lr = 0.00195913
I0706 14:18:04.200214  1643 solver.cpp:243] Iteration 9350, loss = 0.464479
I0706 14:18:04.200242  1643 solver.cpp:259]     Train net output #0: loss = 0.464479 (* 1 = 0.464479 loss)
I0706 14:18:04.200248  1643 solver.cpp:590] Iteration 9350, lr = 0.00194032
I0706 14:18:16.276427  1643 solver.cpp:243] Iteration 9405, loss = 0.374656
I0706 14:18:16.276721  1643 solver.cpp:259]     Train net output #0: loss = 0.374656 (* 1 = 0.374656 loss)
I0706 14:18:16.276731  1643 solver.cpp:590] Iteration 9405, lr = 0.0019217
I0706 14:18:16.336886  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:18:26.640594  1643 solver.cpp:243] Iteration 9460, loss = 0.41175
I0706 14:18:26.640621  1643 solver.cpp:259]     Train net output #0: loss = 0.411749 (* 1 = 0.411749 loss)
I0706 14:18:26.640630  1643 solver.cpp:590] Iteration 9460, lr = 0.00190325
I0706 14:18:38.253101  1643 solver.cpp:243] Iteration 9515, loss = 0.259855
I0706 14:18:38.253157  1643 solver.cpp:259]     Train net output #0: loss = 0.259855 (* 1 = 0.259855 loss)
I0706 14:18:38.253170  1643 solver.cpp:590] Iteration 9515, lr = 0.00188498
I0706 14:18:44.878383  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:18:50.590965  1643 solver.cpp:243] Iteration 9570, loss = 0.375293
I0706 14:18:50.591689  1643 solver.cpp:259]     Train net output #0: loss = 0.375293 (* 1 = 0.375293 loss)
I0706 14:18:50.591699  1643 solver.cpp:590] Iteration 9570, lr = 0.00186689
I0706 14:19:03.173805  1643 solver.cpp:243] Iteration 9625, loss = 0.422086
I0706 14:19:03.173832  1643 solver.cpp:259]     Train net output #0: loss = 0.422086 (* 1 = 0.422086 loss)
I0706 14:19:03.173840  1643 solver.cpp:590] Iteration 9625, lr = 0.00184897
I0706 14:19:13.065055  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:19:15.836509  1643 solver.cpp:243] Iteration 9680, loss = 0.327611
I0706 14:19:15.836539  1643 solver.cpp:259]     Train net output #0: loss = 0.32761 (* 1 = 0.32761 loss)
I0706 14:19:15.836546  1643 solver.cpp:590] Iteration 9680, lr = 0.00183122
I0706 14:19:20.754199  1643 solver.cpp:347] Iteration 9702, Testing net (#0)
I0706 14:19:37.731223  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:19:48.370666  1643 solver.cpp:415]     Test net output #0: accuracy = 0.122716
I0706 14:19:48.370693  1643 solver.cpp:415]     Test net output #1: loss = 6.00764 (* 1 = 6.00764 loss)
I0706 14:19:55.487578  1643 solver.cpp:243] Iteration 9735, loss = 0.260934
I0706 14:19:55.488168  1643 solver.cpp:259]     Train net output #0: loss = 0.260934 (* 1 = 0.260934 loss)
I0706 14:19:55.488184  1643 solver.cpp:590] Iteration 9735, lr = 0.00181364
I0706 14:20:06.461606  1643 solver.cpp:243] Iteration 9790, loss = 0.257135
I0706 14:20:06.461650  1643 solver.cpp:259]     Train net output #0: loss = 0.257135 (* 1 = 0.257135 loss)
I0706 14:20:06.461658  1643 solver.cpp:590] Iteration 9790, lr = 0.00179623
I0706 14:20:16.672653  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:20:17.119976  1643 solver.cpp:243] Iteration 9845, loss = 0.42639
I0706 14:20:17.120003  1643 solver.cpp:259]     Train net output #0: loss = 0.42639 (* 1 = 0.42639 loss)
I0706 14:20:17.120012  1643 solver.cpp:590] Iteration 9845, lr = 0.00177899
I0706 14:20:28.706214  1643 solver.cpp:243] Iteration 9900, loss = 0.225134
I0706 14:20:28.706696  1643 solver.cpp:259]     Train net output #0: loss = 0.225134 (* 1 = 0.225134 loss)
I0706 14:20:28.706712  1643 solver.cpp:590] Iteration 9900, lr = 0.00176191
I0706 14:20:40.962103  1643 solver.cpp:243] Iteration 9955, loss = 0.321022
I0706 14:20:40.962138  1643 solver.cpp:259]     Train net output #0: loss = 0.321021 (* 1 = 0.321021 loss)
I0706 14:20:40.962146  1643 solver.cpp:590] Iteration 9955, lr = 0.001745
I0706 14:20:49.289335  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:20:53.393595  1643 solver.cpp:243] Iteration 10010, loss = 0.225501
I0706 14:20:53.393622  1643 solver.cpp:259]     Train net output #0: loss = 0.225501 (* 1 = 0.225501 loss)
I0706 14:20:53.393628  1643 solver.cpp:590] Iteration 10010, lr = 0.00172825
I0706 14:21:04.681203  1643 solver.cpp:243] Iteration 10065, loss = 0.268129
I0706 14:21:04.681690  1643 solver.cpp:259]     Train net output #0: loss = 0.268128 (* 1 = 0.268128 loss)
I0706 14:21:04.681699  1643 solver.cpp:590] Iteration 10065, lr = 0.00171166
I0706 14:21:13.555304  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:21:16.292948  1643 solver.cpp:243] Iteration 10120, loss = 0.235583
I0706 14:21:16.292975  1643 solver.cpp:259]     Train net output #0: loss = 0.235583 (* 1 = 0.235583 loss)
I0706 14:21:16.292984  1643 solver.cpp:590] Iteration 10120, lr = 0.00169523
I0706 14:21:20.687897  1643 solver.cpp:347] Iteration 10143, Testing net (#0)
I0706 14:21:26.911880  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 14:21:45.603483  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:21:47.191823  1643 solver.cpp:415]     Test net output #0: accuracy = 0.121995
I0706 14:21:47.191850  1643 solver.cpp:415]     Test net output #1: loss = 6.04027 (* 1 = 6.04027 loss)
I0706 14:21:52.775511  1643 solver.cpp:243] Iteration 10175, loss = 0.267033
I0706 14:21:52.775539  1643 solver.cpp:259]     Train net output #0: loss = 0.267033 (* 1 = 0.267033 loss)
I0706 14:21:52.775547  1643 solver.cpp:590] Iteration 10175, lr = 0.00167896
I0706 14:22:05.986865  1643 solver.cpp:243] Iteration 10230, loss = 0.37902
I0706 14:22:05.986893  1643 solver.cpp:259]     Train net output #0: loss = 0.379019 (* 1 = 0.379019 loss)
I0706 14:22:05.986901  1643 solver.cpp:590] Iteration 10230, lr = 0.00166284
I0706 14:22:07.164968  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:22:18.325947  1643 solver.cpp:243] Iteration 10285, loss = 0.463635
I0706 14:22:18.326064  1643 solver.cpp:259]     Train net output #0: loss = 0.463634 (* 1 = 0.463634 loss)
I0706 14:22:18.326073  1643 solver.cpp:590] Iteration 10285, lr = 0.00164688
I0706 14:22:29.250972  1643 solver.cpp:243] Iteration 10340, loss = 0.160538
I0706 14:22:29.250999  1643 solver.cpp:259]     Train net output #0: loss = 0.160538 (* 1 = 0.160538 loss)
I0706 14:22:29.251008  1643 solver.cpp:590] Iteration 10340, lr = 0.00163107
I0706 14:22:38.672780  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:22:40.790381  1643 solver.cpp:243] Iteration 10395, loss = 0.0881883
I0706 14:22:40.790407  1643 solver.cpp:259]     Train net output #0: loss = 0.0881879 (* 1 = 0.0881879 loss)
I0706 14:22:40.790416  1643 solver.cpp:590] Iteration 10395, lr = 0.00161541
I0706 14:22:52.743741  1643 solver.cpp:243] Iteration 10450, loss = 0.168406
I0706 14:22:52.744407  1643 solver.cpp:259]     Train net output #0: loss = 0.168406 (* 1 = 0.168406 loss)
I0706 14:22:52.744431  1643 solver.cpp:590] Iteration 10450, lr = 0.00159991
I0706 14:23:03.328244  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:23:03.844586  1643 solver.cpp:243] Iteration 10505, loss = 0.445425
I0706 14:23:03.844614  1643 solver.cpp:259]     Train net output #0: loss = 0.445424 (* 1 = 0.445424 loss)
I0706 14:23:03.844620  1643 solver.cpp:590] Iteration 10505, lr = 0.00158455
I0706 14:23:14.931404  1643 solver.cpp:243] Iteration 10560, loss = 0.0768961
I0706 14:23:14.931433  1643 solver.cpp:259]     Train net output #0: loss = 0.0768959 (* 1 = 0.0768959 loss)
I0706 14:23:14.931440  1643 solver.cpp:590] Iteration 10560, lr = 0.00156934
I0706 14:23:19.844352  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:23:20.929824  1643 solver.cpp:347] Iteration 10584, Testing net (#0)
I0706 14:23:48.962620  1643 solver.cpp:415]     Test net output #0: accuracy = 0.122236
I0706 14:23:48.963068  1643 solver.cpp:415]     Test net output #1: loss = 6.1929 (* 1 = 6.1929 loss)
I0706 14:23:54.760362  1643 solver.cpp:243] Iteration 10615, loss = 0.0475945
I0706 14:23:54.760391  1643 solver.cpp:259]     Train net output #0: loss = 0.0475943 (* 1 = 0.0475943 loss)
I0706 14:23:54.760399  1643 solver.cpp:590] Iteration 10615, lr = 0.00155427
I0706 14:23:56.217278  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:24:08.370060  1643 solver.cpp:243] Iteration 10670, loss = 0.347774
I0706 14:24:08.370093  1643 solver.cpp:259]     Train net output #0: loss = 0.347774 (* 1 = 0.347774 loss)
I0706 14:24:08.370101  1643 solver.cpp:590] Iteration 10670, lr = 0.00153935
I0706 14:24:17.172241  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:24:20.688199  1643 solver.cpp:243] Iteration 10725, loss = 0.157104
I0706 14:24:20.688282  1643 solver.cpp:259]     Train net output #0: loss = 0.157103 (* 1 = 0.157103 loss)
I0706 14:24:20.688290  1643 solver.cpp:590] Iteration 10725, lr = 0.00152458
I0706 14:24:33.778707  1643 solver.cpp:243] Iteration 10780, loss = 0.148079
I0706 14:24:33.778734  1643 solver.cpp:259]     Train net output #0: loss = 0.148078 (* 1 = 0.148078 loss)
I0706 14:24:33.778743  1643 solver.cpp:590] Iteration 10780, lr = 0.00150994
I0706 14:24:46.056259  1643 solver.cpp:243] Iteration 10835, loss = 0.272594
I0706 14:24:46.056288  1643 solver.cpp:259]     Train net output #0: loss = 0.272594 (* 1 = 0.272594 loss)
I0706 14:24:46.056295  1643 solver.cpp:590] Iteration 10835, lr = 0.00149545
I0706 14:24:47.962292  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:24:59.163373  1643 solver.cpp:243] Iteration 10890, loss = 0.19364
I0706 14:24:59.170518  1643 solver.cpp:259]     Train net output #0: loss = 0.19364 (* 1 = 0.19364 loss)
I0706 14:24:59.170528  1643 solver.cpp:590] Iteration 10890, lr = 0.00148109
I0706 14:25:05.782482  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 14:25:11.862901  1643 solver.cpp:243] Iteration 10945, loss = 0.160988
I0706 14:25:11.862929  1643 solver.cpp:259]     Train net output #0: loss = 0.160987 (* 1 = 0.160987 loss)
I0706 14:25:11.862937  1643 solver.cpp:590] Iteration 10945, lr = 0.00146688
I0706 14:25:15.328883  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:25:23.424108  1643 solver.cpp:243] Iteration 11000, loss = 0.319596
I0706 14:25:23.424137  1643 solver.cpp:259]     Train net output #0: loss = 0.319596 (* 1 = 0.319596 loss)
I0706 14:25:23.424145  1643 solver.cpp:590] Iteration 11000, lr = 0.0014528
I0706 14:25:28.865005  1643 solver.cpp:347] Iteration 11025, Testing net (#0)
I0706 14:25:32.971698  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:25:56.004772  1643 solver.cpp:415]     Test net output #0: accuracy = 0.127404
I0706 14:25:56.004804  1643 solver.cpp:415]     Test net output #1: loss = 6.14771 (* 1 = 6.14771 loss)
I0706 14:26:00.900374  1643 solver.cpp:243] Iteration 11055, loss = 0.429964
I0706 14:26:00.900403  1643 solver.cpp:259]     Train net output #0: loss = 0.429964 (* 1 = 0.429964 loss)
I0706 14:26:00.900410  1643 solver.cpp:590] Iteration 11055, lr = 0.00143885
I0706 14:26:11.117317  1643 solver.cpp:243] Iteration 11110, loss = 0.087778
I0706 14:26:11.117979  1643 solver.cpp:259]     Train net output #0: loss = 0.0877776 (* 1 = 0.0877776 loss)
I0706 14:26:11.117997  1643 solver.cpp:590] Iteration 11110, lr = 0.00142504
I0706 14:26:15.336510  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:26:22.882575  1643 solver.cpp:243] Iteration 11165, loss = 0.146345
I0706 14:26:22.882603  1643 solver.cpp:259]     Train net output #0: loss = 0.146345 (* 1 = 0.146345 loss)
I0706 14:26:22.882611  1643 solver.cpp:590] Iteration 11165, lr = 0.00141136
I0706 14:26:33.417157  1643 solver.cpp:243] Iteration 11220, loss = 0.321327
I0706 14:26:33.417186  1643 solver.cpp:259]     Train net output #0: loss = 0.321326 (* 1 = 0.321326 loss)
I0706 14:26:33.417192  1643 solver.cpp:590] Iteration 11220, lr = 0.00139781
I0706 14:26:45.766021  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:26:47.253157  1643 solver.cpp:243] Iteration 11275, loss = 0.0841527
I0706 14:26:47.253185  1643 solver.cpp:259]     Train net output #0: loss = 0.0841522 (* 1 = 0.0841522 loss)
I0706 14:26:47.253193  1643 solver.cpp:590] Iteration 11275, lr = 0.00138439
I0706 14:26:58.598258  1643 solver.cpp:243] Iteration 11330, loss = 0.123153
I0706 14:26:58.598284  1643 solver.cpp:259]     Train net output #0: loss = 0.123153 (* 1 = 0.123153 loss)
I0706 14:26:58.598290  1643 solver.cpp:590] Iteration 11330, lr = 0.00137111
I0706 14:27:04.391417  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:27:10.714361  1643 solver.cpp:243] Iteration 11385, loss = 0.326753
I0706 14:27:10.714385  1643 solver.cpp:259]     Train net output #0: loss = 0.326752 (* 1 = 0.326752 loss)
I0706 14:27:10.714391  1643 solver.cpp:590] Iteration 11385, lr = 0.00135794
I0706 14:27:22.479535  1643 solver.cpp:243] Iteration 11440, loss = 0.142113
I0706 14:27:22.480186  1643 solver.cpp:259]     Train net output #0: loss = 0.142113 (* 1 = 0.142113 loss)
I0706 14:27:22.480206  1643 solver.cpp:590] Iteration 11440, lr = 0.00134491
I0706 14:27:28.110008  1643 solver.cpp:347] Iteration 11466, Testing net (#0)
I0706 14:27:28.460216  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:27:54.972311  1643 solver.cpp:415]     Test net output #0: accuracy = 0.127885
I0706 14:27:54.972702  1643 solver.cpp:415]     Test net output #1: loss = 6.19134 (* 1 = 6.19134 loss)
I0706 14:27:59.417023  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:28:00.230525  1643 solver.cpp:243] Iteration 11495, loss = 0.227858
I0706 14:28:00.230553  1643 solver.cpp:259]     Train net output #0: loss = 0.227858 (* 1 = 0.227858 loss)
I0706 14:28:00.230561  1643 solver.cpp:590] Iteration 11495, lr = 0.001332
I0706 14:28:12.951468  1643 solver.cpp:243] Iteration 11550, loss = 0.190122
I0706 14:28:12.951499  1643 solver.cpp:259]     Train net output #0: loss = 0.190122 (* 1 = 0.190122 loss)
I0706 14:28:12.951508  1643 solver.cpp:590] Iteration 11550, lr = 0.00131921
I0706 14:28:24.106766  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:28:26.161597  1643 solver.cpp:243] Iteration 11605, loss = 0.244056
I0706 14:28:26.162215  1643 solver.cpp:259]     Train net output #0: loss = 0.244055 (* 1 = 0.244055 loss)
I0706 14:28:26.162227  1643 solver.cpp:590] Iteration 11605, lr = 0.00130655
I0706 14:28:37.673104  1643 solver.cpp:243] Iteration 11660, loss = 0.103369
I0706 14:28:37.673130  1643 solver.cpp:259]     Train net output #0: loss = 0.103369 (* 1 = 0.103369 loss)
I0706 14:28:37.673137  1643 solver.cpp:590] Iteration 11660, lr = 0.00129401
I0706 14:28:41.496254  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 14:28:49.253149  1643 solver.cpp:243] Iteration 11715, loss = 0.114571
I0706 14:28:49.253203  1643 solver.cpp:259]     Train net output #0: loss = 0.114571 (* 1 = 0.114571 loss)
I0706 14:28:49.253219  1643 solver.cpp:590] Iteration 11715, lr = 0.00128159
I0706 14:28:58.283228  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:29:02.561174  1643 solver.cpp:243] Iteration 11770, loss = 0.0682765
I0706 14:29:02.561202  1643 solver.cpp:259]     Train net output #0: loss = 0.0682763 (* 1 = 0.0682763 loss)
I0706 14:29:02.561208  1643 solver.cpp:590] Iteration 11770, lr = 0.00126929
I0706 14:29:14.853288  1643 solver.cpp:243] Iteration 11825, loss = 0.143088
I0706 14:29:14.853317  1643 solver.cpp:259]     Train net output #0: loss = 0.143088 (* 1 = 0.143088 loss)
I0706 14:29:14.853323  1643 solver.cpp:590] Iteration 11825, lr = 0.0012571
I0706 14:29:25.158054  1643 solver.cpp:243] Iteration 11880, loss = 0.190636
I0706 14:29:25.158082  1643 solver.cpp:259]     Train net output #0: loss = 0.190636 (* 1 = 0.190636 loss)
I0706 14:29:25.158090  1643 solver.cpp:590] Iteration 11880, lr = 0.00124503
I0706 14:29:30.090672  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:29:31.224652  1643 solver.cpp:347] Iteration 11907, Testing net (#0)
I0706 14:29:59.751127  1643 solver.cpp:415]     Test net output #0: accuracy = 0.127404
I0706 14:29:59.751154  1643 solver.cpp:415]     Test net output #1: loss = 6.19792 (* 1 = 6.19792 loss)
I0706 14:30:04.578627  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:30:04.656590  1643 solver.cpp:243] Iteration 11935, loss = 0.195668
I0706 14:30:04.656615  1643 solver.cpp:259]     Train net output #0: loss = 0.195668 (* 1 = 0.195668 loss)
I0706 14:30:04.656621  1643 solver.cpp:590] Iteration 11935, lr = 0.00123308
I0706 14:30:16.298766  1643 solver.cpp:243] Iteration 11990, loss = 0.243783
I0706 14:30:16.298794  1643 solver.cpp:259]     Train net output #0: loss = 0.243783 (* 1 = 0.243783 loss)
I0706 14:30:16.298801  1643 solver.cpp:590] Iteration 11990, lr = 0.00122125
I0706 14:30:27.208721  1643 solver.cpp:243] Iteration 12045, loss = 0.242177
I0706 14:30:27.208750  1643 solver.cpp:259]     Train net output #0: loss = 0.242177 (* 1 = 0.242177 loss)
I0706 14:30:27.208760  1643 solver.cpp:590] Iteration 12045, lr = 0.00120952
I0706 14:30:35.162483  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:30:38.885121  1643 solver.cpp:243] Iteration 12100, loss = 0.140128
I0706 14:30:38.885150  1643 solver.cpp:259]     Train net output #0: loss = 0.140128 (* 1 = 0.140128 loss)
I0706 14:30:38.885157  1643 solver.cpp:590] Iteration 12100, lr = 0.00119791
I0706 14:30:49.242584  1643 solver.cpp:243] Iteration 12155, loss = 0.113593
I0706 14:30:49.242611  1643 solver.cpp:259]     Train net output #0: loss = 0.113593 (* 1 = 0.113593 loss)
I0706 14:30:49.242619  1643 solver.cpp:590] Iteration 12155, lr = 0.00118641
I0706 14:31:01.182664  1643 solver.cpp:243] Iteration 12210, loss = 0.11979
I0706 14:31:01.182693  1643 solver.cpp:259]     Train net output #0: loss = 0.11979 (* 1 = 0.11979 loss)
I0706 14:31:01.182700  1643 solver.cpp:590] Iteration 12210, lr = 0.00117503
I0706 14:31:04.792368  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:31:13.296458  1643 solver.cpp:243] Iteration 12265, loss = 0.187724
I0706 14:31:13.297173  1643 solver.cpp:259]     Train net output #0: loss = 0.187724 (* 1 = 0.187724 loss)
I0706 14:31:13.297183  1643 solver.cpp:590] Iteration 12265, lr = 0.00116375
I0706 14:31:25.133991  1643 solver.cpp:243] Iteration 12320, loss = 0.085273
I0706 14:31:25.134021  1643 solver.cpp:259]     Train net output #0: loss = 0.085273 (* 1 = 0.085273 loss)
I0706 14:31:25.134029  1643 solver.cpp:590] Iteration 12320, lr = 0.00115258
I0706 14:31:29.258659  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:31:31.392428  1643 solver.cpp:347] Iteration 12348, Testing net (#0)
I0706 14:31:58.132294  1643 solver.cpp:415]     Test net output #0: accuracy = 0.128486
I0706 14:31:58.132633  1643 solver.cpp:415]     Test net output #1: loss = 6.2284 (* 1 = 6.2284 loss)
I0706 14:32:02.547161  1643 solver.cpp:243] Iteration 12375, loss = 0.0861318
I0706 14:32:02.547188  1643 solver.cpp:259]     Train net output #0: loss = 0.0861318 (* 1 = 0.0861318 loss)
I0706 14:32:02.547194  1643 solver.cpp:590] Iteration 12375, lr = 0.00114151
I0706 14:32:04.501040  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:32:15.059005  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 14:32:15.223906  1643 solver.cpp:243] Iteration 12430, loss = 0.0683835
I0706 14:32:15.223963  1643 solver.cpp:259]     Train net output #0: loss = 0.0683834 (* 1 = 0.0683834 loss)
I0706 14:32:15.223978  1643 solver.cpp:590] Iteration 12430, lr = 0.00113055
I0706 14:32:27.046830  1643 solver.cpp:243] Iteration 12485, loss = 0.0160854
I0706 14:32:27.046859  1643 solver.cpp:259]     Train net output #0: loss = 0.0160853 (* 1 = 0.0160853 loss)
I0706 14:32:27.046866  1643 solver.cpp:590] Iteration 12485, lr = 0.0011197
I0706 14:32:34.231961  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:32:38.969338  1643 solver.cpp:243] Iteration 12540, loss = 0.0563646
I0706 14:32:38.969384  1643 solver.cpp:259]     Train net output #0: loss = 0.0563646 (* 1 = 0.0563646 loss)
I0706 14:32:38.969398  1643 solver.cpp:590] Iteration 12540, lr = 0.00110895
I0706 14:32:51.497848  1643 solver.cpp:243] Iteration 12595, loss = 0.0779852
I0706 14:32:51.497875  1643 solver.cpp:259]     Train net output #0: loss = 0.0779852 (* 1 = 0.0779852 loss)
I0706 14:32:51.497884  1643 solver.cpp:590] Iteration 12595, lr = 0.00109831
I0706 14:32:59.048707  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:33:02.695333  1643 solver.cpp:243] Iteration 12650, loss = 0.146247
I0706 14:33:02.695359  1643 solver.cpp:259]     Train net output #0: loss = 0.146247 (* 1 = 0.146247 loss)
I0706 14:33:02.695365  1643 solver.cpp:590] Iteration 12650, lr = 0.00108777
I0706 14:33:13.583048  1643 solver.cpp:243] Iteration 12705, loss = 0.185218
I0706 14:33:13.583189  1643 solver.cpp:259]     Train net output #0: loss = 0.185218 (* 1 = 0.185218 loss)
I0706 14:33:13.583197  1643 solver.cpp:590] Iteration 12705, lr = 0.00107732
I0706 14:33:19.291975  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:33:25.552166  1643 solver.cpp:243] Iteration 12760, loss = 0.0481608
I0706 14:33:25.552192  1643 solver.cpp:259]     Train net output #0: loss = 0.0481607 (* 1 = 0.0481607 loss)
I0706 14:33:25.552198  1643 solver.cpp:590] Iteration 12760, lr = 0.00106698
I0706 14:33:32.264708  1643 solver.cpp:347] Iteration 12789, Testing net (#0)
I0706 14:33:34.281330  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:33:59.581461  1643 solver.cpp:415]     Test net output #0: accuracy = 0.126322
I0706 14:33:59.581794  1643 solver.cpp:415]     Test net output #1: loss = 6.22829 (* 1 = 6.22829 loss)
I0706 14:34:04.225498  1643 solver.cpp:243] Iteration 12815, loss = 0.0753127
I0706 14:34:04.225527  1643 solver.cpp:259]     Train net output #0: loss = 0.0753127 (* 1 = 0.0753127 loss)
I0706 14:34:04.225534  1643 solver.cpp:590] Iteration 12815, lr = 0.00105674
I0706 14:34:04.858616  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:34:17.283131  1643 solver.cpp:243] Iteration 12870, loss = 0.0900786
I0706 14:34:17.283156  1643 solver.cpp:259]     Train net output #0: loss = 0.0900786 (* 1 = 0.0900786 loss)
I0706 14:34:17.283164  1643 solver.cpp:590] Iteration 12870, lr = 0.0010466
I0706 14:34:26.260282  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:34:30.390303  1643 solver.cpp:243] Iteration 12925, loss = 0.085515
I0706 14:34:30.390749  1643 solver.cpp:259]     Train net output #0: loss = 0.085515 (* 1 = 0.085515 loss)
I0706 14:34:30.390759  1643 solver.cpp:590] Iteration 12925, lr = 0.00103655
I0706 14:34:41.256134  1643 solver.cpp:243] Iteration 12980, loss = 0.0156163
I0706 14:34:41.256162  1643 solver.cpp:259]     Train net output #0: loss = 0.0156163 (* 1 = 0.0156163 loss)
I0706 14:34:41.256170  1643 solver.cpp:590] Iteration 12980, lr = 0.0010266
I0706 14:34:51.802426  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:34:52.363199  1643 solver.cpp:243] Iteration 13035, loss = 0.200588
I0706 14:34:52.363237  1643 solver.cpp:259]     Train net output #0: loss = 0.200588 (* 1 = 0.200588 loss)
I0706 14:34:52.363246  1643 solver.cpp:590] Iteration 13035, lr = 0.00101675
I0706 14:35:05.611976  1643 solver.cpp:243] Iteration 13090, loss = 0.0470235
I0706 14:35:05.612308  1643 solver.cpp:259]     Train net output #0: loss = 0.0470234 (* 1 = 0.0470234 loss)
I0706 14:35:05.612318  1643 solver.cpp:590] Iteration 13090, lr = 0.00100699
I0706 14:35:17.266809  1643 solver.cpp:243] Iteration 13145, loss = 0.074872
I0706 14:35:17.266852  1643 solver.cpp:259]     Train net output #0: loss = 0.0748719 (* 1 = 0.0748719 loss)
I0706 14:35:17.266863  1643 solver.cpp:590] Iteration 13145, lr = 0.000997321
I0706 14:35:18.924784  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:35:28.370144  1643 solver.cpp:243] Iteration 13200, loss = 0.138167
I0706 14:35:28.370199  1643 solver.cpp:259]     Train net output #0: loss = 0.138167 (* 1 = 0.138167 loss)
I0706 14:35:28.370213  1643 solver.cpp:590] Iteration 13200, lr = 0.000987747
I0706 14:35:34.322897  1643 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_13230.caffemodel
I0706 14:35:40.507422  1643 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_13230.solverstate
I0706 14:35:41.340199  1643 solver.cpp:347] Iteration 13230, Testing net (#0)
I0706 14:35:49.498127  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:35:56.901952  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 14:36:08.521699  1643 solver.cpp:415]     Test net output #0: accuracy = 0.133774
I0706 14:36:08.521726  1643 solver.cpp:415]     Test net output #1: loss = 6.28166 (* 1 = 6.28166 loss)
I0706 14:36:12.866415  1643 solver.cpp:243] Iteration 13255, loss = 0.10952
I0706 14:36:12.866518  1643 solver.cpp:259]     Train net output #0: loss = 0.10952 (* 1 = 0.10952 loss)
I0706 14:36:12.866526  1643 solver.cpp:590] Iteration 13255, lr = 0.000978266
I0706 14:36:24.726999  1643 solver.cpp:243] Iteration 13310, loss = 0.163658
I0706 14:36:24.727056  1643 solver.cpp:259]     Train net output #0: loss = 0.163658 (* 1 = 0.163658 loss)
I0706 14:36:24.727067  1643 solver.cpp:590] Iteration 13310, lr = 0.000968875
I0706 14:36:34.755950  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:36:34.927852  1643 solver.cpp:243] Iteration 13365, loss = 0.0782732
I0706 14:36:34.927907  1643 solver.cpp:259]     Train net output #0: loss = 0.0782731 (* 1 = 0.0782731 loss)
I0706 14:36:34.927925  1643 solver.cpp:590] Iteration 13365, lr = 0.000959575
I0706 14:36:47.221809  1643 solver.cpp:243] Iteration 13420, loss = 0.0914663
I0706 14:36:47.222369  1643 solver.cpp:259]     Train net output #0: loss = 0.0914663 (* 1 = 0.0914663 loss)
I0706 14:36:47.222380  1643 solver.cpp:590] Iteration 13420, lr = 0.000950364
I0706 14:36:58.088572  1643 solver.cpp:243] Iteration 13475, loss = 0.102666
I0706 14:36:58.088629  1643 solver.cpp:259]     Train net output #0: loss = 0.102666 (* 1 = 0.102666 loss)
I0706 14:36:58.088645  1643 solver.cpp:590] Iteration 13475, lr = 0.000941241
I0706 14:37:09.636997  1643 solver.cpp:243] Iteration 13530, loss = 0.070726
I0706 14:37:09.637043  1643 solver.cpp:259]     Train net output #0: loss = 0.0707259 (* 1 = 0.0707259 loss)
I0706 14:37:09.637053  1643 solver.cpp:590] Iteration 13530, lr = 0.000932206
I0706 14:37:10.725597  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:37:21.067356  1643 solver.cpp:243] Iteration 13585, loss = 0.0544895
I0706 14:37:21.067497  1643 solver.cpp:259]     Train net output #0: loss = 0.0544895 (* 1 = 0.0544895 loss)
I0706 14:37:21.067507  1643 solver.cpp:590] Iteration 13585, lr = 0.000923258
I0706 14:37:32.036650  1643 solver.cpp:243] Iteration 13640, loss = 0.0473722
I0706 14:37:32.036684  1643 solver.cpp:259]     Train net output #0: loss = 0.0473722 (* 1 = 0.0473722 loss)
I0706 14:37:32.036695  1643 solver.cpp:590] Iteration 13640, lr = 0.000914395
I0706 14:37:32.622900  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:37:37.972458  1643 solver.cpp:347] Iteration 13671, Testing net (#0)
I0706 14:38:01.658764  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:38:06.253012  1643 solver.cpp:415]     Test net output #0: accuracy = 0.130769
I0706 14:38:06.253039  1643 solver.cpp:415]     Test net output #1: loss = 6.32529 (* 1 = 6.32529 loss)
I0706 14:38:10.138661  1643 solver.cpp:243] Iteration 13695, loss = 0.0310066
I0706 14:38:10.138687  1643 solver.cpp:259]     Train net output #0: loss = 0.0310065 (* 1 = 0.0310065 loss)
I0706 14:38:10.138694  1643 solver.cpp:590] Iteration 13695, lr = 0.000905618
I0706 14:38:21.164721  1643 solver.cpp:243] Iteration 13750, loss = 0.095091
I0706 14:38:21.164749  1643 solver.cpp:259]     Train net output #0: loss = 0.0950909 (* 1 = 0.0950909 loss)
I0706 14:38:21.164757  1643 solver.cpp:590] Iteration 13750, lr = 0.000896925
I0706 14:38:32.270817  1643 solver.cpp:243] Iteration 13805, loss = 0.0472572
I0706 14:38:32.270896  1643 solver.cpp:259]     Train net output #0: loss = 0.0472572 (* 1 = 0.0472572 loss)
I0706 14:38:32.270905  1643 solver.cpp:590] Iteration 13805, lr = 0.000888315
I0706 14:38:34.519860  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:38:44.267771  1643 solver.cpp:243] Iteration 13860, loss = 0.14804
I0706 14:38:44.267799  1643 solver.cpp:259]     Train net output #0: loss = 0.14804 (* 1 = 0.14804 loss)
I0706 14:38:44.267817  1643 solver.cpp:590] Iteration 13860, lr = 0.000879788
I0706 14:38:55.895927  1643 solver.cpp:243] Iteration 13915, loss = 0.0442813
I0706 14:38:55.895954  1643 solver.cpp:259]     Train net output #0: loss = 0.0442812 (* 1 = 0.0442812 loss)
I0706 14:38:55.895962  1643 solver.cpp:590] Iteration 13915, lr = 0.000871343
I0706 14:39:04.761215  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:39:07.704931  1643 solver.cpp:243] Iteration 13970, loss = 0.215192
I0706 14:39:07.704957  1643 solver.cpp:259]     Train net output #0: loss = 0.215192 (* 1 = 0.215192 loss)
I0706 14:39:07.704963  1643 solver.cpp:590] Iteration 13970, lr = 0.000862979
I0706 14:39:21.037353  1643 solver.cpp:243] Iteration 14025, loss = 0.147132
I0706 14:39:21.037381  1643 solver.cpp:259]     Train net output #0: loss = 0.147132 (* 1 = 0.147132 loss)
I0706 14:39:21.037389  1643 solver.cpp:590] Iteration 14025, lr = 0.000854695
I0706 14:39:26.797127  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:39:29.338466  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 14:39:34.462424  1643 solver.cpp:243] Iteration 14080, loss = 0.0828627
I0706 14:39:34.462481  1643 solver.cpp:259]     Train net output #0: loss = 0.0828627 (* 1 = 0.0828627 loss)
I0706 14:39:34.462497  1643 solver.cpp:590] Iteration 14080, lr = 0.000846491
I0706 14:39:41.051797  1643 solver.cpp:347] Iteration 14112, Testing net (#0)
I0706 14:39:49.020187  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:40:09.429337  1643 solver.cpp:415]     Test net output #0: accuracy = 0.133413
I0706 14:40:09.429365  1643 solver.cpp:415]     Test net output #1: loss = 6.30174 (* 1 = 6.30174 loss)
I0706 14:40:13.678409  1643 solver.cpp:243] Iteration 14135, loss = 0.0531347
I0706 14:40:13.678501  1643 solver.cpp:259]     Train net output #0: loss = 0.0531347 (* 1 = 0.0531347 loss)
I0706 14:40:13.678510  1643 solver.cpp:590] Iteration 14135, lr = 0.000838365
I0706 14:40:19.873241  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:40:24.821221  1643 solver.cpp:243] Iteration 14190, loss = 0.274804
I0706 14:40:24.821249  1643 solver.cpp:259]     Train net output #0: loss = 0.274804 (* 1 = 0.274804 loss)
I0706 14:40:24.821257  1643 solver.cpp:590] Iteration 14190, lr = 0.000830318
I0706 14:40:37.828656  1643 solver.cpp:243] Iteration 14245, loss = 0.00909862
I0706 14:40:37.828682  1643 solver.cpp:259]     Train net output #0: loss = 0.00909859 (* 1 = 0.00909859 loss)
I0706 14:40:37.828699  1643 solver.cpp:590] Iteration 14245, lr = 0.000822347
I0706 14:40:49.234215  1643 solver.cpp:243] Iteration 14300, loss = 0.0632517
I0706 14:40:49.234627  1643 solver.cpp:259]     Train net output #0: loss = 0.0632517 (* 1 = 0.0632517 loss)
I0706 14:40:49.234642  1643 solver.cpp:590] Iteration 14300, lr = 0.000814453
I0706 14:40:56.782780  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:41:02.419924  1643 solver.cpp:243] Iteration 14355, loss = 0.190951
I0706 14:41:02.419987  1643 solver.cpp:259]     Train net output #0: loss = 0.190951 (* 1 = 0.190951 loss)
I0706 14:41:02.419996  1643 solver.cpp:590] Iteration 14355, lr = 0.000806635
I0706 14:41:14.942610  1643 solver.cpp:243] Iteration 14410, loss = 0.0142744
I0706 14:41:14.942639  1643 solver.cpp:259]     Train net output #0: loss = 0.0142743 (* 1 = 0.0142743 loss)
I0706 14:41:14.942647  1643 solver.cpp:590] Iteration 14410, lr = 0.000798892
I0706 14:41:22.886549  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:41:27.058456  1643 solver.cpp:243] Iteration 14465, loss = 0.0624986
I0706 14:41:27.058485  1643 solver.cpp:259]     Train net output #0: loss = 0.0624985 (* 1 = 0.0624985 loss)
I0706 14:41:27.058491  1643 solver.cpp:590] Iteration 14465, lr = 0.000791224
I0706 14:41:39.773744  1643 solver.cpp:243] Iteration 14520, loss = 0.0304797
I0706 14:41:39.773772  1643 solver.cpp:259]     Train net output #0: loss = 0.0304797 (* 1 = 0.0304797 loss)
I0706 14:41:39.773778  1643 solver.cpp:590] Iteration 14520, lr = 0.000783629
I0706 14:41:44.337818  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:41:47.654731  1643 solver.cpp:347] Iteration 14553, Testing net (#0)
I0706 14:42:13.155338  1643 solver.cpp:415]     Test net output #0: accuracy = 0.136178
I0706 14:42:13.155604  1643 solver.cpp:415]     Test net output #1: loss = 6.30306 (* 1 = 6.30306 loss)
I0706 14:42:16.593765  1643 solver.cpp:243] Iteration 14575, loss = 0.188327
I0706 14:42:16.593791  1643 solver.cpp:259]     Train net output #0: loss = 0.188327 (* 1 = 0.188327 loss)
I0706 14:42:16.593798  1643 solver.cpp:590] Iteration 14575, lr = 0.000776107
I0706 14:42:20.172632  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:42:29.397037  1643 solver.cpp:243] Iteration 14630, loss = 0.0168282
I0706 14:42:29.397083  1643 solver.cpp:259]     Train net output #0: loss = 0.0168281 (* 1 = 0.0168281 loss)
I0706 14:42:29.397099  1643 solver.cpp:590] Iteration 14630, lr = 0.000768657
I0706 14:42:40.555160  1643 solver.cpp:243] Iteration 14685, loss = 0.0262315
I0706 14:42:40.555189  1643 solver.cpp:259]     Train net output #0: loss = 0.0262314 (* 1 = 0.0262314 loss)
I0706 14:42:40.555197  1643 solver.cpp:590] Iteration 14685, lr = 0.000761278
I0706 14:42:52.102056  1643 solver.cpp:243] Iteration 14740, loss = 0.215709
I0706 14:42:52.102529  1643 solver.cpp:259]     Train net output #0: loss = 0.215709 (* 1 = 0.215709 loss)
I0706 14:42:52.102541  1643 solver.cpp:590] Iteration 14740, lr = 0.000753971
I0706 14:42:54.128738  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:43:04.779317  1643 solver.cpp:243] Iteration 14795, loss = 0.017973
I0706 14:43:04.779345  1643 solver.cpp:259]     Train net output #0: loss = 0.0179728 (* 1 = 0.0179728 loss)
I0706 14:43:04.779352  1643 solver.cpp:590] Iteration 14795, lr = 0.000746733
I0706 14:43:08.340826  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 14:43:16.478584  1643 solver.cpp:243] Iteration 14850, loss = 0.188706
I0706 14:43:16.478610  1643 solver.cpp:259]     Train net output #0: loss = 0.188705 (* 1 = 0.188705 loss)
I0706 14:43:16.478617  1643 solver.cpp:590] Iteration 14850, lr = 0.000739565
I0706 14:43:21.568555  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:43:27.778623  1643 solver.cpp:243] Iteration 14905, loss = 0.0430121
I0706 14:43:27.778875  1643 solver.cpp:259]     Train net output #0: loss = 0.0430119 (* 1 = 0.0430119 loss)
I0706 14:43:27.778884  1643 solver.cpp:590] Iteration 14905, lr = 0.000732466
I0706 14:43:40.236567  1643 solver.cpp:243] Iteration 14960, loss = 0.0337041
I0706 14:43:40.236593  1643 solver.cpp:259]     Train net output #0: loss = 0.0337039 (* 1 = 0.0337039 loss)
I0706 14:43:40.236601  1643 solver.cpp:590] Iteration 14960, lr = 0.000725435
I0706 14:43:46.851444  1643 solver.cpp:347] Iteration 14994, Testing net (#0)
I0706 14:43:47.652719  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:44:12.745905  1643 solver.cpp:415]     Test net output #0: accuracy = 0.134014
I0706 14:44:12.745970  1643 solver.cpp:415]     Test net output #1: loss = 6.39362 (* 1 = 6.39362 loss)
I0706 14:44:16.029578  1643 solver.cpp:243] Iteration 15015, loss = 0.0623935
I0706 14:44:16.029604  1643 solver.cpp:259]     Train net output #0: loss = 0.0623934 (* 1 = 0.0623934 loss)
I0706 14:44:16.029613  1643 solver.cpp:590] Iteration 15015, lr = 0.000718472
I0706 14:44:27.011852  1643 solver.cpp:243] Iteration 15070, loss = 0.0596266
I0706 14:44:27.011878  1643 solver.cpp:259]     Train net output #0: loss = 0.0596264 (* 1 = 0.0596264 loss)
I0706 14:44:27.011885  1643 solver.cpp:590] Iteration 15070, lr = 0.000711575
I0706 14:44:28.984165  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:44:38.425048  1643 solver.cpp:243] Iteration 15125, loss = 0.0612084
I0706 14:44:38.425073  1643 solver.cpp:259]     Train net output #0: loss = 0.0612082 (* 1 = 0.0612082 loss)
I0706 14:44:38.425081  1643 solver.cpp:590] Iteration 15125, lr = 0.000704744
I0706 14:44:49.222676  1643 solver.cpp:243] Iteration 15180, loss = 0.109148
I0706 14:44:49.222765  1643 solver.cpp:259]     Train net output #0: loss = 0.109148 (* 1 = 0.109148 loss)
I0706 14:44:49.222774  1643 solver.cpp:590] Iteration 15180, lr = 0.000697979
I0706 14:44:59.221648  1643 solver.cpp:243] Iteration 15235, loss = 0.217669
I0706 14:44:59.221676  1643 solver.cpp:259]     Train net output #0: loss = 0.217669 (* 1 = 0.217669 loss)
I0706 14:44:59.221684  1643 solver.cpp:590] Iteration 15235, lr = 0.00069128
I0706 14:45:11.072329  1643 solver.cpp:243] Iteration 15290, loss = 0.0401224
I0706 14:45:11.072361  1643 solver.cpp:259]     Train net output #0: loss = 0.0401222 (* 1 = 0.0401222 loss)
I0706 14:45:11.072373  1643 solver.cpp:590] Iteration 15290, lr = 0.000684644
I0706 14:45:12.519794  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:45:24.187459  1643 solver.cpp:243] Iteration 15345, loss = 0.0980103
I0706 14:45:24.187552  1643 solver.cpp:259]     Train net output #0: loss = 0.0980101 (* 1 = 0.0980101 loss)
I0706 14:45:24.187562  1643 solver.cpp:590] Iteration 15345, lr = 0.000678072
I0706 14:45:34.621306  1643 solver.cpp:243] Iteration 15400, loss = 0.117224
I0706 14:45:34.621335  1643 solver.cpp:259]     Train net output #0: loss = 0.117224 (* 1 = 0.117224 loss)
I0706 14:45:34.621343  1643 solver.cpp:590] Iteration 15400, lr = 0.000671563
I0706 14:45:41.590456  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:45:42.208878  1643 solver.cpp:347] Iteration 15435, Testing net (#0)
I0706 14:46:08.052073  1643 solver.cpp:415]     Test net output #0: accuracy = 0.136659
I0706 14:46:08.052283  1643 solver.cpp:415]     Test net output #1: loss = 6.34059 (* 1 = 6.34059 loss)
I0706 14:46:11.392262  1643 solver.cpp:243] Iteration 15455, loss = 0.0228452
I0706 14:46:11.392302  1643 solver.cpp:259]     Train net output #0: loss = 0.0228451 (* 1 = 0.0228451 loss)
I0706 14:46:11.392310  1643 solver.cpp:590] Iteration 15455, lr = 0.000665117
I0706 14:46:15.273496  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:46:24.350675  1643 solver.cpp:243] Iteration 15510, loss = 0.0137366
I0706 14:46:24.350715  1643 solver.cpp:259]     Train net output #0: loss = 0.0137365 (* 1 = 0.0137365 loss)
I0706 14:46:24.350729  1643 solver.cpp:590] Iteration 15510, lr = 0.000658732
I0706 14:46:35.531872  1643 solver.cpp:243] Iteration 15565, loss = 0.0502999
I0706 14:46:35.531914  1643 solver.cpp:259]     Train net output #0: loss = 0.0502998 (* 1 = 0.0502998 loss)
I0706 14:46:35.531927  1643 solver.cpp:590] Iteration 15565, lr = 0.000652409
I0706 14:46:36.526336  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 14:46:42.573109  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:46:47.514119  1643 solver.cpp:243] Iteration 15620, loss = 0.0315887
I0706 14:46:47.514147  1643 solver.cpp:259]     Train net output #0: loss = 0.0315885 (* 1 = 0.0315885 loss)
I0706 14:46:47.514154  1643 solver.cpp:590] Iteration 15620, lr = 0.000646146
I0706 14:46:59.142843  1643 solver.cpp:243] Iteration 15675, loss = 0.024734
I0706 14:46:59.142871  1643 solver.cpp:259]     Train net output #0: loss = 0.0247339 (* 1 = 0.0247339 loss)
I0706 14:46:59.142880  1643 solver.cpp:590] Iteration 15675, lr = 0.000639944
I0706 14:47:04.456920  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:47:12.914082  1643 solver.cpp:243] Iteration 15730, loss = 0.0178287
I0706 14:47:12.914638  1643 solver.cpp:259]     Train net output #0: loss = 0.0178286 (* 1 = 0.0178286 loss)
I0706 14:47:12.914652  1643 solver.cpp:590] Iteration 15730, lr = 0.000633801
I0706 14:47:24.067440  1643 solver.cpp:243] Iteration 15785, loss = 0.0157182
I0706 14:47:24.067476  1643 solver.cpp:259]     Train net output #0: loss = 0.0157181 (* 1 = 0.0157181 loss)
I0706 14:47:24.067484  1643 solver.cpp:590] Iteration 15785, lr = 0.000627717
I0706 14:47:34.692940  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:47:35.504251  1643 solver.cpp:243] Iteration 15840, loss = 0.0735596
I0706 14:47:35.504312  1643 solver.cpp:259]     Train net output #0: loss = 0.0735595 (* 1 = 0.0735595 loss)
I0706 14:47:35.504323  1643 solver.cpp:590] Iteration 15840, lr = 0.000621692
I0706 14:47:42.805976  1643 solver.cpp:347] Iteration 15876, Testing net (#0)
I0706 14:48:09.355211  1643 solver.cpp:415]     Test net output #0: accuracy = 0.132452
I0706 14:48:09.355443  1643 solver.cpp:415]     Test net output #1: loss = 6.47154 (* 1 = 6.47154 loss)
I0706 14:48:11.261162  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:48:12.985298  1643 solver.cpp:243] Iteration 15895, loss = 0.0380802
I0706 14:48:12.985327  1643 solver.cpp:259]     Train net output #0: loss = 0.0380802 (* 1 = 0.0380802 loss)
I0706 14:48:12.985334  1643 solver.cpp:590] Iteration 15895, lr = 0.000615724
I0706 14:48:24.978318  1643 solver.cpp:243] Iteration 15950, loss = 0.0346353
I0706 14:48:24.978346  1643 solver.cpp:259]     Train net output #0: loss = 0.0346353 (* 1 = 0.0346353 loss)
I0706 14:48:24.978353  1643 solver.cpp:590] Iteration 15950, lr = 0.000609813
I0706 14:48:35.884886  1643 solver.cpp:243] Iteration 16005, loss = 0.0498542
I0706 14:48:35.884913  1643 solver.cpp:259]     Train net output #0: loss = 0.0498541 (* 1 = 0.0498541 loss)
I0706 14:48:35.884922  1643 solver.cpp:590] Iteration 16005, lr = 0.00060396
I0706 14:48:39.628486  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:48:47.656545  1643 solver.cpp:243] Iteration 16060, loss = 0.0402977
I0706 14:48:47.656575  1643 solver.cpp:259]     Train net output #0: loss = 0.0402977 (* 1 = 0.0402977 loss)
I0706 14:48:47.656584  1643 solver.cpp:590] Iteration 16060, lr = 0.000598162
I0706 14:48:58.562223  1643 solver.cpp:243] Iteration 16115, loss = 0.00987119
I0706 14:48:58.562252  1643 solver.cpp:259]     Train net output #0: loss = 0.00987116 (* 1 = 0.00987116 loss)
I0706 14:48:58.562258  1643 solver.cpp:590] Iteration 16115, lr = 0.000592421
I0706 14:49:04.697263  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:49:10.414288  1643 solver.cpp:243] Iteration 16170, loss = 0.0606984
I0706 14:49:10.414575  1643 solver.cpp:259]     Train net output #0: loss = 0.0606984 (* 1 = 0.0606984 loss)
I0706 14:49:10.414594  1643 solver.cpp:590] Iteration 16170, lr = 0.000586734
I0706 14:49:23.396823  1643 solver.cpp:243] Iteration 16225, loss = 0.119218
I0706 14:49:23.396850  1643 solver.cpp:259]     Train net output #0: loss = 0.119218 (* 1 = 0.119218 loss)
I0706 14:49:23.396857  1643 solver.cpp:590] Iteration 16225, lr = 0.000581102
I0706 14:49:30.784811  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:49:36.579042  1643 solver.cpp:243] Iteration 16280, loss = 0.0416765
I0706 14:49:36.579071  1643 solver.cpp:259]     Train net output #0: loss = 0.0416764 (* 1 = 0.0416764 loss)
I0706 14:49:36.579077  1643 solver.cpp:590] Iteration 16280, lr = 0.000575524
I0706 14:49:44.000188  1643 solver.cpp:347] Iteration 16317, Testing net (#0)
I0706 14:49:47.429770  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:50:10.908612  1643 solver.cpp:415]     Test net output #0: accuracy = 0.132091
I0706 14:50:10.908638  1643 solver.cpp:415]     Test net output #1: loss = 6.43928 (* 1 = 6.43928 loss)
I0706 14:50:11.475191  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 14:50:13.712537  1643 solver.cpp:243] Iteration 16335, loss = 0.0887433
I0706 14:50:13.712563  1643 solver.cpp:259]     Train net output #0: loss = 0.0887433 (* 1 = 0.0887433 loss)
I0706 14:50:13.712570  1643 solver.cpp:590] Iteration 16335, lr = 0.000569999
I0706 14:50:24.839776  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:50:26.126446  1643 solver.cpp:243] Iteration 16390, loss = 0.0611147
I0706 14:50:26.126472  1643 solver.cpp:259]     Train net output #0: loss = 0.0611147 (* 1 = 0.0611147 loss)
I0706 14:50:26.126480  1643 solver.cpp:590] Iteration 16390, lr = 0.000564528
I0706 14:50:37.648141  1643 solver.cpp:243] Iteration 16445, loss = 0.0194045
I0706 14:50:37.648169  1643 solver.cpp:259]     Train net output #0: loss = 0.0194045 (* 1 = 0.0194045 loss)
I0706 14:50:37.648177  1643 solver.cpp:590] Iteration 16445, lr = 0.000559109
I0706 14:50:49.894457  1643 solver.cpp:243] Iteration 16500, loss = 0.0464244
I0706 14:50:49.894486  1643 solver.cpp:259]     Train net output #0: loss = 0.0464244 (* 1 = 0.0464244 loss)
I0706 14:50:49.894495  1643 solver.cpp:590] Iteration 16500, lr = 0.000553742
I0706 14:50:52.144850  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:51:01.359552  1643 solver.cpp:243] Iteration 16555, loss = 0.00743562
I0706 14:51:01.360698  1643 solver.cpp:259]     Train net output #0: loss = 0.00743559 (* 1 = 0.00743559 loss)
I0706 14:51:01.360731  1643 solver.cpp:590] Iteration 16555, lr = 0.000548426
I0706 14:51:12.872779  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:51:15.147179  1643 solver.cpp:243] Iteration 16610, loss = 0.129926
I0706 14:51:15.147205  1643 solver.cpp:259]     Train net output #0: loss = 0.129926 (* 1 = 0.129926 loss)
I0706 14:51:15.147213  1643 solver.cpp:590] Iteration 16610, lr = 0.000543162
I0706 14:51:27.087461  1643 solver.cpp:243] Iteration 16665, loss = 0.09445
I0706 14:51:27.087488  1643 solver.cpp:259]     Train net output #0: loss = 0.09445 (* 1 = 0.09445 loss)
I0706 14:51:27.087496  1643 solver.cpp:590] Iteration 16665, lr = 0.000537948
I0706 14:51:33.385823  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:51:40.548799  1643 solver.cpp:243] Iteration 16720, loss = 0.0173404
I0706 14:51:40.548827  1643 solver.cpp:259]     Train net output #0: loss = 0.0173404 (* 1 = 0.0173404 loss)
I0706 14:51:40.548835  1643 solver.cpp:590] Iteration 16720, lr = 0.000532784
I0706 14:51:47.896574  1643 solver.cpp:347] Iteration 16758, Testing net (#0)
I0706 14:51:56.511915  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:52:15.941375  1643 solver.cpp:415]     Test net output #0: accuracy = 0.135937
I0706 14:52:15.941751  1643 solver.cpp:415]     Test net output #1: loss = 6.45808 (* 1 = 6.45808 loss)
I0706 14:52:18.881947  1643 solver.cpp:243] Iteration 16775, loss = 0.0428373
I0706 14:52:18.881974  1643 solver.cpp:259]     Train net output #0: loss = 0.0428373 (* 1 = 0.0428373 loss)
I0706 14:52:18.881983  1643 solver.cpp:590] Iteration 16775, lr = 0.00052767
I0706 14:52:29.395229  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:52:30.177996  1643 solver.cpp:243] Iteration 16830, loss = 0.0338408
I0706 14:52:30.178022  1643 solver.cpp:259]     Train net output #0: loss = 0.0338407 (* 1 = 0.0338407 loss)
I0706 14:52:30.178030  1643 solver.cpp:590] Iteration 16830, lr = 0.000522605
I0706 14:52:42.560520  1643 solver.cpp:243] Iteration 16885, loss = 0.0675957
I0706 14:52:42.560592  1643 solver.cpp:259]     Train net output #0: loss = 0.0675957 (* 1 = 0.0675957 loss)
I0706 14:52:42.560606  1643 solver.cpp:590] Iteration 16885, lr = 0.000517588
I0706 14:52:50.838383  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:52:55.011929  1643 solver.cpp:243] Iteration 16940, loss = 0.0186279
I0706 14:52:55.011956  1643 solver.cpp:259]     Train net output #0: loss = 0.0186279 (* 1 = 0.0186279 loss)
I0706 14:52:55.011965  1643 solver.cpp:590] Iteration 16940, lr = 0.00051262
I0706 14:53:07.680094  1643 solver.cpp:243] Iteration 16995, loss = 0.0536623
I0706 14:53:07.680142  1643 solver.cpp:259]     Train net output #0: loss = 0.0536623 (* 1 = 0.0536623 loss)
I0706 14:53:07.680155  1643 solver.cpp:590] Iteration 16995, lr = 0.000507699
I0706 14:53:10.084532  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:53:18.896998  1643 solver.cpp:243] Iteration 17050, loss = 0.0161049
I0706 14:53:18.897050  1643 solver.cpp:259]     Train net output #0: loss = 0.0161048 (* 1 = 0.0161048 loss)
I0706 14:53:18.897061  1643 solver.cpp:590] Iteration 17050, lr = 0.000502826
I0706 14:53:31.738059  1643 solver.cpp:243] Iteration 17105, loss = 0.0122801
I0706 14:53:31.738304  1643 solver.cpp:259]     Train net output #0: loss = 0.01228 (* 1 = 0.01228 loss)
I0706 14:53:31.738320  1643 solver.cpp:590] Iteration 17105, lr = 0.000497999
I0706 14:53:38.922519  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:53:45.425056  1643 solver.cpp:243] Iteration 17160, loss = 0.0139986
I0706 14:53:45.425083  1643 solver.cpp:259]     Train net output #0: loss = 0.0139986 (* 1 = 0.0139986 loss)
I0706 14:53:45.425091  1643 solver.cpp:590] Iteration 17160, lr = 0.000493219
I0706 14:53:53.374397  1643 solver.cpp:347] Iteration 17199, Testing net (#0)
I0706 14:53:53.589659  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 14:53:55.922940  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:54:18.496484  1643 solver.cpp:415]     Test net output #0: accuracy = 0.13137
I0706 14:54:18.496707  1643 solver.cpp:415]     Test net output #1: loss = 6.43552 (* 1 = 6.43552 loss)
I0706 14:54:20.978221  1643 solver.cpp:243] Iteration 17215, loss = 0.0441403
I0706 14:54:20.978250  1643 solver.cpp:259]     Train net output #0: loss = 0.0441402 (* 1 = 0.0441402 loss)
I0706 14:54:20.978257  1643 solver.cpp:590] Iteration 17215, lr = 0.000488484
I0706 14:54:32.191339  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:54:33.615106  1643 solver.cpp:243] Iteration 17270, loss = 0.104352
I0706 14:54:33.615134  1643 solver.cpp:259]     Train net output #0: loss = 0.104352 (* 1 = 0.104352 loss)
I0706 14:54:33.615141  1643 solver.cpp:590] Iteration 17270, lr = 0.000483795
I0706 14:54:46.924842  1643 solver.cpp:243] Iteration 17325, loss = 0.0502636
I0706 14:54:46.924863  1643 solver.cpp:259]     Train net output #0: loss = 0.0502635 (* 1 = 0.0502635 loss)
I0706 14:54:46.924868  1643 solver.cpp:590] Iteration 17325, lr = 0.000479151
I0706 14:54:59.329222  1643 solver.cpp:243] Iteration 17380, loss = 0.0166868
I0706 14:54:59.329663  1643 solver.cpp:259]     Train net output #0: loss = 0.0166866 (* 1 = 0.0166866 loss)
I0706 14:54:59.329689  1643 solver.cpp:590] Iteration 17380, lr = 0.000474552
I0706 14:55:00.819612  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:55:10.088573  1643 solver.cpp:243] Iteration 17435, loss = 0.0266712
I0706 14:55:10.088601  1643 solver.cpp:259]     Train net output #0: loss = 0.0266711 (* 1 = 0.0266711 loss)
I0706 14:55:10.088609  1643 solver.cpp:590] Iteration 17435, lr = 0.000469997
I0706 14:55:22.973630  1643 solver.cpp:243] Iteration 17490, loss = 0.0172553
I0706 14:55:22.973672  1643 solver.cpp:259]     Train net output #0: loss = 0.0172552 (* 1 = 0.0172552 loss)
I0706 14:55:22.973683  1643 solver.cpp:590] Iteration 17490, lr = 0.000465485
I0706 14:55:28.960978  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:55:35.840595  1643 solver.cpp:243] Iteration 17545, loss = 0.0356243
I0706 14:55:35.841476  1643 solver.cpp:259]     Train net output #0: loss = 0.0356243 (* 1 = 0.0356243 loss)
I0706 14:55:35.841572  1643 solver.cpp:590] Iteration 17545, lr = 0.000461017
I0706 14:55:46.213265  1643 solver.cpp:243] Iteration 17600, loss = 0.0478005
I0706 14:55:46.213331  1643 solver.cpp:259]     Train net output #0: loss = 0.0478005 (* 1 = 0.0478005 loss)
I0706 14:55:46.213346  1643 solver.cpp:590] Iteration 17600, lr = 0.000456591
I0706 14:55:55.218600  1643 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_17640.caffemodel
I0706 14:56:00.030810  1643 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_17640.solverstate
I0706 14:56:00.872584  1643 solver.cpp:347] Iteration 17640, Testing net (#0)
I0706 14:56:09.924707  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:56:28.871754  1643 solver.cpp:415]     Test net output #0: accuracy = 0.133774
I0706 14:56:28.871798  1643 solver.cpp:415]     Test net output #1: loss = 6.39767 (* 1 = 6.39767 loss)
I0706 14:56:31.113711  1643 solver.cpp:243] Iteration 17655, loss = 0.151321
I0706 14:56:31.113741  1643 solver.cpp:259]     Train net output #0: loss = 0.151321 (* 1 = 0.151321 loss)
I0706 14:56:31.113749  1643 solver.cpp:590] Iteration 17655, lr = 0.000452209
I0706 14:56:35.135088  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:56:43.095988  1643 solver.cpp:243] Iteration 17710, loss = 0.0160893
I0706 14:56:43.096266  1643 solver.cpp:259]     Train net output #0: loss = 0.0160892 (* 1 = 0.0160892 loss)
I0706 14:56:43.096282  1643 solver.cpp:590] Iteration 17710, lr = 0.000447868
I0706 14:56:53.926302  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:56:55.541565  1643 solver.cpp:243] Iteration 17765, loss = 0.0372812
I0706 14:56:55.541594  1643 solver.cpp:259]     Train net output #0: loss = 0.0372811 (* 1 = 0.0372811 loss)
I0706 14:56:55.541601  1643 solver.cpp:590] Iteration 17765, lr = 0.000443569
I0706 14:57:08.350335  1643 solver.cpp:243] Iteration 17820, loss = 0.0110755
I0706 14:57:08.350363  1643 solver.cpp:259]     Train net output #0: loss = 0.0110754 (* 1 = 0.0110754 loss)
I0706 14:57:08.350371  1643 solver.cpp:590] Iteration 17820, lr = 0.000439311
I0706 14:57:19.475111  1643 solver.cpp:243] Iteration 17875, loss = 0.0220783
I0706 14:57:19.475566  1643 solver.cpp:259]     Train net output #0: loss = 0.0220781 (* 1 = 0.0220781 loss)
I0706 14:57:19.475576  1643 solver.cpp:590] Iteration 17875, lr = 0.000435094
I0706 14:57:22.368239  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:57:31.971187  1643 solver.cpp:243] Iteration 17930, loss = 0.0145337
I0706 14:57:31.971216  1643 solver.cpp:259]     Train net output #0: loss = 0.0145336 (* 1 = 0.0145336 loss)
I0706 14:57:31.971223  1643 solver.cpp:590] Iteration 17930, lr = 0.000430917
I0706 14:57:37.134255  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 14:57:44.025332  1643 solver.cpp:243] Iteration 17985, loss = 0.0822433
I0706 14:57:44.025403  1643 solver.cpp:259]     Train net output #0: loss = 0.0822432 (* 1 = 0.0822432 loss)
I0706 14:57:44.025420  1643 solver.cpp:590] Iteration 17985, lr = 0.000426781
I0706 14:57:45.346748  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:57:57.008635  1643 solver.cpp:243] Iteration 18040, loss = 0.0182372
I0706 14:57:57.009008  1643 solver.cpp:259]     Train net output #0: loss = 0.0182371 (* 1 = 0.0182371 loss)
I0706 14:57:57.009018  1643 solver.cpp:590] Iteration 18040, lr = 0.000422684
I0706 14:58:05.844732  1643 solver.cpp:347] Iteration 18081, Testing net (#0)
I0706 14:58:08.200157  1660 blocking_queue.cpp:50] Waiting for data
I0706 14:58:33.842422  1643 solver.cpp:415]     Test net output #0: accuracy = 0.13726
I0706 14:58:33.844101  1643 solver.cpp:415]     Test net output #1: loss = 6.43638 (* 1 = 6.43638 loss)
I0706 14:58:36.115820  1643 solver.cpp:243] Iteration 18095, loss = 0.0449292
I0706 14:58:36.115862  1643 solver.cpp:259]     Train net output #0: loss = 0.044929 (* 1 = 0.044929 loss)
I0706 14:58:36.115871  1643 solver.cpp:590] Iteration 18095, lr = 0.000418627
I0706 14:58:45.819708  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:58:47.803320  1643 solver.cpp:243] Iteration 18150, loss = 0.0333646
I0706 14:58:47.803371  1643 solver.cpp:259]     Train net output #0: loss = 0.0333644 (* 1 = 0.0333644 loss)
I0706 14:58:47.803395  1643 solver.cpp:590] Iteration 18150, lr = 0.000414608
I0706 14:59:00.869423  1643 solver.cpp:243] Iteration 18205, loss = 0.0375139
I0706 14:59:00.869451  1643 solver.cpp:259]     Train net output #0: loss = 0.0375138 (* 1 = 0.0375138 loss)
I0706 14:59:00.869457  1643 solver.cpp:590] Iteration 18205, lr = 0.000410628
I0706 14:59:12.045290  1643 solver.cpp:243] Iteration 18260, loss = 0.128559
I0706 14:59:12.045589  1643 solver.cpp:259]     Train net output #0: loss = 0.128559 (* 1 = 0.128559 loss)
I0706 14:59:12.045600  1643 solver.cpp:590] Iteration 18260, lr = 0.000406687
I0706 14:59:12.911895  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:59:22.564664  1643 solver.cpp:243] Iteration 18315, loss = 0.00895526
I0706 14:59:22.564690  1643 solver.cpp:259]     Train net output #0: loss = 0.00895511 (* 1 = 0.00895511 loss)
I0706 14:59:22.564697  1643 solver.cpp:590] Iteration 18315, lr = 0.000402783
I0706 14:59:34.045753  1643 solver.cpp:243] Iteration 18370, loss = 0.00822953
I0706 14:59:34.045783  1643 solver.cpp:259]     Train net output #0: loss = 0.00822938 (* 1 = 0.00822938 loss)
I0706 14:59:34.045790  1643 solver.cpp:590] Iteration 18370, lr = 0.000398917
I0706 14:59:43.691980  1656 blocking_queue.cpp:50] Waiting for data
I0706 14:59:45.578366  1643 solver.cpp:243] Iteration 18425, loss = 0.03451
I0706 14:59:45.578392  1643 solver.cpp:259]     Train net output #0: loss = 0.0345098 (* 1 = 0.0345098 loss)
I0706 14:59:45.578400  1643 solver.cpp:590] Iteration 18425, lr = 0.000395087
I0706 14:59:57.328416  1643 solver.cpp:243] Iteration 18480, loss = 0.00852041
I0706 14:59:57.328445  1643 solver.cpp:259]     Train net output #0: loss = 0.00852028 (* 1 = 0.00852028 loss)
I0706 14:59:57.328454  1643 solver.cpp:590] Iteration 18480, lr = 0.000391295
I0706 15:00:00.747946  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:00:06.933339  1643 solver.cpp:347] Iteration 18522, Testing net (#0)
I0706 15:00:31.318212  1660 blocking_queue.cpp:50] Waiting for data
I0706 15:00:34.854748  1643 solver.cpp:415]     Test net output #0: accuracy = 0.136298
I0706 15:00:34.854775  1643 solver.cpp:415]     Test net output #1: loss = 6.45241 (* 1 = 6.45241 loss)
I0706 15:00:36.722213  1643 solver.cpp:243] Iteration 18535, loss = 0.0450935
I0706 15:00:36.722246  1643 solver.cpp:259]     Train net output #0: loss = 0.0450934 (* 1 = 0.0450934 loss)
I0706 15:00:36.722255  1643 solver.cpp:590] Iteration 18535, lr = 0.000387539
I0706 15:00:48.116536  1643 solver.cpp:243] Iteration 18590, loss = 0.061159
I0706 15:00:48.116565  1643 solver.cpp:259]     Train net output #0: loss = 0.0611589 (* 1 = 0.0611589 loss)
I0706 15:00:48.116574  1643 solver.cpp:590] Iteration 18590, lr = 0.000383819
I0706 15:00:59.389492  1643 solver.cpp:243] Iteration 18645, loss = 0.0128151
I0706 15:00:59.389524  1643 solver.cpp:259]     Train net output #0: loss = 0.012815 (* 1 = 0.012815 loss)
I0706 15:00:59.389533  1643 solver.cpp:590] Iteration 18645, lr = 0.000380134
I0706 15:01:08.152015  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:01:12.248693  1643 solver.cpp:243] Iteration 18700, loss = 0.0220608
I0706 15:01:12.248735  1643 solver.cpp:259]     Train net output #0: loss = 0.0220607 (* 1 = 0.0220607 loss)
I0706 15:01:12.248749  1643 solver.cpp:590] Iteration 18700, lr = 0.000376485
I0706 15:01:13.419817  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 15:01:23.453791  1643 solver.cpp:243] Iteration 18755, loss = 0.00296422
I0706 15:01:23.453820  1643 solver.cpp:259]     Train net output #0: loss = 0.00296413 (* 1 = 0.00296413 loss)
I0706 15:01:23.453827  1643 solver.cpp:590] Iteration 18755, lr = 0.000372872
I0706 15:01:34.271934  1643 solver.cpp:243] Iteration 18810, loss = 0.0115377
I0706 15:01:34.271963  1643 solver.cpp:259]     Train net output #0: loss = 0.0115376 (* 1 = 0.0115376 loss)
I0706 15:01:34.271972  1643 solver.cpp:590] Iteration 18810, lr = 0.000369292
I0706 15:01:37.215299  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:01:45.549093  1643 solver.cpp:243] Iteration 18865, loss = 0.0518894
I0706 15:01:45.549167  1643 solver.cpp:259]     Train net output #0: loss = 0.0518893 (* 1 = 0.0518893 loss)
I0706 15:01:45.549185  1643 solver.cpp:590] Iteration 18865, lr = 0.000365747
I0706 15:01:57.077421  1643 solver.cpp:243] Iteration 18920, loss = 0.00489676
I0706 15:01:57.077461  1643 solver.cpp:259]     Train net output #0: loss = 0.00489668 (* 1 = 0.00489668 loss)
I0706 15:01:57.077474  1643 solver.cpp:590] Iteration 18920, lr = 0.000362237
I0706 15:02:01.022930  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:02:06.494935  1643 solver.cpp:347] Iteration 18963, Testing net (#0)
I0706 15:02:25.089303  1660 blocking_queue.cpp:50] Waiting for data
I0706 15:02:37.947554  1643 solver.cpp:415]     Test net output #0: accuracy = 0.136659
I0706 15:02:37.947582  1643 solver.cpp:415]     Test net output #1: loss = 6.44518 (* 1 = 6.44518 loss)
I0706 15:02:39.662734  1643 solver.cpp:243] Iteration 18975, loss = 0.0615747
I0706 15:02:39.662761  1643 solver.cpp:259]     Train net output #0: loss = 0.0615747 (* 1 = 0.0615747 loss)
I0706 15:02:39.662770  1643 solver.cpp:590] Iteration 18975, lr = 0.000358759
I0706 15:02:51.936517  1643 solver.cpp:243] Iteration 19030, loss = 0.00557639
I0706 15:02:51.936558  1643 solver.cpp:259]     Train net output #0: loss = 0.0055763 (* 1 = 0.0055763 loss)
I0706 15:02:51.936565  1643 solver.cpp:590] Iteration 19030, lr = 0.000355316
I0706 15:02:55.491001  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:03:03.127984  1643 solver.cpp:243] Iteration 19085, loss = 0.0291168
I0706 15:03:03.128046  1643 solver.cpp:259]     Train net output #0: loss = 0.0291167 (* 1 = 0.0291167 loss)
I0706 15:03:03.128069  1643 solver.cpp:590] Iteration 19085, lr = 0.000351905
I0706 15:03:14.323252  1643 solver.cpp:243] Iteration 19140, loss = 0.0208371
I0706 15:03:14.323295  1643 solver.cpp:259]     Train net output #0: loss = 0.0208371 (* 1 = 0.0208371 loss)
I0706 15:03:14.323303  1643 solver.cpp:590] Iteration 19140, lr = 0.000348527
I0706 15:03:24.501096  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:03:26.839823  1643 solver.cpp:243] Iteration 19195, loss = 0.00228856
I0706 15:03:26.839968  1643 solver.cpp:259]     Train net output #0: loss = 0.0022885 (* 1 = 0.0022885 loss)
I0706 15:03:26.839984  1643 solver.cpp:590] Iteration 19195, lr = 0.000345181
I0706 15:03:37.406798  1643 solver.cpp:243] Iteration 19250, loss = 0.0240113
I0706 15:03:37.406828  1643 solver.cpp:259]     Train net output #0: loss = 0.0240112 (* 1 = 0.0240112 loss)
I0706 15:03:37.406847  1643 solver.cpp:590] Iteration 19250, lr = 0.000341868
I0706 15:03:48.273687  1643 solver.cpp:243] Iteration 19305, loss = 0.00372794
I0706 15:03:48.273723  1643 solver.cpp:259]     Train net output #0: loss = 0.00372786 (* 1 = 0.00372786 loss)
I0706 15:03:48.273737  1643 solver.cpp:590] Iteration 19305, lr = 0.000338586
I0706 15:03:55.908371  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:04:00.018301  1643 solver.cpp:243] Iteration 19360, loss = 0.0113361
I0706 15:04:00.019008  1643 solver.cpp:259]     Train net output #0: loss = 0.011336 (* 1 = 0.011336 loss)
I0706 15:04:00.019023  1643 solver.cpp:590] Iteration 19360, lr = 0.000335336
I0706 15:04:10.739910  1643 solver.cpp:347] Iteration 19404, Testing net (#0)
I0706 15:04:15.316606  1660 blocking_queue.cpp:50] Waiting for data
I0706 15:04:36.787240  1643 solver.cpp:415]     Test net output #0: accuracy = 0.135337
I0706 15:04:36.787575  1643 solver.cpp:415]     Test net output #1: loss = 6.42612 (* 1 = 6.42612 loss)
I0706 15:04:38.322059  1643 solver.cpp:243] Iteration 19415, loss = 0.00461981
I0706 15:04:38.322088  1643 solver.cpp:259]     Train net output #0: loss = 0.00461975 (* 1 = 0.00461975 loss)
I0706 15:04:38.322094  1643 solver.cpp:590] Iteration 19415, lr = 0.000332117
I0706 15:04:48.644645  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 15:04:50.519613  1643 solver.cpp:243] Iteration 19470, loss = 0.0503647
I0706 15:04:50.519664  1643 solver.cpp:259]     Train net output #0: loss = 0.0503647 (* 1 = 0.0503647 loss)
I0706 15:04:50.519681  1643 solver.cpp:590] Iteration 19470, lr = 0.000328929
I0706 15:04:58.103216  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:05:01.386581  1643 solver.cpp:243] Iteration 19525, loss = 0.00526311
I0706 15:05:01.386639  1643 solver.cpp:259]     Train net output #0: loss = 0.00526305 (* 1 = 0.00526305 loss)
I0706 15:05:01.386663  1643 solver.cpp:590] Iteration 19525, lr = 0.000325772
I0706 15:05:12.547041  1643 solver.cpp:243] Iteration 19580, loss = 0.0078332
I0706 15:05:12.547137  1643 solver.cpp:259]     Train net output #0: loss = 0.00783315 (* 1 = 0.00783315 loss)
I0706 15:05:12.547145  1643 solver.cpp:590] Iteration 19580, lr = 0.000322645
I0706 15:05:23.514303  1643 solver.cpp:243] Iteration 19635, loss = 0.0190141
I0706 15:05:23.514330  1643 solver.cpp:259]     Train net output #0: loss = 0.0190141 (* 1 = 0.0190141 loss)
I0706 15:05:23.514338  1643 solver.cpp:590] Iteration 19635, lr = 0.000319548
I0706 15:05:34.341614  1643 solver.cpp:243] Iteration 19690, loss = 0.00201389
I0706 15:05:34.341641  1643 solver.cpp:259]     Train net output #0: loss = 0.00201385 (* 1 = 0.00201385 loss)
I0706 15:05:34.341650  1643 solver.cpp:590] Iteration 19690, lr = 0.00031648
I0706 15:05:37.343060  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:05:46.906086  1643 solver.cpp:243] Iteration 19745, loss = 0.0200573
I0706 15:05:46.906184  1643 solver.cpp:259]     Train net output #0: loss = 0.0200573 (* 1 = 0.0200573 loss)
I0706 15:05:46.906193  1643 solver.cpp:590] Iteration 19745, lr = 0.000313442
I0706 15:05:57.650656  1643 solver.cpp:243] Iteration 19800, loss = 0.0150789
I0706 15:05:57.650732  1643 solver.cpp:259]     Train net output #0: loss = 0.0150789 (* 1 = 0.0150789 loss)
I0706 15:05:57.650759  1643 solver.cpp:590] Iteration 19800, lr = 0.000310434
I0706 15:06:06.198354  1643 solver.cpp:347] Iteration 19845, Testing net (#0)
I0706 15:06:07.780196  1660 blocking_queue.cpp:50] Waiting for data
I0706 15:06:33.416759  1643 solver.cpp:415]     Test net output #0: accuracy = 0.137139
I0706 15:06:33.416949  1643 solver.cpp:415]     Test net output #1: loss = 6.4574 (* 1 = 6.4574 loss)
I0706 15:06:34.765125  1643 solver.cpp:243] Iteration 19855, loss = 0.391144
I0706 15:06:34.765163  1643 solver.cpp:259]     Train net output #0: loss = 0.391144 (* 1 = 0.391144 loss)
I0706 15:06:34.765174  1643 solver.cpp:590] Iteration 19855, lr = 0.000307454
I0706 15:06:43.198948  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:06:46.134402  1643 solver.cpp:243] Iteration 19910, loss = 0.00478794
I0706 15:06:46.134438  1643 solver.cpp:259]     Train net output #0: loss = 0.00478787 (* 1 = 0.00478787 loss)
I0706 15:06:46.134445  1643 solver.cpp:590] Iteration 19910, lr = 0.000304502
I0706 15:06:56.972854  1643 solver.cpp:243] Iteration 19965, loss = 0.00769142
I0706 15:06:56.972929  1643 solver.cpp:259]     Train net output #0: loss = 0.00769136 (* 1 = 0.00769136 loss)
I0706 15:06:56.972954  1643 solver.cpp:590] Iteration 19965, lr = 0.000301579
I0706 15:07:07.247896  1643 solver.cpp:243] Iteration 20020, loss = 0.0269789
I0706 15:07:07.248386  1643 solver.cpp:259]     Train net output #0: loss = 0.0269788 (* 1 = 0.0269788 loss)
I0706 15:07:07.248399  1643 solver.cpp:590] Iteration 20020, lr = 0.000298685
I0706 15:07:18.654736  1643 solver.cpp:243] Iteration 20075, loss = 0.0724973
I0706 15:07:18.654763  1643 solver.cpp:259]     Train net output #0: loss = 0.0724972 (* 1 = 0.0724972 loss)
I0706 15:07:18.654770  1643 solver.cpp:590] Iteration 20075, lr = 0.000295817
I0706 15:07:29.068301  1643 solver.cpp:243] Iteration 20130, loss = 0.0357339
I0706 15:07:29.068326  1643 solver.cpp:259]     Train net output #0: loss = 0.0357338 (* 1 = 0.0357338 loss)
I0706 15:07:29.068334  1643 solver.cpp:590] Iteration 20130, lr = 0.000292978
I0706 15:07:34.800135  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:07:41.453037  1643 solver.cpp:243] Iteration 20185, loss = 0.00689791
I0706 15:07:41.453125  1643 solver.cpp:259]     Train net output #0: loss = 0.0068978 (* 1 = 0.0068978 loss)
I0706 15:07:41.453133  1643 solver.cpp:590] Iteration 20185, lr = 0.000290166
I0706 15:07:53.629451  1643 solver.cpp:243] Iteration 20240, loss = 0.0490982
I0706 15:07:53.629492  1643 solver.cpp:259]     Train net output #0: loss = 0.0490981 (* 1 = 0.0490981 loss)
I0706 15:07:53.629498  1643 solver.cpp:590] Iteration 20240, lr = 0.00028738
I0706 15:08:03.658557  1643 solver.cpp:347] Iteration 20286, Testing net (#0)
I0706 15:08:05.532641  1660 blocking_queue.cpp:50] Waiting for data
I0706 15:08:14.904325  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 15:08:28.000103  1643 solver.cpp:415]     Test net output #0: accuracy = 0.13762
I0706 15:08:28.000129  1643 solver.cpp:415]     Test net output #1: loss = 6.40687 (* 1 = 6.40687 loss)
I0706 15:08:29.196970  1643 solver.cpp:243] Iteration 20295, loss = 0.00445531
I0706 15:08:29.197013  1643 solver.cpp:259]     Train net output #0: loss = 0.0044552 (* 1 = 0.0044552 loss)
I0706 15:08:29.197031  1643 solver.cpp:590] Iteration 20295, lr = 0.000284622
I0706 15:08:41.697434  1643 solver.cpp:243] Iteration 20350, loss = 0.00142721
I0706 15:08:41.697463  1643 solver.cpp:259]     Train net output #0: loss = 0.0014271 (* 1 = 0.0014271 loss)
I0706 15:08:41.697470  1643 solver.cpp:590] Iteration 20350, lr = 0.00028189
I0706 15:08:43.802600  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:08:53.165268  1643 solver.cpp:243] Iteration 20405, loss = 0.0334062
I0706 15:08:53.165395  1643 solver.cpp:259]     Train net output #0: loss = 0.0334061 (* 1 = 0.0334061 loss)
I0706 15:08:53.165410  1643 solver.cpp:590] Iteration 20405, lr = 0.000279184
I0706 15:09:05.256141  1643 solver.cpp:243] Iteration 20460, loss = 0.0374144
I0706 15:09:05.256170  1643 solver.cpp:259]     Train net output #0: loss = 0.0374143 (* 1 = 0.0374143 loss)
I0706 15:09:05.256176  1643 solver.cpp:590] Iteration 20460, lr = 0.000276504
I0706 15:09:07.162045  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:09:18.370538  1643 solver.cpp:243] Iteration 20515, loss = 0.101338
I0706 15:09:18.370566  1643 solver.cpp:259]     Train net output #0: loss = 0.101338 (* 1 = 0.101338 loss)
I0706 15:09:18.370574  1643 solver.cpp:590] Iteration 20515, lr = 0.00027385
I0706 15:09:29.982679  1643 solver.cpp:243] Iteration 20570, loss = 0.101156
I0706 15:09:29.982846  1643 solver.cpp:259]     Train net output #0: loss = 0.101156 (* 1 = 0.101156 loss)
I0706 15:09:29.982856  1643 solver.cpp:590] Iteration 20570, lr = 0.000271221
I0706 15:09:32.775179  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:09:42.863955  1643 solver.cpp:243] Iteration 20625, loss = 0.00207072
I0706 15:09:42.863982  1643 solver.cpp:259]     Train net output #0: loss = 0.00207058 (* 1 = 0.00207058 loss)
I0706 15:09:42.863989  1643 solver.cpp:590] Iteration 20625, lr = 0.000268617
I0706 15:09:54.288697  1643 solver.cpp:243] Iteration 20680, loss = 0.0018408
I0706 15:09:54.288725  1643 solver.cpp:259]     Train net output #0: loss = 0.00184065 (* 1 = 0.00184065 loss)
I0706 15:09:54.288733  1643 solver.cpp:590] Iteration 20680, lr = 0.000266039
I0706 15:09:57.066062  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:10:04.424599  1643 solver.cpp:347] Iteration 20727, Testing net (#0)
I0706 15:10:30.311786  1643 solver.cpp:415]     Test net output #0: accuracy = 0.135937
I0706 15:10:30.311813  1643 solver.cpp:415]     Test net output #1: loss = 6.44883 (* 1 = 6.44883 loss)
I0706 15:10:31.324702  1643 solver.cpp:243] Iteration 20735, loss = 0.0158147
I0706 15:10:31.324728  1643 solver.cpp:259]     Train net output #0: loss = 0.0158145 (* 1 = 0.0158145 loss)
I0706 15:10:31.324736  1643 solver.cpp:590] Iteration 20735, lr = 0.000263485
I0706 15:10:33.853821  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:10:43.111742  1643 solver.cpp:243] Iteration 20790, loss = 0.0120861
I0706 15:10:43.111840  1643 solver.cpp:259]     Train net output #0: loss = 0.0120859 (* 1 = 0.0120859 loss)
I0706 15:10:43.111850  1643 solver.cpp:590] Iteration 20790, lr = 0.000260956
I0706 15:10:54.637799  1643 solver.cpp:243] Iteration 20845, loss = 0.00530284
I0706 15:10:54.637856  1643 solver.cpp:259]     Train net output #0: loss = 0.00530266 (* 1 = 0.00530266 loss)
I0706 15:10:54.637872  1643 solver.cpp:590] Iteration 20845, lr = 0.000258451
I0706 15:10:59.081306  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:11:05.288885  1643 solver.cpp:243] Iteration 20900, loss = 0.0110071
I0706 15:11:05.288938  1643 solver.cpp:259]     Train net output #0: loss = 0.0110069 (* 1 = 0.0110069 loss)
I0706 15:11:05.288955  1643 solver.cpp:590] Iteration 20900, lr = 0.00025597
I0706 15:11:16.136786  1643 solver.cpp:243] Iteration 20955, loss = 0.0101877
I0706 15:11:16.137109  1643 solver.cpp:259]     Train net output #0: loss = 0.0101876 (* 1 = 0.0101876 loss)
I0706 15:11:16.137120  1643 solver.cpp:590] Iteration 20955, lr = 0.000253513
I0706 15:11:29.262320  1643 solver.cpp:243] Iteration 21010, loss = 0.0379286
I0706 15:11:29.262347  1643 solver.cpp:259]     Train net output #0: loss = 0.0379284 (* 1 = 0.0379284 loss)
I0706 15:11:29.262356  1643 solver.cpp:590] Iteration 21010, lr = 0.000251079
I0706 15:11:38.848276  1643 solver.cpp:243] Iteration 21065, loss = 0.0691461
I0706 15:11:38.848332  1643 solver.cpp:259]     Train net output #0: loss = 0.0691459 (* 1 = 0.0691459 loss)
I0706 15:11:38.848347  1643 solver.cpp:590] Iteration 21065, lr = 0.000248669
I0706 15:11:43.961357  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:11:44.960067  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 15:11:50.741008  1643 solver.cpp:243] Iteration 21120, loss = 0.00665357
I0706 15:11:50.741672  1643 solver.cpp:259]     Train net output #0: loss = 0.00665341 (* 1 = 0.00665341 loss)
I0706 15:11:50.741683  1643 solver.cpp:590] Iteration 21120, lr = 0.000246282
I0706 15:11:59.582471  1643 solver.cpp:347] Iteration 21168, Testing net (#0)
I0706 15:12:13.682317  1660 blocking_queue.cpp:50] Waiting for data
I0706 15:12:27.945624  1643 solver.cpp:415]     Test net output #0: accuracy = 0.136418
I0706 15:12:27.945768  1643 solver.cpp:415]     Test net output #1: loss = 6.4678 (* 1 = 6.4678 loss)
I0706 15:12:28.827246  1643 solver.cpp:243] Iteration 21175, loss = 0.0105728
I0706 15:12:28.827299  1643 solver.cpp:259]     Train net output #0: loss = 0.0105726 (* 1 = 0.0105726 loss)
I0706 15:12:28.827309  1643 solver.cpp:590] Iteration 21175, lr = 0.000243918
I0706 15:12:40.325657  1643 solver.cpp:243] Iteration 21230, loss = 0.00360631
I0706 15:12:40.325721  1643 solver.cpp:259]     Train net output #0: loss = 0.00360612 (* 1 = 0.00360612 loss)
I0706 15:12:40.325736  1643 solver.cpp:590] Iteration 21230, lr = 0.000241577
I0706 15:12:48.493532  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:12:51.670967  1643 solver.cpp:243] Iteration 21285, loss = 0.0406727
I0706 15:12:51.670997  1643 solver.cpp:259]     Train net output #0: loss = 0.0406725 (* 1 = 0.0406725 loss)
I0706 15:12:51.671005  1643 solver.cpp:590] Iteration 21285, lr = 0.000239258
I0706 15:13:02.659701  1643 solver.cpp:243] Iteration 21340, loss = 0.0376319
I0706 15:13:02.659780  1643 solver.cpp:259]     Train net output #0: loss = 0.0376317 (* 1 = 0.0376317 loss)
I0706 15:13:02.659795  1643 solver.cpp:590] Iteration 21340, lr = 0.000236961
I0706 15:13:16.218266  1643 solver.cpp:243] Iteration 21395, loss = 0.0117029
I0706 15:13:16.218293  1643 solver.cpp:259]     Train net output #0: loss = 0.0117028 (* 1 = 0.0117028 loss)
I0706 15:13:16.218302  1643 solver.cpp:590] Iteration 21395, lr = 0.000234687
I0706 15:13:24.753366  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:13:28.420744  1643 solver.cpp:243] Iteration 21450, loss = 0.0193941
I0706 15:13:28.420769  1643 solver.cpp:259]     Train net output #0: loss = 0.0193939 (* 1 = 0.0193939 loss)
I0706 15:13:28.420776  1643 solver.cpp:590] Iteration 21450, lr = 0.000232434
I0706 15:13:41.221495  1643 solver.cpp:243] Iteration 21505, loss = 0.0119155
I0706 15:13:41.221910  1643 solver.cpp:259]     Train net output #0: loss = 0.0119153 (* 1 = 0.0119153 loss)
I0706 15:13:41.221920  1643 solver.cpp:590] Iteration 21505, lr = 0.000230203
I0706 15:13:45.260139  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:13:52.621821  1643 solver.cpp:243] Iteration 21560, loss = 0.00817122
I0706 15:13:52.621850  1643 solver.cpp:259]     Train net output #0: loss = 0.00817104 (* 1 = 0.00817104 loss)
I0706 15:13:52.621857  1643 solver.cpp:590] Iteration 21560, lr = 0.000227993
I0706 15:14:02.851938  1643 solver.cpp:347] Iteration 21609, Testing net (#0)
I0706 15:14:04.909740  1660 blocking_queue.cpp:50] Waiting for data
I0706 15:14:32.826542  1643 solver.cpp:415]     Test net output #0: accuracy = 0.134856
I0706 15:14:32.827070  1643 solver.cpp:415]     Test net output #1: loss = 6.5113 (* 1 = 6.5113 loss)
I0706 15:14:33.550181  1643 solver.cpp:243] Iteration 21615, loss = 0.00398392
I0706 15:14:33.550209  1643 solver.cpp:259]     Train net output #0: loss = 0.00398374 (* 1 = 0.00398374 loss)
I0706 15:14:33.550215  1643 solver.cpp:590] Iteration 21615, lr = 0.000225804
I0706 15:14:40.658515  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:14:43.976053  1643 solver.cpp:243] Iteration 21670, loss = 0.0580946
I0706 15:14:43.976085  1643 solver.cpp:259]     Train net output #0: loss = 0.0580944 (* 1 = 0.0580944 loss)
I0706 15:14:43.976099  1643 solver.cpp:590] Iteration 21670, lr = 0.000223637
I0706 15:14:55.885097  1643 solver.cpp:243] Iteration 21725, loss = 0.123758
I0706 15:14:55.885129  1643 solver.cpp:259]     Train net output #0: loss = 0.123758 (* 1 = 0.123758 loss)
I0706 15:14:55.885144  1643 solver.cpp:590] Iteration 21725, lr = 0.00022149
I0706 15:14:58.454357  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:15:07.439146  1643 solver.cpp:243] Iteration 21780, loss = 0.0428818
I0706 15:15:07.439755  1643 solver.cpp:259]     Train net output #0: loss = 0.0428816 (* 1 = 0.0428816 loss)
I0706 15:15:07.439771  1643 solver.cpp:590] Iteration 21780, lr = 0.000219364
I0706 15:15:16.001202  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:15:19.807682  1643 solver.cpp:243] Iteration 21835, loss = 0.0305242
I0706 15:15:19.807723  1643 solver.cpp:259]     Train net output #0: loss = 0.030524 (* 1 = 0.030524 loss)
I0706 15:15:19.807730  1643 solver.cpp:590] Iteration 21835, lr = 0.000217258
I0706 15:15:22.757843  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 15:15:31.048785  1643 solver.cpp:243] Iteration 21890, loss = 0.0064042
I0706 15:15:31.048813  1643 solver.cpp:259]     Train net output #0: loss = 0.00640402 (* 1 = 0.00640402 loss)
I0706 15:15:31.048820  1643 solver.cpp:590] Iteration 21890, lr = 0.000215173
I0706 15:15:42.387786  1643 solver.cpp:243] Iteration 21945, loss = 0.00383068
I0706 15:15:42.387898  1643 solver.cpp:259]     Train net output #0: loss = 0.00383049 (* 1 = 0.00383049 loss)
I0706 15:15:42.387908  1643 solver.cpp:590] Iteration 21945, lr = 0.000213107
I0706 15:15:48.590279  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:15:55.620726  1643 solver.cpp:243] Iteration 22000, loss = 0.191508
I0706 15:15:55.620782  1643 solver.cpp:259]     Train net output #0: loss = 0.191507 (* 1 = 0.191507 loss)
I0706 15:15:55.620800  1643 solver.cpp:590] Iteration 22000, lr = 0.000211062
I0706 15:16:06.150065  1643 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_22050.caffemodel
I0706 15:16:13.744737  1643 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_22050.solverstate
I0706 15:16:14.566659  1643 solver.cpp:347] Iteration 22050, Testing net (#0)
I0706 15:16:32.199298  1660 blocking_queue.cpp:50] Waiting for data
I0706 15:16:40.066124  1643 solver.cpp:415]     Test net output #0: accuracy = 0.13762
I0706 15:16:40.066150  1643 solver.cpp:415]     Test net output #1: loss = 6.4984 (* 1 = 6.4984 loss)
I0706 15:16:40.615564  1643 solver.cpp:243] Iteration 22055, loss = 0.101403
I0706 15:16:40.615595  1643 solver.cpp:259]     Train net output #0: loss = 0.101403 (* 1 = 0.101403 loss)
I0706 15:16:40.615603  1643 solver.cpp:590] Iteration 22055, lr = 0.000209036
I0706 15:16:53.503887  1643 solver.cpp:243] Iteration 22110, loss = 0.0088982
I0706 15:16:53.504276  1643 solver.cpp:259]     Train net output #0: loss = 0.00889796 (* 1 = 0.00889796 loss)
I0706 15:16:53.504286  1643 solver.cpp:590] Iteration 22110, lr = 0.000207029
I0706 15:16:56.872676  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:17:04.362933  1643 solver.cpp:243] Iteration 22165, loss = 0.00782569
I0706 15:17:04.362962  1643 solver.cpp:259]     Train net output #0: loss = 0.00782545 (* 1 = 0.00782545 loss)
I0706 15:17:04.362968  1643 solver.cpp:590] Iteration 22165, lr = 0.000205042
I0706 15:17:18.641314  1643 solver.cpp:243] Iteration 22220, loss = 0.0364465
I0706 15:17:18.641366  1643 solver.cpp:259]     Train net output #0: loss = 0.0364462 (* 1 = 0.0364462 loss)
I0706 15:17:18.641381  1643 solver.cpp:590] Iteration 22220, lr = 0.000203074
I0706 15:17:30.136364  1643 solver.cpp:243] Iteration 22275, loss = 0.221362
I0706 15:17:30.136821  1643 solver.cpp:259]     Train net output #0: loss = 0.221362 (* 1 = 0.221362 loss)
I0706 15:17:30.136831  1643 solver.cpp:590] Iteration 22275, lr = 0.000201124
I0706 15:17:30.835280  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:17:43.409343  1643 solver.cpp:243] Iteration 22330, loss = 0.0174399
I0706 15:17:43.409371  1643 solver.cpp:259]     Train net output #0: loss = 0.0174396 (* 1 = 0.0174396 loss)
I0706 15:17:43.409379  1643 solver.cpp:590] Iteration 22330, lr = 0.000199194
I0706 15:17:55.670089  1643 solver.cpp:243] Iteration 22385, loss = 0.00545394
I0706 15:17:55.670116  1643 solver.cpp:259]     Train net output #0: loss = 0.00545367 (* 1 = 0.00545367 loss)
I0706 15:17:55.670123  1643 solver.cpp:590] Iteration 22385, lr = 0.000197282
I0706 15:18:01.930795  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:18:08.432189  1643 solver.cpp:243] Iteration 22440, loss = 0.0251727
I0706 15:18:08.432219  1643 solver.cpp:259]     Train net output #0: loss = 0.0251724 (* 1 = 0.0251724 loss)
I0706 15:18:08.432225  1643 solver.cpp:590] Iteration 22440, lr = 0.000195388
I0706 15:18:17.937517  1643 solver.cpp:347] Iteration 22491, Testing net (#0)
I0706 15:18:22.562218  1660 blocking_queue.cpp:50] Waiting for data
I0706 15:18:44.011373  1643 solver.cpp:415]     Test net output #0: accuracy = 0.138582
I0706 15:18:44.011864  1643 solver.cpp:415]     Test net output #1: loss = 6.44015 (* 1 = 6.44015 loss)
I0706 15:18:44.390064  1643 solver.cpp:243] Iteration 22495, loss = 0.0213958
I0706 15:18:44.390105  1643 solver.cpp:259]     Train net output #0: loss = 0.0213955 (* 1 = 0.0213955 loss)
I0706 15:18:44.390111  1643 solver.cpp:590] Iteration 22495, lr = 0.000193512
I0706 15:18:56.602128  1643 solver.cpp:243] Iteration 22550, loss = 0.00669558
I0706 15:18:56.602154  1643 solver.cpp:259]     Train net output #0: loss = 0.0066953 (* 1 = 0.0066953 loss)
I0706 15:18:56.602161  1643 solver.cpp:590] Iteration 22550, lr = 0.000191655
I0706 15:19:06.476683  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 15:19:07.595182  1643 solver.cpp:243] Iteration 22605, loss = 0.0297627
I0706 15:19:07.595209  1643 solver.cpp:259]     Train net output #0: loss = 0.0297624 (* 1 = 0.0297624 loss)
I0706 15:19:07.595217  1643 solver.cpp:590] Iteration 22605, lr = 0.000189815
I0706 15:19:09.185889  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:19:19.020051  1643 solver.cpp:243] Iteration 22660, loss = 0.0433268
I0706 15:19:19.020364  1643 solver.cpp:259]     Train net output #0: loss = 0.0433265 (* 1 = 0.0433265 loss)
I0706 15:19:19.020380  1643 solver.cpp:590] Iteration 22660, lr = 0.000187993
I0706 15:19:28.838454  1643 solver.cpp:243] Iteration 22715, loss = 0.0171005
I0706 15:19:28.838508  1643 solver.cpp:259]     Train net output #0: loss = 0.0171003 (* 1 = 0.0171003 loss)
I0706 15:19:28.838523  1643 solver.cpp:590] Iteration 22715, lr = 0.000186189
I0706 15:19:34.764039  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:19:40.214161  1643 solver.cpp:243] Iteration 22770, loss = 0.022843
I0706 15:19:40.214191  1643 solver.cpp:259]     Train net output #0: loss = 0.0228428 (* 1 = 0.0228428 loss)
I0706 15:19:40.214200  1643 solver.cpp:590] Iteration 22770, lr = 0.000184401
I0706 15:19:51.243520  1643 solver.cpp:243] Iteration 22825, loss = 0.0346669
I0706 15:19:51.244060  1643 solver.cpp:259]     Train net output #0: loss = 0.0346667 (* 1 = 0.0346667 loss)
I0706 15:19:51.244073  1643 solver.cpp:590] Iteration 22825, lr = 0.000182631
I0706 15:20:03.026593  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:20:03.842577  1643 solver.cpp:243] Iteration 22880, loss = 0.00544134
I0706 15:20:03.842607  1643 solver.cpp:259]     Train net output #0: loss = 0.00544106 (* 1 = 0.00544106 loss)
I0706 15:20:03.842614  1643 solver.cpp:590] Iteration 22880, lr = 0.000180878
I0706 15:20:15.208039  1643 solver.cpp:347] Iteration 22932, Testing net (#0)
I0706 15:20:27.710490  1660 blocking_queue.cpp:50] Waiting for data
I0706 15:20:40.968649  1643 solver.cpp:415]     Test net output #0: accuracy = 0.136659
I0706 15:20:40.968677  1643 solver.cpp:415]     Test net output #1: loss = 6.47016 (* 1 = 6.47016 loss)
I0706 15:20:41.221684  1643 solver.cpp:243] Iteration 22935, loss = 0.00322282
I0706 15:20:41.221735  1643 solver.cpp:259]     Train net output #0: loss = 0.00322256 (* 1 = 0.00322256 loss)
I0706 15:20:41.221747  1643 solver.cpp:590] Iteration 22935, lr = 0.000179142
I0706 15:20:53.791939  1643 solver.cpp:243] Iteration 22990, loss = 0.00520774
I0706 15:20:53.791975  1643 solver.cpp:259]     Train net output #0: loss = 0.00520748 (* 1 = 0.00520748 loss)
I0706 15:20:53.791985  1643 solver.cpp:590] Iteration 22990, lr = 0.000177422
I0706 15:21:05.319823  1643 solver.cpp:243] Iteration 23045, loss = 0.00349014
I0706 15:21:05.320555  1643 solver.cpp:259]     Train net output #0: loss = 0.00348987 (* 1 = 0.00348987 loss)
I0706 15:21:05.320570  1643 solver.cpp:590] Iteration 23045, lr = 0.000175719
I0706 15:21:07.071543  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:21:16.981350  1643 solver.cpp:243] Iteration 23100, loss = 0.0323479
I0706 15:21:16.981379  1643 solver.cpp:259]     Train net output #0: loss = 0.0323477 (* 1 = 0.0323477 loss)
I0706 15:21:16.981387  1643 solver.cpp:590] Iteration 23100, lr = 0.000174032
I0706 15:21:28.743854  1643 solver.cpp:243] Iteration 23155, loss = 0.249902
I0706 15:21:28.743880  1643 solver.cpp:259]     Train net output #0: loss = 0.249902 (* 1 = 0.249902 loss)
I0706 15:21:28.743888  1643 solver.cpp:590] Iteration 23155, lr = 0.000172362
I0706 15:21:41.421233  1643 solver.cpp:243] Iteration 23210, loss = 0.0547059
I0706 15:21:41.421494  1643 solver.cpp:259]     Train net output #0: loss = 0.0547057 (* 1 = 0.0547057 loss)
I0706 15:21:41.421511  1643 solver.cpp:590] Iteration 23210, lr = 0.000170707
I0706 15:21:43.159735  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:21:53.231097  1643 solver.cpp:243] Iteration 23265, loss = 0.0277262
I0706 15:21:53.231149  1643 solver.cpp:259]     Train net output #0: loss = 0.027726 (* 1 = 0.027726 loss)
I0706 15:21:53.231160  1643 solver.cpp:590] Iteration 23265, lr = 0.000169069
I0706 15:22:07.013183  1643 solver.cpp:243] Iteration 23320, loss = 0.0125721
I0706 15:22:07.013214  1643 solver.cpp:259]     Train net output #0: loss = 0.0125718 (* 1 = 0.0125718 loss)
I0706 15:22:07.013236  1643 solver.cpp:590] Iteration 23320, lr = 0.000167446
I0706 15:22:07.617209  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:22:17.065431  1643 solver.cpp:347] Iteration 23373, Testing net (#0)
I0706 15:22:37.045562  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 15:22:41.108311  1643 solver.cpp:415]     Test net output #0: accuracy = 0.137019
I0706 15:22:41.108338  1643 solver.cpp:415]     Test net output #1: loss = 6.4794 (* 1 = 6.4794 loss)
I0706 15:22:41.282119  1643 solver.cpp:243] Iteration 23375, loss = 0.0560304
I0706 15:22:41.282179  1643 solver.cpp:259]     Train net output #0: loss = 0.0560302 (* 1 = 0.0560302 loss)
I0706 15:22:41.282199  1643 solver.cpp:590] Iteration 23375, lr = 0.000165838
I0706 15:22:42.843716  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:22:52.235358  1643 solver.cpp:243] Iteration 23430, loss = 0.0126972
I0706 15:22:52.236058  1643 solver.cpp:259]     Train net output #0: loss = 0.012697 (* 1 = 0.012697 loss)
I0706 15:22:52.236070  1643 solver.cpp:590] Iteration 23430, lr = 0.000164247
I0706 15:23:00.373103  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:23:03.854456  1643 solver.cpp:243] Iteration 23485, loss = 0.000826401
I0706 15:23:03.854540  1643 solver.cpp:259]     Train net output #0: loss = 0.00082615 (* 1 = 0.00082615 loss)
I0706 15:23:03.854553  1643 solver.cpp:590] Iteration 23485, lr = 0.00016267
I0706 15:23:17.530619  1643 solver.cpp:243] Iteration 23540, loss = 0.021915
I0706 15:23:17.530660  1643 solver.cpp:259]     Train net output #0: loss = 0.0219148 (* 1 = 0.0219148 loss)
I0706 15:23:17.530669  1643 solver.cpp:590] Iteration 23540, lr = 0.000161108
I0706 15:23:24.393972  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:23:30.508520  1643 solver.cpp:243] Iteration 23595, loss = 0.0334639
I0706 15:23:30.508543  1643 solver.cpp:259]     Train net output #0: loss = 0.0334637 (* 1 = 0.0334637 loss)
I0706 15:23:30.508549  1643 solver.cpp:590] Iteration 23595, lr = 0.000159562
I0706 15:23:42.268735  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:23:42.725916  1643 solver.cpp:243] Iteration 23650, loss = 0.00773066
I0706 15:23:42.725945  1643 solver.cpp:259]     Train net output #0: loss = 0.00773043 (* 1 = 0.00773043 loss)
I0706 15:23:42.725953  1643 solver.cpp:590] Iteration 23650, lr = 0.00015803
I0706 15:23:53.885067  1643 solver.cpp:243] Iteration 23705, loss = 0.0213448
I0706 15:23:53.885113  1643 solver.cpp:259]     Train net output #0: loss = 0.0213445 (* 1 = 0.0213445 loss)
I0706 15:23:53.885123  1643 solver.cpp:590] Iteration 23705, lr = 0.000156513
I0706 15:24:05.312057  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:24:05.586477  1643 solver.cpp:243] Iteration 23760, loss = 0.00154776
I0706 15:24:05.586518  1643 solver.cpp:259]     Train net output #0: loss = 0.0015475 (* 1 = 0.0015475 loss)
I0706 15:24:05.586539  1643 solver.cpp:590] Iteration 23760, lr = 0.000155011
I0706 15:24:17.521996  1643 solver.cpp:347] Iteration 23814, Testing net (#0)
I0706 15:24:19.984720  1660 blocking_queue.cpp:50] Waiting for data
I0706 15:24:43.962265  1643 solver.cpp:415]     Test net output #0: accuracy = 0.137139
I0706 15:24:43.962612  1643 solver.cpp:415]     Test net output #1: loss = 6.47237 (* 1 = 6.47237 loss)
I0706 15:24:44.078572  1643 solver.cpp:243] Iteration 23815, loss = 0.0653864
I0706 15:24:44.078630  1643 solver.cpp:259]     Train net output #0: loss = 0.0653861 (* 1 = 0.0653861 loss)
I0706 15:24:44.078640  1643 solver.cpp:590] Iteration 23815, lr = 0.000153523
I0706 15:24:55.195224  1643 solver.cpp:243] Iteration 23870, loss = 0.0428938
I0706 15:24:55.195258  1643 solver.cpp:259]     Train net output #0: loss = 0.0428935 (* 1 = 0.0428935 loss)
I0706 15:24:55.195267  1643 solver.cpp:590] Iteration 23870, lr = 0.000152049
I0706 15:24:55.618157  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:25:07.152129  1643 solver.cpp:243] Iteration 23925, loss = 0.0137655
I0706 15:25:07.152168  1643 solver.cpp:259]     Train net output #0: loss = 0.0137653 (* 1 = 0.0137653 loss)
I0706 15:25:07.152175  1643 solver.cpp:590] Iteration 23925, lr = 0.00015059
I0706 15:25:18.363415  1643 solver.cpp:243] Iteration 23980, loss = 0.00109022
I0706 15:25:18.364116  1643 solver.cpp:259]     Train net output #0: loss = 0.00108997 (* 1 = 0.00108997 loss)
I0706 15:25:18.364127  1643 solver.cpp:590] Iteration 23980, lr = 0.000149144
I0706 15:25:27.004009  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:25:30.020015  1643 solver.cpp:243] Iteration 24035, loss = 0.0126161
I0706 15:25:30.020057  1643 solver.cpp:259]     Train net output #0: loss = 0.0126159 (* 1 = 0.0126159 loss)
I0706 15:25:30.020071  1643 solver.cpp:590] Iteration 24035, lr = 0.000147713
I0706 15:25:42.638674  1643 solver.cpp:243] Iteration 24090, loss = 0.01843
I0706 15:25:42.638702  1643 solver.cpp:259]     Train net output #0: loss = 0.0184298 (* 1 = 0.0184298 loss)
I0706 15:25:42.638710  1643 solver.cpp:590] Iteration 24090, lr = 0.000146295
I0706 15:25:53.239758  1643 solver.cpp:243] Iteration 24145, loss = 0.00423266
I0706 15:25:53.240236  1643 solver.cpp:259]     Train net output #0: loss = 0.00423244 (* 1 = 0.00423244 loss)
I0706 15:25:53.240247  1643 solver.cpp:590] Iteration 24145, lr = 0.00014489
I0706 15:25:55.100188  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:26:05.095229  1643 solver.cpp:243] Iteration 24200, loss = 0.0483495
I0706 15:26:05.095258  1643 solver.cpp:259]     Train net output #0: loss = 0.0483493 (* 1 = 0.0483493 loss)
I0706 15:26:05.095265  1643 solver.cpp:590] Iteration 24200, lr = 0.0001435
I0706 15:26:11.759943  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 15:26:16.936879  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:26:17.017916  1643 solver.cpp:347] Iteration 24255, Testing net (#0)
I0706 15:26:41.947266  1643 solver.cpp:415]     Test net output #0: accuracy = 0.137861
I0706 15:26:41.947620  1643 solver.cpp:415]     Test net output #1: loss = 6.48801 (* 1 = 6.48801 loss)
I0706 15:26:41.998132  1643 solver.cpp:243] Iteration 24255, loss = 0.068477
I0706 15:26:41.998208  1643 solver.cpp:259]     Train net output #0: loss = 0.0684767 (* 1 = 0.0684767 loss)
I0706 15:26:41.998227  1643 solver.cpp:590] Iteration 24255, lr = 0.000142122
I0706 15:26:52.960803  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:26:54.118321  1643 solver.cpp:243] Iteration 24310, loss = 0.0889418
I0706 15:26:54.118348  1643 solver.cpp:259]     Train net output #0: loss = 0.0889416 (* 1 = 0.0889416 loss)
I0706 15:26:54.118355  1643 solver.cpp:590] Iteration 24310, lr = 0.000140758
I0706 15:27:06.780714  1643 solver.cpp:243] Iteration 24365, loss = 0.0330287
I0706 15:27:06.780741  1643 solver.cpp:259]     Train net output #0: loss = 0.0330285 (* 1 = 0.0330285 loss)
I0706 15:27:06.780748  1643 solver.cpp:590] Iteration 24365, lr = 0.000139407
I0706 15:27:16.992079  1643 solver.cpp:243] Iteration 24420, loss = 0.0357878
I0706 15:27:16.992620  1643 solver.cpp:259]     Train net output #0: loss = 0.0357876 (* 1 = 0.0357876 loss)
I0706 15:27:16.992631  1643 solver.cpp:590] Iteration 24420, lr = 0.000138069
I0706 15:27:26.908599  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:27:28.764263  1643 solver.cpp:243] Iteration 24475, loss = 0.0363447
I0706 15:27:28.764299  1643 solver.cpp:259]     Train net output #0: loss = 0.0363445 (* 1 = 0.0363445 loss)
I0706 15:27:28.764309  1643 solver.cpp:590] Iteration 24475, lr = 0.000136743
I0706 15:27:40.689064  1643 solver.cpp:243] Iteration 24530, loss = 0.0133017
I0706 15:27:40.689090  1643 solver.cpp:259]     Train net output #0: loss = 0.0133015 (* 1 = 0.0133015 loss)
I0706 15:27:40.689097  1643 solver.cpp:590] Iteration 24530, lr = 0.000135431
I0706 15:27:52.994374  1643 solver.cpp:243] Iteration 24585, loss = 0.0383409
I0706 15:27:52.994449  1643 solver.cpp:259]     Train net output #0: loss = 0.0383406 (* 1 = 0.0383406 loss)
I0706 15:27:52.994467  1643 solver.cpp:590] Iteration 24585, lr = 0.000134131
I0706 15:27:54.445837  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:28:05.410553  1643 solver.cpp:243] Iteration 24640, loss = 0.00118894
I0706 15:28:05.410579  1643 solver.cpp:259]     Train net output #0: loss = 0.00118868 (* 1 = 0.00118868 loss)
I0706 15:28:05.410586  1643 solver.cpp:590] Iteration 24640, lr = 0.000132843
I0706 15:28:16.731051  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:28:17.700366  1643 solver.cpp:243] Iteration 24695, loss = 0.0157306
I0706 15:28:17.700429  1643 solver.cpp:259]     Train net output #0: loss = 0.0157303 (* 1 = 0.0157303 loss)
I0706 15:28:17.700443  1643 solver.cpp:590] Iteration 24695, lr = 0.000131568
I0706 15:28:17.700860  1643 solver.cpp:347] Iteration 24696, Testing net (#0)
I0706 15:28:45.635233  1643 solver.cpp:415]     Test net output #0: accuracy = 0.137861
I0706 15:28:45.635478  1643 solver.cpp:415]     Test net output #1: loss = 6.47161 (* 1 = 6.47161 loss)
I0706 15:28:49.669576  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:28:56.883045  1643 solver.cpp:243] Iteration 24750, loss = 0.0245964
I0706 15:28:56.883074  1643 solver.cpp:259]     Train net output #0: loss = 0.0245962 (* 1 = 0.0245962 loss)
I0706 15:28:56.883081  1643 solver.cpp:590] Iteration 24750, lr = 0.000130305
I0706 15:29:07.904085  1643 solver.cpp:243] Iteration 24805, loss = 0.0114987
I0706 15:29:07.904139  1643 solver.cpp:259]     Train net output #0: loss = 0.0114985 (* 1 = 0.0114985 loss)
I0706 15:29:07.904155  1643 solver.cpp:590] Iteration 24805, lr = 0.000129054
I0706 15:29:18.816352  1643 solver.cpp:243] Iteration 24860, loss = 0.0278681
I0706 15:29:18.817112  1643 solver.cpp:259]     Train net output #0: loss = 0.0278679 (* 1 = 0.0278679 loss)
I0706 15:29:18.817129  1643 solver.cpp:590] Iteration 24860, lr = 0.000127815
I0706 15:29:27.859338  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:29:31.832675  1643 solver.cpp:243] Iteration 24915, loss = 0.0177726
I0706 15:29:31.832703  1643 solver.cpp:259]     Train net output #0: loss = 0.0177723 (* 1 = 0.0177723 loss)
I0706 15:29:31.832710  1643 solver.cpp:590] Iteration 24915, lr = 0.000126588
I0706 15:29:45.128123  1643 solver.cpp:243] Iteration 24970, loss = 0.00241073
I0706 15:29:45.128154  1643 solver.cpp:259]     Train net output #0: loss = 0.00241049 (* 1 = 0.00241049 loss)
I0706 15:29:45.128163  1643 solver.cpp:590] Iteration 24970, lr = 0.000125373
I0706 15:29:48.741369  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 15:29:57.346050  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:29:59.319798  1643 solver.cpp:243] Iteration 25025, loss = 0.0500014
I0706 15:29:59.319838  1643 solver.cpp:259]     Train net output #0: loss = 0.0500012 (* 1 = 0.0500012 loss)
I0706 15:29:59.319851  1643 solver.cpp:590] Iteration 25025, lr = 0.00012417
I0706 15:30:11.659610  1643 solver.cpp:243] Iteration 25080, loss = 0.00361293
I0706 15:30:11.659634  1643 solver.cpp:259]     Train net output #0: loss = 0.00361268 (* 1 = 0.00361268 loss)
I0706 15:30:11.659641  1643 solver.cpp:590] Iteration 25080, lr = 0.000122978
I0706 15:30:20.190022  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:30:26.508116  1643 solver.cpp:243] Iteration 25135, loss = 0.0108428
I0706 15:30:26.508144  1643 solver.cpp:259]     Train net output #0: loss = 0.0108425 (* 1 = 0.0108425 loss)
I0706 15:30:26.508152  1643 solver.cpp:590] Iteration 25135, lr = 0.000121797
I0706 15:30:26.676340  1643 solver.cpp:347] Iteration 25137, Testing net (#0)
I0706 15:30:46.287178  1660 blocking_queue.cpp:50] Waiting for data
I0706 15:30:52.626376  1643 solver.cpp:415]     Test net output #0: accuracy = 0.139303
I0706 15:30:52.626427  1643 solver.cpp:415]     Test net output #1: loss = 6.47545 (* 1 = 6.47545 loss)
I0706 15:31:04.538861  1643 solver.cpp:243] Iteration 25190, loss = 0.0343285
I0706 15:31:04.538916  1643 solver.cpp:259]     Train net output #0: loss = 0.0343283 (* 1 = 0.0343283 loss)
I0706 15:31:04.538933  1643 solver.cpp:590] Iteration 25190, lr = 0.000120628
I0706 15:31:12.886898  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:31:16.796689  1643 solver.cpp:243] Iteration 25245, loss = 0.0245008
I0706 15:31:16.797164  1643 solver.cpp:259]     Train net output #0: loss = 0.0245005 (* 1 = 0.0245005 loss)
I0706 15:31:16.797195  1643 solver.cpp:590] Iteration 25245, lr = 0.00011947
I0706 15:31:30.034459  1643 solver.cpp:243] Iteration 25300, loss = 0.00604033
I0706 15:31:30.034519  1643 solver.cpp:259]     Train net output #0: loss = 0.00604005 (* 1 = 0.00604005 loss)
I0706 15:31:30.034534  1643 solver.cpp:590] Iteration 25300, lr = 0.000118324
I0706 15:31:39.098212  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:31:42.943428  1643 solver.cpp:243] Iteration 25355, loss = 0.00428353
I0706 15:31:42.943456  1643 solver.cpp:259]     Train net output #0: loss = 0.00428325 (* 1 = 0.00428325 loss)
I0706 15:31:42.943464  1643 solver.cpp:590] Iteration 25355, lr = 0.000117188
I0706 15:31:55.013411  1643 solver.cpp:243] Iteration 25410, loss = 0.0196859
I0706 15:31:55.014056  1643 solver.cpp:259]     Train net output #0: loss = 0.0196856 (* 1 = 0.0196856 loss)
I0706 15:31:55.014075  1643 solver.cpp:590] Iteration 25410, lr = 0.000116063
I0706 15:32:06.804107  1643 solver.cpp:243] Iteration 25465, loss = 0.00207069
I0706 15:32:06.804136  1643 solver.cpp:259]     Train net output #0: loss = 0.00207042 (* 1 = 0.00207042 loss)
I0706 15:32:06.804144  1643 solver.cpp:590] Iteration 25465, lr = 0.000114949
I0706 15:32:08.091397  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:32:19.202147  1643 solver.cpp:243] Iteration 25520, loss = 0.00430472
I0706 15:32:19.202204  1643 solver.cpp:259]     Train net output #0: loss = 0.00430444 (* 1 = 0.00430444 loss)
I0706 15:32:19.202219  1643 solver.cpp:590] Iteration 25520, lr = 0.000113845
I0706 15:32:29.334522  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:32:30.629093  1643 solver.cpp:243] Iteration 25575, loss = 0.149103
I0706 15:32:30.629133  1643 solver.cpp:259]     Train net output #0: loss = 0.149103 (* 1 = 0.149103 loss)
I0706 15:32:30.629148  1643 solver.cpp:590] Iteration 25575, lr = 0.000112753
I0706 15:32:30.981822  1643 solver.cpp:347] Iteration 25578, Testing net (#0)
I0706 15:32:57.871191  1643 solver.cpp:415]     Test net output #0: accuracy = 0.138221
I0706 15:32:57.871217  1643 solver.cpp:415]     Test net output #1: loss = 6.51667 (* 1 = 6.51667 loss)
I0706 15:33:06.601716  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:33:07.900693  1643 solver.cpp:243] Iteration 25630, loss = 0.00935791
I0706 15:33:07.900717  1643 solver.cpp:259]     Train net output #0: loss = 0.00935757 (* 1 = 0.00935757 loss)
I0706 15:33:07.900723  1643 solver.cpp:590] Iteration 25630, lr = 0.00011167
I0706 15:33:19.172941  1643 solver.cpp:243] Iteration 25685, loss = 0.003477
I0706 15:33:19.172971  1643 solver.cpp:259]     Train net output #0: loss = 0.00347667 (* 1 = 0.00347667 loss)
I0706 15:33:19.172977  1643 solver.cpp:590] Iteration 25685, lr = 0.000110598
I0706 15:33:31.455684  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 15:33:31.786741  1643 solver.cpp:243] Iteration 25740, loss = 0.0883717
I0706 15:33:31.786768  1643 solver.cpp:259]     Train net output #0: loss = 0.0883714 (* 1 = 0.0883714 loss)
I0706 15:33:31.786775  1643 solver.cpp:590] Iteration 25740, lr = 0.000109537
I0706 15:33:41.786489  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:33:43.762923  1643 solver.cpp:243] Iteration 25795, loss = 0.00842628
I0706 15:33:43.762959  1643 solver.cpp:259]     Train net output #0: loss = 0.00842593 (* 1 = 0.00842593 loss)
I0706 15:33:43.762969  1643 solver.cpp:590] Iteration 25795, lr = 0.000108485
I0706 15:33:56.078608  1643 solver.cpp:243] Iteration 25850, loss = 0.0183474
I0706 15:33:56.078672  1643 solver.cpp:259]     Train net output #0: loss = 0.018347 (* 1 = 0.018347 loss)
I0706 15:33:56.078692  1643 solver.cpp:590] Iteration 25850, lr = 0.000107444
I0706 15:33:59.892995  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:34:08.256188  1643 solver.cpp:243] Iteration 25905, loss = 0.0104208
I0706 15:34:08.256239  1643 solver.cpp:259]     Train net output #0: loss = 0.0104205 (* 1 = 0.0104205 loss)
I0706 15:34:08.256258  1643 solver.cpp:590] Iteration 25905, lr = 0.000106412
I0706 15:34:20.491395  1643 solver.cpp:243] Iteration 25960, loss = 0.030429
I0706 15:34:20.491868  1643 solver.cpp:259]     Train net output #0: loss = 0.0304286 (* 1 = 0.0304286 loss)
I0706 15:34:20.491883  1643 solver.cpp:590] Iteration 25960, lr = 0.000105391
I0706 15:34:24.553154  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:34:31.389574  1643 solver.cpp:243] Iteration 26015, loss = 0.0342844
I0706 15:34:31.389598  1643 solver.cpp:259]     Train net output #0: loss = 0.034284 (* 1 = 0.034284 loss)
I0706 15:34:31.389605  1643 solver.cpp:590] Iteration 26015, lr = 0.000104379
I0706 15:34:32.259184  1643 solver.cpp:347] Iteration 26019, Testing net (#0)
I0706 15:34:57.754899  1643 solver.cpp:415]     Test net output #0: accuracy = 0.139062
I0706 15:34:57.755151  1643 solver.cpp:415]     Test net output #1: loss = 6.51563 (* 1 = 6.51563 loss)
I0706 15:35:06.544729  1643 solver.cpp:243] Iteration 26070, loss = 0.0395849
I0706 15:35:06.544756  1643 solver.cpp:259]     Train net output #0: loss = 0.0395846 (* 1 = 0.0395846 loss)
I0706 15:35:06.544764  1643 solver.cpp:590] Iteration 26070, lr = 0.000103377
I0706 15:35:07.433264  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:35:17.787340  1643 solver.cpp:243] Iteration 26125, loss = 0.0178068
I0706 15:35:17.787369  1643 solver.cpp:259]     Train net output #0: loss = 0.0178065 (* 1 = 0.0178065 loss)
I0706 15:35:17.787376  1643 solver.cpp:590] Iteration 26125, lr = 0.000102385
I0706 15:35:28.559309  1643 solver.cpp:243] Iteration 26180, loss = 0.00404071
I0706 15:35:28.559412  1643 solver.cpp:259]     Train net output #0: loss = 0.00404033 (* 1 = 0.00404033 loss)
I0706 15:35:28.559422  1643 solver.cpp:590] Iteration 26180, lr = 0.000101402
I0706 15:35:40.391633  1643 solver.cpp:243] Iteration 26235, loss = 0.0238878
I0706 15:35:40.391660  1643 solver.cpp:259]     Train net output #0: loss = 0.0238874 (* 1 = 0.0238874 loss)
I0706 15:35:40.391669  1643 solver.cpp:590] Iteration 26235, lr = 0.000100429
I0706 15:35:41.291070  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:35:52.666931  1643 solver.cpp:243] Iteration 26290, loss = 0.0113662
I0706 15:35:52.666970  1643 solver.cpp:259]     Train net output #0: loss = 0.0113658 (* 1 = 0.0113658 loss)
I0706 15:35:52.666980  1643 solver.cpp:590] Iteration 26290, lr = 9.94648e-05
I0706 15:36:04.459470  1643 solver.cpp:243] Iteration 26345, loss = 0.011032
I0706 15:36:04.459666  1643 solver.cpp:259]     Train net output #0: loss = 0.0110316 (* 1 = 0.0110316 loss)
I0706 15:36:04.459677  1643 solver.cpp:590] Iteration 26345, lr = 9.85101e-05
I0706 15:36:07.289472  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:36:16.713590  1643 solver.cpp:243] Iteration 26400, loss = 0.011801
I0706 15:36:16.713644  1643 solver.cpp:259]     Train net output #0: loss = 0.0118006 (* 1 = 0.0118006 loss)
I0706 15:36:16.713655  1643 solver.cpp:590] Iteration 26400, lr = 9.75645e-05
I0706 15:36:27.855612  1643 solver.cpp:243] Iteration 26455, loss = 0.00486777
I0706 15:36:27.855664  1643 solver.cpp:259]     Train net output #0: loss = 0.00486742 (* 1 = 0.00486742 loss)
I0706 15:36:27.855680  1643 solver.cpp:590] Iteration 26455, lr = 9.66279e-05
I0706 15:36:28.554430  1643 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_26460.caffemodel
I0706 15:36:35.107583  1643 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_26460.solverstate
I0706 15:36:35.924271  1643 solver.cpp:347] Iteration 26460, Testing net (#0)
I0706 15:36:39.170416  1660 blocking_queue.cpp:50] Waiting for data
I0706 15:37:02.649394  1643 solver.cpp:415]     Test net output #0: accuracy = 0.139183
I0706 15:37:02.649420  1643 solver.cpp:415]     Test net output #1: loss = 6.51489 (* 1 = 6.51489 loss)
I0706 15:37:07.924068  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 15:37:11.633682  1643 solver.cpp:243] Iteration 26510, loss = 0.0760479
I0706 15:37:11.633729  1643 solver.cpp:259]     Train net output #0: loss = 0.0760475 (* 1 = 0.0760475 loss)
I0706 15:37:11.633739  1643 solver.cpp:590] Iteration 26510, lr = 9.57004e-05
I0706 15:37:13.999465  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:37:24.141005  1643 solver.cpp:243] Iteration 26565, loss = 0.010411
I0706 15:37:24.141032  1643 solver.cpp:259]     Train net output #0: loss = 0.0104107 (* 1 = 0.0104107 loss)
I0706 15:37:24.141039  1643 solver.cpp:590] Iteration 26565, lr = 9.47817e-05
I0706 15:37:35.584692  1643 solver.cpp:243] Iteration 26620, loss = 0.00173176
I0706 15:37:35.584717  1643 solver.cpp:259]     Train net output #0: loss = 0.00173143 (* 1 = 0.00173143 loss)
I0706 15:37:35.584722  1643 solver.cpp:590] Iteration 26620, lr = 9.38719e-05
I0706 15:37:35.713915  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:37:46.686995  1643 solver.cpp:243] Iteration 26675, loss = 0.0474838
I0706 15:37:46.687221  1643 solver.cpp:259]     Train net output #0: loss = 0.0474835 (* 1 = 0.0474835 loss)
I0706 15:37:46.687228  1643 solver.cpp:590] Iteration 26675, lr = 9.29708e-05
I0706 15:37:58.253093  1643 solver.cpp:243] Iteration 26730, loss = 0.0120783
I0706 15:37:58.253120  1643 solver.cpp:259]     Train net output #0: loss = 0.012078 (* 1 = 0.012078 loss)
I0706 15:37:58.253128  1643 solver.cpp:590] Iteration 26730, lr = 9.20784e-05
I0706 15:38:04.937706  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:38:11.207680  1643 solver.cpp:243] Iteration 26785, loss = 0.0302628
I0706 15:38:11.207716  1643 solver.cpp:259]     Train net output #0: loss = 0.0302625 (* 1 = 0.0302625 loss)
I0706 15:38:11.207725  1643 solver.cpp:590] Iteration 26785, lr = 9.11945e-05
I0706 15:38:25.478368  1643 solver.cpp:243] Iteration 26840, loss = 0.0191911
I0706 15:38:25.478962  1643 solver.cpp:259]     Train net output #0: loss = 0.0191908 (* 1 = 0.0191908 loss)
I0706 15:38:25.478978  1643 solver.cpp:590] Iteration 26840, lr = 9.03191e-05
I0706 15:38:27.726754  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:38:38.788383  1643 solver.cpp:243] Iteration 26895, loss = 0.0127032
I0706 15:38:38.788411  1643 solver.cpp:259]     Train net output #0: loss = 0.0127029 (* 1 = 0.0127029 loss)
I0706 15:38:38.788419  1643 solver.cpp:590] Iteration 26895, lr = 8.94522e-05
I0706 15:38:39.977599  1643 solver.cpp:347] Iteration 26901, Testing net (#0)
I0706 15:38:41.377169  1660 blocking_queue.cpp:50] Waiting for data
I0706 15:39:07.454442  1643 solver.cpp:415]     Test net output #0: accuracy = 0.140144
I0706 15:39:07.454911  1643 solver.cpp:415]     Test net output #1: loss = 6.52774 (* 1 = 6.52774 loss)
I0706 15:39:10.251363  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:39:18.193720  1643 solver.cpp:243] Iteration 26950, loss = 0.0456264
I0706 15:39:18.193749  1643 solver.cpp:259]     Train net output #0: loss = 0.0456261 (* 1 = 0.0456261 loss)
I0706 15:39:18.193758  1643 solver.cpp:590] Iteration 26950, lr = 8.85935e-05
I0706 15:39:28.678612  1643 solver.cpp:243] Iteration 27005, loss = 0.00214558
I0706 15:39:28.678648  1643 solver.cpp:259]     Train net output #0: loss = 0.00214529 (* 1 = 0.00214529 loss)
I0706 15:39:28.678660  1643 solver.cpp:590] Iteration 27005, lr = 8.77431e-05
I0706 15:39:42.009896  1643 solver.cpp:243] Iteration 27060, loss = 0.00430385
I0706 15:39:42.010475  1643 solver.cpp:259]     Train net output #0: loss = 0.00430354 (* 1 = 0.00430354 loss)
I0706 15:39:42.010496  1643 solver.cpp:590] Iteration 27060, lr = 8.69008e-05
I0706 15:39:45.601049  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:39:55.016367  1643 solver.cpp:243] Iteration 27115, loss = 0.0188675
I0706 15:39:55.016396  1643 solver.cpp:259]     Train net output #0: loss = 0.0188672 (* 1 = 0.0188672 loss)
I0706 15:39:55.016404  1643 solver.cpp:590] Iteration 27115, lr = 8.60667e-05
I0706 15:40:07.150300  1643 solver.cpp:243] Iteration 27170, loss = 0.00627159
I0706 15:40:07.150364  1643 solver.cpp:259]     Train net output #0: loss = 0.00627127 (* 1 = 0.00627127 loss)
I0706 15:40:07.150377  1643 solver.cpp:590] Iteration 27170, lr = 8.52405e-05
I0706 15:40:13.497711  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:40:19.995117  1643 solver.cpp:243] Iteration 27225, loss = 0.0061473
I0706 15:40:19.995157  1643 solver.cpp:259]     Train net output #0: loss = 0.00614696 (* 1 = 0.00614696 loss)
I0706 15:40:19.995169  1643 solver.cpp:590] Iteration 27225, lr = 8.44223e-05
I0706 15:40:32.041523  1643 solver.cpp:243] Iteration 27280, loss = 0.00183874
I0706 15:40:32.041550  1643 solver.cpp:259]     Train net output #0: loss = 0.00183842 (* 1 = 0.00183842 loss)
I0706 15:40:32.041558  1643 solver.cpp:590] Iteration 27280, lr = 8.36119e-05
I0706 15:40:34.819469  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:40:43.483949  1643 solver.cpp:243] Iteration 27335, loss = 0.123613
I0706 15:40:43.483975  1643 solver.cpp:259]     Train net output #0: loss = 0.123613 (* 1 = 0.123613 loss)
I0706 15:40:43.483983  1643 solver.cpp:590] Iteration 27335, lr = 8.28093e-05
I0706 15:40:44.509176  1643 solver.cpp:347] Iteration 27342, Testing net (#0)
I0706 15:40:49.618793  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 15:41:08.033495  1643 solver.cpp:415]     Test net output #0: accuracy = 0.140144
I0706 15:41:08.033522  1643 solver.cpp:415]     Test net output #1: loss = 6.5106 (* 1 = 6.5106 loss)
I0706 15:41:09.918851  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:41:16.620723  1643 solver.cpp:243] Iteration 27390, loss = 0.0109593
I0706 15:41:16.621117  1643 solver.cpp:259]     Train net output #0: loss = 0.0109589 (* 1 = 0.0109589 loss)
I0706 15:41:16.621127  1643 solver.cpp:590] Iteration 27390, lr = 8.20144e-05
I0706 15:41:28.687432  1643 solver.cpp:243] Iteration 27445, loss = 0.0755451
I0706 15:41:28.687460  1643 solver.cpp:259]     Train net output #0: loss = 0.0755448 (* 1 = 0.0755448 loss)
I0706 15:41:28.687466  1643 solver.cpp:590] Iteration 27445, lr = 8.12271e-05
I0706 15:41:29.554782  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:41:38.283957  1643 solver.cpp:243] Iteration 27500, loss = 0.00110659
I0706 15:41:38.283999  1643 solver.cpp:259]     Train net output #0: loss = 0.00110627 (* 1 = 0.00110627 loss)
I0706 15:41:38.284008  1643 solver.cpp:590] Iteration 27500, lr = 8.04474e-05
I0706 15:41:51.038206  1643 solver.cpp:243] Iteration 27555, loss = 0.00777736
I0706 15:41:51.039065  1643 solver.cpp:259]     Train net output #0: loss = 0.00777704 (* 1 = 0.00777704 loss)
I0706 15:41:51.039082  1643 solver.cpp:590] Iteration 27555, lr = 7.96752e-05
I0706 15:41:52.105679  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:42:03.244987  1643 solver.cpp:243] Iteration 27610, loss = 0.00629478
I0706 15:42:03.245029  1643 solver.cpp:259]     Train net output #0: loss = 0.00629447 (* 1 = 0.00629447 loss)
I0706 15:42:03.245038  1643 solver.cpp:590] Iteration 27610, lr = 7.89104e-05
I0706 15:42:15.799693  1643 solver.cpp:243] Iteration 27665, loss = 0.0577953
I0706 15:42:15.799716  1643 solver.cpp:259]     Train net output #0: loss = 0.0577951 (* 1 = 0.0577951 loss)
I0706 15:42:15.799723  1643 solver.cpp:590] Iteration 27665, lr = 7.81529e-05
I0706 15:42:18.431198  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:42:27.926007  1643 solver.cpp:243] Iteration 27720, loss = 0.0526523
I0706 15:42:27.926112  1643 solver.cpp:259]     Train net output #0: loss = 0.052652 (* 1 = 0.052652 loss)
I0706 15:42:27.926121  1643 solver.cpp:590] Iteration 27720, lr = 7.74027e-05
I0706 15:42:38.270560  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:42:38.560837  1643 solver.cpp:243] Iteration 27775, loss = 0.0924336
I0706 15:42:38.560892  1643 solver.cpp:259]     Train net output #0: loss = 0.0924333 (* 1 = 0.0924333 loss)
I0706 15:42:38.560906  1643 solver.cpp:590] Iteration 27775, lr = 7.66597e-05
I0706 15:42:40.312885  1643 solver.cpp:347] Iteration 27783, Testing net (#0)
I0706 15:43:00.808133  1660 blocking_queue.cpp:50] Waiting for data
I0706 15:43:11.122655  1643 solver.cpp:415]     Test net output #0: accuracy = 0.138582
I0706 15:43:11.122683  1643 solver.cpp:415]     Test net output #1: loss = 6.50792 (* 1 = 6.50792 loss)
I0706 15:43:18.645781  1643 solver.cpp:243] Iteration 27830, loss = 0.00186432
I0706 15:43:18.645812  1643 solver.cpp:259]     Train net output #0: loss = 0.00186399 (* 1 = 0.00186399 loss)
I0706 15:43:18.645820  1643 solver.cpp:590] Iteration 27830, lr = 7.59238e-05
I0706 15:43:30.518317  1643 solver.cpp:243] Iteration 27885, loss = 0.0180792
I0706 15:43:30.518349  1643 solver.cpp:259]     Train net output #0: loss = 0.0180789 (* 1 = 0.0180789 loss)
I0706 15:43:30.518358  1643 solver.cpp:590] Iteration 27885, lr = 7.51951e-05
I0706 15:43:37.713009  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:43:42.444797  1643 solver.cpp:243] Iteration 27940, loss = 0.00682373
I0706 15:43:42.444860  1643 solver.cpp:259]     Train net output #0: loss = 0.00682341 (* 1 = 0.00682341 loss)
I0706 15:43:42.444878  1643 solver.cpp:590] Iteration 27940, lr = 7.44732e-05
I0706 15:43:54.376510  1643 solver.cpp:243] Iteration 27995, loss = 0.00466256
I0706 15:43:54.376540  1643 solver.cpp:259]     Train net output #0: loss = 0.00466224 (* 1 = 0.00466224 loss)
I0706 15:43:54.376551  1643 solver.cpp:590] Iteration 27995, lr = 7.37584e-05
I0706 15:44:06.299528  1643 solver.cpp:243] Iteration 28050, loss = 0.0171689
I0706 15:44:06.299556  1643 solver.cpp:259]     Train net output #0: loss = 0.0171686 (* 1 = 0.0171686 loss)
I0706 15:44:06.299563  1643 solver.cpp:590] Iteration 28050, lr = 7.30504e-05
I0706 15:44:13.998988  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:44:18.341372  1643 solver.cpp:243] Iteration 28105, loss = 0.0940213
I0706 15:44:18.341399  1643 solver.cpp:259]     Train net output #0: loss = 0.094021 (* 1 = 0.094021 loss)
I0706 15:44:18.341406  1643 solver.cpp:590] Iteration 28105, lr = 7.23491e-05
I0706 15:44:21.765856  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 15:44:29.026790  1643 solver.cpp:243] Iteration 28160, loss = 0.00283083
I0706 15:44:29.026818  1643 solver.cpp:259]     Train net output #0: loss = 0.00283052 (* 1 = 0.00283052 loss)
I0706 15:44:29.026825  1643 solver.cpp:590] Iteration 28160, lr = 7.16546e-05
I0706 15:44:39.409490  1643 solver.cpp:243] Iteration 28215, loss = 0.044396
I0706 15:44:39.409538  1643 solver.cpp:259]     Train net output #0: loss = 0.0443957 (* 1 = 0.0443957 loss)
I0706 15:44:39.409557  1643 solver.cpp:590] Iteration 28215, lr = 7.09668e-05
I0706 15:44:41.022341  1643 solver.cpp:347] Iteration 28224, Testing net (#0)
I0706 15:44:41.462855  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:45:06.315369  1643 solver.cpp:415]     Test net output #0: accuracy = 0.139183
I0706 15:45:06.315485  1643 solver.cpp:415]     Test net output #1: loss = 6.52112 (* 1 = 6.52112 loss)
I0706 15:45:16.583932  1643 solver.cpp:243] Iteration 28270, loss = 0.0312518
I0706 15:45:16.583986  1643 solver.cpp:259]     Train net output #0: loss = 0.0312515 (* 1 = 0.0312515 loss)
I0706 15:45:16.583997  1643 solver.cpp:590] Iteration 28270, lr = 7.02856e-05
I0706 15:45:16.668640  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:45:29.943204  1643 solver.cpp:243] Iteration 28325, loss = 0.0710289
I0706 15:45:29.943233  1643 solver.cpp:259]     Train net output #0: loss = 0.0710286 (* 1 = 0.0710286 loss)
I0706 15:45:29.943241  1643 solver.cpp:590] Iteration 28325, lr = 6.96109e-05
I0706 15:45:41.112131  1643 solver.cpp:243] Iteration 28380, loss = 0.0176293
I0706 15:45:41.112293  1643 solver.cpp:259]     Train net output #0: loss = 0.017629 (* 1 = 0.017629 loss)
I0706 15:45:41.112303  1643 solver.cpp:590] Iteration 28380, lr = 6.89427e-05
I0706 15:45:51.767698  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:45:52.577857  1643 solver.cpp:243] Iteration 28435, loss = 0.0275017
I0706 15:45:52.577893  1643 solver.cpp:259]     Train net output #0: loss = 0.0275014 (* 1 = 0.0275014 loss)
I0706 15:45:52.577903  1643 solver.cpp:590] Iteration 28435, lr = 6.82809e-05
I0706 15:46:03.856710  1643 solver.cpp:243] Iteration 28490, loss = 0.021845
I0706 15:46:03.856766  1643 solver.cpp:259]     Train net output #0: loss = 0.0218447 (* 1 = 0.0218447 loss)
I0706 15:46:03.856782  1643 solver.cpp:590] Iteration 28490, lr = 6.76255e-05
I0706 15:46:16.574132  1643 solver.cpp:243] Iteration 28545, loss = 0.0351851
I0706 15:46:16.574498  1643 solver.cpp:259]     Train net output #0: loss = 0.0351848 (* 1 = 0.0351848 loss)
I0706 15:46:16.574512  1643 solver.cpp:590] Iteration 28545, lr = 6.69764e-05
I0706 15:46:17.860046  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:46:27.600324  1643 solver.cpp:243] Iteration 28600, loss = 0.0171361
I0706 15:46:27.600395  1643 solver.cpp:259]     Train net output #0: loss = 0.0171358 (* 1 = 0.0171358 loss)
I0706 15:46:27.600410  1643 solver.cpp:590] Iteration 28600, lr = 6.63334e-05
I0706 15:46:42.006796  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:46:42.072684  1643 solver.cpp:243] Iteration 28655, loss = 0.00505038
I0706 15:46:42.072711  1643 solver.cpp:259]     Train net output #0: loss = 0.00505007 (* 1 = 0.00505007 loss)
I0706 15:46:42.072720  1643 solver.cpp:590] Iteration 28655, lr = 6.56967e-05
I0706 15:46:43.641449  1643 solver.cpp:347] Iteration 28665, Testing net (#0)
I0706 15:47:10.417433  1643 solver.cpp:415]     Test net output #0: accuracy = 0.139663
I0706 15:47:10.417538  1643 solver.cpp:415]     Test net output #1: loss = 6.51318 (* 1 = 6.51318 loss)
I0706 15:47:12.880252  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:47:20.222476  1643 solver.cpp:243] Iteration 28710, loss = 0.0216625
I0706 15:47:20.222534  1643 solver.cpp:259]     Train net output #0: loss = 0.0216622 (* 1 = 0.0216622 loss)
I0706 15:47:20.222553  1643 solver.cpp:590] Iteration 28710, lr = 6.50661e-05
I0706 15:47:31.367095  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:47:34.344801  1643 solver.cpp:243] Iteration 28765, loss = 0.0139882
I0706 15:47:34.344830  1643 solver.cpp:259]     Train net output #0: loss = 0.0139879 (* 1 = 0.0139879 loss)
I0706 15:47:34.344836  1643 solver.cpp:590] Iteration 28765, lr = 6.44415e-05
I0706 15:47:46.624022  1643 solver.cpp:243] Iteration 28820, loss = 0.0175149
I0706 15:47:46.624091  1643 solver.cpp:259]     Train net output #0: loss = 0.0175146 (* 1 = 0.0175146 loss)
I0706 15:47:46.624100  1643 solver.cpp:590] Iteration 28820, lr = 6.38229e-05
I0706 15:47:58.033210  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:47:58.115178  1643 solver.cpp:243] Iteration 28875, loss = 0.00604808
I0706 15:47:58.115233  1643 solver.cpp:259]     Train net output #0: loss = 0.00604779 (* 1 = 0.00604779 loss)
I0706 15:47:58.115249  1643 solver.cpp:590] Iteration 28875, lr = 6.32103e-05
I0706 15:47:58.289681  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 15:48:10.089251  1643 solver.cpp:243] Iteration 28930, loss = 0.0194881
I0706 15:48:10.089279  1643 solver.cpp:259]     Train net output #0: loss = 0.0194878 (* 1 = 0.0194878 loss)
I0706 15:48:10.089287  1643 solver.cpp:590] Iteration 28930, lr = 6.26035e-05
I0706 15:48:22.642956  1643 solver.cpp:243] Iteration 28985, loss = 0.000411735
I0706 15:48:22.643054  1643 solver.cpp:259]     Train net output #0: loss = 0.000411439 (* 1 = 0.000411439 loss)
I0706 15:48:22.643072  1643 solver.cpp:590] Iteration 28985, lr = 6.20026e-05
I0706 15:48:29.256330  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:48:36.007333  1643 solver.cpp:243] Iteration 29040, loss = 0.0258493
I0706 15:48:36.007361  1643 solver.cpp:259]     Train net output #0: loss = 0.0258491 (* 1 = 0.0258491 loss)
I0706 15:48:36.007369  1643 solver.cpp:590] Iteration 29040, lr = 6.14074e-05
I0706 15:48:48.246472  1643 solver.cpp:243] Iteration 29095, loss = 0.00172995
I0706 15:48:48.246500  1643 solver.cpp:259]     Train net output #0: loss = 0.00172967 (* 1 = 0.00172967 loss)
I0706 15:48:48.246507  1643 solver.cpp:590] Iteration 29095, lr = 6.0818e-05
I0706 15:48:50.297201  1643 solver.cpp:347] Iteration 29106, Testing net (#0)
I0706 15:48:51.443827  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:49:17.886586  1643 solver.cpp:415]     Test net output #0: accuracy = 0.139904
I0706 15:49:17.886761  1643 solver.cpp:415]     Test net output #1: loss = 6.51566 (* 1 = 6.51566 loss)
I0706 15:49:22.008427  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:49:26.863570  1643 solver.cpp:243] Iteration 29150, loss = 0.0103655
I0706 15:49:26.863598  1643 solver.cpp:259]     Train net output #0: loss = 0.0103652 (* 1 = 0.0103652 loss)
I0706 15:49:26.863605  1643 solver.cpp:590] Iteration 29150, lr = 6.02342e-05
I0706 15:49:38.876561  1643 solver.cpp:243] Iteration 29205, loss = 0.0177162
I0706 15:49:38.876605  1643 solver.cpp:259]     Train net output #0: loss = 0.017716 (* 1 = 0.017716 loss)
I0706 15:49:38.876613  1643 solver.cpp:590] Iteration 29205, lr = 5.9656e-05
I0706 15:49:50.294474  1643 solver.cpp:243] Iteration 29260, loss = 0.0206704
I0706 15:49:50.294682  1643 solver.cpp:259]     Train net output #0: loss = 0.0206701 (* 1 = 0.0206701 loss)
I0706 15:49:50.294692  1643 solver.cpp:590] Iteration 29260, lr = 5.90833e-05
I0706 15:49:58.046399  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:50:01.480201  1643 solver.cpp:243] Iteration 29315, loss = 0.0308367
I0706 15:50:01.480235  1643 solver.cpp:259]     Train net output #0: loss = 0.0308365 (* 1 = 0.0308365 loss)
I0706 15:50:01.480243  1643 solver.cpp:590] Iteration 29315, lr = 5.85162e-05
I0706 15:50:13.478701  1643 solver.cpp:243] Iteration 29370, loss = 0.0299018
I0706 15:50:13.478729  1643 solver.cpp:259]     Train net output #0: loss = 0.0299016 (* 1 = 0.0299016 loss)
I0706 15:50:13.478734  1643 solver.cpp:590] Iteration 29370, lr = 5.79545e-05
I0706 15:50:24.792232  1643 solver.cpp:243] Iteration 29425, loss = 0.0149988
I0706 15:50:24.792546  1643 solver.cpp:259]     Train net output #0: loss = 0.0149985 (* 1 = 0.0149985 loss)
I0706 15:50:24.792557  1643 solver.cpp:590] Iteration 29425, lr = 5.73982e-05
I0706 15:50:27.786481  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:50:37.612037  1643 solver.cpp:243] Iteration 29480, loss = 0.00182061
I0706 15:50:37.612067  1643 solver.cpp:259]     Train net output #0: loss = 0.00182035 (* 1 = 0.00182035 loss)
I0706 15:50:37.612074  1643 solver.cpp:590] Iteration 29480, lr = 5.68472e-05
I0706 15:50:46.474403  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:50:50.331859  1643 solver.cpp:243] Iteration 29535, loss = 0.00946458
I0706 15:50:50.331882  1643 solver.cpp:259]     Train net output #0: loss = 0.0094643 (* 1 = 0.0094643 loss)
I0706 15:50:50.331888  1643 solver.cpp:590] Iteration 29535, lr = 5.63015e-05
I0706 15:50:52.694625  1643 solver.cpp:347] Iteration 29547, Testing net (#0)
I0706 15:51:10.714170  1660 blocking_queue.cpp:50] Waiting for data
I0706 15:51:19.519263  1643 solver.cpp:415]     Test net output #0: accuracy = 0.138822
I0706 15:51:19.519306  1643 solver.cpp:415]     Test net output #1: loss = 6.51276 (* 1 = 6.51276 loss)
I0706 15:51:28.999704  1643 solver.cpp:243] Iteration 29590, loss = 0.0460774
I0706 15:51:28.999732  1643 solver.cpp:259]     Train net output #0: loss = 0.0460771 (* 1 = 0.0460771 loss)
I0706 15:51:28.999740  1643 solver.cpp:590] Iteration 29590, lr = 5.57611e-05
I0706 15:51:37.371465  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 15:51:39.508777  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:51:40.922056  1643 solver.cpp:243] Iteration 29645, loss = 0.00816064
I0706 15:51:40.922149  1643 solver.cpp:259]     Train net output #0: loss = 0.00816036 (* 1 = 0.00816036 loss)
I0706 15:51:40.922168  1643 solver.cpp:590] Iteration 29645, lr = 5.52258e-05
I0706 15:51:51.683707  1643 solver.cpp:243] Iteration 29700, loss = 0.0236122
I0706 15:51:51.683745  1643 solver.cpp:259]     Train net output #0: loss = 0.023612 (* 1 = 0.023612 loss)
I0706 15:51:51.683755  1643 solver.cpp:590] Iteration 29700, lr = 5.46957e-05
I0706 15:52:04.914923  1643 solver.cpp:243] Iteration 29755, loss = 0.0922562
I0706 15:52:04.914952  1643 solver.cpp:259]     Train net output #0: loss = 0.0922559 (* 1 = 0.0922559 loss)
I0706 15:52:04.914959  1643 solver.cpp:590] Iteration 29755, lr = 5.41707e-05
I0706 15:52:15.433480  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:52:16.847585  1643 solver.cpp:243] Iteration 29810, loss = 0.00824022
I0706 15:52:16.847615  1643 solver.cpp:259]     Train net output #0: loss = 0.00823992 (* 1 = 0.00823992 loss)
I0706 15:52:16.847623  1643 solver.cpp:590] Iteration 29810, lr = 5.36507e-05
I0706 15:52:28.115739  1643 solver.cpp:243] Iteration 29865, loss = 0.00991881
I0706 15:52:28.115769  1643 solver.cpp:259]     Train net output #0: loss = 0.0099185 (* 1 = 0.0099185 loss)
I0706 15:52:28.115778  1643 solver.cpp:590] Iteration 29865, lr = 5.31357e-05
I0706 15:52:39.052356  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:52:39.130450  1643 solver.cpp:243] Iteration 29920, loss = 0.00194413
I0706 15:52:39.130506  1643 solver.cpp:259]     Train net output #0: loss = 0.00194381 (* 1 = 0.00194381 loss)
I0706 15:52:39.130514  1643 solver.cpp:590] Iteration 29920, lr = 5.26256e-05
I0706 15:52:51.469135  1643 solver.cpp:243] Iteration 29975, loss = 0.028158
I0706 15:52:51.469259  1643 solver.cpp:259]     Train net output #0: loss = 0.0281576 (* 1 = 0.0281576 loss)
I0706 15:52:51.469269  1643 solver.cpp:590] Iteration 29975, lr = 5.21204e-05
I0706 15:52:53.549127  1643 solver.cpp:347] Iteration 29988, Testing net (#0)
I0706 15:53:15.821874  1660 blocking_queue.cpp:50] Waiting for data
I0706 15:53:19.111543  1643 solver.cpp:415]     Test net output #0: accuracy = 0.139423
I0706 15:53:19.111570  1643 solver.cpp:415]     Test net output #1: loss = 6.51433 (* 1 = 6.51433 loss)
I0706 15:53:26.874452  1643 solver.cpp:243] Iteration 30030, loss = 0.0340343
I0706 15:53:26.874596  1643 solver.cpp:259]     Train net output #0: loss = 0.034034 (* 1 = 0.034034 loss)
I0706 15:53:26.874616  1643 solver.cpp:590] Iteration 30030, lr = 5.16201e-05
I0706 15:53:38.737298  1643 solver.cpp:243] Iteration 30085, loss = 0.00370891
I0706 15:53:38.737340  1643 solver.cpp:259]     Train net output #0: loss = 0.00370859 (* 1 = 0.00370859 loss)
I0706 15:53:38.737354  1643 solver.cpp:590] Iteration 30085, lr = 5.11246e-05
I0706 15:53:49.327517  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:53:50.948915  1643 solver.cpp:243] Iteration 30140, loss = 0.00686262
I0706 15:53:50.948942  1643 solver.cpp:259]     Train net output #0: loss = 0.0068623 (* 1 = 0.0068623 loss)
I0706 15:53:50.948950  1643 solver.cpp:590] Iteration 30140, lr = 5.06339e-05
I0706 15:54:03.829177  1643 solver.cpp:243] Iteration 30195, loss = 0.00194328
I0706 15:54:03.829264  1643 solver.cpp:259]     Train net output #0: loss = 0.00194295 (* 1 = 0.00194295 loss)
I0706 15:54:03.829272  1643 solver.cpp:590] Iteration 30195, lr = 5.01478e-05
I0706 15:54:14.782888  1643 solver.cpp:243] Iteration 30250, loss = 0.0110443
I0706 15:54:14.782917  1643 solver.cpp:259]     Train net output #0: loss = 0.011044 (* 1 = 0.011044 loss)
I0706 15:54:14.782925  1643 solver.cpp:590] Iteration 30250, lr = 4.96665e-05
I0706 15:54:19.415169  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:54:27.598229  1643 solver.cpp:243] Iteration 30305, loss = 0.0151953
I0706 15:54:27.598266  1643 solver.cpp:259]     Train net output #0: loss = 0.0151949 (* 1 = 0.0151949 loss)
I0706 15:54:27.598274  1643 solver.cpp:590] Iteration 30305, lr = 4.91897e-05
I0706 15:54:36.978953  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:54:39.740882  1643 solver.cpp:243] Iteration 30360, loss = 0.043116
I0706 15:54:39.740912  1643 solver.cpp:259]     Train net output #0: loss = 0.0431156 (* 1 = 0.0431156 loss)
I0706 15:54:39.740919  1643 solver.cpp:590] Iteration 30360, lr = 4.87175e-05
I0706 15:54:51.698300  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:54:53.064199  1643 solver.cpp:243] Iteration 30415, loss = 0.0638323
I0706 15:54:53.064241  1643 solver.cpp:259]     Train net output #0: loss = 0.063832 (* 1 = 0.063832 loss)
I0706 15:54:53.064254  1643 solver.cpp:590] Iteration 30415, lr = 4.82499e-05
I0706 15:54:56.328461  1643 solver.cpp:347] Iteration 30429, Testing net (#0)
I0706 15:55:13.063624  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 15:55:23.598078  1643 solver.cpp:415]     Test net output #0: accuracy = 0.139303
I0706 15:55:23.598119  1643 solver.cpp:415]     Test net output #1: loss = 6.51017 (* 1 = 6.51017 loss)
I0706 15:55:25.658314  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:55:32.884866  1643 solver.cpp:243] Iteration 30470, loss = 0.0324104
I0706 15:55:32.884901  1643 solver.cpp:259]     Train net output #0: loss = 0.03241 (* 1 = 0.03241 loss)
I0706 15:55:32.884912  1643 solver.cpp:590] Iteration 30470, lr = 4.77867e-05
I0706 15:55:43.924470  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:55:44.615548  1643 solver.cpp:243] Iteration 30525, loss = 0.0325426
I0706 15:55:44.615587  1643 solver.cpp:259]     Train net output #0: loss = 0.0325423 (* 1 = 0.0325423 loss)
I0706 15:55:44.615605  1643 solver.cpp:590] Iteration 30525, lr = 4.7328e-05
I0706 15:55:57.476951  1643 solver.cpp:243] Iteration 30580, loss = 0.101492
I0706 15:55:57.477000  1643 solver.cpp:259]     Train net output #0: loss = 0.101491 (* 1 = 0.101491 loss)
I0706 15:55:57.477016  1643 solver.cpp:590] Iteration 30580, lr = 4.68737e-05
I0706 15:56:08.091542  1643 solver.cpp:243] Iteration 30635, loss = 0.0145567
I0706 15:56:08.091573  1643 solver.cpp:259]     Train net output #0: loss = 0.0145564 (* 1 = 0.0145564 loss)
I0706 15:56:08.091581  1643 solver.cpp:590] Iteration 30635, lr = 4.64238e-05
I0706 15:56:12.936106  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:56:22.359118  1643 solver.cpp:243] Iteration 30690, loss = 0.0490872
I0706 15:56:22.359205  1643 solver.cpp:259]     Train net output #0: loss = 0.0490868 (* 1 = 0.0490868 loss)
I0706 15:56:22.359215  1643 solver.cpp:590] Iteration 30690, lr = 4.59781e-05
I0706 15:56:35.454789  1643 solver.cpp:243] Iteration 30745, loss = 0.0197194
I0706 15:56:35.454816  1643 solver.cpp:259]     Train net output #0: loss = 0.0197191 (* 1 = 0.0197191 loss)
I0706 15:56:35.454824  1643 solver.cpp:590] Iteration 30745, lr = 4.55368e-05
I0706 15:56:44.839880  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:56:47.749601  1643 solver.cpp:243] Iteration 30800, loss = 0.00112316
I0706 15:56:47.749644  1643 solver.cpp:259]     Train net output #0: loss = 0.00112282 (* 1 = 0.00112282 loss)
I0706 15:56:47.749652  1643 solver.cpp:590] Iteration 30800, lr = 4.50997e-05
I0706 15:56:59.933683  1643 solver.cpp:243] Iteration 30855, loss = 0.0171451
I0706 15:56:59.933753  1643 solver.cpp:259]     Train net output #0: loss = 0.0171448 (* 1 = 0.0171448 loss)
I0706 15:56:59.933760  1643 solver.cpp:590] Iteration 30855, lr = 4.46668e-05
I0706 15:57:02.681953  1643 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_30870.caffemodel
I0706 15:57:08.915392  1643 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_30870.solverstate
I0706 15:57:09.748275  1643 solver.cpp:347] Iteration 30870, Testing net (#0)
I0706 15:57:21.345500  1660 blocking_queue.cpp:50] Waiting for data
I0706 15:57:35.596335  1643 solver.cpp:415]     Test net output #0: accuracy = 0.139062
I0706 15:57:35.596426  1643 solver.cpp:415]     Test net output #1: loss = 6.5143 (* 1 = 6.5143 loss)
I0706 15:57:42.739667  1643 solver.cpp:243] Iteration 30910, loss = 0.00201918
I0706 15:57:42.739696  1643 solver.cpp:259]     Train net output #0: loss = 0.00201882 (* 1 = 0.00201882 loss)
I0706 15:57:42.739702  1643 solver.cpp:590] Iteration 30910, lr = 4.4238e-05
I0706 15:57:54.765440  1643 solver.cpp:243] Iteration 30965, loss = 0.0135921
I0706 15:57:54.765468  1643 solver.cpp:259]     Train net output #0: loss = 0.0135917 (* 1 = 0.0135917 loss)
I0706 15:57:54.765475  1643 solver.cpp:590] Iteration 30965, lr = 4.38134e-05
I0706 15:57:57.239997  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:58:08.687374  1643 solver.cpp:243] Iteration 31020, loss = 0.0862158
I0706 15:58:08.687490  1643 solver.cpp:259]     Train net output #0: loss = 0.0862155 (* 1 = 0.0862155 loss)
I0706 15:58:08.687500  1643 solver.cpp:590] Iteration 31020, lr = 4.33928e-05
I0706 15:58:19.722656  1643 solver.cpp:243] Iteration 31075, loss = 0.0052389
I0706 15:58:19.722697  1643 solver.cpp:259]     Train net output #0: loss = 0.00523852 (* 1 = 0.00523852 loss)
I0706 15:58:19.722714  1643 solver.cpp:590] Iteration 31075, lr = 4.29763e-05
I0706 15:58:28.235066  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:58:31.783491  1643 solver.cpp:243] Iteration 31130, loss = 0.00845673
I0706 15:58:31.783535  1643 solver.cpp:259]     Train net output #0: loss = 0.00845636 (* 1 = 0.00845636 loss)
I0706 15:58:31.783547  1643 solver.cpp:590] Iteration 31130, lr = 4.25637e-05
I0706 15:58:42.442169  1643 solver.cpp:243] Iteration 31185, loss = 0.00232752
I0706 15:58:42.443274  1643 solver.cpp:259]     Train net output #0: loss = 0.00232716 (* 1 = 0.00232716 loss)
I0706 15:58:42.443284  1643 solver.cpp:590] Iteration 31185, lr = 4.21552e-05
I0706 15:58:54.451359  1643 solver.cpp:243] Iteration 31240, loss = 0.00309292
I0706 15:58:54.451388  1643 solver.cpp:259]     Train net output #0: loss = 0.00309256 (* 1 = 0.00309256 loss)
I0706 15:58:54.451396  1643 solver.cpp:590] Iteration 31240, lr = 4.17505e-05
I0706 15:58:58.772188  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 15:59:06.199313  1643 solver.cpp:243] Iteration 31295, loss = 0.00227778
I0706 15:59:06.199342  1643 solver.cpp:259]     Train net output #0: loss = 0.00227743 (* 1 = 0.00227743 loss)
I0706 15:59:06.199349  1643 solver.cpp:590] Iteration 31295, lr = 4.13497e-05
I0706 15:59:06.705867  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:59:09.138247  1643 solver.cpp:347] Iteration 31311, Testing net (#0)
I0706 15:59:34.872730  1643 solver.cpp:415]     Test net output #0: accuracy = 0.138702
I0706 15:59:34.872951  1643 solver.cpp:415]     Test net output #1: loss = 6.50075 (* 1 = 6.50075 loss)
I0706 15:59:38.443212  1656 blocking_queue.cpp:50] Waiting for data
I0706 15:59:42.161561  1643 solver.cpp:243] Iteration 31350, loss = 0.00416476
I0706 15:59:42.161588  1643 solver.cpp:259]     Train net output #0: loss = 0.0041644 (* 1 = 0.0041644 loss)
I0706 15:59:42.161597  1643 solver.cpp:590] Iteration 31350, lr = 4.09528e-05
I0706 15:59:53.245436  1643 solver.cpp:243] Iteration 31405, loss = 0.00807458
I0706 15:59:53.245463  1643 solver.cpp:259]     Train net output #0: loss = 0.0080742 (* 1 = 0.0080742 loss)
I0706 15:59:53.245471  1643 solver.cpp:590] Iteration 31405, lr = 4.05597e-05
I0706 16:00:03.437790  1643 solver.cpp:243] Iteration 31460, loss = 0.0615702
I0706 16:00:03.437820  1643 solver.cpp:259]     Train net output #0: loss = 0.0615698 (* 1 = 0.0615698 loss)
I0706 16:00:03.437829  1643 solver.cpp:590] Iteration 31460, lr = 4.01704e-05
I0706 16:00:14.599488  1643 solver.cpp:243] Iteration 31515, loss = 0.00271265
I0706 16:00:14.599793  1643 solver.cpp:259]     Train net output #0: loss = 0.0027123 (* 1 = 0.0027123 loss)
I0706 16:00:14.599802  1643 solver.cpp:590] Iteration 31515, lr = 3.97848e-05
I0706 16:00:16.373133  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:00:28.166968  1643 solver.cpp:243] Iteration 31570, loss = 0.0301009
I0706 16:00:28.167001  1643 solver.cpp:259]     Train net output #0: loss = 0.0301006 (* 1 = 0.0301006 loss)
I0706 16:00:28.167009  1643 solver.cpp:590] Iteration 31570, lr = 3.94029e-05
I0706 16:00:39.809056  1643 solver.cpp:243] Iteration 31625, loss = 0.0265602
I0706 16:00:39.809105  1643 solver.cpp:259]     Train net output #0: loss = 0.0265599 (* 1 = 0.0265599 loss)
I0706 16:00:39.809115  1643 solver.cpp:590] Iteration 31625, lr = 3.90246e-05
I0706 16:00:44.169016  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:00:50.907757  1643 solver.cpp:243] Iteration 31680, loss = 0.0323232
I0706 16:00:50.908136  1643 solver.cpp:259]     Train net output #0: loss = 0.0323228 (* 1 = 0.0323228 loss)
I0706 16:00:50.908146  1643 solver.cpp:590] Iteration 31680, lr = 3.865e-05
I0706 16:01:03.084738  1643 solver.cpp:243] Iteration 31735, loss = 0.0272326
I0706 16:01:03.084764  1643 solver.cpp:259]     Train net output #0: loss = 0.0272322 (* 1 = 0.0272322 loss)
I0706 16:01:03.084770  1643 solver.cpp:590] Iteration 31735, lr = 3.8279e-05
I0706 16:01:03.501255  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:01:06.992451  1643 solver.cpp:347] Iteration 31752, Testing net (#0)
I0706 16:01:31.519587  1660 blocking_queue.cpp:50] Waiting for data
I0706 16:01:34.564064  1643 solver.cpp:415]     Test net output #0: accuracy = 0.138221
I0706 16:01:34.564091  1643 solver.cpp:415]     Test net output #1: loss = 6.50711 (* 1 = 6.50711 loss)
I0706 16:01:40.851752  1643 solver.cpp:243] Iteration 31790, loss = 0.000954103
I0706 16:01:40.851800  1643 solver.cpp:259]     Train net output #0: loss = 0.000953741 (* 1 = 0.000953741 loss)
I0706 16:01:40.851811  1643 solver.cpp:590] Iteration 31790, lr = 3.79116e-05
I0706 16:01:54.729823  1643 solver.cpp:243] Iteration 31845, loss = 0.0122082
I0706 16:01:54.729853  1643 solver.cpp:259]     Train net output #0: loss = 0.0122079 (* 1 = 0.0122079 loss)
I0706 16:01:54.729861  1643 solver.cpp:590] Iteration 31845, lr = 3.75477e-05
I0706 16:02:06.700791  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:02:07.059481  1643 solver.cpp:243] Iteration 31900, loss = 0.00167619
I0706 16:02:07.059540  1643 solver.cpp:259]     Train net output #0: loss = 0.00167581 (* 1 = 0.00167581 loss)
I0706 16:02:07.059556  1643 solver.cpp:590] Iteration 31900, lr = 3.71872e-05
I0706 16:02:19.445734  1643 solver.cpp:243] Iteration 31955, loss = 0.00611251
I0706 16:02:19.445762  1643 solver.cpp:259]     Train net output #0: loss = 0.00611212 (* 1 = 0.00611212 loss)
I0706 16:02:19.445770  1643 solver.cpp:590] Iteration 31955, lr = 3.68303e-05
I0706 16:02:30.640210  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:02:31.454679  1643 solver.cpp:243] Iteration 32010, loss = 0.0106012
I0706 16:02:31.454707  1643 solver.cpp:259]     Train net output #0: loss = 0.0106008 (* 1 = 0.0106008 loss)
I0706 16:02:31.454715  1643 solver.cpp:590] Iteration 32010, lr = 3.64767e-05
I0706 16:02:32.267809  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 16:02:43.228621  1643 solver.cpp:243] Iteration 32065, loss = 0.0463664
I0706 16:02:43.229110  1643 solver.cpp:259]     Train net output #0: loss = 0.046366 (* 1 = 0.046366 loss)
I0706 16:02:43.229125  1643 solver.cpp:590] Iteration 32065, lr = 3.61266e-05
I0706 16:02:54.550806  1643 solver.cpp:243] Iteration 32120, loss = 0.0603125
I0706 16:02:54.550835  1643 solver.cpp:259]     Train net output #0: loss = 0.0603121 (* 1 = 0.0603121 loss)
I0706 16:02:54.550843  1643 solver.cpp:590] Iteration 32120, lr = 3.57798e-05
I0706 16:02:57.844774  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:03:07.627048  1643 solver.cpp:243] Iteration 32175, loss = 0.0305966
I0706 16:03:07.627076  1643 solver.cpp:259]     Train net output #0: loss = 0.0305962 (* 1 = 0.0305962 loss)
I0706 16:03:07.627084  1643 solver.cpp:590] Iteration 32175, lr = 3.54364e-05
I0706 16:03:10.576108  1643 solver.cpp:347] Iteration 32193, Testing net (#0)
I0706 16:03:24.165966  1660 blocking_queue.cpp:50] Waiting for data
I0706 16:03:37.198985  1643 solver.cpp:415]     Test net output #0: accuracy = 0.139303
I0706 16:03:37.199012  1643 solver.cpp:415]     Test net output #1: loss = 6.50701 (* 1 = 6.50701 loss)
I0706 16:03:43.595145  1643 solver.cpp:243] Iteration 32230, loss = 0.00228988
I0706 16:03:43.595171  1643 solver.cpp:259]     Train net output #0: loss = 0.00228948 (* 1 = 0.00228948 loss)
I0706 16:03:43.595178  1643 solver.cpp:590] Iteration 32230, lr = 3.50962e-05
I0706 16:03:56.248827  1643 solver.cpp:243] Iteration 32285, loss = 0.00780036
I0706 16:03:56.248965  1643 solver.cpp:259]     Train net output #0: loss = 0.00779998 (* 1 = 0.00779998 loss)
I0706 16:03:56.248976  1643 solver.cpp:590] Iteration 32285, lr = 3.47593e-05
I0706 16:04:07.017874  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:04:07.137856  1643 solver.cpp:243] Iteration 32340, loss = 0.0204846
I0706 16:04:07.137881  1643 solver.cpp:259]     Train net output #0: loss = 0.0204842 (* 1 = 0.0204842 loss)
I0706 16:04:07.137888  1643 solver.cpp:590] Iteration 32340, lr = 3.44257e-05
I0706 16:04:18.368140  1643 solver.cpp:243] Iteration 32395, loss = 0.00369108
I0706 16:04:18.368167  1643 solver.cpp:259]     Train net output #0: loss = 0.0036907 (* 1 = 0.0036907 loss)
I0706 16:04:18.368175  1643 solver.cpp:590] Iteration 32395, lr = 3.40952e-05
I0706 16:04:29.930886  1643 solver.cpp:243] Iteration 32450, loss = 0.00451866
I0706 16:04:29.931021  1643 solver.cpp:259]     Train net output #0: loss = 0.0045183 (* 1 = 0.0045183 loss)
I0706 16:04:29.931028  1643 solver.cpp:590] Iteration 32450, lr = 3.37679e-05
I0706 16:04:40.280376  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:04:41.550043  1643 solver.cpp:243] Iteration 32505, loss = 0.0276563
I0706 16:04:41.550071  1643 solver.cpp:259]     Train net output #0: loss = 0.027656 (* 1 = 0.027656 loss)
I0706 16:04:41.550078  1643 solver.cpp:590] Iteration 32505, lr = 3.34438e-05
I0706 16:04:54.175671  1643 solver.cpp:243] Iteration 32560, loss = 0.00386851
I0706 16:04:54.175699  1643 solver.cpp:259]     Train net output #0: loss = 0.00386815 (* 1 = 0.00386815 loss)
I0706 16:04:54.175707  1643 solver.cpp:590] Iteration 32560, lr = 3.31227e-05
I0706 16:05:03.927544  1643 solver.cpp:243] Iteration 32615, loss = 0.0105754
I0706 16:05:03.928050  1643 solver.cpp:259]     Train net output #0: loss = 0.010575 (* 1 = 0.010575 loss)
I0706 16:05:03.928061  1643 solver.cpp:590] Iteration 32615, lr = 3.28048e-05
I0706 16:05:07.376601  1643 solver.cpp:347] Iteration 32634, Testing net (#0)
I0706 16:05:09.337800  1660 blocking_queue.cpp:50] Waiting for data
I0706 16:05:31.248456  1643 solver.cpp:415]     Test net output #0: accuracy = 0.138822
I0706 16:05:31.248483  1643 solver.cpp:415]     Test net output #1: loss = 6.5135 (* 1 = 6.5135 loss)
I0706 16:05:38.772240  1643 solver.cpp:243] Iteration 32670, loss = 0.0628614
I0706 16:05:38.772651  1643 solver.cpp:259]     Train net output #0: loss = 0.0628611 (* 1 = 0.0628611 loss)
I0706 16:05:38.772661  1643 solver.cpp:590] Iteration 32670, lr = 3.24899e-05
I0706 16:05:50.683650  1643 solver.cpp:243] Iteration 32725, loss = 0.0199693
I0706 16:05:50.683696  1643 solver.cpp:259]     Train net output #0: loss = 0.0199689 (* 1 = 0.0199689 loss)
I0706 16:05:50.683709  1643 solver.cpp:590] Iteration 32725, lr = 3.2178e-05
I0706 16:05:59.203533  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:06:00.007953  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 16:06:02.858700  1643 solver.cpp:243] Iteration 32780, loss = 0.0191275
I0706 16:06:02.858737  1643 solver.cpp:259]     Train net output #0: loss = 0.0191272 (* 1 = 0.0191272 loss)
I0706 16:06:02.858748  1643 solver.cpp:590] Iteration 32780, lr = 3.18691e-05
I0706 16:06:14.914839  1643 solver.cpp:243] Iteration 32835, loss = 0.00656021
I0706 16:06:14.914904  1643 solver.cpp:259]     Train net output #0: loss = 0.00655988 (* 1 = 0.00655988 loss)
I0706 16:06:14.914913  1643 solver.cpp:590] Iteration 32835, lr = 3.15632e-05
I0706 16:06:24.992466  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:06:27.571303  1643 solver.cpp:243] Iteration 32890, loss = 0.00293667
I0706 16:06:27.571331  1643 solver.cpp:259]     Train net output #0: loss = 0.00293634 (* 1 = 0.00293634 loss)
I0706 16:06:27.571338  1643 solver.cpp:590] Iteration 32890, lr = 3.12602e-05
I0706 16:06:39.749419  1643 solver.cpp:243] Iteration 32945, loss = 0.00417829
I0706 16:06:39.749464  1643 solver.cpp:259]     Train net output #0: loss = 0.00417795 (* 1 = 0.00417795 loss)
I0706 16:06:39.749474  1643 solver.cpp:590] Iteration 32945, lr = 3.09602e-05
I0706 16:06:50.713246  1643 solver.cpp:243] Iteration 33000, loss = 0.0159335
I0706 16:06:50.713357  1643 solver.cpp:259]     Train net output #0: loss = 0.0159331 (* 1 = 0.0159331 loss)
I0706 16:06:50.713366  1643 solver.cpp:590] Iteration 33000, lr = 3.0663e-05
I0706 16:06:53.786861  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:07:05.171120  1643 solver.cpp:243] Iteration 33055, loss = 0.0388348
I0706 16:07:05.171150  1643 solver.cpp:259]     Train net output #0: loss = 0.0388344 (* 1 = 0.0388344 loss)
I0706 16:07:05.171159  1643 solver.cpp:590] Iteration 33055, lr = 3.03687e-05
I0706 16:07:08.442883  1643 solver.cpp:347] Iteration 33075, Testing net (#0)
I0706 16:07:09.385468  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:07:36.334448  1643 solver.cpp:415]     Test net output #0: accuracy = 0.139423
I0706 16:07:36.423553  1643 solver.cpp:415]     Test net output #1: loss = 6.51232 (* 1 = 6.51232 loss)
I0706 16:07:43.092885  1643 solver.cpp:243] Iteration 33110, loss = 0.0167724
I0706 16:07:43.092942  1643 solver.cpp:259]     Train net output #0: loss = 0.016772 (* 1 = 0.016772 loss)
I0706 16:07:43.092958  1643 solver.cpp:590] Iteration 33110, lr = 3.00771e-05
I0706 16:07:47.202682  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:07:55.059190  1643 solver.cpp:243] Iteration 33165, loss = 0.00119425
I0706 16:07:55.059217  1643 solver.cpp:259]     Train net output #0: loss = 0.00119395 (* 1 = 0.00119395 loss)
I0706 16:07:55.059226  1643 solver.cpp:590] Iteration 33165, lr = 2.97884e-05
I0706 16:08:07.667132  1643 solver.cpp:243] Iteration 33220, loss = 0.00438895
I0706 16:08:07.667219  1643 solver.cpp:259]     Train net output #0: loss = 0.00438865 (* 1 = 0.00438865 loss)
I0706 16:08:07.667232  1643 solver.cpp:590] Iteration 33220, lr = 2.95025e-05
I0706 16:08:20.282608  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:08:21.482419  1643 solver.cpp:243] Iteration 33275, loss = 0.00918314
I0706 16:08:21.482458  1643 solver.cpp:259]     Train net output #0: loss = 0.00918284 (* 1 = 0.00918284 loss)
I0706 16:08:21.482466  1643 solver.cpp:590] Iteration 33275, lr = 2.92193e-05
I0706 16:08:32.516683  1643 solver.cpp:243] Iteration 33330, loss = 0.0162766
I0706 16:08:32.516712  1643 solver.cpp:259]     Train net output #0: loss = 0.0162763 (* 1 = 0.0162763 loss)
I0706 16:08:32.516721  1643 solver.cpp:590] Iteration 33330, lr = 2.89388e-05
I0706 16:08:39.008348  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:08:43.998847  1643 solver.cpp:243] Iteration 33385, loss = 0.0792629
I0706 16:08:43.998875  1643 solver.cpp:259]     Train net output #0: loss = 0.0792626 (* 1 = 0.0792626 loss)
I0706 16:08:43.998883  1643 solver.cpp:590] Iteration 33385, lr = 2.8661e-05
I0706 16:08:55.967144  1643 solver.cpp:243] Iteration 33440, loss = 0.064155
I0706 16:08:55.967186  1643 solver.cpp:259]     Train net output #0: loss = 0.0641547 (* 1 = 0.0641547 loss)
I0706 16:08:55.967200  1643 solver.cpp:590] Iteration 33440, lr = 2.83859e-05
I0706 16:09:00.335510  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:09:07.984395  1643 solver.cpp:243] Iteration 33495, loss = 0.00719851
I0706 16:09:07.984423  1643 solver.cpp:259]     Train net output #0: loss = 0.0071982 (* 1 = 0.0071982 loss)
I0706 16:09:07.984431  1643 solver.cpp:590] Iteration 33495, lr = 2.81134e-05
I0706 16:09:11.757052  1643 solver.cpp:347] Iteration 33516, Testing net (#0)
I0706 16:09:13.367215  1660 blocking_queue.cpp:50] Waiting for data
I0706 16:09:37.446483  1643 solver.cpp:415]     Test net output #0: accuracy = 0.139062
I0706 16:09:37.446511  1643 solver.cpp:415]     Test net output #1: loss = 6.51363 (* 1 = 6.51363 loss)
I0706 16:09:38.305377  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 16:09:44.249495  1643 solver.cpp:243] Iteration 33550, loss = 0.00743151
I0706 16:09:44.249644  1643 solver.cpp:259]     Train net output #0: loss = 0.00743119 (* 1 = 0.00743119 loss)
I0706 16:09:44.249660  1643 solver.cpp:590] Iteration 33550, lr = 2.78436e-05
I0706 16:09:51.422708  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:09:55.946436  1643 solver.cpp:243] Iteration 33605, loss = 0.00232556
I0706 16:09:55.946465  1643 solver.cpp:259]     Train net output #0: loss = 0.00232526 (* 1 = 0.00232526 loss)
I0706 16:09:55.946472  1643 solver.cpp:590] Iteration 33605, lr = 2.75763e-05
I0706 16:10:08.123795  1643 solver.cpp:243] Iteration 33660, loss = 0.015923
I0706 16:10:08.123822  1643 solver.cpp:259]     Train net output #0: loss = 0.0159227 (* 1 = 0.0159227 loss)
I0706 16:10:08.123829  1643 solver.cpp:590] Iteration 33660, lr = 2.73116e-05
I0706 16:10:18.599622  1643 solver.cpp:243] Iteration 33715, loss = 0.0036555
I0706 16:10:18.599725  1643 solver.cpp:259]     Train net output #0: loss = 0.00365521 (* 1 = 0.00365521 loss)
I0706 16:10:18.599735  1643 solver.cpp:590] Iteration 33715, lr = 2.70494e-05
I0706 16:10:28.267638  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:10:30.722990  1643 solver.cpp:243] Iteration 33770, loss = 0.0249388
I0706 16:10:30.723018  1643 solver.cpp:259]     Train net output #0: loss = 0.0249385 (* 1 = 0.0249385 loss)
I0706 16:10:30.723026  1643 solver.cpp:590] Iteration 33770, lr = 2.67898e-05
I0706 16:10:41.413972  1643 solver.cpp:243] Iteration 33825, loss = 0.0735682
I0706 16:10:41.414016  1643 solver.cpp:259]     Train net output #0: loss = 0.0735679 (* 1 = 0.0735679 loss)
I0706 16:10:41.414027  1643 solver.cpp:590] Iteration 33825, lr = 2.65326e-05
I0706 16:10:53.682212  1643 solver.cpp:243] Iteration 33880, loss = 0.172701
I0706 16:10:53.682826  1643 solver.cpp:259]     Train net output #0: loss = 0.172701 (* 1 = 0.172701 loss)
I0706 16:10:53.682835  1643 solver.cpp:590] Iteration 33880, lr = 2.62779e-05
I0706 16:11:02.092731  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:11:05.487037  1643 solver.cpp:243] Iteration 33935, loss = 0.00554827
I0706 16:11:05.487082  1643 solver.cpp:259]     Train net output #0: loss = 0.00554799 (* 1 = 0.00554799 loss)
I0706 16:11:05.487095  1643 solver.cpp:590] Iteration 33935, lr = 2.60257e-05
I0706 16:11:09.425876  1643 solver.cpp:347] Iteration 33957, Testing net (#0)
I0706 16:11:32.117527  1660 blocking_queue.cpp:50] Waiting for data
I0706 16:11:36.250249  1643 solver.cpp:415]     Test net output #0: accuracy = 0.139663
I0706 16:11:36.250277  1643 solver.cpp:415]     Test net output #1: loss = 6.51289 (* 1 = 6.51289 loss)
I0706 16:11:41.984906  1643 solver.cpp:243] Iteration 33990, loss = 0.0317326
I0706 16:11:41.984935  1643 solver.cpp:259]     Train net output #0: loss = 0.0317324 (* 1 = 0.0317324 loss)
I0706 16:11:41.984942  1643 solver.cpp:590] Iteration 33990, lr = 2.57758e-05
I0706 16:11:53.960813  1643 solver.cpp:243] Iteration 34045, loss = 0.00453915
I0706 16:11:53.960841  1643 solver.cpp:259]     Train net output #0: loss = 0.00453885 (* 1 = 0.00453885 loss)
I0706 16:11:53.960850  1643 solver.cpp:590] Iteration 34045, lr = 2.55284e-05
I0706 16:12:04.575245  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:12:06.158738  1643 solver.cpp:243] Iteration 34100, loss = 0.00206655
I0706 16:12:06.158792  1643 solver.cpp:259]     Train net output #0: loss = 0.00206625 (* 1 = 0.00206625 loss)
I0706 16:12:06.158813  1643 solver.cpp:590] Iteration 34100, lr = 2.52834e-05
I0706 16:12:16.973956  1643 solver.cpp:243] Iteration 34155, loss = 0.0649377
I0706 16:12:16.973984  1643 solver.cpp:259]     Train net output #0: loss = 0.0649374 (* 1 = 0.0649374 loss)
I0706 16:12:16.973991  1643 solver.cpp:590] Iteration 34155, lr = 2.50407e-05
I0706 16:12:28.699291  1643 solver.cpp:243] Iteration 34210, loss = 0.0318487
I0706 16:12:28.699319  1643 solver.cpp:259]     Train net output #0: loss = 0.0318484 (* 1 = 0.0318484 loss)
I0706 16:12:28.699327  1643 solver.cpp:590] Iteration 34210, lr = 2.48003e-05
I0706 16:12:39.379225  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:12:39.625388  1643 solver.cpp:243] Iteration 34265, loss = 0.00363951
I0706 16:12:39.625422  1643 solver.cpp:259]     Train net output #0: loss = 0.00363924 (* 1 = 0.00363924 loss)
I0706 16:12:39.625430  1643 solver.cpp:590] Iteration 34265, lr = 2.45622e-05
I0706 16:12:50.932746  1643 solver.cpp:243] Iteration 34320, loss = 0.0122007
I0706 16:12:50.932775  1643 solver.cpp:259]     Train net output #0: loss = 0.0122005 (* 1 = 0.0122005 loss)
I0706 16:12:50.932782  1643 solver.cpp:590] Iteration 34320, lr = 2.43265e-05
I0706 16:12:58.368530  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:13:03.180718  1643 solver.cpp:243] Iteration 34375, loss = 0.0089697
I0706 16:13:03.180744  1643 solver.cpp:259]     Train net output #0: loss = 0.00896941 (* 1 = 0.00896941 loss)
I0706 16:13:03.180752  1643 solver.cpp:590] Iteration 34375, lr = 2.4093e-05
I0706 16:13:09.965773  1643 solver.cpp:347] Iteration 34398, Testing net (#0)
I0706 16:13:10.514334  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 16:13:13.901644  1660 blocking_queue.cpp:50] Waiting for data
I0706 16:13:37.336869  1643 solver.cpp:415]     Test net output #0: accuracy = 0.138822
I0706 16:13:37.336895  1643 solver.cpp:415]     Test net output #1: loss = 6.51811 (* 1 = 6.51811 loss)
I0706 16:13:42.901300  1643 solver.cpp:243] Iteration 34430, loss = 0.0165413
I0706 16:13:42.901928  1643 solver.cpp:259]     Train net output #0: loss = 0.016541 (* 1 = 0.016541 loss)
I0706 16:13:42.901945  1643 solver.cpp:590] Iteration 34430, lr = 2.38617e-05
I0706 16:13:54.817445  1643 solver.cpp:243] Iteration 34485, loss = 0.00755985
I0706 16:13:54.817472  1643 solver.cpp:259]     Train net output #0: loss = 0.00755956 (* 1 = 0.00755956 loss)
I0706 16:13:54.817481  1643 solver.cpp:590] Iteration 34485, lr = 2.36326e-05
I0706 16:13:58.234624  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:14:05.374264  1643 solver.cpp:243] Iteration 34540, loss = 0.0244312
I0706 16:14:05.374307  1643 solver.cpp:259]     Train net output #0: loss = 0.0244309 (* 1 = 0.0244309 loss)
I0706 16:14:05.374320  1643 solver.cpp:590] Iteration 34540, lr = 2.34058e-05
I0706 16:14:16.583755  1643 solver.cpp:243] Iteration 34595, loss = 0.00161002
I0706 16:14:16.584278  1643 solver.cpp:259]     Train net output #0: loss = 0.00160975 (* 1 = 0.00160975 loss)
I0706 16:14:16.584290  1643 solver.cpp:590] Iteration 34595, lr = 2.31811e-05
I0706 16:14:25.276731  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:14:28.786453  1643 solver.cpp:243] Iteration 34650, loss = 0.00365495
I0706 16:14:28.786481  1643 solver.cpp:259]     Train net output #0: loss = 0.00365469 (* 1 = 0.00365469 loss)
I0706 16:14:28.786489  1643 solver.cpp:590] Iteration 34650, lr = 2.29586e-05
I0706 16:14:39.653285  1643 solver.cpp:243] Iteration 34705, loss = 0.025271
I0706 16:14:39.653311  1643 solver.cpp:259]     Train net output #0: loss = 0.0252708 (* 1 = 0.0252708 loss)
I0706 16:14:39.653319  1643 solver.cpp:590] Iteration 34705, lr = 2.27382e-05
I0706 16:14:50.531863  1643 solver.cpp:243] Iteration 34760, loss = 0.00480059
I0706 16:14:50.531966  1643 solver.cpp:259]     Train net output #0: loss = 0.00480033 (* 1 = 0.00480033 loss)
I0706 16:14:50.531978  1643 solver.cpp:590] Iteration 34760, lr = 2.25199e-05
I0706 16:15:00.678728  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:15:02.460064  1643 solver.cpp:243] Iteration 34815, loss = 0.00747721
I0706 16:15:02.460106  1643 solver.cpp:259]     Train net output #0: loss = 0.00747695 (* 1 = 0.00747695 loss)
I0706 16:15:02.460129  1643 solver.cpp:590] Iteration 34815, lr = 2.23038e-05
I0706 16:15:08.969157  1643 solver.cpp:347] Iteration 34839, Testing net (#0)
I0706 16:15:31.546730  1660 blocking_queue.cpp:50] Waiting for data
I0706 16:15:33.681902  1643 solver.cpp:415]     Test net output #0: accuracy = 0.139062
I0706 16:15:33.681931  1643 solver.cpp:415]     Test net output #1: loss = 6.51363 (* 1 = 6.51363 loss)
I0706 16:15:39.603246  1643 solver.cpp:243] Iteration 34870, loss = 0.0922081
I0706 16:15:39.603276  1643 solver.cpp:259]     Train net output #0: loss = 0.0922078 (* 1 = 0.0922078 loss)
I0706 16:15:39.603292  1643 solver.cpp:590] Iteration 34870, lr = 2.20897e-05
I0706 16:15:52.029240  1643 solver.cpp:243] Iteration 34925, loss = 0.135862
I0706 16:15:52.029268  1643 solver.cpp:259]     Train net output #0: loss = 0.135862 (* 1 = 0.135862 loss)
I0706 16:15:52.029275  1643 solver.cpp:590] Iteration 34925, lr = 2.18776e-05
I0706 16:16:04.469401  1643 solver.cpp:243] Iteration 34980, loss = 0.00132208
I0706 16:16:04.469488  1643 solver.cpp:259]     Train net output #0: loss = 0.00132182 (* 1 = 0.00132182 loss)
I0706 16:16:04.469498  1643 solver.cpp:590] Iteration 34980, lr = 2.16676e-05
I0706 16:16:04.636029  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:16:15.855484  1643 solver.cpp:243] Iteration 35035, loss = 0.00238902
I0706 16:16:15.855538  1643 solver.cpp:259]     Train net output #0: loss = 0.00238876 (* 1 = 0.00238876 loss)
I0706 16:16:15.855556  1643 solver.cpp:590] Iteration 35035, lr = 2.14596e-05
I0706 16:16:27.119004  1643 solver.cpp:243] Iteration 35090, loss = 0.00236403
I0706 16:16:27.119030  1643 solver.cpp:259]     Train net output #0: loss = 0.00236377 (* 1 = 0.00236377 loss)
I0706 16:16:27.119038  1643 solver.cpp:590] Iteration 35090, lr = 2.12536e-05
I0706 16:16:37.932821  1643 solver.cpp:243] Iteration 35145, loss = 0.0121258
I0706 16:16:37.933274  1643 solver.cpp:259]     Train net output #0: loss = 0.0121255 (* 1 = 0.0121255 loss)
I0706 16:16:37.933284  1643 solver.cpp:590] Iteration 35145, lr = 2.10496e-05
I0706 16:16:40.127344  1643 blocking_queue.cpp:50] Data layer prefetch queue empty
I0706 16:16:44.780055  1656 blocking_queue.cpp:50] Waiting for data
I0706 16:16:49.923077  1643 solver.cpp:243] Iteration 35200, loss = 0.0141761
I0706 16:16:49.923126  1643 solver.cpp:259]     Train net output #0: loss = 0.0141758 (* 1 = 0.0141758 loss)
I0706 16:16:49.923135  1643 solver.cpp:590] Iteration 35200, lr = 2.08476e-05
I0706 16:17:01.999189  1643 solver.cpp:243] Iteration 35255, loss = 0.0979418
I0706 16:17:01.999231  1643 solver.cpp:259]     Train net output #0: loss = 0.0979416 (* 1 = 0.0979416 loss)
I0706 16:17:01.999239  1643 solver.cpp:590] Iteration 35255, lr = 2.06475e-05
I0706 16:17:07.050437  1643 solver.cpp:468] Snapshotting to binary proto file snapshot_iter_35280.caffemodel
I0706 16:17:16.476672  1643 solver.cpp:753] Snapshotting solver state to binary proto file snapshot_iter_35280.solverstate
I0706 16:17:17.323222  1643 solver.cpp:347] Iteration 35280, Testing net (#0)
I0706 16:17:31.259683  1660 blocking_queue.cpp:50] Waiting for data
I0706 16:17:42.258741  1643 solver.cpp:415]     Test net output #0: accuracy = 0.139784
I0706 16:17:42.258769  1643 solver.cpp:415]     Test net output #1: loss = 6.5157 (* 1 = 6.5157 loss)
I0706 16:17:42.258772  1643 solver.cpp:332] Optimization Done.
I0706 16:17:42.258774  1643 caffe.cpp:223] Optimization Done.
